(() => {
  var __create = Object.create;
  var __defProp = Object.defineProperty;
  var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
  var __getOwnPropNames = Object.getOwnPropertyNames;
  var __getOwnPropSymbols = Object.getOwnPropertySymbols;
  var __getProtoOf = Object.getPrototypeOf;
  var __hasOwnProp = Object.prototype.hasOwnProperty;
  var __propIsEnum = Object.prototype.propertyIsEnumerable;
  var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
  var __spreadValues = (a, b) => {
    for (var prop in b || (b = {}))
      if (__hasOwnProp.call(b, prop))
        __defNormalProp(a, prop, b[prop]);
    if (__getOwnPropSymbols)
      for (var prop of __getOwnPropSymbols(b)) {
        if (__propIsEnum.call(b, prop))
          __defNormalProp(a, prop, b[prop]);
      }
    return a;
  };
  var __esm = (fn, res) => function __init() {
    return fn && (res = (0, fn[__getOwnPropNames(fn)[0]])(fn = 0)), res;
  };
  var __commonJS = (cb, mod3) => function __require() {
    return mod3 || (0, cb[__getOwnPropNames(cb)[0]])((mod3 = { exports: {} }).exports, mod3), mod3.exports;
  };
  var __export = (target, all3) => {
    for (var name in all3)
      __defProp(target, name, { get: all3[name], enumerable: true });
  };
  var __copyProps = (to, from, except, desc) => {
    if (from && typeof from === "object" || typeof from === "function") {
      for (let key of __getOwnPropNames(from))
        if (!__hasOwnProp.call(to, key) && key !== except)
          __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
    }
    return to;
  };
  var __toESM = (mod3, isNodeMode, target) => (target = mod3 != null ? __create(__getProtoOf(mod3)) : {}, __copyProps(
    // If the importer is in node compatibility mode or this is not an ESM
    // file that has been converted to a CommonJS file using a Babel-
    // compatible transform (i.e. "__esModule" has not been set), then set
    // "default" to the CommonJS "module.exports" for node compatibility.
    isNodeMode || !mod3 || !mod3.__esModule ? __defProp(target, "default", { value: mod3, enumerable: true }) : target,
    mod3
  ));
  var __publicField = (obj, key, value) => {
    __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
    return value;
  };
  var __async = (__this, __arguments, generator) => {
    return new Promise((resolve, reject) => {
      var fulfilled = (value) => {
        try {
          step3(generator.next(value));
        } catch (e) {
          reject(e);
        }
      };
      var rejected = (value) => {
        try {
          step3(generator.throw(value));
        } catch (e) {
          reject(e);
        }
      };
      var step3 = (x) => x.done ? resolve(x.value) : Promise.resolve(x.value).then(fulfilled, rejected);
      step3((generator = generator.apply(__this, __arguments)).next());
    });
  };

  // node_modules/@tensorflow/tfjs-core/dist/backends/backend.js
  function notYetImplemented(kernelName) {
    throw new Error(`'${kernelName}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`);
  }
  var EPSILON_FLOAT32, EPSILON_FLOAT16, DataStorage, KernelBackend;
  var init_backend = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/backends/backend.js"() {
      EPSILON_FLOAT32 = 1e-7;
      EPSILON_FLOAT16 = 1e-4;
      DataStorage = class {
        constructor(backend, dataMover) {
          this.backend = backend;
          this.dataMover = dataMover;
          this.data = /* @__PURE__ */ new WeakMap();
          this.dataIdsCount = 0;
        }
        get(dataId) {
          if (!this.data.has(dataId)) {
            this.dataMover.moveData(this.backend, dataId);
          }
          return this.data.get(dataId);
        }
        set(dataId, value) {
          this.dataIdsCount++;
          this.data.set(dataId, value);
        }
        has(dataId) {
          return this.data.has(dataId);
        }
        delete(dataId) {
          this.dataIdsCount--;
          return this.data.delete(dataId);
        }
        numDataIds() {
          return this.dataIdsCount;
        }
      };
      KernelBackend = class {
        refCount(dataId) {
          return notYetImplemented("refCount");
        }
        incRef(dataId) {
          return notYetImplemented("incRef");
        }
        timerAvailable() {
          return true;
        }
        time(f) {
          return notYetImplemented("time");
        }
        read(dataId) {
          return notYetImplemented("read");
        }
        readSync(dataId) {
          return notYetImplemented("readSync");
        }
        readToGPU(dataId, options) {
          return notYetImplemented("readToGPU");
        }
        numDataIds() {
          return notYetImplemented("numDataIds");
        }
        disposeData(dataId, force) {
          return notYetImplemented("disposeData");
        }
        write(values, shape, dtype) {
          return notYetImplemented("write");
        }
        move(dataId, values, shape, dtype, refCount) {
          return notYetImplemented("move");
        }
        createTensorFromGPUData(values, shape, dtype) {
          return notYetImplemented("createTensorFromGPUData");
        }
        memory() {
          return notYetImplemented("memory");
        }
        /** Returns the highest precision for floats in bits (e.g. 16 or 32) */
        floatPrecision() {
          return notYetImplemented("floatPrecision");
        }
        /** Returns the smallest representable number.  */
        epsilon() {
          return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;
        }
        dispose() {
          return notYetImplemented("dispose");
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/util_base.js
  function shuffle(array) {
    let counter = array.length;
    let index = 0;
    while (counter > 0) {
      index = Math.random() * counter | 0;
      counter--;
      swap(array, counter, index);
    }
  }
  function shuffleCombo(array, array2) {
    if (array.length !== array2.length) {
      throw new Error(`Array sizes must match to be shuffled together First array length was ${array.length}Second array length was ${array2.length}`);
    }
    let counter = array.length;
    let index = 0;
    while (counter > 0) {
      index = Math.random() * counter | 0;
      counter--;
      swap(array, counter, index);
      swap(array2, counter, index);
    }
  }
  function clamp(min3, x, max3) {
    return Math.max(min3, Math.min(x, max3));
  }
  function nearestLargerEven(val) {
    return val % 2 === 0 ? val : val + 1;
  }
  function swap(object, left, right) {
    const temp = object[left];
    object[left] = object[right];
    object[right] = temp;
  }
  function sum(arr) {
    let sum4 = 0;
    for (let i = 0; i < arr.length; i++) {
      sum4 += arr[i];
    }
    return sum4;
  }
  function randUniform(a, b) {
    const r = Math.random();
    return b * r + (1 - r) * a;
  }
  function distSquared(a, b) {
    let result = 0;
    for (let i = 0; i < a.length; i++) {
      const diff = Number(a[i]) - Number(b[i]);
      result += diff * diff;
    }
    return result;
  }
  function assert(expr, msg) {
    if (!expr) {
      throw new Error(typeof msg === "string" ? msg : msg());
    }
  }
  function assertShapesMatch(shapeA, shapeB, errorMessagePrefix = "") {
    assert(arraysEqual(shapeA, shapeB), () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);
  }
  function assertNonNull(a) {
    assert(a != null, () => `The input to the tensor constructor must be a non-null value.`);
  }
  function sizeFromShape(shape) {
    if (shape.length === 0) {
      return 1;
    }
    let size = shape[0];
    for (let i = 1; i < shape.length; i++) {
      size *= shape[i];
    }
    return size;
  }
  function isScalarShape(shape) {
    return shape.length === 0;
  }
  function arraysEqual(n1, n2) {
    if (n1 === n2) {
      return true;
    }
    if (n1 == null || n2 == null) {
      return false;
    }
    if (n1.length !== n2.length) {
      return false;
    }
    for (let i = 0; i < n1.length; i++) {
      if (n1[i] !== n2[i]) {
        return false;
      }
    }
    return true;
  }
  function isInt(a) {
    return a % 1 === 0;
  }
  function tanh(x) {
    if (Math.tanh != null) {
      return Math.tanh(x);
    }
    if (x === Infinity) {
      return 1;
    } else if (x === -Infinity) {
      return -1;
    } else {
      const e2x = Math.exp(2 * x);
      return (e2x - 1) / (e2x + 1);
    }
  }
  function sizeToSquarishShape(size) {
    const width = Math.ceil(Math.sqrt(size));
    return [width, Math.ceil(size / width)];
  }
  function createShuffledIndices(n) {
    const shuffledIndices = new Uint32Array(n);
    for (let i = 0; i < n; ++i) {
      shuffledIndices[i] = i;
    }
    shuffle(shuffledIndices);
    return shuffledIndices;
  }
  function rightPad(a, size) {
    if (size <= a.length) {
      return a;
    }
    return a + " ".repeat(size - a.length);
  }
  function repeatedTry(checkFn, delayFn = (counter) => 0, maxCounter, scheduleFn) {
    return new Promise((resolve, reject) => {
      let tryCount = 0;
      const tryFn = () => {
        if (checkFn()) {
          resolve();
          return;
        }
        tryCount++;
        const nextBackoff = delayFn(tryCount);
        if (maxCounter != null && tryCount >= maxCounter) {
          reject();
          return;
        }
        if (scheduleFn != null) {
          scheduleFn(tryFn, nextBackoff);
        } else {
          setTimeout(tryFn, nextBackoff);
        }
      };
      tryFn();
    });
  }
  function inferFromImplicitShape(shape, size) {
    let shapeProd = 1;
    let implicitIdx = -1;
    for (let i = 0; i < shape.length; ++i) {
      if (shape[i] >= 0) {
        shapeProd *= shape[i];
      } else if (shape[i] === -1) {
        if (implicitIdx !== -1) {
          throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${implicitIdx} and dim ${i}`);
        }
        implicitIdx = i;
      } else if (shape[i] < 0) {
        throw Error(`Shapes can not be < 0. Found ${shape[i]} at dim ${i}`);
      }
    }
    if (implicitIdx === -1) {
      if (size > 0 && size !== shapeProd) {
        throw Error(`Size(${size}) must match the product of shape ${shape}`);
      }
      return shape;
    }
    if (shapeProd === 0) {
      throw Error(`Cannot infer the missing size in [${shape}] when there are 0 elements`);
    }
    if (size % shapeProd !== 0) {
      throw Error(`The implicit shape can't be a fractional number. Got ${size} / ${shapeProd}`);
    }
    const newShape = shape.slice();
    newShape[implicitIdx] = size / shapeProd;
    return newShape;
  }
  function parseAxisParam(axis, shape) {
    const rank = shape.length;
    axis = axis == null ? shape.map((s, i) => i) : [].concat(axis);
    assert(axis.every((ax) => ax >= -rank && ax < rank), () => `All values in axis param must be in range [-${rank}, ${rank}) but got axis ${axis}`);
    assert(axis.every((ax) => isInt(ax)), () => `All values in axis param must be integers but got axis ${axis}`);
    return axis.map((a) => a < 0 ? rank + a : a);
  }
  function squeezeShape(shape, axis) {
    const newShape = [];
    const keptDims = [];
    const isEmptyArray = axis != null && Array.isArray(axis) && axis.length === 0;
    const axes = axis == null || isEmptyArray ? null : parseAxisParam(axis, shape).sort();
    let j2 = 0;
    for (let i = 0; i < shape.length; ++i) {
      if (axes != null) {
        if (axes[j2] === i && shape[i] !== 1) {
          throw new Error(`Can't squeeze axis ${i} since its dim '${shape[i]}' is not 1`);
        }
        if ((axes[j2] == null || axes[j2] > i) && shape[i] === 1) {
          newShape.push(shape[i]);
          keptDims.push(i);
        }
        if (axes[j2] <= i) {
          j2++;
        }
      }
      if (shape[i] !== 1) {
        newShape.push(shape[i]);
        keptDims.push(i);
      }
    }
    return { newShape, keptDims };
  }
  function getTypedArrayFromDType(dtype, size) {
    let values = null;
    if (dtype == null || dtype === "float32") {
      values = new Float32Array(size);
    } else if (dtype === "int32") {
      values = new Int32Array(size);
    } else if (dtype === "bool") {
      values = new Uint8Array(size);
    } else {
      throw new Error(`Unknown data type ${dtype}`);
    }
    return values;
  }
  function getArrayFromDType(dtype, size) {
    let values = null;
    if (dtype == null || dtype === "float32") {
      values = new Float32Array(size);
    } else if (dtype === "int32") {
      values = new Int32Array(size);
    } else if (dtype === "bool") {
      values = new Uint8Array(size);
    } else if (dtype === "string") {
      values = new Array(size);
    } else {
      throw new Error(`Unknown data type ${dtype}`);
    }
    return values;
  }
  function checkConversionForErrors(vals, dtype) {
    for (let i = 0; i < vals.length; i++) {
      const num = vals[i];
      if (isNaN(num) || !isFinite(num)) {
        throw Error(`A tensor of type ${dtype} being uploaded contains ${num}.`);
      }
    }
  }
  function isValidDtype(dtype) {
    return dtype === "bool" || dtype === "complex64" || dtype === "float32" || dtype === "int32" || dtype === "string";
  }
  function hasEncodingLoss(oldType, newType) {
    if (newType === "complex64") {
      return false;
    }
    if (newType === "float32" && oldType !== "complex64") {
      return false;
    }
    if (newType === "int32" && oldType !== "float32" && oldType !== "complex64") {
      return false;
    }
    if (newType === "bool" && oldType === "bool") {
      return false;
    }
    return true;
  }
  function bytesPerElement(dtype) {
    if (dtype === "float32" || dtype === "int32") {
      return 4;
    } else if (dtype === "complex64") {
      return 8;
    } else if (dtype === "bool") {
      return 1;
    } else {
      throw new Error(`Unknown dtype ${dtype}`);
    }
  }
  function bytesFromStringArray(arr) {
    if (arr == null) {
      return 0;
    }
    let bytes = 0;
    arr.forEach((x) => bytes += x.length);
    return bytes;
  }
  function isString(value) {
    return typeof value === "string" || value instanceof String;
  }
  function isBoolean(value) {
    return typeof value === "boolean";
  }
  function isNumber(value) {
    return typeof value === "number";
  }
  function inferDtype(values) {
    if (Array.isArray(values)) {
      return inferDtype(values[0]);
    }
    if (values instanceof Float32Array) {
      return "float32";
    } else if (values instanceof Int32Array || values instanceof Uint8Array || values instanceof Uint8ClampedArray) {
      return "int32";
    } else if (isNumber(values)) {
      return "float32";
    } else if (isString(values)) {
      return "string";
    } else if (isBoolean(values)) {
      return "bool";
    }
    return "float32";
  }
  function isFunction(f) {
    return !!(f && f.constructor && f.call && f.apply);
  }
  function nearestDivisor(size, start) {
    for (let i = start; i < size; ++i) {
      if (size % i === 0) {
        return i;
      }
    }
    return size;
  }
  function computeStrides(shape) {
    const rank = shape.length;
    if (rank < 2) {
      return [];
    }
    const strides = new Array(rank - 1);
    strides[rank - 2] = shape[rank - 1];
    for (let i = rank - 3; i >= 0; --i) {
      strides[i] = strides[i + 1] * shape[i + 1];
    }
    return strides;
  }
  function createNestedArray(offset, shape, a, isComplex = false) {
    const ret = new Array();
    if (shape.length === 1) {
      const d = shape[0] * (isComplex ? 2 : 1);
      for (let i = 0; i < d; i++) {
        ret[i] = a[offset + i];
      }
    } else {
      const d = shape[0];
      const rest = shape.slice(1);
      const len = rest.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);
      for (let i = 0; i < d; i++) {
        ret[i] = createNestedArray(offset + i * len, rest, a, isComplex);
      }
    }
    return ret;
  }
  function toNestedArray(shape, a, isComplex = false) {
    if (shape.length === 0) {
      return a[0];
    }
    const size = shape.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);
    if (size === 0) {
      return [];
    }
    if (size !== a.length) {
      throw new Error(`[${shape}] does not match the input size ${a.length}${isComplex ? " for a complex tensor" : ""}.`);
    }
    return createNestedArray(0, shape, a, isComplex);
  }
  function convertBackendValuesAndArrayBuffer(data, dtype) {
    if (Array.isArray(data)) {
      return data;
    }
    if (dtype === "float32") {
      return data instanceof Float32Array ? data : new Float32Array(data);
    } else if (dtype === "int32") {
      return data instanceof Int32Array ? data : new Int32Array(data);
    } else if (dtype === "bool" || dtype === "string") {
      return Uint8Array.from(new Int32Array(data));
    } else {
      throw new Error(`Unknown dtype ${dtype}`);
    }
  }
  function makeOnesTypedArray(size, dtype) {
    const array = makeZerosTypedArray(size, dtype);
    for (let i = 0; i < array.length; i++) {
      array[i] = 1;
    }
    return array;
  }
  function makeZerosTypedArray(size, dtype) {
    if (dtype == null || dtype === "float32" || dtype === "complex64") {
      return new Float32Array(size);
    } else if (dtype === "int32") {
      return new Int32Array(size);
    } else if (dtype === "bool") {
      return new Uint8Array(size);
    } else {
      throw new Error(`Unknown data type ${dtype}`);
    }
  }
  function makeZerosNestedTypedArray(shape, dtype) {
    const size = shape.reduce((prev, curr) => prev * curr, 1);
    if (dtype == null || dtype === "float32") {
      return toNestedArray(shape, new Float32Array(size));
    } else if (dtype === "int32") {
      return toNestedArray(shape, new Int32Array(size));
    } else if (dtype === "bool") {
      return toNestedArray(shape, new Uint8Array(size));
    } else {
      throw new Error(`Unknown data type ${dtype}`);
    }
  }
  function assertNonNegativeIntegerDimensions(shape) {
    shape.forEach((dimSize) => {
      assert(Number.isInteger(dimSize) && dimSize >= 0, () => `Tensor must have a shape comprised of positive integers but got shape [${shape}].`);
    });
  }
  function locToIndex(locs, rank, strides) {
    if (rank === 0) {
      return 0;
    } else if (rank === 1) {
      return locs[0];
    }
    let index = locs[locs.length - 1];
    for (let i = 0; i < locs.length - 1; ++i) {
      index += strides[i] * locs[i];
    }
    return index;
  }
  function indexToLoc(index, rank, strides) {
    if (rank === 0) {
      return [];
    } else if (rank === 1) {
      return [index];
    }
    const locs = new Array(rank);
    for (let i = 0; i < locs.length - 1; ++i) {
      locs[i] = Math.floor(index / strides[i]);
      index -= locs[i] * strides[i];
    }
    locs[locs.length - 1] = index;
    return locs;
  }
  function isPromise(object) {
    return object && object.then && typeof object.then === "function";
  }
  var init_util_base = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/util_base.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/environment.js
  function getQueryParams(queryString) {
    const params = {};
    queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (s, ...t2) => {
      decodeParam(params, t2[0], t2[1]);
      return t2.join("=");
    });
    return params;
  }
  function decodeParam(params, name, value) {
    params[decodeURIComponent(name)] = decodeURIComponent(value || "");
  }
  function parseValue(flagName, value) {
    value = value.toLowerCase();
    if (value === "true" || value === "false") {
      return value === "true";
    } else if (`${+value}` === value) {
      return +value;
    }
    throw new Error(`Could not parse value flag value ${value} for flag ${flagName}.`);
  }
  function env() {
    return ENV;
  }
  function setEnvironmentGlobal(environment) {
    ENV = environment;
  }
  var TENSORFLOWJS_FLAGS_PREFIX, Environment, ENV;
  var init_environment = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/environment.js"() {
      init_util_base();
      TENSORFLOWJS_FLAGS_PREFIX = "tfjsflags";
      Environment = class {
        // tslint:disable-next-line: no-any
        constructor(global2) {
          this.global = global2;
          this.flags = {};
          this.flagRegistry = {};
          this.urlFlags = {};
          this.getQueryParams = getQueryParams;
          this.populateURLFlags();
        }
        setPlatform(platformName, platform) {
          if (this.platform != null) {
            if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
              console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${platformName}.`);
            }
          }
          this.platformName = platformName;
          this.platform = platform;
        }
        registerFlag(flagName, evaluationFn, setHook) {
          this.flagRegistry[flagName] = { evaluationFn, setHook };
          if (this.urlFlags[flagName] != null) {
            const flagValue = this.urlFlags[flagName];
            if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
              console.warn(`Setting feature override from URL ${flagName}: ${flagValue}.`);
            }
            this.set(flagName, flagValue);
          }
        }
        getAsync(flagName) {
          return __async(this, null, function* () {
            if (flagName in this.flags) {
              return this.flags[flagName];
            }
            this.flags[flagName] = yield this.evaluateFlag(flagName);
            return this.flags[flagName];
          });
        }
        get(flagName) {
          if (flagName in this.flags) {
            return this.flags[flagName];
          }
          const flagValue = this.evaluateFlag(flagName);
          if (isPromise(flagValue)) {
            throw new Error(`Flag ${flagName} cannot be synchronously evaluated. Please use getAsync() instead.`);
          }
          this.flags[flagName] = flagValue;
          return this.flags[flagName];
        }
        getNumber(flagName) {
          return this.get(flagName);
        }
        getBool(flagName) {
          return this.get(flagName);
        }
        getFlags() {
          return this.flags;
        }
        // For backwards compatibility.
        get features() {
          return this.flags;
        }
        set(flagName, value) {
          if (this.flagRegistry[flagName] == null) {
            throw new Error(`Cannot set flag ${flagName} as it has not been registered.`);
          }
          this.flags[flagName] = value;
          if (this.flagRegistry[flagName].setHook != null) {
            this.flagRegistry[flagName].setHook(value);
          }
        }
        evaluateFlag(flagName) {
          if (this.flagRegistry[flagName] == null) {
            throw new Error(`Cannot evaluate flag '${flagName}': no evaluation function found.`);
          }
          return this.flagRegistry[flagName].evaluationFn();
        }
        setFlags(flags) {
          this.flags = Object.assign({}, flags);
        }
        reset() {
          this.flags = {};
          this.urlFlags = {};
          this.populateURLFlags();
        }
        populateURLFlags() {
          if (typeof this.global === "undefined" || typeof this.global.location === "undefined" || typeof this.global.location.search === "undefined") {
            return;
          }
          const urlParams = this.getQueryParams(this.global.location.search);
          if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {
            const keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(",");
            keyValues.forEach((keyValue) => {
              const [key, value] = keyValue.split(":");
              this.urlFlags[key] = parseValue(key, value);
            });
          }
        }
      };
      ENV = null;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/global_util.js
  function getGlobalNamespace() {
    if (globalNameSpace == null) {
      let ns;
      if (typeof window !== "undefined") {
        ns = window;
      } else if (typeof global !== "undefined") {
        ns = global;
      } else if (typeof process !== "undefined") {
        ns = process;
      } else if (typeof self !== "undefined") {
        ns = self;
      } else {
        throw new Error("Could not find a global object");
      }
      globalNameSpace = ns;
    }
    return globalNameSpace;
  }
  function getGlobalMap() {
    const ns = getGlobalNamespace();
    if (ns._tfGlobals == null) {
      ns._tfGlobals = /* @__PURE__ */ new Map();
    }
    return ns._tfGlobals;
  }
  function getGlobal(key, init) {
    const globalMap = getGlobalMap();
    if (globalMap.has(key)) {
      return globalMap.get(key);
    } else {
      const singleton = init();
      globalMap.set(key, singleton);
      return globalMap.get(key);
    }
  }
  var globalNameSpace;
  var init_global_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/global_util.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/kernel_names.js
  var Abs, Acos, Acosh, Add, AddN, All, Any, ArgMax, ArgMin, Asin, Asinh, Atan, Atanh, Atan2, AvgPool, AvgPoolGrad, AvgPool3D, AvgPool3DGrad, BatchMatMul, BatchToSpaceND, Bincount, BroadcastArgs, Cast, Ceil, ClipByValue, Complex, ComplexAbs, Concat, Conv2D, Conv2DBackpropFilter, Conv2DBackpropInput, Conv3D, Conv3DBackpropFilterV2, Conv3DBackpropInputV2, Cos, Cosh, Cumprod, Cumsum, CropAndResize, DenseBincount, DepthToSpace, DepthwiseConv2dNative, DepthwiseConv2dNativeBackpropFilter, DepthwiseConv2dNativeBackpropInput, Diag, Dilation2D, Dilation2DBackpropInput, Dilation2DBackpropFilter, RealDiv, Einsum, Elu, EluGrad, Erf, Equal, Exp, ExpandDims, Expm1, FFT, Fill, FlipLeftRight, Floor, FloorDiv, FusedBatchNorm, GatherV2, GatherNd, Greater, GreaterEqual, Identity, IFFT, Imag, IsFinite, IsInf, IsNan, LeakyRelu, Less, LessEqual, LinSpace, Log, Log1p, LogicalAnd, LogicalNot, LogicalOr, LRN, LRNGrad, Max, Maximum, MaxPool, MaxPoolGrad, MaxPool3D, MaxPool3DGrad, MaxPoolWithArgmax, Mean, Min, Minimum, MirrorPad, Mod, Multinomial, Multiply, Neg, NotEqual, NonMaxSuppressionV3, NonMaxSuppressionV4, NonMaxSuppressionV5, OnesLike, OneHot, Pack, PadV2, Pow, Prelu, Prod, RaggedGather, RaggedRange, RaggedTensorToTensor, Range, Real, Reciprocal, Relu, Reshape, ResizeNearestNeighbor, ResizeNearestNeighborGrad, ResizeBilinear, ResizeBilinearGrad, Relu6, Reverse, Round, Rsqrt, ScatterNd, SearchSorted, Select, Selu, Slice, Sin, Sinh, Sign, Sigmoid, Softplus, Sqrt, Sum, SpaceToBatchND, SplitV, Softmax, SparseFillEmptyRows, SparseReshape, SparseSegmentMean, SparseSegmentSum, SparseToDense, SquaredDifference, Square, StridedSlice, StringNGrams, StringSplit, StringToHashBucketFast, Sub, Tan, Tanh, Tile, TopK, Transform, Transpose, Unique, Unpack, UnsortedSegmentSum, ZerosLike, Step, FromPixels, RotateWithOffset, _FusedMatMul, FusedConv2D, FusedDepthwiseConv2D;
  var init_kernel_names = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/kernel_names.js"() {
      Abs = "Abs";
      Acos = "Acos";
      Acosh = "Acosh";
      Add = "Add";
      AddN = "AddN";
      All = "All";
      Any = "Any";
      ArgMax = "ArgMax";
      ArgMin = "ArgMin";
      Asin = "Asin";
      Asinh = "Asinh";
      Atan = "Atan";
      Atanh = "Atanh";
      Atan2 = "Atan2";
      AvgPool = "AvgPool";
      AvgPoolGrad = "AvgPoolGrad";
      AvgPool3D = "AvgPool3D";
      AvgPool3DGrad = "AvgPool3DGrad";
      BatchMatMul = "BatchMatMul";
      BatchToSpaceND = "BatchToSpaceND";
      Bincount = "Bincount";
      BroadcastArgs = "BroadcastArgs";
      Cast = "Cast";
      Ceil = "Ceil";
      ClipByValue = "ClipByValue";
      Complex = "Complex";
      ComplexAbs = "ComplexAbs";
      Concat = "Concat";
      Conv2D = "Conv2D";
      Conv2DBackpropFilter = "Conv2DBackpropFilter";
      Conv2DBackpropInput = "Conv2DBackpropInput";
      Conv3D = "Conv3D";
      Conv3DBackpropFilterV2 = "Conv3DBackpropFilterV2";
      Conv3DBackpropInputV2 = "Conv3DBackpropInputV2";
      Cos = "Cos";
      Cosh = "Cosh";
      Cumprod = "Cumprod";
      Cumsum = "Cumsum";
      CropAndResize = "CropAndResize";
      DenseBincount = "DenseBincount";
      DepthToSpace = "DepthToSpace";
      DepthwiseConv2dNative = "DepthwiseConv2dNative";
      DepthwiseConv2dNativeBackpropFilter = "DepthwiseConv2dNativeBackpropFilter";
      DepthwiseConv2dNativeBackpropInput = "DepthwiseConv2dNativeBackpropInput";
      Diag = "Diag";
      Dilation2D = "Dilation2D";
      Dilation2DBackpropInput = "Dilation2DBackpropInput";
      Dilation2DBackpropFilter = "Dilation2DBackpropFilter";
      RealDiv = "RealDiv";
      Einsum = "Einsum";
      Elu = "Elu";
      EluGrad = "EluGrad";
      Erf = "Erf";
      Equal = "Equal";
      Exp = "Exp";
      ExpandDims = "ExpandDims";
      Expm1 = "Expm1";
      FFT = "FFT";
      Fill = "Fill";
      FlipLeftRight = "FlipLeftRight";
      Floor = "Floor";
      FloorDiv = "FloorDiv";
      FusedBatchNorm = "FusedBatchNorm";
      GatherV2 = "GatherV2";
      GatherNd = "GatherNd";
      Greater = "Greater";
      GreaterEqual = "GreaterEqual";
      Identity = "Identity";
      IFFT = "IFFT";
      Imag = "Imag";
      IsFinite = "IsFinite";
      IsInf = "IsInf";
      IsNan = "IsNan";
      LeakyRelu = "LeakyRelu";
      Less = "Less";
      LessEqual = "LessEqual";
      LinSpace = "LinSpace";
      Log = "Log";
      Log1p = "Log1p";
      LogicalAnd = "LogicalAnd";
      LogicalNot = "LogicalNot";
      LogicalOr = "LogicalOr";
      LRN = "LRN";
      LRNGrad = "LRNGrad";
      Max = "Max";
      Maximum = "Maximum";
      MaxPool = "MaxPool";
      MaxPoolGrad = "MaxPoolGrad";
      MaxPool3D = "MaxPool3D";
      MaxPool3DGrad = "MaxPool3DGrad";
      MaxPoolWithArgmax = "MaxPoolWithArgmax";
      Mean = "Mean";
      Min = "Min";
      Minimum = "Minimum";
      MirrorPad = "MirrorPad";
      Mod = "Mod";
      Multinomial = "Multinomial";
      Multiply = "Multiply";
      Neg = "Neg";
      NotEqual = "NotEqual";
      NonMaxSuppressionV3 = "NonMaxSuppressionV3";
      NonMaxSuppressionV4 = "NonMaxSuppressionV4";
      NonMaxSuppressionV5 = "NonMaxSuppressionV5";
      OnesLike = "OnesLike";
      OneHot = "OneHot";
      Pack = "Pack";
      PadV2 = "PadV2";
      Pow = "Pow";
      Prelu = "Prelu";
      Prod = "Prod";
      RaggedGather = "RaggedGather";
      RaggedRange = "RaggedRange";
      RaggedTensorToTensor = "RaggedTensorToTensor";
      Range = "Range";
      Real = "Real";
      Reciprocal = "Reciprocal";
      Relu = "Relu";
      Reshape = "Reshape";
      ResizeNearestNeighbor = "ResizeNearestNeighbor";
      ResizeNearestNeighborGrad = "ResizeNearestNeighborGrad";
      ResizeBilinear = "ResizeBilinear";
      ResizeBilinearGrad = "ResizeBilinearGrad";
      Relu6 = "Relu6";
      Reverse = "Reverse";
      Round = "Round";
      Rsqrt = "Rsqrt";
      ScatterNd = "ScatterNd";
      SearchSorted = "SearchSorted";
      Select = "Select";
      Selu = "Selu";
      Slice = "Slice";
      Sin = "Sin";
      Sinh = "Sinh";
      Sign = "Sign";
      Sigmoid = "Sigmoid";
      Softplus = "Softplus";
      Sqrt = "Sqrt";
      Sum = "Sum";
      SpaceToBatchND = "SpaceToBatchND";
      SplitV = "SplitV";
      Softmax = "Softmax";
      SparseFillEmptyRows = "SparseFillEmptyRows";
      SparseReshape = "SparseReshape";
      SparseSegmentMean = "SparseSegmentMean";
      SparseSegmentSum = "SparseSegmentSum";
      SparseToDense = "SparseToDense";
      SquaredDifference = "SquaredDifference";
      Square = "Square";
      StridedSlice = "StridedSlice";
      StringNGrams = "StringNGrams";
      StringSplit = "StringSplit";
      StringToHashBucketFast = "StringToHashBucketFast";
      Sub = "Sub";
      Tan = "Tan";
      Tanh = "Tanh";
      Tile = "Tile";
      TopK = "TopK";
      Transform = "Transform";
      Transpose = "Transpose";
      Unique = "Unique";
      Unpack = "Unpack";
      UnsortedSegmentSum = "UnsortedSegmentSum";
      ZerosLike = "ZerosLike";
      Step = "Step";
      FromPixels = "FromPixels";
      RotateWithOffset = "RotateWithOffset";
      _FusedMatMul = "_FusedMatMul";
      FusedConv2D = "FusedConv2D";
      FusedDepthwiseConv2D = "FusedDepthwiseConv2D";
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/log.js
  function warn(...msg) {
    if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
      console.warn(...msg);
    }
  }
  function log(...msg) {
    if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
      console.log(...msg);
    }
  }
  var init_log = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/log.js"() {
      init_environment();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js
  function getKernel(kernelName, backendName) {
    const key = makeKey(kernelName, backendName);
    return kernelRegistry.get(key);
  }
  function getGradient(kernelName) {
    return gradRegistry.get(kernelName);
  }
  function getKernelsForBackend(backendName) {
    const it2 = kernelRegistry.entries();
    const result = [];
    while (true) {
      const { done, value } = it2.next();
      if (done) {
        break;
      }
      const [key, config] = value;
      const [backend] = key.split("_");
      if (backend === backendName) {
        result.push(config);
      }
    }
    return result;
  }
  function registerKernel(config) {
    const { kernelName, backendName } = config;
    const key = makeKey(kernelName, backendName);
    if (kernelRegistry.has(key)) {
      warn(`The kernel '${kernelName}' for backend '${backendName}' is already registered`);
    }
    kernelRegistry.set(key, config);
  }
  function makeKey(kernelName, backendName) {
    return `${backendName}_${kernelName}`;
  }
  var kernelRegistry, gradRegistry;
  var init_kernel_registry = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js"() {
      init_global_util();
      init_log();
      kernelRegistry = getGlobal("kernelRegistry", () => /* @__PURE__ */ new Map());
      gradRegistry = getGlobal("gradRegistry", () => /* @__PURE__ */ new Map());
    }
  });

  // node_modules/long/src/long.js
  var require_long = __commonJS({
    "node_modules/long/src/long.js"(exports, module) {
      module.exports = Long2;
      var wasm = null;
      try {
        wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([
          0,
          97,
          115,
          109,
          1,
          0,
          0,
          0,
          1,
          13,
          2,
          96,
          0,
          1,
          127,
          96,
          4,
          127,
          127,
          127,
          127,
          1,
          127,
          3,
          7,
          6,
          0,
          1,
          1,
          1,
          1,
          1,
          6,
          6,
          1,
          127,
          1,
          65,
          0,
          11,
          7,
          50,
          6,
          3,
          109,
          117,
          108,
          0,
          1,
          5,
          100,
          105,
          118,
          95,
          115,
          0,
          2,
          5,
          100,
          105,
          118,
          95,
          117,
          0,
          3,
          5,
          114,
          101,
          109,
          95,
          115,
          0,
          4,
          5,
          114,
          101,
          109,
          95,
          117,
          0,
          5,
          8,
          103,
          101,
          116,
          95,
          104,
          105,
          103,
          104,
          0,
          0,
          10,
          191,
          1,
          6,
          4,
          0,
          35,
          0,
          11,
          36,
          1,
          1,
          126,
          32,
          0,
          173,
          32,
          1,
          173,
          66,
          32,
          134,
          132,
          32,
          2,
          173,
          32,
          3,
          173,
          66,
          32,
          134,
          132,
          126,
          34,
          4,
          66,
          32,
          135,
          167,
          36,
          0,
          32,
          4,
          167,
          11,
          36,
          1,
          1,
          126,
          32,
          0,
          173,
          32,
          1,
          173,
          66,
          32,
          134,
          132,
          32,
          2,
          173,
          32,
          3,
          173,
          66,
          32,
          134,
          132,
          127,
          34,
          4,
          66,
          32,
          135,
          167,
          36,
          0,
          32,
          4,
          167,
          11,
          36,
          1,
          1,
          126,
          32,
          0,
          173,
          32,
          1,
          173,
          66,
          32,
          134,
          132,
          32,
          2,
          173,
          32,
          3,
          173,
          66,
          32,
          134,
          132,
          128,
          34,
          4,
          66,
          32,
          135,
          167,
          36,
          0,
          32,
          4,
          167,
          11,
          36,
          1,
          1,
          126,
          32,
          0,
          173,
          32,
          1,
          173,
          66,
          32,
          134,
          132,
          32,
          2,
          173,
          32,
          3,
          173,
          66,
          32,
          134,
          132,
          129,
          34,
          4,
          66,
          32,
          135,
          167,
          36,
          0,
          32,
          4,
          167,
          11,
          36,
          1,
          1,
          126,
          32,
          0,
          173,
          32,
          1,
          173,
          66,
          32,
          134,
          132,
          32,
          2,
          173,
          32,
          3,
          173,
          66,
          32,
          134,
          132,
          130,
          34,
          4,
          66,
          32,
          135,
          167,
          36,
          0,
          32,
          4,
          167,
          11
        ])), {}).exports;
      } catch (e) {
      }
      function Long2(low, high, unsigned) {
        this.low = low | 0;
        this.high = high | 0;
        this.unsigned = !!unsigned;
      }
      Long2.prototype.__isLong__;
      Object.defineProperty(Long2.prototype, "__isLong__", { value: true });
      function isLong(obj) {
        return (obj && obj["__isLong__"]) === true;
      }
      Long2.isLong = isLong;
      var INT_CACHE = {};
      var UINT_CACHE = {};
      function fromInt(value, unsigned) {
        var obj, cachedObj, cache;
        if (unsigned) {
          value >>>= 0;
          if (cache = 0 <= value && value < 256) {
            cachedObj = UINT_CACHE[value];
            if (cachedObj)
              return cachedObj;
          }
          obj = fromBits(value, (value | 0) < 0 ? -1 : 0, true);
          if (cache)
            UINT_CACHE[value] = obj;
          return obj;
        } else {
          value |= 0;
          if (cache = -128 <= value && value < 128) {
            cachedObj = INT_CACHE[value];
            if (cachedObj)
              return cachedObj;
          }
          obj = fromBits(value, value < 0 ? -1 : 0, false);
          if (cache)
            INT_CACHE[value] = obj;
          return obj;
        }
      }
      Long2.fromInt = fromInt;
      function fromNumber(value, unsigned) {
        if (isNaN(value))
          return unsigned ? UZERO : ZERO;
        if (unsigned) {
          if (value < 0)
            return UZERO;
          if (value >= TWO_PWR_64_DBL)
            return MAX_UNSIGNED_VALUE;
        } else {
          if (value <= -TWO_PWR_63_DBL)
            return MIN_VALUE;
          if (value + 1 >= TWO_PWR_63_DBL)
            return MAX_VALUE;
        }
        if (value < 0)
          return fromNumber(-value, unsigned).neg();
        return fromBits(value % TWO_PWR_32_DBL | 0, value / TWO_PWR_32_DBL | 0, unsigned);
      }
      Long2.fromNumber = fromNumber;
      function fromBits(lowBits, highBits, unsigned) {
        return new Long2(lowBits, highBits, unsigned);
      }
      Long2.fromBits = fromBits;
      var pow_dbl = Math.pow;
      function fromString(str, unsigned, radix) {
        if (str.length === 0)
          throw Error("empty string");
        if (str === "NaN" || str === "Infinity" || str === "+Infinity" || str === "-Infinity")
          return ZERO;
        if (typeof unsigned === "number") {
          radix = unsigned, unsigned = false;
        } else {
          unsigned = !!unsigned;
        }
        radix = radix || 10;
        if (radix < 2 || 36 < radix)
          throw RangeError("radix");
        var p2;
        if ((p2 = str.indexOf("-")) > 0)
          throw Error("interior hyphen");
        else if (p2 === 0) {
          return fromString(str.substring(1), unsigned, radix).neg();
        }
        var radixToPower = fromNumber(pow_dbl(radix, 8));
        var result = ZERO;
        for (var i = 0; i < str.length; i += 8) {
          var size = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size), radix);
          if (size < 8) {
            var power = fromNumber(pow_dbl(radix, size));
            result = result.mul(power).add(fromNumber(value));
          } else {
            result = result.mul(radixToPower);
            result = result.add(fromNumber(value));
          }
        }
        result.unsigned = unsigned;
        return result;
      }
      Long2.fromString = fromString;
      function fromValue(val, unsigned) {
        if (typeof val === "number")
          return fromNumber(val, unsigned);
        if (typeof val === "string")
          return fromString(val, unsigned);
        return fromBits(val.low, val.high, typeof unsigned === "boolean" ? unsigned : val.unsigned);
      }
      Long2.fromValue = fromValue;
      var TWO_PWR_16_DBL = 1 << 16;
      var TWO_PWR_24_DBL = 1 << 24;
      var TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;
      var TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;
      var TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;
      var TWO_PWR_24 = fromInt(TWO_PWR_24_DBL);
      var ZERO = fromInt(0);
      Long2.ZERO = ZERO;
      var UZERO = fromInt(0, true);
      Long2.UZERO = UZERO;
      var ONE = fromInt(1);
      Long2.ONE = ONE;
      var UONE = fromInt(1, true);
      Long2.UONE = UONE;
      var NEG_ONE = fromInt(-1);
      Long2.NEG_ONE = NEG_ONE;
      var MAX_VALUE = fromBits(4294967295 | 0, 2147483647 | 0, false);
      Long2.MAX_VALUE = MAX_VALUE;
      var MAX_UNSIGNED_VALUE = fromBits(4294967295 | 0, 4294967295 | 0, true);
      Long2.MAX_UNSIGNED_VALUE = MAX_UNSIGNED_VALUE;
      var MIN_VALUE = fromBits(0, 2147483648 | 0, false);
      Long2.MIN_VALUE = MIN_VALUE;
      var LongPrototype = Long2.prototype;
      LongPrototype.toInt = function toInt() {
        return this.unsigned ? this.low >>> 0 : this.low;
      };
      LongPrototype.toNumber = function toNumber() {
        if (this.unsigned)
          return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);
        return this.high * TWO_PWR_32_DBL + (this.low >>> 0);
      };
      LongPrototype.toString = function toString(radix) {
        radix = radix || 10;
        if (radix < 2 || 36 < radix)
          throw RangeError("radix");
        if (this.isZero())
          return "0";
        if (this.isNegative()) {
          if (this.eq(MIN_VALUE)) {
            var radixLong = fromNumber(radix), div3 = this.div(radixLong), rem1 = div3.mul(radixLong).sub(this);
            return div3.toString(radix) + rem1.toInt().toString(radix);
          } else
            return "-" + this.neg().toString(radix);
        }
        var radixToPower = fromNumber(pow_dbl(radix, 6), this.unsigned), rem = this;
        var result = "";
        while (true) {
          var remDiv = rem.div(radixToPower), intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0, digits = intval.toString(radix);
          rem = remDiv;
          if (rem.isZero())
            return digits + result;
          else {
            while (digits.length < 6)
              digits = "0" + digits;
            result = "" + digits + result;
          }
        }
      };
      LongPrototype.getHighBits = function getHighBits() {
        return this.high;
      };
      LongPrototype.getHighBitsUnsigned = function getHighBitsUnsigned() {
        return this.high >>> 0;
      };
      LongPrototype.getLowBits = function getLowBits() {
        return this.low;
      };
      LongPrototype.getLowBitsUnsigned = function getLowBitsUnsigned() {
        return this.low >>> 0;
      };
      LongPrototype.getNumBitsAbs = function getNumBitsAbs() {
        if (this.isNegative())
          return this.eq(MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();
        var val = this.high != 0 ? this.high : this.low;
        for (var bit = 31; bit > 0; bit--)
          if ((val & 1 << bit) != 0)
            break;
        return this.high != 0 ? bit + 33 : bit + 1;
      };
      LongPrototype.isZero = function isZero() {
        return this.high === 0 && this.low === 0;
      };
      LongPrototype.eqz = LongPrototype.isZero;
      LongPrototype.isNegative = function isNegative() {
        return !this.unsigned && this.high < 0;
      };
      LongPrototype.isPositive = function isPositive() {
        return this.unsigned || this.high >= 0;
      };
      LongPrototype.isOdd = function isOdd() {
        return (this.low & 1) === 1;
      };
      LongPrototype.isEven = function isEven() {
        return (this.low & 1) === 0;
      };
      LongPrototype.equals = function equals(other) {
        if (!isLong(other))
          other = fromValue(other);
        if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)
          return false;
        return this.high === other.high && this.low === other.low;
      };
      LongPrototype.eq = LongPrototype.equals;
      LongPrototype.notEquals = function notEquals(other) {
        return !this.eq(
          /* validates */
          other
        );
      };
      LongPrototype.neq = LongPrototype.notEquals;
      LongPrototype.ne = LongPrototype.notEquals;
      LongPrototype.lessThan = function lessThan(other) {
        return this.comp(
          /* validates */
          other
        ) < 0;
      };
      LongPrototype.lt = LongPrototype.lessThan;
      LongPrototype.lessThanOrEqual = function lessThanOrEqual(other) {
        return this.comp(
          /* validates */
          other
        ) <= 0;
      };
      LongPrototype.lte = LongPrototype.lessThanOrEqual;
      LongPrototype.le = LongPrototype.lessThanOrEqual;
      LongPrototype.greaterThan = function greaterThan(other) {
        return this.comp(
          /* validates */
          other
        ) > 0;
      };
      LongPrototype.gt = LongPrototype.greaterThan;
      LongPrototype.greaterThanOrEqual = function greaterThanOrEqual(other) {
        return this.comp(
          /* validates */
          other
        ) >= 0;
      };
      LongPrototype.gte = LongPrototype.greaterThanOrEqual;
      LongPrototype.ge = LongPrototype.greaterThanOrEqual;
      LongPrototype.compare = function compare(other) {
        if (!isLong(other))
          other = fromValue(other);
        if (this.eq(other))
          return 0;
        var thisNeg = this.isNegative(), otherNeg = other.isNegative();
        if (thisNeg && !otherNeg)
          return -1;
        if (!thisNeg && otherNeg)
          return 1;
        if (!this.unsigned)
          return this.sub(other).isNegative() ? -1 : 1;
        return other.high >>> 0 > this.high >>> 0 || other.high === this.high && other.low >>> 0 > this.low >>> 0 ? -1 : 1;
      };
      LongPrototype.comp = LongPrototype.compare;
      LongPrototype.negate = function negate() {
        if (!this.unsigned && this.eq(MIN_VALUE))
          return MIN_VALUE;
        return this.not().add(ONE);
      };
      LongPrototype.neg = LongPrototype.negate;
      LongPrototype.add = function add4(addend) {
        if (!isLong(addend))
          addend = fromValue(addend);
        var a48 = this.high >>> 16;
        var a32 = this.high & 65535;
        var a16 = this.low >>> 16;
        var a00 = this.low & 65535;
        var b48 = addend.high >>> 16;
        var b32 = addend.high & 65535;
        var b16 = addend.low >>> 16;
        var b00 = addend.low & 65535;
        var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
        c00 += a00 + b00;
        c16 += c00 >>> 16;
        c00 &= 65535;
        c16 += a16 + b16;
        c32 += c16 >>> 16;
        c16 &= 65535;
        c32 += a32 + b32;
        c48 += c32 >>> 16;
        c32 &= 65535;
        c48 += a48 + b48;
        c48 &= 65535;
        return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
      };
      LongPrototype.subtract = function subtract(subtrahend) {
        if (!isLong(subtrahend))
          subtrahend = fromValue(subtrahend);
        return this.add(subtrahend.neg());
      };
      LongPrototype.sub = LongPrototype.subtract;
      LongPrototype.multiply = function multiply2(multiplier) {
        if (this.isZero())
          return ZERO;
        if (!isLong(multiplier))
          multiplier = fromValue(multiplier);
        if (wasm) {
          var low = wasm.mul(
            this.low,
            this.high,
            multiplier.low,
            multiplier.high
          );
          return fromBits(low, wasm.get_high(), this.unsigned);
        }
        if (multiplier.isZero())
          return ZERO;
        if (this.eq(MIN_VALUE))
          return multiplier.isOdd() ? MIN_VALUE : ZERO;
        if (multiplier.eq(MIN_VALUE))
          return this.isOdd() ? MIN_VALUE : ZERO;
        if (this.isNegative()) {
          if (multiplier.isNegative())
            return this.neg().mul(multiplier.neg());
          else
            return this.neg().mul(multiplier).neg();
        } else if (multiplier.isNegative())
          return this.mul(multiplier.neg()).neg();
        if (this.lt(TWO_PWR_24) && multiplier.lt(TWO_PWR_24))
          return fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);
        var a48 = this.high >>> 16;
        var a32 = this.high & 65535;
        var a16 = this.low >>> 16;
        var a00 = this.low & 65535;
        var b48 = multiplier.high >>> 16;
        var b32 = multiplier.high & 65535;
        var b16 = multiplier.low >>> 16;
        var b00 = multiplier.low & 65535;
        var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
        c00 += a00 * b00;
        c16 += c00 >>> 16;
        c00 &= 65535;
        c16 += a16 * b00;
        c32 += c16 >>> 16;
        c16 &= 65535;
        c16 += a00 * b16;
        c32 += c16 >>> 16;
        c16 &= 65535;
        c32 += a32 * b00;
        c48 += c32 >>> 16;
        c32 &= 65535;
        c32 += a16 * b16;
        c48 += c32 >>> 16;
        c32 &= 65535;
        c32 += a00 * b32;
        c48 += c32 >>> 16;
        c32 &= 65535;
        c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;
        c48 &= 65535;
        return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
      };
      LongPrototype.mul = LongPrototype.multiply;
      LongPrototype.divide = function divide(divisor) {
        if (!isLong(divisor))
          divisor = fromValue(divisor);
        if (divisor.isZero())
          throw Error("division by zero");
        if (wasm) {
          if (!this.unsigned && this.high === -2147483648 && divisor.low === -1 && divisor.high === -1) {
            return this;
          }
          var low = (this.unsigned ? wasm.div_u : wasm.div_s)(
            this.low,
            this.high,
            divisor.low,
            divisor.high
          );
          return fromBits(low, wasm.get_high(), this.unsigned);
        }
        if (this.isZero())
          return this.unsigned ? UZERO : ZERO;
        var approx, rem, res;
        if (!this.unsigned) {
          if (this.eq(MIN_VALUE)) {
            if (divisor.eq(ONE) || divisor.eq(NEG_ONE))
              return MIN_VALUE;
            else if (divisor.eq(MIN_VALUE))
              return ONE;
            else {
              var halfThis = this.shr(1);
              approx = halfThis.div(divisor).shl(1);
              if (approx.eq(ZERO)) {
                return divisor.isNegative() ? ONE : NEG_ONE;
              } else {
                rem = this.sub(divisor.mul(approx));
                res = approx.add(rem.div(divisor));
                return res;
              }
            }
          } else if (divisor.eq(MIN_VALUE))
            return this.unsigned ? UZERO : ZERO;
          if (this.isNegative()) {
            if (divisor.isNegative())
              return this.neg().div(divisor.neg());
            return this.neg().div(divisor).neg();
          } else if (divisor.isNegative())
            return this.div(divisor.neg()).neg();
          res = ZERO;
        } else {
          if (!divisor.unsigned)
            divisor = divisor.toUnsigned();
          if (divisor.gt(this))
            return UZERO;
          if (divisor.gt(this.shru(1)))
            return UONE;
          res = UZERO;
        }
        rem = this;
        while (rem.gte(divisor)) {
          approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));
          var log22 = Math.ceil(Math.log(approx) / Math.LN2), delta = log22 <= 48 ? 1 : pow_dbl(2, log22 - 48), approxRes = fromNumber(approx), approxRem = approxRes.mul(divisor);
          while (approxRem.isNegative() || approxRem.gt(rem)) {
            approx -= delta;
            approxRes = fromNumber(approx, this.unsigned);
            approxRem = approxRes.mul(divisor);
          }
          if (approxRes.isZero())
            approxRes = ONE;
          res = res.add(approxRes);
          rem = rem.sub(approxRem);
        }
        return res;
      };
      LongPrototype.div = LongPrototype.divide;
      LongPrototype.modulo = function modulo(divisor) {
        if (!isLong(divisor))
          divisor = fromValue(divisor);
        if (wasm) {
          var low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(
            this.low,
            this.high,
            divisor.low,
            divisor.high
          );
          return fromBits(low, wasm.get_high(), this.unsigned);
        }
        return this.sub(this.div(divisor).mul(divisor));
      };
      LongPrototype.mod = LongPrototype.modulo;
      LongPrototype.rem = LongPrototype.modulo;
      LongPrototype.not = function not() {
        return fromBits(~this.low, ~this.high, this.unsigned);
      };
      LongPrototype.and = function and(other) {
        if (!isLong(other))
          other = fromValue(other);
        return fromBits(this.low & other.low, this.high & other.high, this.unsigned);
      };
      LongPrototype.or = function or(other) {
        if (!isLong(other))
          other = fromValue(other);
        return fromBits(this.low | other.low, this.high | other.high, this.unsigned);
      };
      LongPrototype.xor = function xor(other) {
        if (!isLong(other))
          other = fromValue(other);
        return fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);
      };
      LongPrototype.shiftLeft = function shiftLeft(numBits) {
        if (isLong(numBits))
          numBits = numBits.toInt();
        if ((numBits &= 63) === 0)
          return this;
        else if (numBits < 32)
          return fromBits(this.low << numBits, this.high << numBits | this.low >>> 32 - numBits, this.unsigned);
        else
          return fromBits(0, this.low << numBits - 32, this.unsigned);
      };
      LongPrototype.shl = LongPrototype.shiftLeft;
      LongPrototype.shiftRight = function shiftRight(numBits) {
        if (isLong(numBits))
          numBits = numBits.toInt();
        if ((numBits &= 63) === 0)
          return this;
        else if (numBits < 32)
          return fromBits(this.low >>> numBits | this.high << 32 - numBits, this.high >> numBits, this.unsigned);
        else
          return fromBits(this.high >> numBits - 32, this.high >= 0 ? 0 : -1, this.unsigned);
      };
      LongPrototype.shr = LongPrototype.shiftRight;
      LongPrototype.shiftRightUnsigned = function shiftRightUnsigned(numBits) {
        if (isLong(numBits))
          numBits = numBits.toInt();
        numBits &= 63;
        if (numBits === 0)
          return this;
        else {
          var high = this.high;
          if (numBits < 32) {
            var low = this.low;
            return fromBits(low >>> numBits | high << 32 - numBits, high >>> numBits, this.unsigned);
          } else if (numBits === 32)
            return fromBits(high, 0, this.unsigned);
          else
            return fromBits(high >>> numBits - 32, 0, this.unsigned);
        }
      };
      LongPrototype.shru = LongPrototype.shiftRightUnsigned;
      LongPrototype.shr_u = LongPrototype.shiftRightUnsigned;
      LongPrototype.toSigned = function toSigned() {
        if (!this.unsigned)
          return this;
        return fromBits(this.low, this.high, false);
      };
      LongPrototype.toUnsigned = function toUnsigned() {
        if (this.unsigned)
          return this;
        return fromBits(this.low, this.high, true);
      };
      LongPrototype.toBytes = function toBytes(le) {
        return le ? this.toBytesLE() : this.toBytesBE();
      };
      LongPrototype.toBytesLE = function toBytesLE() {
        var hi = this.high, lo = this.low;
        return [
          lo & 255,
          lo >>> 8 & 255,
          lo >>> 16 & 255,
          lo >>> 24,
          hi & 255,
          hi >>> 8 & 255,
          hi >>> 16 & 255,
          hi >>> 24
        ];
      };
      LongPrototype.toBytesBE = function toBytesBE() {
        var hi = this.high, lo = this.low;
        return [
          hi >>> 24,
          hi >>> 16 & 255,
          hi >>> 8 & 255,
          hi & 255,
          lo >>> 24,
          lo >>> 16 & 255,
          lo >>> 8 & 255,
          lo & 255
        ];
      };
      Long2.fromBytes = function fromBytes(bytes, unsigned, le) {
        return le ? Long2.fromBytesLE(bytes, unsigned) : Long2.fromBytesBE(bytes, unsigned);
      };
      Long2.fromBytesLE = function fromBytesLE(bytes, unsigned) {
        return new Long2(
          bytes[0] | bytes[1] << 8 | bytes[2] << 16 | bytes[3] << 24,
          bytes[4] | bytes[5] << 8 | bytes[6] << 16 | bytes[7] << 24,
          unsigned
        );
      };
      Long2.fromBytesBE = function fromBytesBE(bytes, unsigned) {
        return new Long2(
          bytes[4] << 24 | bytes[5] << 16 | bytes[6] << 8 | bytes[7],
          bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3],
          unsigned
        );
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/hash_util.js
  function hexToLong(hex) {
    return Long.fromString(hex, true, 16);
  }
  function shiftMix(val) {
    return val.xor(val.shru(47));
  }
  function fetch2(s, offset, numBytes) {
    const bytes = s.slice(offset, offset + numBytes);
    return Long.fromBytes(Array.from(bytes), true, true);
  }
  function fetch64(s, offset) {
    return fetch2(s, offset, 8);
  }
  function fetch32(s, offset) {
    return fetch2(s, offset, 4);
  }
  function rotate64(val, shift) {
    return shift === 0 ? val : val.shru(shift).or(val.shl(64 - shift));
  }
  function hashLen16(u, v, mul2 = hexToLong("9ddfea08eb382d69")) {
    let a = u.xor(v).mul(mul2);
    a = a.xor(a.shru(47));
    let b = v.xor(a).mul(mul2);
    b = b.xor(b.shru(47));
    b = b.mul(mul2);
    return b;
  }
  function weakHashLen32WithSeeds(w, x, y, z2, a, b) {
    a = a.add(w);
    b = rotate64(b.add(a).add(z2), 21);
    const c = a;
    a = a.add(x);
    a = a.add(y);
    b = b.add(rotate64(a, 44));
    return [a.add(z2), b.add(c)];
  }
  function weakHashLen32WithSeedsStr(s, offset, a, b) {
    return weakHashLen32WithSeeds(fetch64(s, offset), fetch64(s, offset + 8), fetch64(s, offset + 16), fetch64(s, offset + 24), a, b);
  }
  function hashLen0to16(s, len = s.length) {
    if (len >= 8) {
      const mul2 = k2.add(len * 2);
      const a = fetch64(s, 0).add(k2);
      const b = fetch64(s, len - 8);
      const c = rotate64(b, 37).mul(mul2).add(a);
      const d = rotate64(a, 25).add(b).mul(mul2);
      return hashLen16(c, d, mul2);
    }
    if (len >= 4) {
      const mul2 = k2.add(len * 2);
      const a = fetch32(s, 0);
      return hashLen16(a.shl(3).add(len), fetch32(s, len - 4), mul2);
    }
    if (len > 0) {
      const a = s[0];
      const b = s[len >> 1];
      const c = s[len - 1];
      const y = a + (b << 8);
      const z2 = len + (c << 2);
      return shiftMix(k2.mul(y).xor(k0.mul(z2))).mul(k2);
    }
    return k2;
  }
  function hashLen17to32(s, len = s.length) {
    const mul2 = k2.add(len * 2);
    const a = fetch64(s, 0).mul(k1);
    const b = fetch64(s, 8);
    const c = fetch64(s, len - 8).mul(mul2);
    const d = fetch64(s, len - 16).mul(k2);
    return hashLen16(rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d), a.add(rotate64(b.add(k2), 18)).add(c), mul2);
  }
  function hashLen33to64(s, len = s.length) {
    const mul2 = k2.add(len * 2);
    const a = fetch64(s, 0).mul(k2);
    const b = fetch64(s, 8);
    const c = fetch64(s, len - 8).mul(mul2);
    const d = fetch64(s, len - 16).mul(k2);
    const y = rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d);
    const z2 = hashLen16(y, a.add(rotate64(b.add(k2), 18)).add(c), mul2);
    const e = fetch64(s, 16).mul(mul2);
    const f = fetch64(s, 24);
    const g = y.add(fetch64(s, len - 32)).mul(mul2);
    const h = z2.add(fetch64(s, len - 24)).mul(mul2);
    return hashLen16(rotate64(e.add(f), 43).add(rotate64(g, 30)).add(h), e.add(rotate64(f.add(a), 18)).add(g), mul2);
  }
  function fingerPrint64(s, len = s.length) {
    const seed = Long.fromNumber(81, true);
    if (len <= 32) {
      if (len <= 16) {
        return hashLen0to16(s, len);
      } else {
        return hashLen17to32(s, len);
      }
    } else if (len <= 64) {
      return hashLen33to64(s, len);
    }
    let x = seed;
    let y = seed.mul(k1).add(113);
    let z2 = shiftMix(y.mul(k2).add(113)).mul(k2);
    let v = [Long.UZERO, Long.UZERO];
    let w = [Long.UZERO, Long.UZERO];
    x = x.mul(k2).add(fetch64(s, 0));
    let offset = 0;
    const end = (len - 1 >> 6) * 64;
    const last64 = end + (len - 1 & 63) - 63;
    do {
      x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(k1);
      y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(k1);
      x = x.xor(w[1]);
      y = y.add(v[0]).add(fetch64(s, offset + 40));
      z2 = rotate64(z2.add(w[0]), 33).mul(k1);
      v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(k1), x.add(w[0]));
      w = weakHashLen32WithSeedsStr(s, offset + 32, z2.add(w[1]), y.add(fetch64(s, offset + 16)));
      [z2, x] = [x, z2];
      offset += 64;
    } while (offset !== end);
    const mul2 = k1.add(z2.and(255).shl(1));
    offset = last64;
    w[0] = w[0].add(len - 1 & 63);
    v[0] = v[0].add(w[0]);
    w[0] = w[0].add(v[0]);
    x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(mul2);
    y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(mul2);
    x = x.xor(w[1].mul(9));
    y = y.add(v[0].mul(9).add(fetch64(s, offset + 40)));
    z2 = rotate64(z2.add(w[0]), 33).mul(mul2);
    v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(mul2), x.add(w[0]));
    w = weakHashLen32WithSeedsStr(s, offset + 32, z2.add(w[1]), y.add(fetch64(s, offset + 16)));
    [z2, x] = [x, z2];
    return hashLen16(hashLen16(v[0], w[0], mul2).add(shiftMix(y).mul(k0)).add(z2), hashLen16(v[1], w[1], mul2).add(x), mul2);
  }
  var LongExports, Long, k0, k1, k2;
  var init_hash_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/hash_util.js"() {
      LongExports = __toESM(require_long());
      Long = // tslint:disable-next-line
      LongExports.default || LongExports;
      k0 = hexToLong("c3a5c85c97cb3127");
      k1 = hexToLong("b492b66fbe98f273");
      k2 = hexToLong("9ae16a3b2f90404f");
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/util.js
  var util_exports = {};
  __export(util_exports, {
    arraysEqual: () => arraysEqual,
    assert: () => assert,
    assertNonNegativeIntegerDimensions: () => assertNonNegativeIntegerDimensions,
    assertNonNull: () => assertNonNull,
    assertShapesMatch: () => assertShapesMatch,
    bytesFromStringArray: () => bytesFromStringArray,
    bytesPerElement: () => bytesPerElement,
    checkConversionForErrors: () => checkConversionForErrors,
    clamp: () => clamp,
    computeStrides: () => computeStrides,
    convertBackendValuesAndArrayBuffer: () => convertBackendValuesAndArrayBuffer,
    createScalarValue: () => createScalarValue,
    createShuffledIndices: () => createShuffledIndices,
    decodeString: () => decodeString,
    distSquared: () => distSquared,
    encodeString: () => encodeString,
    fetch: () => fetch3,
    fingerPrint64: () => fingerPrint64,
    flatten: () => flatten,
    getArrayFromDType: () => getArrayFromDType,
    getTypedArrayFromDType: () => getTypedArrayFromDType,
    hasEncodingLoss: () => hasEncodingLoss,
    hexToLong: () => hexToLong,
    indexToLoc: () => indexToLoc,
    inferDtype: () => inferDtype,
    inferFromImplicitShape: () => inferFromImplicitShape,
    isBoolean: () => isBoolean,
    isFunction: () => isFunction,
    isInt: () => isInt,
    isNumber: () => isNumber,
    isPromise: () => isPromise,
    isScalarShape: () => isScalarShape,
    isString: () => isString,
    isTypedArray: () => isTypedArray,
    isValidDtype: () => isValidDtype,
    locToIndex: () => locToIndex,
    makeOnesTypedArray: () => makeOnesTypedArray,
    makeZerosNestedTypedArray: () => makeZerosNestedTypedArray,
    makeZerosTypedArray: () => makeZerosTypedArray,
    nearestDivisor: () => nearestDivisor,
    nearestLargerEven: () => nearestLargerEven,
    now: () => now,
    parseAxisParam: () => parseAxisParam,
    randUniform: () => randUniform,
    repeatedTry: () => repeatedTry,
    rightPad: () => rightPad,
    shuffle: () => shuffle,
    shuffleCombo: () => shuffleCombo,
    sizeFromShape: () => sizeFromShape,
    sizeToSquarishShape: () => sizeToSquarishShape,
    squeezeShape: () => squeezeShape,
    sum: () => sum,
    swap: () => swap,
    tanh: () => tanh,
    toNestedArray: () => toNestedArray,
    toTypedArray: () => toTypedArray
  });
  function createScalarValue(value, dtype) {
    if (dtype === "string") {
      return encodeString(value);
    }
    return toTypedArray([value], dtype);
  }
  function noConversionNeeded(a, dtype) {
    return a instanceof Float32Array && dtype === "float32" || a instanceof Int32Array && dtype === "int32" || a instanceof Uint8Array && dtype === "bool";
  }
  function toTypedArray(a, dtype) {
    if (dtype === "string") {
      throw new Error("Cannot convert a string[] to a TypedArray");
    }
    if (Array.isArray(a)) {
      a = flatten(a);
    }
    if (env().getBool("DEBUG")) {
      checkConversionForErrors(a, dtype);
    }
    if (noConversionNeeded(a, dtype)) {
      return a;
    }
    if (dtype == null || dtype === "float32" || dtype === "complex64") {
      return new Float32Array(a);
    } else if (dtype === "int32") {
      return new Int32Array(a);
    } else if (dtype === "bool") {
      const bool = new Uint8Array(a.length);
      for (let i = 0; i < bool.length; ++i) {
        if (Math.round(a[i]) !== 0) {
          bool[i] = 1;
        }
      }
      return bool;
    } else {
      throw new Error(`Unknown data type ${dtype}`);
    }
  }
  function now() {
    return env().platform.now();
  }
  function fetch3(path, requestInits) {
    return env().platform.fetch(path, requestInits);
  }
  function encodeString(s, encoding = "utf-8") {
    encoding = encoding || "utf-8";
    return env().platform.encode(s, encoding);
  }
  function decodeString(bytes, encoding = "utf-8") {
    encoding = encoding || "utf-8";
    return env().platform.decode(bytes, encoding);
  }
  function isTypedArray(a) {
    return env().platform.isTypedArray(a);
  }
  function flatten(arr, result = [], skipTypedArray = false) {
    if (result == null) {
      result = [];
    }
    if (typeof arr === "boolean" || typeof arr === "number" || typeof arr === "string" || isPromise(arr) || arr == null || isTypedArray(arr) && skipTypedArray) {
      result.push(arr);
    } else if (Array.isArray(arr) || isTypedArray(arr)) {
      for (let i = 0; i < arr.length; ++i) {
        flatten(arr[i], result, skipTypedArray);
      }
    } else {
      let maxIndex = -1;
      for (const key of Object.keys(arr)) {
        if (/^([1-9]+[0-9]*|0)$/.test(key)) {
          maxIndex = Math.max(maxIndex, Number(key));
        }
      }
      for (let i = 0; i <= maxIndex; i++) {
        flatten(arr[i], result, skipTypedArray);
      }
    }
    return result;
  }
  var init_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/util.js"() {
      init_environment();
      init_util_base();
      init_util_base();
      init_hash_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/profiler.js
  function checkComputationForErrors(vals, dtype, kernelName) {
    if (dtype !== "float32") {
      return false;
    }
    for (let i = 0; i < vals.length; i++) {
      const num = vals[i];
      if (isNaN(num) || !isFinite(num)) {
        console.warn(`Found ${num} in the result of '${kernelName}'`);
        return true;
      }
    }
    return false;
  }
  var Profiler, Logger;
  var init_profiler = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/profiler.js"() {
      init_environment();
      init_util();
      Profiler = class {
        constructor(backendTimer, logger) {
          this.backendTimer = backendTimer;
          this.logger = logger;
          if (logger == null) {
            this.logger = new Logger();
          }
        }
        profileKernel(kernelName, inputs, f) {
          let outputs;
          const holdResultWrapperFn = () => {
            outputs = f();
          };
          let timer;
          const start = now();
          if (this.backendTimer.timerAvailable()) {
            timer = this.backendTimer.time(holdResultWrapperFn);
          } else {
            holdResultWrapperFn();
            for (const output of outputs) {
              output.dataSync();
            }
            timer = Promise.resolve({ kernelMs: now() - start });
          }
          if (env().getBool("CHECK_COMPUTATION_FOR_ERRORS")) {
            for (let i = 0; i < outputs.length; i++) {
              const output = outputs[i];
              output.data().then((tensorVals) => {
                checkComputationForErrors(tensorVals, output.dtype, kernelName);
              });
            }
          }
          const kernelProfile = {
            kernelName,
            outputs,
            inputs,
            timeMs: timer.then((timing) => timing.kernelMs),
            extraInfo: timer.then((timing) => timing.getExtraProfileInfo != null ? timing.getExtraProfileInfo() : "")
          };
          return kernelProfile;
        }
        logKernelProfile(kernelProfile) {
          const { kernelName, outputs, timeMs, inputs, extraInfo } = kernelProfile;
          outputs.forEach((result) => {
            Promise.all([result.data(), timeMs, extraInfo]).then((valueContainer) => {
              this.logger.logKernelProfile(kernelName, result, valueContainer[0], valueContainer[1], inputs, valueContainer[2]);
            });
          });
        }
      };
      Logger = class {
        logKernelProfile(name, result, vals, timeMs, inputs, extraInfo) {
          const time = typeof timeMs === "number" ? rightPad(`${timeMs}ms`, 9) : timeMs["error"];
          const paddedName = rightPad(name, 25);
          const rank = result.rank;
          const size = result.size;
          const shape = rightPad(result.shape.toString(), 14);
          let inputShapesDescription = "";
          for (const name2 in inputs) {
            const input = inputs[name2];
            if (input != null) {
              const inputShape = input.shape || result.shape;
              const inputRank = inputShape.length;
              inputShapesDescription += `${name2}: ${inputRank}D ${inputRank > 0 ? inputShape : ""} `;
            }
          }
          console.log(`%c${paddedName}	%c${time}	%c${rank}D ${shape}	%c${size}	%c${inputShapesDescription}	%c${extraInfo}`, "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/tape.js
  function getFilteredNodesXToY(tape, xs, y) {
    const tensorsFromX = {};
    const nodesFromX = {};
    for (let i = 0; i < xs.length; i++) {
      tensorsFromX[xs[i].id] = true;
    }
    for (let i = 0; i < tape.length; i++) {
      const node = tape[i];
      const nodeInputs = node.inputs;
      for (const inputName in nodeInputs) {
        const input = nodeInputs[inputName];
        let anyInputFromX = false;
        for (let j2 = 0; j2 < xs.length; j2++) {
          if (tensorsFromX[input.id]) {
            node.outputs.forEach((output) => tensorsFromX[output.id] = true);
            anyInputFromX = true;
            nodesFromX[node.id] = true;
            break;
          }
        }
        if (anyInputFromX) {
          break;
        }
      }
    }
    const tensorsLeadToY = {};
    tensorsLeadToY[y.id] = true;
    const nodesToY = {};
    for (let i = tape.length - 1; i >= 0; i--) {
      const node = tape[i];
      const nodeInputs = node.inputs;
      for (let j2 = 0; j2 < node.outputs.length; j2++) {
        if (tensorsLeadToY[node.outputs[j2].id]) {
          for (const inputName in nodeInputs) {
            tensorsLeadToY[nodeInputs[inputName].id] = true;
            nodesToY[node.id] = true;
          }
          break;
        }
      }
    }
    const filteredTape = [];
    for (let i = 0; i < tape.length; i++) {
      const node = tape[i];
      if (nodesFromX[node.id] && nodesToY[node.id]) {
        const prunedInputs = {};
        for (const inputName in node.inputs) {
          const nodeInput = node.inputs[inputName];
          if (tensorsFromX[nodeInput.id]) {
            prunedInputs[inputName] = nodeInput;
          }
        }
        const prunedNode = Object.assign({}, node);
        prunedNode.inputs = prunedInputs;
        prunedNode.outputs = node.outputs;
        filteredTape.push(prunedNode);
      }
    }
    return filteredTape;
  }
  function backpropagateGradients(tensorAccumulatedGradientMap, filteredTape, tidy2, add4) {
    for (let i = filteredTape.length - 1; i >= 0; i--) {
      const node = filteredTape[i];
      const dys = [];
      node.outputs.forEach((o) => {
        const gradTensor = tensorAccumulatedGradientMap[o.id];
        if (gradTensor != null) {
          dys.push(gradTensor);
        } else {
          dys.push(null);
        }
      });
      if (node.gradient == null) {
        throw new Error(`Cannot compute gradient: gradient function not found for ${node.kernelName}.`);
      }
      const inputGradients = node.gradient(dys);
      for (const inputName in node.inputs) {
        if (!(inputName in inputGradients)) {
          throw new Error(`Cannot backprop through input ${inputName}. Available gradients found: ${Object.keys(inputGradients)}.`);
        }
        const dx = tidy2(() => inputGradients[inputName]());
        if (dx.dtype !== "float32") {
          throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input ${inputName} must have 'float32' dtype, but has '${dx.dtype}'`);
        }
        const x = node.inputs[inputName];
        if (!arraysEqual(dx.shape, x.shape)) {
          throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input '${inputName}' has shape '${dx.shape}', which does not match the shape of the input '${x.shape}'`);
        }
        if (tensorAccumulatedGradientMap[x.id] == null) {
          tensorAccumulatedGradientMap[x.id] = dx;
        } else {
          const curGradient = tensorAccumulatedGradientMap[x.id];
          tensorAccumulatedGradientMap[x.id] = add4(curGradient, dx);
          curGradient.dispose();
        }
      }
    }
  }
  var init_tape = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/tape.js"() {
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/tensor_format.js
  function tensorToString(vals, shape, dtype, verbose) {
    const strides = computeStrides(shape);
    const padPerCol = computeMaxSizePerColumn(vals, shape, dtype, strides);
    const rank = shape.length;
    const valsLines = subTensorToString(vals, shape, dtype, strides, padPerCol);
    const lines = ["Tensor"];
    if (verbose) {
      lines.push(`  dtype: ${dtype}`);
      lines.push(`  rank: ${rank}`);
      lines.push(`  shape: [${shape}]`);
      lines.push(`  values:`);
    }
    lines.push(valsLines.map((l) => "    " + l).join("\n"));
    return lines.join("\n");
  }
  function computeMaxSizePerColumn(vals, shape, dtype, strides) {
    const n = sizeFromShape(shape);
    const numCols = strides[strides.length - 1];
    const padPerCol = new Array(numCols).fill(0);
    const rank = shape.length;
    const valuesOrTuples = dtype === "complex64" ? createComplexTuples(vals) : vals;
    if (rank > 1) {
      for (let row = 0; row < n / numCols; row++) {
        const offset = row * numCols;
        for (let j2 = 0; j2 < numCols; j2++) {
          padPerCol[j2] = Math.max(padPerCol[j2], valToString(valuesOrTuples[offset + j2], 0, dtype).length);
        }
      }
    }
    return padPerCol;
  }
  function valToString(val, pad2, dtype) {
    let valStr;
    if (Array.isArray(val)) {
      valStr = `${parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS))} + ${parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS))}j`;
    } else if (isString(val)) {
      valStr = `'${val}'`;
    } else if (dtype === "bool") {
      valStr = boolNumToString(val);
    } else {
      valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString();
    }
    return rightPad(valStr, pad2);
  }
  function boolNumToString(v) {
    return v === 0 ? "false" : "true";
  }
  function subTensorToString(vals, shape, dtype, strides, padPerCol, isLast = true) {
    const storagePerElement = dtype === "complex64" ? 2 : 1;
    const size = shape[0];
    const rank = shape.length;
    if (rank === 0) {
      if (dtype === "complex64") {
        const complexTuple = createComplexTuples(vals);
        return [valToString(complexTuple[0], 0, dtype)];
      }
      if (dtype === "bool") {
        return [boolNumToString(vals[0])];
      }
      return [vals[0].toString()];
    }
    if (rank === 1) {
      if (size > FORMAT_LIMIT_NUM_VALS) {
        const firstValsSize = FORMAT_NUM_FIRST_LAST_VALS * storagePerElement;
        let firstVals = Array.from(vals.slice(0, firstValsSize));
        let lastVals = Array.from(vals.slice((size - FORMAT_NUM_FIRST_LAST_VALS) * storagePerElement, size * storagePerElement));
        if (dtype === "complex64") {
          firstVals = createComplexTuples(firstVals);
          lastVals = createComplexTuples(lastVals);
        }
        return [
          "[" + firstVals.map((x, i) => valToString(x, padPerCol[i], dtype)).join(", ") + ", ..., " + lastVals.map((x, i) => valToString(x, padPerCol[size - FORMAT_NUM_FIRST_LAST_VALS + i], dtype)).join(", ") + "]"
        ];
      }
      const displayVals = dtype === "complex64" ? createComplexTuples(vals) : Array.from(vals);
      return [
        "[" + displayVals.map((x, i) => valToString(x, padPerCol[i], dtype)).join(", ") + "]"
      ];
    }
    const subshape = shape.slice(1);
    const substrides = strides.slice(1);
    const stride = strides[0] * storagePerElement;
    const lines = [];
    if (size > FORMAT_LIMIT_NUM_VALS) {
      for (let i = 0; i < FORMAT_NUM_FIRST_LAST_VALS; i++) {
        const start = i * stride;
        const end = start + stride;
        lines.push(...subTensorToString(
          vals.slice(start, end),
          subshape,
          dtype,
          substrides,
          padPerCol,
          false
          /* isLast */
        ));
      }
      lines.push("...");
      for (let i = size - FORMAT_NUM_FIRST_LAST_VALS; i < size; i++) {
        const start = i * stride;
        const end = start + stride;
        lines.push(...subTensorToString(
          vals.slice(start, end),
          subshape,
          dtype,
          substrides,
          padPerCol,
          i === size - 1
          /* isLast */
        ));
      }
    } else {
      for (let i = 0; i < size; i++) {
        const start = i * stride;
        const end = start + stride;
        lines.push(...subTensorToString(
          vals.slice(start, end),
          subshape,
          dtype,
          substrides,
          padPerCol,
          i === size - 1
          /* isLast */
        ));
      }
    }
    const sep = rank === 2 ? "," : "";
    lines[0] = "[" + (size > 0 ? lines[0] + sep : "");
    for (let i = 1; i < lines.length - 1; i++) {
      lines[i] = " " + lines[i] + sep;
    }
    let newLineSep = ",\n";
    for (let i = 2; i < rank; i++) {
      newLineSep += "\n";
    }
    lines[lines.length - 1] = " " + lines[lines.length - 1] + "]" + (isLast ? "" : newLineSep);
    return lines;
  }
  function createComplexTuples(vals) {
    const complexTuples = [];
    for (let i = 0; i < vals.length; i += 2) {
      complexTuples.push([vals[i], vals[i + 1]]);
    }
    return complexTuples;
  }
  var FORMAT_LIMIT_NUM_VALS, FORMAT_NUM_FIRST_LAST_VALS, FORMAT_NUM_SIG_DIGITS;
  var init_tensor_format = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/tensor_format.js"() {
      init_util();
      FORMAT_LIMIT_NUM_VALS = 20;
      FORMAT_NUM_FIRST_LAST_VALS = 3;
      FORMAT_NUM_SIG_DIGITS = 7;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/tensor.js
  function setTensorTracker(fn) {
    trackerFn = fn;
  }
  function setOpHandler(handler) {
    opHandler = handler;
  }
  function setDeprecationWarningFn(fn) {
    deprecationWarningFn = fn;
  }
  function getGlobalTensorClass() {
    return getGlobal("Tensor", () => {
      return Tensor;
    });
  }
  var TensorBuffer, trackerFn, opHandler, deprecationWarningFn, Tensor, Variable;
  var init_tensor = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/tensor.js"() {
      init_global_util();
      init_tensor_format();
      init_util();
      init_util();
      TensorBuffer = class {
        constructor(shape, dtype, values) {
          this.dtype = dtype;
          this.shape = shape.slice();
          this.size = sizeFromShape(shape);
          if (values != null) {
            const n = values.length;
            assert(n === this.size, () => `Length of values '${n}' does not match the size inferred by the shape '${this.size}'.`);
          }
          if (dtype === "complex64") {
            throw new Error(`complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).`);
          }
          this.values = values || getArrayFromDType(dtype, this.size);
          this.strides = computeStrides(shape);
        }
        /**
         * Sets a value in the buffer at a given location.
         *
         * @param value The value to set.
         * @param locs  The location indices.
         *
         * @doc {heading: 'Tensors', subheading: 'Creation'}
         */
        set(value, ...locs) {
          if (locs.length === 0) {
            locs = [0];
          }
          assert(locs.length === this.rank, () => `The number of provided coordinates (${locs.length}) must match the rank (${this.rank})`);
          const index = this.locToIndex(locs);
          this.values[index] = value;
        }
        /**
         * Returns the value in the buffer at the provided location.
         *
         * @param locs The location indices.
         *
         * @doc {heading: 'Tensors', subheading: 'Creation'}
         */
        get(...locs) {
          if (locs.length === 0) {
            locs = [0];
          }
          let i = 0;
          for (const loc of locs) {
            if (loc < 0 || loc >= this.shape[i]) {
              const msg = `Requested out of range element at ${locs}.   Buffer shape=${this.shape}`;
              throw new Error(msg);
            }
            i++;
          }
          let index = locs[locs.length - 1];
          for (let i2 = 0; i2 < locs.length - 1; ++i2) {
            index += this.strides[i2] * locs[i2];
          }
          return this.values[index];
        }
        locToIndex(locs) {
          if (this.rank === 0) {
            return 0;
          } else if (this.rank === 1) {
            return locs[0];
          }
          let index = locs[locs.length - 1];
          for (let i = 0; i < locs.length - 1; ++i) {
            index += this.strides[i] * locs[i];
          }
          return index;
        }
        indexToLoc(index) {
          if (this.rank === 0) {
            return [];
          } else if (this.rank === 1) {
            return [index];
          }
          const locs = new Array(this.shape.length);
          for (let i = 0; i < locs.length - 1; ++i) {
            locs[i] = Math.floor(index / this.strides[i]);
            index -= locs[i] * this.strides[i];
          }
          locs[locs.length - 1] = index;
          return locs;
        }
        get rank() {
          return this.shape.length;
        }
        /**
         * Creates an immutable `tf.Tensor` object from the buffer.
         *
         * @doc {heading: 'Tensors', subheading: 'Creation'}
         */
        toTensor() {
          return trackerFn().makeTensor(this.values, this.shape, this.dtype);
        }
      };
      trackerFn = null;
      opHandler = null;
      deprecationWarningFn = null;
      Tensor = class {
        constructor(shape, dtype, dataId, id) {
          this.kept = false;
          this.isDisposedInternal = false;
          this.shape = shape.slice();
          this.dtype = dtype || "float32";
          this.size = sizeFromShape(shape);
          this.strides = computeStrides(shape);
          this.dataId = dataId;
          this.id = id;
          this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
        }
        get rank() {
          return this.shape.length;
        }
        /**
         * Returns a promise of `tf.TensorBuffer` that holds the underlying data.
         *
         * @doc {heading: 'Tensors', subheading: 'Classes'}
         */
        buffer() {
          return __async(this, null, function* () {
            const vals = yield this.data();
            return opHandler.buffer(this.shape, this.dtype, vals);
          });
        }
        /**
         * Returns a `tf.TensorBuffer` that holds the underlying data.
         * @doc {heading: 'Tensors', subheading: 'Classes'}
         */
        bufferSync() {
          return opHandler.buffer(this.shape, this.dtype, this.dataSync());
        }
        /**
         * Returns the tensor data as a nested array. The transfer of data is done
         * asynchronously.
         *
         * @doc {heading: 'Tensors', subheading: 'Classes'}
         */
        array() {
          return __async(this, null, function* () {
            const vals = yield this.data();
            return toNestedArray(this.shape, vals, this.dtype === "complex64");
          });
        }
        /**
         * Returns the tensor data as a nested array. The transfer of data is done
         * synchronously.
         *
         * @doc {heading: 'Tensors', subheading: 'Classes'}
         */
        arraySync() {
          return toNestedArray(this.shape, this.dataSync(), this.dtype === "complex64");
        }
        /**
         * Asynchronously downloads the values from the `tf.Tensor`. Returns a
         * promise of `TypedArray` that resolves when the computation has finished.
         *
         * @doc {heading: 'Tensors', subheading: 'Classes'}
         */
        data() {
          return __async(this, null, function* () {
            this.throwIfDisposed();
            const data = trackerFn().read(this.dataId);
            if (this.dtype === "string") {
              const bytes = yield data;
              try {
                return bytes.map((b) => decodeString(b));
              } catch (_a) {
                throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
              }
            }
            return data;
          });
        }
        /**
         * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`
         * and `data()`, this method prevents data from being downloaded to CPU.
         *
         * For WebGL backend, the data will be stored on a densely packed texture.
         * This means that the texture will use the RGBA channels to store value.
         *
         * For WebGPU backend, the data will be stored on a buffer. There is no
         * parameter, so can not use a user-defined size to create the buffer.
         *
         * @param options:
         *     For WebGL,
         *         - customTexShape: Optional. If set, will use the user defined
         *     texture shape to create the texture.
         *
         * @returns For WebGL backend, a GPUData contains the new texture and
         *     its information.
         *     {
         *        tensorRef: The tensor that is associated with this texture,
         *        texture: WebGLTexture,
         *        texShape: [number, number] // [height, width]
         *     }
         *
         *     For WebGPU backend, a GPUData contains the new buffer and
         *     its information.
         *     {
         *        tensorRef: The tensor that is associated with this buffer,
         *        buffer: GPUBuffer,
         *        bufSize: number
         *     }
         *
         *     Remember to dispose the GPUData after it is used by
         *     `res.tensorRef.dispose()`.
         *
         * @doc {heading: 'Tensors', subheading: 'Classes'}
         */
        dataToGPU(options) {
          this.throwIfDisposed();
          return trackerFn().readToGPU(this.dataId, options);
        }
        /**
         * Synchronously downloads the values from the `tf.Tensor`. This blocks the
         * UI thread until the values are ready, which can cause performance issues.
         *
         * @doc {heading: 'Tensors', subheading: 'Classes'}
         */
        dataSync() {
          this.throwIfDisposed();
          const data = trackerFn().readSync(this.dataId);
          if (this.dtype === "string") {
            try {
              return data.map((b) => decodeString(b));
            } catch (_a) {
              throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
            }
          }
          return data;
        }
        /** Returns the underlying bytes of the tensor's data. */
        bytes() {
          return __async(this, null, function* () {
            this.throwIfDisposed();
            const data = yield trackerFn().read(this.dataId);
            if (this.dtype === "string") {
              return data;
            } else {
              return new Uint8Array(data.buffer);
            }
          });
        }
        /**
         * Disposes `tf.Tensor` from memory.
         *
         * @doc {heading: 'Tensors', subheading: 'Classes'}
         */
        dispose() {
          if (this.isDisposed) {
            return;
          }
          trackerFn().disposeTensor(this);
          this.isDisposedInternal = true;
        }
        get isDisposed() {
          return this.isDisposedInternal;
        }
        throwIfDisposed() {
          if (this.isDisposed) {
            throw new Error(`Tensor is disposed.`);
          }
        }
        /**
         * Prints the `tf.Tensor`. See `tf.print` for details.
         *
         * @param verbose Whether to print verbose information about the tensor,
         *    including dtype and size.
         *
         * @doc {heading: 'Tensors', subheading: 'Classes'}
         */
        print(verbose = false) {
          return opHandler.print(this, verbose);
        }
        /**
         * Returns a copy of the tensor. See `tf.clone` for details.
         * @doc {heading: 'Tensors', subheading: 'Classes'}
         */
        clone() {
          this.throwIfDisposed();
          return opHandler.clone(this);
        }
        /**
         * Returns a human-readable description of the tensor. Useful for logging.
         *
         * @doc {heading: 'Tensors', subheading: 'Classes'}
         */
        toString(verbose = false) {
          const vals = this.dataSync();
          return tensorToString(vals, this.shape, this.dtype, verbose);
        }
        cast(dtype) {
          this.throwIfDisposed();
          return opHandler.cast(this, dtype);
        }
        variable(trainable = true, name, dtype) {
          this.throwIfDisposed();
          return trackerFn().makeVariable(this, trainable, name, dtype);
        }
      };
      Object.defineProperty(Tensor, Symbol.hasInstance, {
        value: (instance) => {
          return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;
        }
      });
      getGlobalTensorClass();
      Variable = class extends Tensor {
        constructor(initialValue, trainable, name, tensorId) {
          super(initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);
          this.trainable = trainable;
          this.name = name;
        }
        /**
         * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have
         * the same shape and dtype as the old `tf.Tensor`.
         *
         * @param newValue New tensor to be assigned to this variable.
         *
         * @doc {heading: 'Tensors', subheading: 'Classes'}
         */
        assign(newValue) {
          if (newValue.dtype !== this.dtype) {
            throw new Error(`dtype of the new value (${newValue.dtype}) and previous value (${this.dtype}) must match`);
          }
          if (!arraysEqual(newValue.shape, this.shape)) {
            throw new Error(`shape of the new value (${newValue.shape}) and previous value (${this.shape}) must match`);
          }
          trackerFn().disposeTensor(this);
          this.dataId = newValue.dataId;
          trackerFn().incRef(
            this,
            null
            /* backend */
          );
        }
        dispose() {
          trackerFn().disposeVariable(this);
          this.isDisposedInternal = true;
        }
      };
      Object.defineProperty(Variable, Symbol.hasInstance, {
        value: (instance) => {
          return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;
        }
      });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/types.js
  function upcastType(typeA, typeB) {
    if (typeA === "string" || typeB === "string") {
      if (typeA === "string" && typeB === "string") {
        return "string";
      }
      throw new Error(`Can not upcast ${typeA} with ${typeB}`);
    }
    return upcastTypeMap[typeA][typeB];
  }
  var Rank, UpcastInt32AndMap, UpcastBoolAndMap, UpcastFloat32AndMap, UpcastComplex64AndMap, upcastTypeMap;
  var init_types = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/types.js"() {
      (function(Rank2) {
        Rank2["R0"] = "R0";
        Rank2["R1"] = "R1";
        Rank2["R2"] = "R2";
        Rank2["R3"] = "R3";
        Rank2["R4"] = "R4";
        Rank2["R5"] = "R5";
        Rank2["R6"] = "R6";
      })(Rank || (Rank = {}));
      (function(UpcastInt32AndMap2) {
        UpcastInt32AndMap2["float32"] = "float32";
        UpcastInt32AndMap2["int32"] = "int32";
        UpcastInt32AndMap2["bool"] = "int32";
        UpcastInt32AndMap2["complex64"] = "complex64";
      })(UpcastInt32AndMap || (UpcastInt32AndMap = {}));
      (function(UpcastBoolAndMap2) {
        UpcastBoolAndMap2["float32"] = "float32";
        UpcastBoolAndMap2["int32"] = "int32";
        UpcastBoolAndMap2["bool"] = "bool";
        UpcastBoolAndMap2["complex64"] = "complex64";
      })(UpcastBoolAndMap || (UpcastBoolAndMap = {}));
      (function(UpcastFloat32AndMap2) {
        UpcastFloat32AndMap2["float32"] = "float32";
        UpcastFloat32AndMap2["int32"] = "float32";
        UpcastFloat32AndMap2["bool"] = "float32";
        UpcastFloat32AndMap2["complex64"] = "complex64";
      })(UpcastFloat32AndMap || (UpcastFloat32AndMap = {}));
      (function(UpcastComplex64AndMap2) {
        UpcastComplex64AndMap2["float32"] = "complex64";
        UpcastComplex64AndMap2["int32"] = "complex64";
        UpcastComplex64AndMap2["bool"] = "complex64";
        UpcastComplex64AndMap2["complex64"] = "complex64";
      })(UpcastComplex64AndMap || (UpcastComplex64AndMap = {}));
      upcastTypeMap = {
        "float32": UpcastFloat32AndMap,
        "int32": UpcastInt32AndMap,
        "bool": UpcastBoolAndMap,
        "complex64": UpcastComplex64AndMap
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/tensor_util.js
  function makeTypesMatch(a, b) {
    if (a.dtype === b.dtype) {
      return [a, b];
    }
    const dtype = upcastType(a.dtype, b.dtype);
    return [a.cast(dtype), b.cast(dtype)];
  }
  function assertTypesMatch(a, b) {
    assert(a.dtype === b.dtype, () => `The dtypes of the first(${a.dtype}) and second(${b.dtype}) input must match`);
  }
  function getTensorsInContainer(result) {
    const list = [];
    const seen = /* @__PURE__ */ new Set();
    walkTensorContainer(result, list, seen);
    return list;
  }
  function walkTensorContainer(container, list, seen) {
    if (container == null) {
      return;
    }
    if (container instanceof Tensor) {
      list.push(container);
      return;
    }
    if (!isIterable(container)) {
      return;
    }
    const iterable = container;
    for (const k3 in iterable) {
      const val = iterable[k3];
      if (!seen.has(val)) {
        seen.add(val);
        walkTensorContainer(val, list, seen);
      }
    }
  }
  function isIterable(obj) {
    return Array.isArray(obj) || typeof obj === "object";
  }
  var init_tensor_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/tensor_util.js"() {
      init_tensor();
      init_types();
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/engine.js
  function isRegisteredKernelInvocation(kernelInvocation) {
    return kernelInvocation.kernelName != null;
  }
  function ones(shape) {
    const values = makeOnesTypedArray(sizeFromShape(shape), "float32");
    return ENGINE.makeTensor(values, shape, "float32");
  }
  function getOrMakeEngine() {
    const ns = getGlobalNamespace();
    if (ns._tfengine == null) {
      const environment = new Environment(ns);
      ns._tfengine = new Engine(environment);
    }
    setEnvironmentGlobal(ns._tfengine.ENV);
    setTensorTracker(() => ns._tfengine);
    return ns._tfengine;
  }
  function add(a, b) {
    const inputs = { a, b };
    return ENGINE.runKernel(Add, inputs);
  }
  var EngineState, Engine, ENGINE;
  var init_engine = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/engine.js"() {
      init_backend();
      init_environment();
      init_global_util();
      init_kernel_names();
      init_kernel_registry();
      init_log();
      init_profiler();
      init_tape();
      init_tensor();
      init_tensor_util();
      init_util();
      init_util();
      EngineState = class {
        constructor() {
          this.registeredVariables = {};
          this.nextTapeNodeId = 0;
          this.numBytes = 0;
          this.numTensors = 0;
          this.numStringTensors = 0;
          this.numDataBuffers = 0;
          this.gradientDepth = 0;
          this.kernelDepth = 0;
          this.scopeStack = [];
          this.numDataMovesStack = [];
          this.nextScopeId = 0;
          this.tensorInfo = /* @__PURE__ */ new WeakMap();
          this.profiling = false;
          this.activeProfile = {
            newBytes: 0,
            newTensors: 0,
            peakBytes: 0,
            kernels: [],
            result: null,
            get kernelNames() {
              return Array.from(new Set(this.kernels.map((k3) => k3.name)));
            }
          };
        }
        dispose() {
          for (const variableName in this.registeredVariables) {
            this.registeredVariables[variableName].dispose();
          }
        }
      };
      Engine = class {
        constructor(ENV4) {
          this.ENV = ENV4;
          this.registry = {};
          this.registryFactory = {};
          this.pendingBackendInitId = 0;
          this.state = new EngineState();
        }
        ready() {
          return __async(this, null, function* () {
            if (this.pendingBackendInit != null) {
              return this.pendingBackendInit.then(() => {
              });
            }
            if (this.backendInstance != null) {
              return;
            }
            const sortedBackends = this.getSortedBackends();
            for (let i = 0; i < sortedBackends.length; i++) {
              const backendName = sortedBackends[i];
              const success = yield this.initializeBackend(backendName).success;
              if (success) {
                yield this.setBackend(backendName);
                return;
              }
            }
            throw new Error(`Could not initialize any backends, all backend initializations failed.`);
          });
        }
        get backend() {
          if (this.pendingBackendInit != null) {
            throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
          }
          if (this.backendInstance == null) {
            const { name, asyncInit } = this.initializeBackendsAndReturnBest();
            if (asyncInit) {
              throw new Error(`The highest priority backend '${name}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
            }
            this.setBackend(name);
          }
          return this.backendInstance;
        }
        backendNames() {
          return Object.keys(this.registryFactory);
        }
        findBackend(backendName) {
          if (!(backendName in this.registry)) {
            if (backendName in this.registryFactory) {
              const { asyncInit } = this.initializeBackend(backendName);
              if (asyncInit) {
                return null;
              }
            } else {
              return null;
            }
          }
          return this.registry[backendName];
        }
        findBackendFactory(backendName) {
          if (!(backendName in this.registryFactory)) {
            return null;
          }
          return this.registryFactory[backendName].factory;
        }
        registerBackend(backendName, factory, priority = 1) {
          if (backendName in this.registryFactory) {
            warn(`${backendName} backend was already registered. Reusing existing backend factory.`);
            return false;
          }
          this.registryFactory[backendName] = { factory, priority };
          return true;
        }
        setBackend(backendName) {
          return __async(this, null, function* () {
            if (this.registryFactory[backendName] == null) {
              throw new Error(`Backend name '${backendName}' not found in registry`);
            }
            this.backendName = backendName;
            if (this.registry[backendName] == null) {
              this.backendInstance = null;
              const { success, asyncInit } = this.initializeBackend(backendName);
              const result = asyncInit ? yield success : success;
              if (!result) {
                return false;
              }
            }
            this.backendInstance = this.registry[backendName];
            this.setupRegisteredKernels();
            this.profiler = new Profiler(this.backendInstance);
            return true;
          });
        }
        setupRegisteredKernels() {
          const kernels = getKernelsForBackend(this.backendName);
          kernels.forEach((kernel) => {
            if (kernel.setupFunc != null) {
              kernel.setupFunc(this.backendInstance);
            }
          });
        }
        disposeRegisteredKernels(backendName) {
          const kernels = getKernelsForBackend(backendName);
          kernels.forEach((kernel) => {
            if (kernel.disposeFunc != null) {
              kernel.disposeFunc(this.registry[backendName]);
            }
          });
        }
        /**
         * Initializes a backend by looking up the backend name in the factory
         * registry and calling the factory method. Returns a boolean representing
         * whether the initialization of the backend suceeded. Throws an error if
         * there is no backend in the factory registry.
         */
        initializeBackend(backendName) {
          const registryFactoryEntry = this.registryFactory[backendName];
          if (registryFactoryEntry == null) {
            throw new Error(`Cannot initialize backend ${backendName}, no registration found.`);
          }
          try {
            const backend = registryFactoryEntry.factory();
            if (backend && !(backend instanceof KernelBackend) && typeof backend.then === "function") {
              const promiseId = ++this.pendingBackendInitId;
              const success = backend.then((backendInstance) => {
                if (promiseId < this.pendingBackendInitId) {
                  return false;
                }
                this.registry[backendName] = backendInstance;
                this.pendingBackendInit = null;
                return true;
              }).catch((err) => {
                if (promiseId < this.pendingBackendInitId) {
                  return false;
                }
                this.pendingBackendInit = null;
                warn(`Initialization of backend ${backendName} failed`);
                warn(err.stack || err.message);
                return false;
              });
              this.pendingBackendInit = success;
              return { success, asyncInit: true };
            } else {
              this.registry[backendName] = backend;
              return { success: true, asyncInit: false };
            }
          } catch (err) {
            warn(`Initialization of backend ${backendName} failed`);
            warn(err.stack || err.message);
            return { success: false, asyncInit: false };
          }
        }
        removeBackend(backendName) {
          if (!(backendName in this.registryFactory)) {
            throw new Error(`${backendName} backend not found in registry`);
          }
          if (this.backendName === backendName && this.pendingBackendInit != null) {
            this.pendingBackendInitId++;
          }
          if (backendName in this.registry) {
            this.disposeRegisteredKernels(backendName);
            this.registry[backendName].dispose();
            delete this.registry[backendName];
          }
          delete this.registryFactory[backendName];
          if (this.backendName === backendName) {
            this.pendingBackendInit = null;
            this.backendName = null;
            this.backendInstance = null;
          }
        }
        getSortedBackends() {
          if (Object.keys(this.registryFactory).length === 0) {
            throw new Error("No backend found in registry.");
          }
          return Object.keys(this.registryFactory).sort((a, b) => {
            return this.registryFactory[b].priority - this.registryFactory[a].priority;
          });
        }
        initializeBackendsAndReturnBest() {
          const sortedBackends = this.getSortedBackends();
          for (let i = 0; i < sortedBackends.length; i++) {
            const backendName = sortedBackends[i];
            const { success, asyncInit } = this.initializeBackend(backendName);
            if (asyncInit || success) {
              return { name: backendName, asyncInit };
            }
          }
          throw new Error(`Could not initialize any backends, all backend initializations failed.`);
        }
        moveData(backend, dataId) {
          const info = this.state.tensorInfo.get(dataId);
          const srcBackend = info.backend;
          const values = this.readSync(dataId);
          const refCount = srcBackend.refCount(dataId);
          srcBackend.disposeData(dataId, true);
          info.backend = backend;
          backend.move(dataId, values, info.shape, info.dtype, refCount);
          if (this.shouldCheckForMemLeaks()) {
            this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
          }
        }
        tidy(nameOrFn, fn) {
          let name = null;
          if (fn == null) {
            if (typeof nameOrFn !== "function") {
              throw new Error("Please provide a function to tidy()");
            }
            fn = nameOrFn;
          } else {
            if (typeof nameOrFn !== "string" && !(nameOrFn instanceof String)) {
              throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
            }
            if (typeof fn !== "function") {
              throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
            }
            name = nameOrFn;
          }
          let result;
          return this.scopedRun(() => this.startScope(name), () => this.endScope(result), () => {
            result = fn();
            if (result instanceof Promise) {
              console.error("Cannot return a Promise inside of tidy.");
            }
            return result;
          });
        }
        scopedRun(start, end, f) {
          start();
          try {
            const res = f();
            end();
            return res;
          } catch (ex) {
            end();
            throw ex;
          }
        }
        nextTensorId() {
          return Engine.nextTensorId++;
        }
        nextVariableId() {
          return Engine.nextVariableId++;
        }
        /**
         * This method is called instead of the public-facing tensor.clone() when
         * saving a tensor for backwards pass. It makes sure to add the clone
         * operation to the tape regardless of being called inside a kernel
         * execution.
         */
        clone(x) {
          const y = ENGINE.runKernel(Identity, { x });
          const inputs = { x };
          const grad = (dy) => ({
            x: () => {
              const dtype = "float32";
              const gradInputs = { x: dy };
              const attrs = { dtype };
              return ENGINE.runKernel(
                Cast,
                gradInputs,
                // tslint:disable-next-line: no-unnecessary-type-assertion
                attrs
              );
            }
          });
          const saved = [];
          this.addTapeNode(this.state.activeScope.name, inputs, [y], grad, saved, {});
          return y;
        }
        /**
         * Execute a kernel with the given name and return the output tensor.
         *
         * @param kernelName The name of the kernel to execute.
         * @param inputs A map of input names to tensors.
         * @param attrs A map of attribute names to their values. An attribute is a
         *     primitive (non-tensor) input to the kernel.
         * @param inputsToSave A list of tensors, inputs to save for the backprop
         *     computation.
         * @param outputsToSave A list of booleans, specifying which output to save
         *     for the backprop computation. These are booleans since the output
         * tensors are not visible to the user.
         */
        runKernel(kernelName, inputs, attrs) {
          if (this.backendName == null) {
            this.backend;
          }
          const hasKernel = getKernel(kernelName, this.backendName) != null;
          if (!hasKernel) {
            throw new Error(`Kernel '${kernelName}' not registered for backend '${this.backendName}'`);
          }
          return this.runKernelFunc({ kernelName, inputs, attrs });
        }
        shouldCheckForMemLeaks() {
          return this.ENV.getBool("IS_TEST");
        }
        checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos) {
          const numDataIdsAfter = this.backend.numDataIds();
          let numOutputDataIds = 0;
          outInfos.forEach((info) => {
            numOutputDataIds += info.dtype === "complex64" ? 3 : 1;
          });
          const numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];
          const dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;
          if (dataIdsLeaked > 0) {
            throw new Error(`Backend '${this.backendName}' has an internal memory leak (${dataIdsLeaked} data ids) after running '${kernelName}'`);
          }
        }
        /**
         * Internal helper method to execute a kernel Func
         *
         * Use `runKernel` to execute kernels from outside of engine.
         */
        runKernelFunc(kernelParams) {
          let outputs;
          let saved = [];
          const isTapeOn = this.isTapeOn();
          const startingBytecount = this.state.numBytes;
          const startingNumTensors = this.state.numTensors;
          if (this.shouldCheckForMemLeaks()) {
            this.state.numDataMovesStack.push(0);
          }
          let kernelFunc;
          if (this.backendName == null) {
            this.backend;
          }
          let out;
          const kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ? kernelParams.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
          if (isRegisteredKernelInvocation(kernelParams)) {
            const { kernelName, inputs: inputs2, attrs: attrs2 } = kernelParams;
            if (this.backendName == null) {
              this.backend;
            }
            const kernel = getKernel(kernelName, this.backendName);
            assert(kernel != null, () => `Cannot find registered kernel '${kernelName}' for backend '${this.backendName}'`);
            kernelFunc = () => {
              const numDataIdsBefore = this.backend.numDataIds();
              out = kernel.kernelFunc({ inputs: inputs2, attrs: attrs2, backend: this.backend });
              const outInfos = Array.isArray(out) ? out : [out];
              if (this.shouldCheckForMemLeaks()) {
                this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);
              }
              const outTensors = outInfos.map((outInfo) => {
                if (outInfo.rank != null) {
                  return outInfo;
                }
                return this.makeTensorFromTensorInfo(outInfo);
              });
              if (isTapeOn) {
                const tensorsToSave = this.getTensorsForGradient(kernelName, inputs2, outTensors);
                saved = this.saveTensorsForBackwardMode(tensorsToSave);
              }
              return outTensors;
            };
          } else {
            const { forwardFunc } = kernelParams;
            const saveFunc = (tensors) => {
              if (!isTapeOn) {
                return;
              }
              saved = tensors.map((tensor2) => this.keep(this.clone(tensor2)));
            };
            kernelFunc = () => {
              const numDataIdsBefore = this.backend.numDataIds();
              out = this.tidy(() => forwardFunc(this.backend, saveFunc));
              const outs = Array.isArray(out) ? out : [out];
              if (this.shouldCheckForMemLeaks()) {
                this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);
              }
              return outs;
            };
          }
          const { inputs, attrs } = kernelParams;
          const backwardsFunc = isRegisteredKernelInvocation(kernelParams) ? null : kernelParams.backwardsFunc;
          let kernelProfile;
          this.scopedRun(
            // Stop recording to a tape when running a kernel.
            () => this.state.kernelDepth++,
            () => this.state.kernelDepth--,
            () => {
              if (!this.ENV.getBool("DEBUG") && !this.state.profiling) {
                outputs = kernelFunc();
              } else {
                kernelProfile = this.profiler.profileKernel(kernelOrScopeName, inputs, () => kernelFunc());
                if (this.ENV.getBool("DEBUG")) {
                  this.profiler.logKernelProfile(kernelProfile);
                }
                outputs = kernelProfile.outputs;
              }
            }
          );
          if (isTapeOn) {
            this.addTapeNode(kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);
          }
          if (this.state.profiling) {
            this.state.activeProfile.kernels.push({
              name: kernelOrScopeName,
              bytesAdded: this.state.numBytes - startingBytecount,
              totalBytesSnapshot: this.state.numBytes,
              tensorsAdded: this.state.numTensors - startingNumTensors,
              totalTensorsSnapshot: this.state.numTensors,
              inputShapes: Object.keys(inputs).map((key) => inputs[key] != null ? inputs[key].shape : null),
              outputShapes: outputs.map((item) => item.shape),
              kernelTimeMs: kernelProfile.timeMs,
              extraInfo: kernelProfile.extraInfo
            });
          }
          return Array.isArray(out) ? outputs : outputs[0];
        }
        /**
         * Saves tensors used in forward mode for use in backward mode.
         *
         * @param tensors the list of tensors to save.
         */
        saveTensorsForBackwardMode(tensors) {
          const saved = tensors.map((tensor2) => this.keep(this.clone(tensor2)));
          return saved;
        }
        /**
         * Returns a list of tensors to save for a given gradient calculation.
         *
         * @param kernelName name of kernel to look up gradient for.
         * @param inputs a map of input tensors.
         * @param outputs an array of output tensors from forward mode of kernel.
         */
        getTensorsForGradient(kernelName, inputs, outputs) {
          const gradConfig = getGradient(kernelName);
          if (gradConfig != null) {
            const inputsToSave = gradConfig.inputsToSave || [];
            const outputsToSave = gradConfig.outputsToSave || [];
            let inputTensorsToSave;
            if (gradConfig.saveAllInputs) {
              assert(Array.isArray(inputs), () => "saveAllInputs is true, expected inputs to be an array.");
              inputTensorsToSave = Object.keys(inputs).map((key) => inputs[key]);
            } else {
              inputTensorsToSave = inputsToSave.map((inputName) => inputs[inputName]);
            }
            const outputTensorsToSave = outputs.filter((_2, i) => outputsToSave[i]);
            return inputTensorsToSave.concat(outputTensorsToSave);
          }
          return [];
        }
        /**
         * Internal method used by public APIs for tensor creation. Makes a new
         * tensor with the provided shape, dtype and values. It always
         * creates a new data id and writes the values to the underlying backend.
         */
        makeTensor(values, shape, dtype, backend) {
          if (values == null) {
            throw new Error("Values passed to engine.makeTensor() are null");
          }
          dtype = dtype || "float32";
          backend = backend || this.backend;
          let backendVals = values;
          if (dtype === "string" && isString(values[0])) {
            backendVals = values.map((d) => encodeString(d));
          }
          const dataId = backend.write(backendVals, shape, dtype);
          const t2 = new Tensor(shape, dtype, dataId, this.nextTensorId());
          this.trackTensor(t2, backend);
          if (dtype === "string") {
            const info = this.state.tensorInfo.get(dataId);
            const newBytes = bytesFromStringArray(backendVals);
            this.state.numBytes += newBytes - info.bytes;
            info.bytes = newBytes;
          }
          return t2;
        }
        /**
         * Internal method used by backends. Makes a new tensor
         * that is a wrapper around an existing data id. It doesn't create
         * a new data id, only increments the ref count used in memory tracking.
         * @deprecated
         */
        makeTensorFromDataId(dataId, shape, dtype, backend) {
          dtype = dtype || "float32";
          const tensorInfo = { dataId, shape, dtype };
          return this.makeTensorFromTensorInfo(tensorInfo, backend);
        }
        /**
         * Internal method used by backends. Makes a new tensor that is a wrapper
         * around an existing data id in TensorInfo. It doesn't create a new data id,
         * only increments the ref count used in memory tracking.
         */
        makeTensorFromTensorInfo(tensorInfo, backend) {
          const { dataId, shape, dtype } = tensorInfo;
          const t2 = new Tensor(shape, dtype, dataId, this.nextTensorId());
          this.trackTensor(t2, backend);
          return t2;
        }
        makeVariable(initialValue, trainable = true, name, dtype) {
          name = name || this.nextVariableId().toString();
          if (dtype != null && dtype !== initialValue.dtype) {
            initialValue = initialValue.cast(dtype);
          }
          const v = new Variable(initialValue, trainable, name, this.nextTensorId());
          if (this.state.registeredVariables[v.name] != null) {
            throw new Error(`Variable with name ${v.name} was already registered`);
          }
          this.state.registeredVariables[v.name] = v;
          this.incRef(v, this.backend);
          return v;
        }
        trackTensor(a, backend) {
          this.state.numTensors++;
          if (a.dtype === "string") {
            this.state.numStringTensors++;
          }
          let bytes = 0;
          if (a.dtype !== "complex64" && a.dtype !== "string") {
            bytes = a.size * bytesPerElement(a.dtype);
          }
          this.state.numBytes += bytes;
          if (!this.state.tensorInfo.has(a.dataId)) {
            this.state.numDataBuffers++;
            this.state.tensorInfo.set(a.dataId, {
              backend: backend || this.backend,
              dtype: a.dtype,
              shape: a.shape,
              bytes
            });
          }
          if (!(a instanceof Variable)) {
            this.track(a);
          }
        }
        // Track the tensor by dataId and increase the refCount for the dataId in the
        // backend.
        // TODO(pyu10055): This is currently used by makeVariable method, to increase
        // refCount on the backend for the dataId. It can potentially be replaced with
        // Identity op indead of calling backend directly.
        incRef(a, backend) {
          this.trackTensor(a, backend);
          this.backend.incRef(a.dataId);
        }
        removeDataId(dataId, backend) {
          if (this.state.tensorInfo.has(dataId) && this.state.tensorInfo.get(dataId).backend === backend) {
            this.state.tensorInfo.delete(dataId);
            this.state.numDataBuffers--;
          }
        }
        disposeTensor(a) {
          if (!this.state.tensorInfo.has(a.dataId)) {
            return;
          }
          const info = this.state.tensorInfo.get(a.dataId);
          this.state.numTensors--;
          if (a.dtype === "string") {
            this.state.numStringTensors--;
            this.state.numBytes -= info.bytes;
          }
          if (a.dtype !== "complex64" && a.dtype !== "string") {
            const bytes = a.size * bytesPerElement(a.dtype);
            this.state.numBytes -= bytes;
          }
          if (info.backend.disposeData(a.dataId)) {
            this.removeDataId(a.dataId, info.backend);
          }
        }
        disposeVariables() {
          for (const varName in this.state.registeredVariables) {
            const v = this.state.registeredVariables[varName];
            this.disposeVariable(v);
          }
        }
        disposeVariable(v) {
          this.disposeTensor(v);
          if (this.state.registeredVariables[v.name] != null) {
            delete this.state.registeredVariables[v.name];
          }
        }
        memory() {
          const info = this.backend.memory();
          info.numTensors = this.state.numTensors;
          info.numDataBuffers = this.state.numDataBuffers;
          info.numBytes = this.state.numBytes;
          if (this.state.numStringTensors > 0) {
            info.unreliable = true;
            if (info.reasons == null) {
              info.reasons = [];
            }
            info.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)");
          }
          return info;
        }
        profile(query) {
          return __async(this, null, function* () {
            this.state.profiling = true;
            const startBytes = this.state.numBytes;
            const startNumTensors = this.state.numTensors;
            this.state.activeProfile.kernels = [];
            this.state.activeProfile.result = yield query();
            this.state.profiling = false;
            this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map((d) => d.totalBytesSnapshot));
            this.state.activeProfile.newBytes = this.state.numBytes - startBytes;
            this.state.activeProfile.newTensors = this.state.numTensors - startNumTensors;
            for (const kernel of this.state.activeProfile.kernels) {
              kernel.kernelTimeMs = yield kernel.kernelTimeMs;
              kernel.extraInfo = yield kernel.extraInfo;
            }
            return this.state.activeProfile;
          });
        }
        isTapeOn() {
          return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
        }
        addTapeNode(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {
          const tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };
          const gradConfig = getGradient(kernelName);
          if (gradConfig != null) {
            gradientsFunc = gradConfig.gradFunc;
          }
          if (gradientsFunc != null) {
            tapeNode.gradient = (dys) => {
              dys = dys.map((dy, i) => {
                if (dy == null) {
                  const output = outputs[i];
                  const vals = makeZerosTypedArray(output.size, output.dtype);
                  return this.makeTensor(vals, output.shape, output.dtype);
                }
                return dy;
              });
              return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);
            };
          }
          this.state.activeTape.push(tapeNode);
        }
        keep(result) {
          result.kept = true;
          return result;
        }
        startTape() {
          if (this.state.gradientDepth === 0) {
            this.state.activeTape = [];
          }
          this.state.gradientDepth++;
        }
        endTape() {
          this.state.gradientDepth--;
        }
        /**
         * Start a scope. Use this with endScope() to achieve the same functionality
         * as scope() without the need for a function closure.
         */
        startScope(name) {
          const scopeInfo = {
            track: [],
            name: "unnamed scope",
            id: this.state.nextScopeId++
          };
          if (name) {
            scopeInfo.name = name;
          }
          this.state.scopeStack.push(scopeInfo);
          this.state.activeScope = scopeInfo;
        }
        /**
         * End a scope. Use this with startScope() to achieve the same functionality
         * as scope() without the need for a function closure.
         */
        endScope(result) {
          const tensorsToTrackInParent = getTensorsInContainer(result);
          const tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map((t2) => t2.id));
          for (let i = 0; i < this.state.activeScope.track.length; i++) {
            const tensor2 = this.state.activeScope.track[i];
            if (!tensor2.kept && !tensorsToTrackInParentSet.has(tensor2.id)) {
              tensor2.dispose();
            }
          }
          const oldScope = this.state.scopeStack.pop();
          this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1];
          tensorsToTrackInParent.forEach((tensor2) => {
            if (!tensor2.kept && tensor2.scopeId === oldScope.id) {
              this.track(tensor2);
            }
          });
        }
        /**
         * Returns gradients of `f` with respect to each of the `xs`. The gradients
         * returned are of the same length as `xs`, but some might be null if `f`
         * was not a function of that `x`. It also takes optional dy to multiply the
         * gradient, which defaults to `1`.
         */
        gradients(f, xs, dy, allowNoGradients = false) {
          assert(xs.length > 0, () => "gradients() received an empty list of xs.");
          if (dy != null && dy.dtype !== "float32") {
            throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`);
          }
          const y = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy("forward", f));
          assert(y instanceof Tensor, () => "The result y returned by f() must be a tensor.");
          const filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);
          if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {
            throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
          }
          return this.tidy("backward", () => {
            const accumulatedGradientMap = {};
            accumulatedGradientMap[y.id] = dy == null ? ones(y.shape) : dy;
            backpropagateGradients(
              accumulatedGradientMap,
              filteredTape,
              // Pass the tidy function to avoid circular dep with `tape.ts`.
              (f2) => this.tidy(f2),
              // Pass an add function to avoide a circular dep with `tape.ts`.
              add
            );
            const grads = xs.map((x) => accumulatedGradientMap[x.id]);
            if (this.state.gradientDepth === 0) {
              this.state.activeTape.forEach((node) => {
                for (const tensor2 of node.saved) {
                  tensor2.dispose();
                }
              });
              this.state.activeTape = null;
            }
            return { value: y, grads };
          });
        }
        customGrad(f) {
          assert(isFunction(f), () => "The f passed in customGrad(f) must be a function.");
          return (...inputs) => {
            assert(inputs.every((t2) => t2 instanceof Tensor), () => "The args passed in customGrad(f)(x1, x2,...) must all be tensors");
            let res;
            const inputMap = {};
            inputs.forEach((input, i) => {
              inputMap[i] = input;
            });
            const forwardFunc = (_2, save) => {
              res = f(...[...inputs, save]);
              assert(res.value instanceof Tensor, () => "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor");
              assert(isFunction(res.gradFunc), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.");
              return res.value;
            };
            const backwardsFunc = (dy, saved) => {
              const gradRes = res.gradFunc(dy, saved);
              const grads = Array.isArray(gradRes) ? gradRes : [gradRes];
              assert(grads.length === inputs.length, () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).");
              assert(grads.every((t2) => t2 instanceof Tensor), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");
              const gradMap = {};
              grads.forEach((grad, i) => {
                gradMap[i] = () => grad;
              });
              return gradMap;
            };
            return this.runKernelFunc({
              forwardFunc,
              backwardsFunc,
              inputs: inputMap
            });
          };
        }
        readSync(dataId) {
          const info = this.state.tensorInfo.get(dataId);
          return info.backend.readSync(dataId);
        }
        read(dataId) {
          const info = this.state.tensorInfo.get(dataId);
          return info.backend.read(dataId);
        }
        readToGPU(dataId, options) {
          const info = this.state.tensorInfo.get(dataId);
          return info.backend.readToGPU(dataId, options);
        }
        time(query) {
          return __async(this, null, function* () {
            const start = now();
            const timingInfo = yield this.backend.time(query);
            timingInfo.wallMs = now() - start;
            return timingInfo;
          });
        }
        /**
         * Tracks a Tensor in the current scope to be automatically cleaned up
         * when the current scope ends, and returns the value.
         *
         * @param result The Tensor to track in the current scope.
         */
        track(result) {
          if (this.state.activeScope != null) {
            result.scopeId = this.state.activeScope.id;
            this.state.activeScope.track.push(result);
          }
          return result;
        }
        get registeredVariables() {
          return this.state.registeredVariables;
        }
        /**
         * Resets the engine state. Removes all backends but does not remove
         * registered backend factories.
         */
        reset() {
          this.pendingBackendInitId++;
          this.state.dispose();
          this.ENV.reset();
          this.state = new EngineState();
          for (const backendName in this.registry) {
            this.disposeRegisteredKernels(backendName);
            this.registry[backendName].dispose();
            delete this.registry[backendName];
          }
          this.backendName = null;
          this.backendInstance = null;
          this.pendingBackendInit = null;
        }
      };
      Engine.nextTensorId = 0;
      Engine.nextVariableId = 0;
      ENGINE = getOrMakeEngine();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/device_util.js
  function isBrowser() {
    return typeof window !== "undefined" && window.document != null || //@ts-ignore
    typeof WorkerGlobalScope !== "undefined";
  }
  var init_device_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/device_util.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/flags.js
  var ENV2;
  var init_flags = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/flags.js"() {
      init_engine();
      init_device_util();
      init_environment();
      ENV2 = env();
      ENV2.registerFlag("DEBUG", () => false, (debugValue) => {
        if (debugValue) {
          console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
        }
      });
      ENV2.registerFlag("IS_BROWSER", () => isBrowser());
      ENV2.registerFlag("IS_NODE", () => typeof process !== "undefined" && typeof process.versions !== "undefined" && typeof process.versions.node !== "undefined");
      ENV2.registerFlag("IS_CHROME", () => typeof navigator !== "undefined" && navigator != null && navigator.userAgent != null && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor));
      ENV2.registerFlag("PROD", () => false);
      ENV2.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", () => ENV2.getBool("DEBUG"));
      ENV2.registerFlag("DEPRECATION_WARNINGS_ENABLED", () => true);
      ENV2.registerFlag("IS_TEST", () => false);
      ENV2.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", () => true);
      ENV2.registerFlag("WRAP_TO_IMAGEBITMAP", () => false);
      ENV2.registerFlag("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU", () => false);
      ENV2.registerFlag("USE_SETTIMEOUTCUSTOM", () => false);
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js
  function inferShape(val, dtype) {
    let firstElem = val;
    if (isTypedArray(val)) {
      return dtype === "string" ? [] : [val.length];
    }
    const isObject = typeof val === "object";
    if (isObject) {
      if ("texture" in val) {
        const usedChannels = val.channels || "RGBA";
        return [val.height, val.width * usedChannels.length];
      } else if ("buffer" in val && !(val.buffer instanceof ArrayBuffer)) {
        return [val.buffer.size / (dtype == null ? 4 : bytesPerElement(dtype))];
      }
    }
    if (!Array.isArray(val)) {
      return [];
    }
    const shape = [];
    while (Array.isArray(firstElem) || isTypedArray(firstElem) && dtype !== "string") {
      shape.push(firstElem.length);
      firstElem = firstElem[0];
    }
    if (Array.isArray(val) && env().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")) {
      deepAssertShapeConsistency(val, shape, []);
    }
    return shape;
  }
  function deepAssertShapeConsistency(val, shape, indices) {
    indices = indices || [];
    if (!Array.isArray(val) && !isTypedArray(val)) {
      assert(shape.length === 0, () => `Element arr[${indices.join("][")}] is a primitive, but should be an array/TypedArray of ${shape[0]} elements`);
      return;
    }
    assert(shape.length > 0, () => `Element arr[${indices.join("][")}] should be a primitive, but is an array of ${val.length} elements`);
    assert(val.length === shape[0], () => `Element arr[${indices.join("][")}] should have ${shape[0]} elements, but has ${val.length} elements`);
    const subShape = shape.slice(1);
    for (let i = 0; i < val.length; ++i) {
      deepAssertShapeConsistency(val[i], subShape, indices.concat(i));
    }
  }
  function assertDtype(expectedDtype, actualDType, argName, functionName) {
    if (expectedDtype === "string_or_numeric") {
      return;
    }
    if (expectedDtype == null) {
      throw new Error(`Expected dtype cannot be null.`);
    }
    if (expectedDtype !== "numeric" && expectedDtype !== actualDType || expectedDtype === "numeric" && actualDType === "string") {
      throw new Error(`Argument '${argName}' passed to '${functionName}' must be ${expectedDtype} tensor, but got ${actualDType} tensor`);
    }
  }
  function convertToTensor(x, argName, functionName, parseAsDtype = "numeric") {
    if (x instanceof Tensor) {
      assertDtype(parseAsDtype, x.dtype, argName, functionName);
      return x;
    }
    let inferredDtype = inferDtype(x);
    if (inferredDtype !== "string" && ["bool", "int32", "float32"].indexOf(parseAsDtype) >= 0) {
      inferredDtype = parseAsDtype;
    }
    assertDtype(parseAsDtype, inferredDtype, argName, functionName);
    if (x == null || !isTypedArray(x) && !Array.isArray(x) && typeof x !== "number" && typeof x !== "boolean" && typeof x !== "string") {
      const type = x == null ? "null" : x.constructor.name;
      throw new Error(`Argument '${argName}' passed to '${functionName}' must be a Tensor or TensorLike, but got '${type}'`);
    }
    const inferredShape = inferShape(x, inferredDtype);
    if (!isTypedArray(x) && !Array.isArray(x)) {
      x = [x];
    }
    const skipTypedArray = true;
    const values = inferredDtype !== "string" ? toTypedArray(x, inferredDtype) : flatten(x, [], skipTypedArray);
    return ENGINE.makeTensor(values, inferredShape, inferredDtype);
  }
  function convertToTensorArray(arg, argName, functionName, parseAsDtype = "numeric") {
    if (!Array.isArray(arg)) {
      throw new Error(`Argument ${argName} passed to ${functionName} must be a \`Tensor[]\` or \`TensorLike[]\``);
    }
    const tensors = arg;
    return tensors.map((t2, i) => convertToTensor(t2, `${argName}[${i}]`, functionName, parseAsDtype));
  }
  var init_tensor_util_env = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js"() {
      init_engine();
      init_environment();
      init_tensor();
      init_util();
      init_util_base();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/operation.js
  function op(f) {
    const keys = Object.keys(f);
    if (keys.length !== 1) {
      throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${keys.length} keys.`);
    }
    let opName = keys[0];
    const fn = f[opName];
    if (opName.endsWith("_")) {
      opName = opName.substring(0, opName.length - 1);
    }
    opName = opName + OP_SCOPE_SUFFIX;
    const f2 = (...args) => {
      ENGINE.startScope(opName);
      try {
        const result = fn(...args);
        if (isPromise(result)) {
          console.error("Cannot return a Promise inside of tidy.");
        }
        ENGINE.endScope(result);
        return result;
      } catch (ex) {
        ENGINE.endScope(null);
        throw ex;
      }
    };
    Object.defineProperty(f2, "name", { value: opName, configurable: true });
    return f2;
  }
  var OP_SCOPE_SUFFIX;
  var init_operation = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/operation.js"() {
      init_engine();
      init_util();
      OP_SCOPE_SUFFIX = "__op";
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/complex.js
  function complex_(real3, imag3) {
    const $real = convertToTensor(real3, "real", "complex");
    const $imag = convertToTensor(imag3, "imag", "complex");
    assertShapesMatch($real.shape, $imag.shape, `real and imag shapes, ${$real.shape} and ${$imag.shape}, must match in call to tf.complex().`);
    const inputs = { real: $real, imag: $imag };
    return ENGINE.runKernel(Complex, inputs);
  }
  var complex;
  var init_complex = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/complex.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      complex = /* @__PURE__ */ op({ complex_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js
  function makeTensor(values, shape, inferredShape, dtype) {
    if (dtype == null) {
      dtype = inferDtype(values);
    } else if (dtype === "complex64") {
      throw new Error(`Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).`);
    }
    if (typeof values === "object" && ("texture" in values || "buffer" in values && !(values.buffer instanceof ArrayBuffer))) {
      if (dtype !== "float32" && dtype !== "int32") {
        throw new Error(`Creating tensor from GPU data only supports 'float32'|'int32' dtype, while the dtype is ${dtype}.`);
      }
      return ENGINE.backend.createTensorFromGPUData(values, shape || inferredShape, dtype);
    }
    if (!isTypedArray(values) && !Array.isArray(values) && typeof values !== "number" && typeof values !== "boolean" && typeof values !== "string") {
      throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
    }
    if (shape != null) {
      assertNonNegativeIntegerDimensions(shape);
      const providedSize = sizeFromShape(shape);
      const inferredSize = sizeFromShape(inferredShape);
      assert(providedSize === inferredSize, () => `Based on the provided shape, [${shape}], the tensor should have ${providedSize} values but has ${inferredSize}`);
      for (let i = 0; i < inferredShape.length; ++i) {
        const inferred = inferredShape[i];
        const flatDimsDontMatch = i === inferredShape.length - 1 ? inferred !== sizeFromShape(shape.slice(i)) : true;
        assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, () => `Error creating a new Tensor. Inferred shape (${inferredShape}) does not match the provided shape (${shape}). `);
      }
    }
    if (!isTypedArray(values) && !Array.isArray(values)) {
      values = [values];
    }
    shape = shape || inferredShape;
    values = dtype !== "string" ? toTypedArray(values, dtype) : flatten(values, [], true);
    return ENGINE.makeTensor(values, shape, dtype);
  }
  var init_tensor_ops_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js"() {
      init_engine();
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js
  function tensor(values, shape, dtype) {
    const inferredShape = inferShape(values, dtype);
    return makeTensor(values, shape, inferredShape, dtype);
  }
  var init_tensor2 = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js"() {
      init_tensor_util_env();
      init_tensor_ops_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/types.js
  var DTYPE_VALUE_SIZE_MAP;
  var init_types2 = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/io/types.js"() {
      DTYPE_VALUE_SIZE_MAP = {
        "float32": 4,
        "float16": 2,
        "int32": 4,
        "uint16": 2,
        "uint8": 1,
        "bool": 1,
        "complex64": 8
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js
  function encodeWeights(tensors, group) {
    return __async(this, null, function* () {
      const specs = [];
      const dataPromises = [];
      const names = Array.isArray(tensors) ? tensors.map((tensor2) => tensor2.name) : Object.keys(tensors);
      for (let i = 0; i < names.length; ++i) {
        const name = names[i];
        const t2 = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];
        if (t2.dtype !== "float32" && t2.dtype !== "int32" && t2.dtype !== "bool" && t2.dtype !== "string" && t2.dtype !== "complex64") {
          throw new Error(`Unsupported dtype in weight '${name}': ${t2.dtype}`);
        }
        const spec = { name, shape: t2.shape, dtype: t2.dtype };
        if (t2.dtype === "string") {
          const utf8bytes = new Promise((resolve) => __async(this, null, function* () {
            const vals = yield t2.bytes();
            const totalNumBytes = vals.reduce((p2, c) => p2 + c.length, 0) + NUM_BYTES_STRING_LENGTH * vals.length;
            const bytes = new Uint8Array(totalNumBytes);
            let offset = 0;
            for (let i2 = 0; i2 < vals.length; i2++) {
              const val = vals[i2];
              const bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);
              bytes.set(bytesOfLength, offset);
              offset += NUM_BYTES_STRING_LENGTH;
              bytes.set(val, offset);
              offset += val.length;
            }
            resolve(bytes);
          }));
          dataPromises.push(utf8bytes);
        } else {
          dataPromises.push(t2.data());
        }
        if (group != null) {
          spec.group = group;
        }
        specs.push(spec);
      }
      const tensorValues = yield Promise.all(dataPromises);
      return { data: concatenateTypedArrays(tensorValues), specs };
    });
  }
  function decodeWeights(buffer2, specs) {
    const out = {};
    let float16Decode;
    let offset = 0;
    for (const spec of specs) {
      const name = spec.name;
      const dtype = spec.dtype;
      const shape = spec.shape;
      const size = sizeFromShape(shape);
      let values;
      if ("quantization" in spec) {
        const quantization = spec.quantization;
        if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
          if (!("min" in quantization && "scale" in quantization)) {
            throw new Error(`Weight ${spec.name} with quantization ${quantization.dtype} doesn't have corresponding metadata min and scale.`);
          }
        } else if (quantization.dtype === "float16") {
          if (dtype !== "float32") {
            throw new Error(`Weight ${spec.name} is quantized with ${quantization.dtype} which only supports weights of type float32 not ${dtype}.`);
          }
        } else {
          throw new Error(`Weight ${spec.name} has unknown quantization dtype ${quantization.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);
        }
        const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
        const byteBuffer = buffer2.slice(offset, offset + size * quantizationSizeFactor);
        const quantizedArray = quantization.dtype === "uint8" ? new Uint8Array(byteBuffer) : new Uint16Array(byteBuffer);
        if (dtype === "float32") {
          if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
            values = new Float32Array(quantizedArray.length);
            for (let i = 0; i < quantizedArray.length; i++) {
              const v = quantizedArray[i];
              values[i] = v * quantization.scale + quantization.min;
            }
          } else if (quantization.dtype === "float16") {
            if (float16Decode === void 0) {
              float16Decode = getFloat16Decoder();
            }
            values = float16Decode(quantizedArray);
          } else {
            throw new Error(`Unsupported quantization type ${quantization.dtype} for weight type float32.`);
          }
        } else if (dtype === "int32") {
          if (quantization.dtype !== "uint8" && quantization.dtype !== "uint16") {
            throw new Error(`Unsupported quantization type ${quantization.dtype} for weight type int32.`);
          }
          values = new Int32Array(quantizedArray.length);
          for (let i = 0; i < quantizedArray.length; i++) {
            const v = quantizedArray[i];
            values[i] = Math.round(v * quantization.scale + quantization.min);
          }
        } else {
          throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);
        }
        offset += size * quantizationSizeFactor;
      } else if (dtype === "string") {
        const size2 = sizeFromShape(spec.shape);
        values = [];
        for (let i = 0; i < size2; i++) {
          const byteLength = new Uint32Array(buffer2.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];
          offset += NUM_BYTES_STRING_LENGTH;
          const bytes = new Uint8Array(buffer2.slice(offset, offset + byteLength));
          values.push(bytes);
          offset += byteLength;
        }
      } else {
        const dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];
        const byteBuffer = buffer2.slice(offset, offset + size * dtypeFactor);
        if (dtype === "float32") {
          values = new Float32Array(byteBuffer);
        } else if (dtype === "int32") {
          values = new Int32Array(byteBuffer);
        } else if (dtype === "bool") {
          values = new Uint8Array(byteBuffer);
        } else if (dtype === "complex64") {
          values = new Float32Array(byteBuffer);
          const real3 = new Float32Array(values.length / 2);
          const image2 = new Float32Array(values.length / 2);
          for (let i = 0; i < real3.length; i++) {
            real3[i] = values[i * 2];
            image2[i] = values[i * 2 + 1];
          }
          const realTensor = tensor(real3, shape, "float32");
          const imageTensor = tensor(image2, shape, "float32");
          out[name] = complex(realTensor, imageTensor);
          realTensor.dispose();
          imageTensor.dispose();
        } else {
          throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);
        }
        offset += size * dtypeFactor;
      }
      if (dtype !== "complex64") {
        out[name] = tensor(values, shape, dtype);
      }
    }
    return out;
  }
  function concatenateTypedArrays(xs) {
    if (xs === null) {
      throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);
    }
    let totalByteLength = 0;
    const normalizedXs = [];
    xs.forEach((x) => {
      totalByteLength += x.byteLength;
      normalizedXs.push(x.byteLength === x.buffer.byteLength ? x : new x.constructor(x));
      if (!(x instanceof Float32Array || x instanceof Int32Array || x instanceof Uint8Array)) {
        throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);
      }
    });
    const y = new Uint8Array(totalByteLength);
    let offset = 0;
    normalizedXs.forEach((x) => {
      y.set(new Uint8Array(x.buffer), offset);
      offset += x.byteLength;
    });
    return y.buffer;
  }
  function stringByteLength(str) {
    if (useNodeBuffer) {
      return Buffer.byteLength(str);
    }
    return new Blob([str]).size;
  }
  function arrayBufferToBase64String(buffer2) {
    if (useNodeBuffer) {
      return Buffer.from(buffer2).toString("base64");
    }
    const buf = new Uint8Array(buffer2);
    let s = "";
    for (let i = 0, l = buf.length; i < l; i++) {
      s += String.fromCharCode(buf[i]);
    }
    return btoa(s);
  }
  function base64StringToArrayBuffer(str) {
    if (useNodeBuffer) {
      const buf = Buffer.from(str, "base64");
      return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);
    }
    const s = atob(str);
    const buffer2 = new Uint8Array(s.length);
    for (let i = 0; i < s.length; ++i) {
      buffer2.set([s.charCodeAt(i)], i);
    }
    return buffer2.buffer;
  }
  function concatenateArrayBuffers(buffers) {
    if (buffers.length === 1) {
      return buffers[0];
    }
    let totalByteLength = 0;
    buffers.forEach((buffer2) => {
      totalByteLength += buffer2.byteLength;
    });
    const temp = new Uint8Array(totalByteLength);
    let offset = 0;
    buffers.forEach((buffer2) => {
      temp.set(new Uint8Array(buffer2), offset);
      offset += buffer2.byteLength;
    });
    return temp.buffer;
  }
  function basename(path) {
    const SEPARATOR = "/";
    path = path.trim();
    while (path.endsWith(SEPARATOR)) {
      path = path.slice(0, path.length - 1);
    }
    const items = path.split(SEPARATOR);
    return items[items.length - 1];
  }
  function getModelJSONForModelArtifacts(artifacts, manifest) {
    const result = {
      modelTopology: artifacts.modelTopology,
      format: artifacts.format,
      generatedBy: artifacts.generatedBy,
      convertedBy: artifacts.convertedBy,
      weightsManifest: manifest
    };
    if (artifacts.signature != null) {
      result.signature = artifacts.signature;
    }
    if (artifacts.userDefinedMetadata != null) {
      result.userDefinedMetadata = artifacts.userDefinedMetadata;
    }
    if (artifacts.modelInitializer != null) {
      result.modelInitializer = artifacts.modelInitializer;
    }
    if (artifacts.initializerSignature != null) {
      result.initializerSignature = artifacts.initializerSignature;
    }
    if (artifacts.trainingConfig != null) {
      result.trainingConfig = artifacts.trainingConfig;
    }
    return result;
  }
  function getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData) {
    const modelArtifacts = {
      modelTopology: modelJSON.modelTopology,
      format: modelJSON.format,
      generatedBy: modelJSON.generatedBy,
      convertedBy: modelJSON.convertedBy
    };
    if (modelJSON.trainingConfig != null) {
      modelArtifacts.trainingConfig = modelJSON.trainingConfig;
    }
    if (modelJSON.weightsManifest != null) {
      if (!weightSpecs) {
        throw new Error("modelJSON has weightsManifest but weightSpecs is null");
      }
      if (!weightData) {
        throw new Error("modelJSON has weightsManifest but weightData is null");
      }
      modelArtifacts.weightSpecs = weightSpecs;
      modelArtifacts.weightData = weightData;
    }
    if (modelJSON.signature != null) {
      modelArtifacts.signature = modelJSON.signature;
    }
    if (modelJSON.userDefinedMetadata != null) {
      modelArtifacts.userDefinedMetadata = modelJSON.userDefinedMetadata;
    }
    if (modelJSON.modelInitializer != null) {
      modelArtifacts.modelInitializer = modelJSON.modelInitializer;
    }
    if (modelJSON.initializerSignature != null) {
      modelArtifacts.initializerSignature = modelJSON.initializerSignature;
    }
    return modelArtifacts;
  }
  function getModelArtifactsForJSON(modelJSON, loadWeights2) {
    return __async(this, null, function* () {
      let weightSpecs;
      let weightData;
      if (modelJSON.weightsManifest != null) {
        [weightSpecs, weightData] = yield loadWeights2(modelJSON.weightsManifest);
      }
      return getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData);
    });
  }
  function getModelArtifactsInfoForJSON(modelArtifacts) {
    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
      throw new Error("Expected JSON model topology, received ArrayBuffer.");
    }
    return {
      dateSaved: /* @__PURE__ */ new Date(),
      modelTopologyType: "JSON",
      modelTopologyBytes: modelArtifacts.modelTopology == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),
      weightSpecsBytes: modelArtifacts.weightSpecs == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),
      weightDataBytes: modelArtifacts.weightData == null ? 0 : modelArtifacts.weightData.byteLength
    };
  }
  function getWeightSpecs(weightsManifest) {
    const weightSpecs = [];
    for (const entry of weightsManifest) {
      weightSpecs.push(...entry.weights);
    }
    return weightSpecs;
  }
  function computeFloat16MantisaTable() {
    const convertMantissa = (i) => {
      let m = i << 13;
      let e = 0;
      while ((m & 8388608) === 0) {
        e -= 8388608;
        m <<= 1;
      }
      m &= ~8388608;
      e += 947912704;
      return m | e;
    };
    const mantisaTable = new Uint32Array(2048);
    mantisaTable[0] = 0;
    for (let i = 1; i < 1024; i++) {
      mantisaTable[i] = convertMantissa(i);
    }
    for (let i = 1024; i < 2048; i++) {
      mantisaTable[i] = 939524096 + (i - 1024 << 13);
    }
    return mantisaTable;
  }
  function computeFloat16ExponentTable() {
    const exponentTable = new Uint32Array(64);
    exponentTable[0] = 0;
    exponentTable[31] = 1199570944;
    exponentTable[32] = 2147483648;
    exponentTable[63] = 3347054592;
    for (let i = 1; i < 31; i++) {
      exponentTable[i] = i << 23;
    }
    for (let i = 33; i < 63; i++) {
      exponentTable[i] = 2147483648 + (i - 32 << 23);
    }
    return exponentTable;
  }
  function computeFloat16OffsetTable() {
    const offsetTable = new Uint32Array(64);
    for (let i = 0; i < 64; i++) {
      offsetTable[i] = 1024;
    }
    offsetTable[0] = offsetTable[32] = 0;
    return offsetTable;
  }
  function getFloat16Decoder() {
    const mantisaTable = computeFloat16MantisaTable();
    const exponentTable = computeFloat16ExponentTable();
    const offsetTable = computeFloat16OffsetTable();
    return (quantizedArray) => {
      const buffer2 = new ArrayBuffer(4 * quantizedArray.length);
      const bufferUint32View = new Uint32Array(buffer2);
      for (let index = 0; index < quantizedArray.length; index++) {
        const float16Bits = quantizedArray[index];
        const float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 1023)] + exponentTable[float16Bits >> 10];
        bufferUint32View[index] = float32Bits;
      }
      return new Float32Array(buffer2);
    };
  }
  var NUM_BYTES_STRING_LENGTH, useNodeBuffer;
  var init_io_utils = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js"() {
      init_complex();
      init_tensor2();
      init_util();
      init_types2();
      NUM_BYTES_STRING_LENGTH = 4;
      useNodeBuffer = typeof Buffer !== "undefined" && (typeof Blob === "undefined" || typeof atob === "undefined" || typeof btoa === "undefined");
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js
  var IORouterRegistry, registerSaveRouter, registerLoadRouter, getSaveHandlers, getLoadHandlers;
  var init_router_registry = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js"() {
      IORouterRegistry = class {
        constructor() {
          this.saveRouters = [];
          this.loadRouters = [];
        }
        static getInstance() {
          if (IORouterRegistry.instance == null) {
            IORouterRegistry.instance = new IORouterRegistry();
          }
          return IORouterRegistry.instance;
        }
        /**
         * Register a save-handler router.
         *
         * @param saveRouter A function that maps a URL-like string onto an instance
         * of `IOHandler` with the `save` method defined or `null`.
         */
        static registerSaveRouter(saveRouter) {
          IORouterRegistry.getInstance().saveRouters.push(saveRouter);
        }
        /**
         * Register a load-handler router.
         *
         * @param loadRouter A function that maps a URL-like string onto an instance
         * of `IOHandler` with the `load` method defined or `null`.
         */
        static registerLoadRouter(loadRouter) {
          IORouterRegistry.getInstance().loadRouters.push(loadRouter);
        }
        /**
         * Look up IOHandler for saving, given a URL-like string.
         *
         * @param url
         * @returns If only one match is found, an instance of IOHandler with the
         * `save` method defined. If no match is found, `null`.
         * @throws Error, if more than one match is found.
         */
        static getSaveHandlers(url) {
          return IORouterRegistry.getHandlers(url, "save");
        }
        /**
         * Look up IOHandler for loading, given a URL-like string.
         *
         * @param url
         * @param loadOptions Optional, custom load options.
         * @returns All valid handlers for `url`, given the currently registered
         *   handler routers.
         */
        static getLoadHandlers(url, loadOptions) {
          return IORouterRegistry.getHandlers(url, "load", loadOptions);
        }
        static getHandlers(url, handlerType, loadOptions) {
          const validHandlers = [];
          const routers = handlerType === "load" ? IORouterRegistry.getInstance().loadRouters : IORouterRegistry.getInstance().saveRouters;
          routers.forEach((router) => {
            const handler = router(url, loadOptions);
            if (handler !== null) {
              validHandlers.push(handler);
            }
          });
          return validHandlers;
        }
      };
      registerSaveRouter = (loudRouter) => IORouterRegistry.registerSaveRouter(loudRouter);
      registerLoadRouter = (loudRouter) => IORouterRegistry.registerLoadRouter(loudRouter);
      getSaveHandlers = (url) => IORouterRegistry.getSaveHandlers(url);
      getLoadHandlers = (url, loadOptions) => IORouterRegistry.getLoadHandlers(url, loadOptions);
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js
  function getIndexedDBFactory() {
    if (!env().getBool("IS_BROWSER")) {
      throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
    }
    const theWindow = typeof window === "undefined" ? self : window;
    const factory = theWindow.indexedDB || theWindow.mozIndexedDB || theWindow.webkitIndexedDB || theWindow.msIndexedDB || theWindow.shimIndexedDB;
    if (factory == null) {
      throw new Error("The current browser does not appear to support IndexedDB.");
    }
    return factory;
  }
  function setUpDatabase(openRequest) {
    const db = openRequest.result;
    db.createObjectStore(MODEL_STORE_NAME, { keyPath: "modelPath" });
    db.createObjectStore(INFO_STORE_NAME, { keyPath: "modelPath" });
  }
  function browserIndexedDB(modelPath) {
    return new BrowserIndexedDB(modelPath);
  }
  function maybeStripScheme(key) {
    return key.startsWith(BrowserIndexedDB.URL_SCHEME) ? key.slice(BrowserIndexedDB.URL_SCHEME.length) : key;
  }
  var DATABASE_NAME, DATABASE_VERSION, MODEL_STORE_NAME, INFO_STORE_NAME, BrowserIndexedDB, indexedDBRouter, BrowserIndexedDBManager;
  var init_indexed_db = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js"() {
      init_flags();
      init_environment();
      init_io_utils();
      init_router_registry();
      DATABASE_NAME = "tensorflowjs";
      DATABASE_VERSION = 1;
      MODEL_STORE_NAME = "models_store";
      INFO_STORE_NAME = "model_info_store";
      BrowserIndexedDB = class {
        constructor(modelPath) {
          this.indexedDB = getIndexedDBFactory();
          if (modelPath == null || !modelPath) {
            throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
          }
          this.modelPath = modelPath;
        }
        save(modelArtifacts) {
          return __async(this, null, function* () {
            if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
              throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
            }
            return this.databaseAction(this.modelPath, modelArtifacts);
          });
        }
        load() {
          return __async(this, null, function* () {
            return this.databaseAction(this.modelPath);
          });
        }
        /**
         * Perform database action to put model artifacts into or read model artifacts
         * from IndexedDB object store.
         *
         * Whether the action is put or get depends on whether `modelArtifacts` is
         * specified. If it is specified, the action will be put; otherwise the action
         * will be get.
         *
         * @param modelPath A unique string path for the model.
         * @param modelArtifacts If specified, it will be the model artifacts to be
         *   stored in IndexedDB.
         * @returns A `Promise` of `SaveResult`, if the action is put, or a `Promise`
         *   of `ModelArtifacts`, if the action is get.
         */
        databaseAction(modelPath, modelArtifacts) {
          return new Promise((resolve, reject) => {
            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
            openRequest.onsuccess = () => {
              const db = openRequest.result;
              if (modelArtifacts == null) {
                const modelTx = db.transaction(MODEL_STORE_NAME, "readonly");
                const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
                const getRequest = modelStore.get(this.modelPath);
                getRequest.onsuccess = () => {
                  if (getRequest.result == null) {
                    db.close();
                    return reject(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));
                  } else {
                    resolve(getRequest.result.modelArtifacts);
                  }
                };
                getRequest.onerror = (error) => {
                  db.close();
                  return reject(getRequest.error);
                };
                modelTx.oncomplete = () => db.close();
              } else {
                const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);
                const infoTx = db.transaction(INFO_STORE_NAME, "readwrite");
                let infoStore = infoTx.objectStore(INFO_STORE_NAME);
                const putInfoRequest = infoStore.put({ modelPath: this.modelPath, modelArtifactsInfo });
                let modelTx;
                putInfoRequest.onsuccess = () => {
                  modelTx = db.transaction(MODEL_STORE_NAME, "readwrite");
                  const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
                  const putModelRequest = modelStore.put({
                    modelPath: this.modelPath,
                    modelArtifacts,
                    modelArtifactsInfo
                  });
                  putModelRequest.onsuccess = () => resolve({ modelArtifactsInfo });
                  putModelRequest.onerror = (error) => {
                    infoStore = infoTx.objectStore(INFO_STORE_NAME);
                    const deleteInfoRequest = infoStore.delete(this.modelPath);
                    deleteInfoRequest.onsuccess = () => {
                      db.close();
                      return reject(putModelRequest.error);
                    };
                    deleteInfoRequest.onerror = (error2) => {
                      db.close();
                      return reject(putModelRequest.error);
                    };
                  };
                };
                putInfoRequest.onerror = (error) => {
                  db.close();
                  return reject(putInfoRequest.error);
                };
                infoTx.oncomplete = () => {
                  if (modelTx == null) {
                    db.close();
                  } else {
                    modelTx.oncomplete = () => db.close();
                  }
                };
              }
            };
            openRequest.onerror = (error) => reject(openRequest.error);
          });
        }
      };
      BrowserIndexedDB.URL_SCHEME = "indexeddb://";
      indexedDBRouter = (url) => {
        if (!env().getBool("IS_BROWSER")) {
          return null;
        } else {
          if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {
            return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));
          } else {
            return null;
          }
        }
      };
      IORouterRegistry.registerSaveRouter(indexedDBRouter);
      IORouterRegistry.registerLoadRouter(indexedDBRouter);
      BrowserIndexedDBManager = class {
        constructor() {
          this.indexedDB = getIndexedDBFactory();
        }
        listModels() {
          return __async(this, null, function* () {
            return new Promise((resolve, reject) => {
              const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
              openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
              openRequest.onsuccess = () => {
                const db = openRequest.result;
                const tx = db.transaction(INFO_STORE_NAME, "readonly");
                const store = tx.objectStore(INFO_STORE_NAME);
                const getAllInfoRequest = store.getAll();
                getAllInfoRequest.onsuccess = () => {
                  const out = {};
                  for (const item of getAllInfoRequest.result) {
                    out[item.modelPath] = item.modelArtifactsInfo;
                  }
                  resolve(out);
                };
                getAllInfoRequest.onerror = (error) => {
                  db.close();
                  return reject(getAllInfoRequest.error);
                };
                tx.oncomplete = () => db.close();
              };
              openRequest.onerror = (error) => reject(openRequest.error);
            });
          });
        }
        removeModel(path) {
          return __async(this, null, function* () {
            path = maybeStripScheme(path);
            return new Promise((resolve, reject) => {
              const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
              openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
              openRequest.onsuccess = () => {
                const db = openRequest.result;
                const infoTx = db.transaction(INFO_STORE_NAME, "readwrite");
                const infoStore = infoTx.objectStore(INFO_STORE_NAME);
                const getInfoRequest = infoStore.get(path);
                let modelTx;
                getInfoRequest.onsuccess = () => {
                  if (getInfoRequest.result == null) {
                    db.close();
                    return reject(new Error(`Cannot find model with path '${path}' in IndexedDB.`));
                  } else {
                    const deleteInfoRequest = infoStore.delete(path);
                    const deleteModelData = () => {
                      modelTx = db.transaction(MODEL_STORE_NAME, "readwrite");
                      const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
                      const deleteModelRequest = modelStore.delete(path);
                      deleteModelRequest.onsuccess = () => resolve(getInfoRequest.result.modelArtifactsInfo);
                      deleteModelRequest.onerror = (error) => reject(getInfoRequest.error);
                    };
                    deleteInfoRequest.onsuccess = deleteModelData;
                    deleteInfoRequest.onerror = (error) => {
                      deleteModelData();
                      db.close();
                      return reject(getInfoRequest.error);
                    };
                  }
                };
                getInfoRequest.onerror = (error) => {
                  db.close();
                  return reject(getInfoRequest.error);
                };
                infoTx.oncomplete = () => {
                  if (modelTx == null) {
                    db.close();
                  } else {
                    modelTx.oncomplete = () => db.close();
                  }
                };
              };
              openRequest.onerror = (error) => reject(openRequest.error);
            });
          });
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js
  function getModelKeys(path) {
    return {
      info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),
      topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),
      weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),
      weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),
      modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)
    };
  }
  function removeItems(keys) {
    for (const key of Object.values(keys)) {
      window.localStorage.removeItem(key);
    }
  }
  function getModelPathFromKey(key) {
    const items = key.split(PATH_SEPARATOR);
    if (items.length < 3) {
      throw new Error(`Invalid key format: ${key}`);
    }
    return items.slice(1, items.length - 1).join(PATH_SEPARATOR);
  }
  function maybeStripScheme2(key) {
    return key.startsWith(BrowserLocalStorage.URL_SCHEME) ? key.slice(BrowserLocalStorage.URL_SCHEME.length) : key;
  }
  function browserLocalStorage(modelPath) {
    return new BrowserLocalStorage(modelPath);
  }
  var PATH_SEPARATOR, PATH_PREFIX, INFO_SUFFIX, MODEL_TOPOLOGY_SUFFIX, WEIGHT_SPECS_SUFFIX, WEIGHT_DATA_SUFFIX, MODEL_METADATA_SUFFIX, BrowserLocalStorage, localStorageRouter, BrowserLocalStorageManager;
  var init_local_storage = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js"() {
      init_flags();
      init_environment();
      init_util();
      init_io_utils();
      init_router_registry();
      PATH_SEPARATOR = "/";
      PATH_PREFIX = "tensorflowjs_models";
      INFO_SUFFIX = "info";
      MODEL_TOPOLOGY_SUFFIX = "model_topology";
      WEIGHT_SPECS_SUFFIX = "weight_specs";
      WEIGHT_DATA_SUFFIX = "weight_data";
      MODEL_METADATA_SUFFIX = "model_metadata";
      BrowserLocalStorage = class {
        constructor(modelPath) {
          if (!env().getBool("IS_BROWSER") || typeof window === "undefined" || typeof window.localStorage === "undefined") {
            throw new Error("The current environment does not support local storage.");
          }
          this.LS = window.localStorage;
          if (modelPath == null || !modelPath) {
            throw new Error("For local storage, modelPath must not be null, undefined or empty.");
          }
          this.modelPath = modelPath;
          this.keys = getModelKeys(this.modelPath);
        }
        /**
         * Save model artifacts to browser local storage.
         *
         * See the documentation to `browserLocalStorage` for details on the saved
         * artifacts.
         *
         * @param modelArtifacts The model artifacts to be stored.
         * @returns An instance of SaveResult.
         */
        save(modelArtifacts) {
          return __async(this, null, function* () {
            if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
              throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
            } else {
              const topology = JSON.stringify(modelArtifacts.modelTopology);
              const weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);
              const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);
              try {
                this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));
                this.LS.setItem(this.keys.topology, topology);
                this.LS.setItem(this.keys.weightSpecs, weightSpecs);
                this.LS.setItem(this.keys.weightData, arrayBufferToBase64String(modelArtifacts.weightData));
                const metadata = {
                  format: modelArtifacts.format,
                  generatedBy: modelArtifacts.generatedBy,
                  convertedBy: modelArtifacts.convertedBy,
                  signature: modelArtifacts.signature != null ? modelArtifacts.signature : void 0,
                  userDefinedMetadata: modelArtifacts.userDefinedMetadata != null ? modelArtifacts.userDefinedMetadata : void 0,
                  modelInitializer: modelArtifacts.modelInitializer != null ? modelArtifacts.modelInitializer : void 0,
                  initializerSignature: modelArtifacts.initializerSignature != null ? modelArtifacts.initializerSignature : void 0,
                  trainingConfig: modelArtifacts.trainingConfig != null ? modelArtifacts.trainingConfig : void 0
                };
                this.LS.setItem(this.keys.modelMetadata, JSON.stringify(metadata));
                return { modelArtifactsInfo };
              } catch (err) {
                removeItems(this.keys);
                throw new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${modelArtifactsInfo.modelTopologyBytes}, weightSpecsBytes=${modelArtifactsInfo.weightSpecsBytes}, weightDataBytes=${modelArtifactsInfo.weightDataBytes}.`);
              }
            }
          });
        }
        /**
         * Load a model from local storage.
         *
         * See the documentation to `browserLocalStorage` for details on the saved
         * artifacts.
         *
         * @returns The loaded model (if loading succeeds).
         */
        load() {
          return __async(this, null, function* () {
            const info = JSON.parse(this.LS.getItem(this.keys.info));
            if (info == null) {
              throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);
            }
            if (info.modelTopologyType !== "JSON") {
              throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
            }
            const out = {};
            const topology = JSON.parse(this.LS.getItem(this.keys.topology));
            if (topology == null) {
              throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);
            }
            out.modelTopology = topology;
            const weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));
            if (weightSpecs == null) {
              throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);
            }
            out.weightSpecs = weightSpecs;
            const metadataString = this.LS.getItem(this.keys.modelMetadata);
            if (metadataString != null) {
              const metadata = JSON.parse(metadataString);
              out.format = metadata.format;
              out.generatedBy = metadata.generatedBy;
              out.convertedBy = metadata.convertedBy;
              if (metadata.signature != null) {
                out.signature = metadata.signature;
              }
              if (metadata.userDefinedMetadata != null) {
                out.userDefinedMetadata = metadata.userDefinedMetadata;
              }
              if (metadata.modelInitializer != null) {
                out.modelInitializer = metadata.modelInitializer;
              }
              if (metadata.initializerSignature != null) {
                out.initializerSignature = metadata.initializerSignature;
              }
              if (metadata.trainingConfig != null) {
                out.trainingConfig = metadata.trainingConfig;
              }
            }
            const weightDataBase64 = this.LS.getItem(this.keys.weightData);
            if (weightDataBase64 == null) {
              throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);
            }
            out.weightData = base64StringToArrayBuffer(weightDataBase64);
            return out;
          });
        }
      };
      BrowserLocalStorage.URL_SCHEME = "localstorage://";
      localStorageRouter = (url) => {
        if (!env().getBool("IS_BROWSER")) {
          return null;
        } else {
          if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {
            return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));
          } else {
            return null;
          }
        }
      };
      IORouterRegistry.registerSaveRouter(localStorageRouter);
      IORouterRegistry.registerLoadRouter(localStorageRouter);
      BrowserLocalStorageManager = class {
        constructor() {
          assert(env().getBool("IS_BROWSER"), () => "Current environment is not a web browser");
          assert(typeof window === "undefined" || typeof window.localStorage !== "undefined", () => "Current browser does not appear to support localStorage");
          this.LS = window.localStorage;
        }
        listModels() {
          return __async(this, null, function* () {
            const out = {};
            const prefix = PATH_PREFIX + PATH_SEPARATOR;
            const suffix = PATH_SEPARATOR + INFO_SUFFIX;
            for (let i = 0; i < this.LS.length; ++i) {
              const key = this.LS.key(i);
              if (key.startsWith(prefix) && key.endsWith(suffix)) {
                const modelPath = getModelPathFromKey(key);
                out[modelPath] = JSON.parse(this.LS.getItem(key));
              }
            }
            return out;
          });
        }
        removeModel(path) {
          return __async(this, null, function* () {
            path = maybeStripScheme2(path);
            const keys = getModelKeys(path);
            if (this.LS.getItem(keys.info) == null) {
              throw new Error(`Cannot find model at path '${path}'`);
            }
            const info = JSON.parse(this.LS.getItem(keys.info));
            removeItems(keys);
            return info;
          });
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/model_management.js
  function parseURL(url) {
    if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {
      throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${ModelStoreManagerRegistry.getSchemes().join(",")}`);
    }
    return {
      scheme: url.split(URL_SCHEME_SUFFIX)[0],
      path: url.split(URL_SCHEME_SUFFIX)[1]
    };
  }
  function cloneModelInternal(sourceURL, destURL, deleteSource = false) {
    return __async(this, null, function* () {
      assert(sourceURL !== destURL, () => `Old path and new path are the same: '${sourceURL}'`);
      const loadHandlers = IORouterRegistry.getLoadHandlers(sourceURL);
      assert(loadHandlers.length > 0, () => `Copying failed because no load handler is found for source URL ${sourceURL}.`);
      assert(loadHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) load handlers for source URL ${sourceURL}.`);
      const loadHandler = loadHandlers[0];
      const saveHandlers = IORouterRegistry.getSaveHandlers(destURL);
      assert(saveHandlers.length > 0, () => `Copying failed because no save handler is found for destination URL ${destURL}.`);
      assert(saveHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) save handlers for destination URL ${destURL}.`);
      const saveHandler = saveHandlers[0];
      const sourceScheme = parseURL(sourceURL).scheme;
      const sourcePath = parseURL(sourceURL).path;
      const sameMedium = sourceScheme === parseURL(sourceURL).scheme;
      const modelArtifacts = yield loadHandler.load();
      if (deleteSource && sameMedium) {
        yield ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath);
      }
      const saveResult = yield saveHandler.save(modelArtifacts);
      if (deleteSource && !sameMedium) {
        yield ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath);
      }
      return saveResult.modelArtifactsInfo;
    });
  }
  function listModels() {
    return __async(this, null, function* () {
      const schemes = ModelStoreManagerRegistry.getSchemes();
      const out = {};
      for (const scheme of schemes) {
        const schemeOut = yield ModelStoreManagerRegistry.getManager(scheme).listModels();
        for (const path in schemeOut) {
          const url = scheme + URL_SCHEME_SUFFIX + path;
          out[url] = schemeOut[path];
        }
      }
      return out;
    });
  }
  function removeModel(url) {
    return __async(this, null, function* () {
      const schemeAndPath = parseURL(url);
      const manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);
      return manager.removeModel(schemeAndPath.path);
    });
  }
  function copyModel(sourceURL, destURL) {
    return __async(this, null, function* () {
      const deleteSource = false;
      return cloneModelInternal(sourceURL, destURL, deleteSource);
    });
  }
  function moveModel(sourceURL, destURL) {
    return __async(this, null, function* () {
      const deleteSource = true;
      return cloneModelInternal(sourceURL, destURL, deleteSource);
    });
  }
  var URL_SCHEME_SUFFIX, ModelStoreManagerRegistry;
  var init_model_management = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/io/model_management.js"() {
      init_util();
      init_router_registry();
      URL_SCHEME_SUFFIX = "://";
      ModelStoreManagerRegistry = class {
        constructor() {
          this.managers = {};
        }
        static getInstance() {
          if (ModelStoreManagerRegistry.instance == null) {
            ModelStoreManagerRegistry.instance = new ModelStoreManagerRegistry();
          }
          return ModelStoreManagerRegistry.instance;
        }
        /**
         * Register a save-handler router.
         *
         * @param saveRouter A function that maps a URL-like string onto an instance
         * of `IOHandler` with the `save` method defined or `null`.
         */
        static registerManager(scheme, manager) {
          assert(scheme != null, () => "scheme must not be undefined or null.");
          if (scheme.endsWith(URL_SCHEME_SUFFIX)) {
            scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));
          }
          assert(scheme.length > 0, () => "scheme must not be an empty string.");
          const registry = ModelStoreManagerRegistry.getInstance();
          assert(registry.managers[scheme] == null, () => `A model store manager is already registered for scheme '${scheme}'.`);
          registry.managers[scheme] = manager;
        }
        static getManager(scheme) {
          const manager = ModelStoreManagerRegistry.getInstance().managers[scheme];
          if (manager == null) {
            throw new Error(`Cannot find model manager for scheme '${scheme}'`);
          }
          return manager;
        }
        static getSchemes() {
          return Object.keys(ModelStoreManagerRegistry.getInstance().managers);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js
  var PlatformBrowser;
  var init_platform_browser = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js"() {
      init_flags();
      init_environment();
      init_indexed_db();
      init_local_storage();
      init_model_management();
      PlatformBrowser = class {
        constructor() {
          this.messageName = "setTimeoutCustom";
          this.functionRefs = [];
          this.handledMessageCount = 0;
          this.hasEventListener = false;
        }
        fetch(path, init) {
          return fetch(path, init);
        }
        now() {
          return performance.now();
        }
        encode(text, encoding) {
          if (encoding !== "utf-8" && encoding !== "utf8") {
            throw new Error(`Browser's encoder only supports utf-8, but got ${encoding}`);
          }
          if (this.textEncoder == null) {
            this.textEncoder = new TextEncoder();
          }
          return this.textEncoder.encode(text);
        }
        decode(bytes, encoding) {
          return new TextDecoder(encoding).decode(bytes);
        }
        // If the setTimeout nesting level is greater than 5 and timeout is less
        // than 4ms, timeout will be clamped to 4ms, which hurts the perf.
        // Interleaving window.postMessage and setTimeout will trick the browser and
        // avoid the clamp.
        setTimeoutCustom(functionRef, delay) {
          if (typeof window === "undefined" || !env().getBool("USE_SETTIMEOUTCUSTOM")) {
            setTimeout(functionRef, delay);
            return;
          }
          this.functionRefs.push(functionRef);
          setTimeout(() => {
            window.postMessage({ name: this.messageName, index: this.functionRefs.length - 1 }, "*");
          }, delay);
          if (!this.hasEventListener) {
            this.hasEventListener = true;
            window.addEventListener("message", (event) => {
              if (event.source === window && event.data.name === this.messageName) {
                event.stopPropagation();
                const functionRef2 = this.functionRefs[event.data.index];
                functionRef2();
                this.handledMessageCount++;
                if (this.handledMessageCount === this.functionRefs.length) {
                  this.functionRefs = [];
                  this.handledMessageCount = 0;
                }
              }
            }, true);
          }
        }
        isTypedArray(a) {
          return a instanceof Float32Array || a instanceof Int32Array || a instanceof Uint8Array || a instanceof Uint8ClampedArray;
        }
      };
      if (env().get("IS_BROWSER")) {
        env().setPlatform("browser", new PlatformBrowser());
        try {
          ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());
        } catch (err) {
        }
        try {
          ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());
        } catch (err) {
        }
      }
    }
  });

  // (disabled):node_modules/node-fetch/browser.js
  var require_browser = __commonJS({
    "(disabled):node_modules/node-fetch/browser.js"() {
    }
  });

  // (disabled):../../node_modules/util/util.js
  var require_util = __commonJS({
    "(disabled):../../node_modules/util/util.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js
  var getNodeFetch, systemFetch, PlatformNode;
  var init_platform_node = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js"() {
      init_environment();
      getNodeFetch = {
        // tslint:disable-next-line:no-require-imports
        importFetch: () => require_browser()
      };
      PlatformNode = class {
        constructor() {
          this.util = require_util();
          this.textEncoder = new this.util.TextEncoder();
        }
        fetch(path, requestInits) {
          if (env().global.fetch != null) {
            return env().global.fetch(path, requestInits);
          }
          if (systemFetch == null) {
            systemFetch = getNodeFetch.importFetch();
          }
          return systemFetch(path, requestInits);
        }
        now() {
          const time = process.hrtime();
          return time[0] * 1e3 + time[1] / 1e6;
        }
        encode(text, encoding) {
          if (encoding !== "utf-8" && encoding !== "utf8") {
            throw new Error(`Node built-in encoder only supports utf-8, but got ${encoding}`);
          }
          return this.textEncoder.encode(text);
        }
        decode(bytes, encoding) {
          if (bytes.length === 0) {
            return "";
          }
          return new this.util.TextDecoder(encoding).decode(bytes);
        }
        isTypedArray(a) {
          return this.util.types.isFloat32Array(a) || this.util.types.isInt32Array(a) || this.util.types.isUint8Array(a) || this.util.types.isUint8ClampedArray(a);
        }
      };
      if (env().get("IS_NODE") && !env().get("IS_BROWSER")) {
        env().setPlatform("node", new PlatformNode());
      }
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/buffer.js
  function buffer(shape, dtype = "float32", values) {
    dtype = dtype || "float32";
    assertNonNegativeIntegerDimensions(shape);
    return new TensorBuffer(shape, dtype, values);
  }
  var init_buffer = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/buffer.js"() {
      init_tensor();
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/cast.js
  function cast_(x, dtype) {
    const $x = convertToTensor(x, "x", "cast");
    if (!isValidDtype(dtype)) {
      throw new Error(`Failed to cast to unknown dtype ${dtype}`);
    }
    if (dtype === "string" && $x.dtype !== "string" || dtype !== "string" && $x.dtype === "string") {
      throw new Error("Only strings can be casted to strings");
    }
    const inputs = { x: $x };
    const attrs = { dtype };
    return ENGINE.runKernel(Cast, inputs, attrs);
  }
  var cast;
  var init_cast = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/cast.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      cast = /* @__PURE__ */ op({ cast_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/clone.js
  function clone_(x) {
    const $x = convertToTensor(x, "x", "clone", "string_or_numeric");
    const inputs = { x: $x };
    return ENGINE.runKernel(Identity, inputs);
  }
  var clone;
  var init_clone = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/clone.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      clone = /* @__PURE__ */ op({ clone_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/print.js
  function print(x, verbose = false) {
    console.log(x.toString(verbose));
  }
  var init_print = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/print.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/base_side_effects.js
  var opHandler2;
  var init_base_side_effects = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/base_side_effects.js"() {
      init_engine();
      init_flags();
      init_platform_browser();
      init_platform_node();
      init_buffer();
      init_cast();
      init_clone();
      init_print();
      init_tensor();
      getOrMakeEngine();
      opHandler2 = {
        buffer,
        cast,
        clone,
        print
      };
      setOpHandler(opHandler2);
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/globals.js
  function deprecationWarn(msg) {
    if (env().getBool("DEPRECATION_WARNINGS_ENABLED")) {
      console.warn(msg + " You can disable deprecation warnings with tf.disableDeprecationWarnings().");
    }
  }
  function engine() {
    return ENGINE;
  }
  function tidy(nameOrFn, fn) {
    return ENGINE.tidy(nameOrFn, fn);
  }
  function dispose(container) {
    const tensors = getTensorsInContainer(container);
    tensors.forEach((tensor2) => tensor2.dispose());
  }
  function keep(result) {
    return ENGINE.keep(result);
  }
  function setBackend(backendName) {
    return ENGINE.setBackend(backendName);
  }
  function ready() {
    return ENGINE.ready();
  }
  function registerBackend(name, factory, priority = 1) {
    return ENGINE.registerBackend(name, factory, priority);
  }
  var init_globals = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/globals.js"() {
      init_engine();
      init_environment();
      init_tensor();
      init_tensor_util();
      setDeprecationWarningFn(deprecationWarn);
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/add.js
  function add_(a, b) {
    let $a = convertToTensor(a, "a", "add");
    let $b = convertToTensor(b, "b", "add");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Add, inputs);
  }
  var add2;
  var init_add = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/add.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_operation();
      add2 = /* @__PURE__ */ op({ add_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/floorDiv.js
  function floorDiv_(a, b) {
    let $a = convertToTensor(a, "a", "floorDiv");
    let $b = convertToTensor(b, "b", "floorDiv");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(FloorDiv, inputs);
  }
  var floorDiv;
  var init_floorDiv = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/floorDiv.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_operation();
      floorDiv = /* @__PURE__ */ op({ floorDiv_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/div.js
  function div_(a, b) {
    let $a = convertToTensor(a, "a", "div");
    let $b = convertToTensor(b, "b", "div");
    [$a, $b] = makeTypesMatch($a, $b);
    if ($a.dtype === "int32" && $b.dtype === "int32") {
      return floorDiv($a, $b);
    }
    const inputs = { a: $a, b: $b };
    const attrs = {};
    return ENGINE.runKernel(RealDiv, inputs, attrs);
  }
  var div;
  var init_div = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/div.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_floorDiv();
      init_operation();
      div = /* @__PURE__ */ op({ div_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/mul.js
  function mul_(a, b) {
    let $a = convertToTensor(a, "a", "mul");
    let $b = convertToTensor(b, "b", "mul");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Multiply, inputs);
  }
  var mul;
  var init_mul = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/mul.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_operation();
      mul = /* @__PURE__ */ op({ mul_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/abs.js
  function abs_(x) {
    const $x = convertToTensor(x, "x", "abs");
    if ($x.dtype === "complex64") {
      const inputs = { x: $x };
      return ENGINE.runKernel(ComplexAbs, inputs);
    } else {
      const inputs = { x: $x };
      return ENGINE.runKernel(Abs, inputs);
    }
  }
  var abs;
  var init_abs = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/abs.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      abs = /* @__PURE__ */ op({ abs_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/acos.js
  function acos_(x) {
    const $x = convertToTensor(x, "x", "acos");
    const inputs = { x: $x };
    return ENGINE.runKernel(Acos, inputs);
  }
  var acos;
  var init_acos = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/acos.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      acos = /* @__PURE__ */ op({ acos_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/acosh.js
  function acosh_(x) {
    const $x = convertToTensor(x, "x", "acosh");
    const inputs = { x: $x };
    return ENGINE.runKernel(Acosh, inputs);
  }
  var acosh;
  var init_acosh = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/acosh.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      acosh = /* @__PURE__ */ op({ acosh_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/add_n.js
  function addN_(tensors) {
    assert(Array.isArray(tensors), () => "The argument passed to tf.addN() must be a list of tensors");
    assert(tensors.length >= 1, () => `Must pass at least one tensor to tf.addN(), but got ${tensors.length}`);
    const $tensors = tensors.map((t2, i) => convertToTensor(t2, `tensors${i}`, "addN"));
    const firstTensor = $tensors[0];
    $tensors.forEach((t2) => {
      if (t2.dtype !== firstTensor.dtype) {
        throw new Error("All tensors passed to tf.addN() must have the same dtype");
      }
    });
    $tensors.forEach((t2) => {
      if (!arraysEqual(t2.shape, firstTensor.shape)) {
        throw new Error("All tensors passed to tf.addN() must have the same shape");
      }
    });
    const inputs = $tensors;
    return ENGINE.runKernel(AddN, inputs);
  }
  var addN;
  var init_add_n = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/add_n.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      addN = /* @__PURE__ */ op({ addN_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/all.js
  function all_(x, axis = null, keepDims = false) {
    const $x = convertToTensor(x, "x", "all", "bool");
    const inputs = { x: $x };
    const attrs = { axis, keepDims };
    return ENGINE.runKernel(All, inputs, attrs);
  }
  var all;
  var init_all = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/all.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      all = /* @__PURE__ */ op({ all_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/any.js
  function any_(x, axis = null, keepDims = false) {
    const $x = convertToTensor(x, "x", "any", "bool");
    const inputs = { x: $x };
    const attrs = { axis, keepDims };
    return ENGINE.runKernel(Any, inputs, attrs);
  }
  var any;
  var init_any = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/any.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      any = /* @__PURE__ */ op({ any_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/arg_max.js
  function argMax_(x, axis = 0) {
    const $x = convertToTensor(x, "x", "argMax");
    const inputs = { x: $x };
    const attrs = { axis };
    return ENGINE.runKernel(ArgMax, inputs, attrs);
  }
  var argMax;
  var init_arg_max = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/arg_max.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      argMax = /* @__PURE__ */ op({ argMax_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/arg_min.js
  function argMin_(x, axis = 0) {
    const $x = convertToTensor(x, "x", "argMin");
    const inputs = { x: $x };
    const attrs = { axis };
    return ENGINE.runKernel(ArgMin, inputs, attrs);
  }
  var argMin;
  var init_arg_min = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/arg_min.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      argMin = /* @__PURE__ */ op({ argMin_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/asin.js
  function asin_(x) {
    const $x = convertToTensor(x, "x", "asin");
    const inputs = { x: $x };
    return ENGINE.runKernel(Asin, inputs);
  }
  var asin;
  var init_asin = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/asin.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      asin = /* @__PURE__ */ op({ asin_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/asinh.js
  function asinh_(x) {
    const $x = convertToTensor(x, "x", "asinh");
    const inputs = { x: $x };
    return ENGINE.runKernel(Asinh, inputs);
  }
  var asinh;
  var init_asinh = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/asinh.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      asinh = /* @__PURE__ */ op({ asinh_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/atan.js
  function atan_(x) {
    const $x = convertToTensor(x, "x", "atan");
    const inputs = { x: $x };
    return ENGINE.runKernel(Atan, inputs);
  }
  var atan;
  var init_atan = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/atan.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      atan = /* @__PURE__ */ op({ atan_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/atan2.js
  function atan2_(a, b) {
    let $a = convertToTensor(a, "a", "atan2");
    let $b = convertToTensor(b, "b", "atan2");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Atan2, inputs);
  }
  var atan2;
  var init_atan2 = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/atan2.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_operation();
      atan2 = /* @__PURE__ */ op({ atan2_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/atanh.js
  function atanh_(x) {
    const $x = convertToTensor(x, "x", "atanh");
    const inputs = { x: $x };
    return ENGINE.runKernel(Atanh, inputs);
  }
  var atanh;
  var init_atanh = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/atanh.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      atanh = /* @__PURE__ */ op({ atanh_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js
  function computeDilation2DInfo(inputShape, filterShape, strides, pad2, dataFormat = "NHWC", dilations) {
    const inputChannels = inputShape[3];
    const $filterShape = [...filterShape, inputChannels];
    const $dataFormat = convertConv2DDataFormat(dataFormat);
    return computeConv2DInfo(inputShape, $filterShape, strides, dilations, pad2, null, null, $dataFormat);
  }
  function computePool2DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat = "channelsLast") {
    const [filterHeight, filterWidth] = parseTupleParam(filterSize);
    let filterShape;
    if (dataFormat === "channelsLast") {
      filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];
    } else if (dataFormat === "channelsFirst") {
      filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];
    } else {
      throw new Error(`Unknown dataFormat ${dataFormat}`);
    }
    return computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, false, dataFormat);
  }
  function computePool3DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat = "NDHWC") {
    const [filterDepth, filterHeight, filterWidth] = parse3TupleParam(filterSize);
    let filterShape;
    let $dataFormat;
    if (dataFormat === "NDHWC") {
      $dataFormat = "channelsLast";
      filterShape = [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];
    } else if (dataFormat === "NCDHW") {
      $dataFormat = "channelsFirst";
      filterShape = [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];
    } else {
      throw new Error(`Unknown dataFormat ${dataFormat}`);
    }
    return computeConv3DInfo(inShape, filterShape, strides, dilations, pad2, false, $dataFormat, roundingMode);
  }
  function computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, depthwise = false, dataFormat = "channelsLast") {
    let [batchSize, inHeight, inWidth, inChannels] = [-1, -1, -1, -1];
    if (dataFormat === "channelsLast") {
      [batchSize, inHeight, inWidth, inChannels] = inShape;
    } else if (dataFormat === "channelsFirst") {
      [batchSize, inChannels, inHeight, inWidth] = inShape;
    } else {
      throw new Error(`Unknown dataFormat ${dataFormat}`);
    }
    const [filterHeight, filterWidth, , filterChannels] = filterShape;
    const [strideHeight, strideWidth] = parseTupleParam(strides);
    const [dilationHeight, dilationWidth] = parseTupleParam(dilations);
    const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
    const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
    const { padInfo, outHeight, outWidth } = getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat);
    const outChannels = depthwise ? filterChannels * inChannels : filterChannels;
    let outShape;
    if (dataFormat === "channelsFirst") {
      outShape = [batchSize, outChannels, outHeight, outWidth];
    } else if (dataFormat === "channelsLast") {
      outShape = [batchSize, outHeight, outWidth, outChannels];
    }
    return {
      batchSize,
      dataFormat,
      inHeight,
      inWidth,
      inChannels,
      outHeight,
      outWidth,
      outChannels,
      padInfo,
      strideHeight,
      strideWidth,
      filterHeight,
      filterWidth,
      effectiveFilterHeight,
      effectiveFilterWidth,
      dilationHeight,
      dilationWidth,
      inShape,
      outShape,
      filterShape
    };
  }
  function computeConv3DInfo(inShape, filterShape, strides, dilations, pad2, depthwise = false, dataFormat = "channelsLast", roundingMode) {
    let [batchSize, inDepth, inHeight, inWidth, inChannels] = [-1, -1, -1, -1, -1];
    if (dataFormat === "channelsLast") {
      [batchSize, inDepth, inHeight, inWidth, inChannels] = inShape;
    } else if (dataFormat === "channelsFirst") {
      [batchSize, inChannels, inDepth, inHeight, inWidth] = inShape;
    } else {
      throw new Error(`Unknown dataFormat ${dataFormat}`);
    }
    const [filterDepth, filterHeight, filterWidth, , filterChannels] = filterShape;
    const [strideDepth, strideHeight, strideWidth] = parse3TupleParam(strides);
    const [dilationDepth, dilationHeight, dilationWidth] = parse3TupleParam(dilations);
    const effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);
    const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
    const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
    const { padInfo, outDepth, outHeight, outWidth } = get3DPadAndOutInfo(pad2, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode);
    const outChannels = depthwise ? filterChannels * inChannels : filterChannels;
    let outShape;
    if (dataFormat === "channelsFirst") {
      outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];
    } else if (dataFormat === "channelsLast") {
      outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];
    }
    return {
      batchSize,
      dataFormat,
      inDepth,
      inHeight,
      inWidth,
      inChannels,
      outDepth,
      outHeight,
      outWidth,
      outChannels,
      padInfo,
      strideDepth,
      strideHeight,
      strideWidth,
      filterDepth,
      filterHeight,
      filterWidth,
      effectiveFilterDepth,
      effectiveFilterHeight,
      effectiveFilterWidth,
      dilationDepth,
      dilationHeight,
      dilationWidth,
      inShape,
      outShape,
      filterShape
    };
  }
  function computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {
    if (zeroPad == null) {
      zeroPad = computeDefaultPad(inShape, fieldSize, stride);
    }
    const inputRows = inShape[0];
    const inputCols = inShape[1];
    const outputRows = round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
    const outputCols = round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
    return [outputRows, outputCols];
  }
  function computeOutputShape4D(inShape, filterShape, outChannels, strides, zeroPad, roundingMode) {
    if (zeroPad == null) {
      zeroPad = computeDefaultPad(inShape, filterShape[0], strides[0]);
    }
    const outShape = [0, 0, 0, outChannels];
    for (let index = 0; index < 3; index++) {
      if (inShape[index] + 2 * zeroPad >= filterShape[index]) {
        outShape[index] = round((inShape[index] - filterShape[index] + 2 * zeroPad) / strides[index] + 1, roundingMode);
      }
    }
    return outShape;
  }
  function computeDefaultPad(inputShape, fieldSize, stride, dilation = 1) {
    const effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);
    return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);
  }
  function parseTupleParam(param) {
    if (typeof param === "number") {
      return [param, param, param];
    }
    if (param.length === 2) {
      return [param[0], param[1], 1];
    }
    return param;
  }
  function parse3TupleParam(param) {
    return typeof param === "number" ? [param, param, param] : param;
  }
  function getEffectiveFilterSize(filterSize, dilation) {
    if (dilation <= 1) {
      return filterSize;
    }
    return filterSize + (filterSize - 1) * (dilation - 1);
  }
  function getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {
    let padInfo;
    let outHeight;
    let outWidth;
    if (typeof pad2 === "number") {
      const padType = pad2 === 0 ? "VALID" : "NUMBER";
      padInfo = { top: pad2, bottom: pad2, left: pad2, right: pad2, type: padType };
      const outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad2, roundingMode);
      outHeight = outShape[0];
      outWidth = outShape[1];
    } else if (pad2 === "same") {
      outHeight = Math.ceil(inHeight / strideHeight);
      outWidth = Math.ceil(inWidth / strideWidth);
      const padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);
      const padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);
      const top = Math.floor(padAlongHeight / 2);
      const bottom = padAlongHeight - top;
      const left = Math.floor(padAlongWidth / 2);
      const right = padAlongWidth - left;
      padInfo = { top, bottom, left, right, type: "SAME" };
    } else if (pad2 === "valid") {
      padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: "VALID" };
      outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
      outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
    } else if (typeof pad2 === "object") {
      const top = dataFormat === "channelsLast" ? pad2[1][0] : pad2[2][0];
      const bottom = dataFormat === "channelsLast" ? pad2[1][1] : pad2[2][1];
      const left = dataFormat === "channelsLast" ? pad2[2][0] : pad2[3][0];
      const right = dataFormat === "channelsLast" ? pad2[2][1] : pad2[3][1];
      const padType = top === 0 && bottom === 0 && left === 0 && right === 0 ? "VALID" : "EXPLICIT";
      padInfo = { top, bottom, left, right, type: padType };
      outHeight = round((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);
      outWidth = round((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);
    } else {
      throw Error(`Unknown padding parameter: ${pad2}`);
    }
    return { padInfo, outHeight, outWidth };
  }
  function get3DPadAndOutInfo(pad2, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {
    let padInfo;
    let outDepth;
    let outHeight;
    let outWidth;
    if (pad2 === "valid") {
      pad2 = 0;
    }
    if (typeof pad2 === "number") {
      const padType = pad2 === 0 ? "VALID" : "NUMBER";
      padInfo = {
        top: pad2,
        bottom: pad2,
        left: pad2,
        right: pad2,
        front: pad2,
        back: pad2,
        type: padType
      };
      const outShape = computeOutputShape4D([inDepth, inHeight, inWidth, 1], [filterDepth, filterHeight, filterWidth], 1, [strideDepth, strideHeight, strideWidth], pad2, roundingMode);
      outDepth = outShape[0];
      outHeight = outShape[1];
      outWidth = outShape[2];
    } else if (pad2 === "same") {
      outDepth = Math.ceil(inDepth / strideDepth);
      outHeight = Math.ceil(inHeight / strideHeight);
      outWidth = Math.ceil(inWidth / strideWidth);
      const padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;
      const padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;
      const padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;
      const front = Math.floor(padAlongDepth / 2);
      const back = padAlongDepth - front;
      const top = Math.floor(padAlongHeight / 2);
      const bottom = padAlongHeight - top;
      const left = Math.floor(padAlongWidth / 2);
      const right = padAlongWidth - left;
      padInfo = { top, bottom, left, right, front, back, type: "SAME" };
    } else {
      throw Error(`Unknown padding parameter: ${pad2}`);
    }
    return { padInfo, outDepth, outHeight, outWidth };
  }
  function round(value, roundingMode) {
    if (!roundingMode) {
      return Math.trunc(value);
    }
    switch (roundingMode) {
      case "round":
        return Math.round(value);
      case "ceil":
        return Math.ceil(value);
      case "floor":
        return Math.floor(value);
      default:
        throw new Error(`Unknown roundingMode ${roundingMode}`);
    }
  }
  function tupleValuesAreOne(param) {
    const [dimA, dimB, dimC] = parseTupleParam(param);
    return dimA === 1 && dimB === 1 && dimC === 1;
  }
  function eitherStridesOrDilationsAreOne(strides, dilations) {
    return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);
  }
  function stridesOrDilationsArePositive(values) {
    return parseTupleParam(values).every((value) => value > 0);
  }
  function convertConv2DDataFormat(dataFormat) {
    if (dataFormat === "NHWC") {
      return "channelsLast";
    } else if (dataFormat === "NCHW") {
      return "channelsFirst";
    } else {
      throw new Error(`Unknown dataFormat ${dataFormat}`);
    }
  }
  function checkPadOnDimRoundingMode(opDesc, pad2, dimRoundingMode) {
    if (dimRoundingMode != null) {
      if (typeof pad2 === "string") {
        throw Error(`Error in ${opDesc}: pad must be an integer when using dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
      } else if (typeof pad2 === "number") {
        assert(isInt(pad2), () => `Error in ${opDesc}: pad must be an integer when using dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
      } else if (typeof pad2 === "object") {
        pad2.forEach((p2) => {
          p2.forEach((v) => {
            assert(isInt(v), () => `Error in ${opDesc}: pad must be an integer when using dimRoundingMode ${dimRoundingMode} but got pad ${v}.`);
          });
        });
      } else {
        throw Error(`Error in ${opDesc}: Unknown padding parameter: ${pad2}`);
      }
    }
  }
  var init_conv_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js"() {
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/reshape.js
  function reshape_(x, shape) {
    const $x = convertToTensor(x, "x", "reshape", "string_or_numeric");
    const inputs = { x: $x };
    const attrs = { shape };
    return ENGINE.runKernel(Reshape, inputs, attrs);
  }
  var reshape;
  var init_reshape = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/reshape.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      reshape = /* @__PURE__ */ op({ reshape_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool.js
  function avgPool_(x, filterSize, strides, pad2, dimRoundingMode) {
    const $x = convertToTensor(x, "x", "avgPool", "float32");
    const dilations = 1;
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in avgPool: x must be rank 4 but got rank ${x4D.rank}.`);
    checkPadOnDimRoundingMode("avgPool", pad2, dimRoundingMode);
    const inputs = { x: x4D };
    const attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
    let res = ENGINE.runKernel(AvgPool, inputs, attrs);
    res = cast(res, $x.dtype);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var avgPool;
  var init_avg_pool = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_cast();
      init_conv_util();
      init_operation();
      init_reshape();
      avgPool = /* @__PURE__ */ op({ avgPool_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d.js
  function avgPool3d_(x, filterSize, strides, pad2, dimRoundingMode, dataFormat = "NDHWC") {
    const $x = convertToTensor(x, "x", "avgPool3d", "float32");
    let x5D = $x;
    let reshapedTo5D = false;
    if ($x.rank === 4) {
      reshapedTo5D = true;
      x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
    }
    assert(x5D.rank === 5, () => `Error in avgPool3d: x must be rank 5 but got rank ${x5D.rank}.`);
    assert(dataFormat === "NDHWC", () => `Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${dataFormat}`);
    assert(typeof strides === "number" && strides > 0 || Array.isArray(strides) && strides[0] > 0 && strides[1] > 0 && strides[2] > 0, () => `Error in avgPool3d: Stride must be > 0, but got '${strides}'`);
    checkPadOnDimRoundingMode("avgPool3d", pad2, dimRoundingMode);
    const inputs = { x: x5D };
    const attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
    let res = ENGINE.runKernel(AvgPool3D, inputs, attrs);
    res = cast(res, x5D.dtype);
    if (reshapedTo5D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
    }
    return res;
  }
  var avgPool3d;
  var init_avg_pool_3d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_cast();
      init_conv_util();
      init_operation();
      init_reshape();
      avgPool3d = /* @__PURE__ */ op({ avgPool3d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/concat.js
  function concat_(tensors, axis = 0) {
    assert(tensors.length >= 1, () => "Pass at least one tensor to concat");
    const $tensors = convertToTensorArray(tensors, "tensors", "concat", "string_or_numeric");
    if ($tensors[0].dtype === "complex64") {
      $tensors.forEach((tensor2) => {
        if (tensor2.dtype !== "complex64") {
          throw new Error(`Cannot concatenate complex64 tensors with a tensor
          with dtype ${tensor2.dtype}. `);
        }
      });
    }
    if ($tensors.length === 1) {
      return clone($tensors[0]);
    }
    const inputs = $tensors;
    const attr = { axis };
    return ENGINE.runKernel(Concat, inputs, attr);
  }
  var concat;
  var init_concat = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/concat.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_clone();
      init_operation();
      concat = /* @__PURE__ */ op({ concat_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/mat_mul.js
  function matMul_(a, b, transposeA = false, transposeB = false) {
    let $a = convertToTensor(a, "a", "matMul");
    let $b = convertToTensor(b, "b", "matMul");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    const attrs = { transposeA, transposeB };
    return ENGINE.runKernel(BatchMatMul, inputs, attrs);
  }
  var matMul;
  var init_mat_mul = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/mat_mul.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_operation();
      matMul = /* @__PURE__ */ op({ matMul_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sigmoid.js
  function sigmoid_(x) {
    const $x = convertToTensor(x, "x", "sigmoid", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Sigmoid, inputs);
  }
  var sigmoid;
  var init_sigmoid = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sigmoid.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      sigmoid = /* @__PURE__ */ op({ sigmoid_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/slice.js
  function slice_(x, begin, size) {
    const $x = convertToTensor(x, "x", "slice", "string_or_numeric");
    if ($x.rank === 0) {
      throw new Error("Slicing scalar is not possible");
    }
    const inputs = { x: $x };
    const attrs = { begin, size };
    return ENGINE.runKernel(Slice, inputs, attrs);
  }
  var slice;
  var init_slice = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/slice.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      slice = /* @__PURE__ */ op({ slice_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tanh.js
  function tanh_(x) {
    const $x = convertToTensor(x, "x", "tanh", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Tanh, inputs);
  }
  var tanh2;
  var init_tanh = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/tanh.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      tanh2 = /* @__PURE__ */ op({ tanh_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/basic_lstm_cell.js
  function basicLSTMCell_(forgetBias, lstmKernel, lstmBias, data, c, h) {
    const $forgetBias = convertToTensor(forgetBias, "forgetBias", "basicLSTMCell");
    const $lstmKernel = convertToTensor(lstmKernel, "lstmKernel", "basicLSTMCell");
    const $lstmBias = convertToTensor(lstmBias, "lstmBias", "basicLSTMCell");
    const $data = convertToTensor(data, "data", "basicLSTMCell");
    const $c = convertToTensor(c, "c", "basicLSTMCell");
    const $h = convertToTensor(h, "h", "basicLSTMCell");
    const combined = concat([$data, $h], 1);
    const weighted = matMul(combined, $lstmKernel);
    const res = add2(weighted, $lstmBias);
    const batchSize = res.shape[0];
    const sliceCols = res.shape[1] / 4;
    const sliceSize = [batchSize, sliceCols];
    const i = slice(res, [0, 0], sliceSize);
    const j2 = slice(res, [0, sliceCols], sliceSize);
    const f = slice(res, [0, sliceCols * 2], sliceSize);
    const o = slice(res, [0, sliceCols * 3], sliceSize);
    const newC = add2(mul(sigmoid(i), tanh2(j2)), mul($c, sigmoid(add2($forgetBias, f))));
    const newH = mul(tanh2(newC), sigmoid(o));
    return [newC, newH];
  }
  var basicLSTMCell;
  var init_basic_lstm_cell = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/basic_lstm_cell.js"() {
      init_tensor_util_env();
      init_add();
      init_concat();
      init_mat_mul();
      init_mul();
      init_operation();
      init_sigmoid();
      init_slice();
      init_tanh();
      basicLSTMCell = /* @__PURE__ */ op({ basicLSTMCell_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js
  function batchToSpaceND_(x, blockShape, crops) {
    const $x = convertToTensor(x, "x", "batchToSpaceND");
    const prod3 = blockShape.reduce((a, b) => a * b);
    assert($x.rank >= 1 + blockShape.length, () => `input rank is ${$x.rank} but should be > than blockShape.length ${blockShape.length}`);
    assert(crops.length === blockShape.length, () => `crops.length is ${crops.length} but should be equal to blockShape.length  ${blockShape.length}`);
    assert($x.shape[0] % prod3 === 0, () => `input tensor batch is ${$x.shape[0]} but is not divisible by the product of the elements of blockShape ${blockShape.join(" * ")} === ${prod3}`);
    const inputs = { x: $x };
    const attrs = { blockShape, crops };
    return ENGINE.runKernel(BatchToSpaceND, inputs, attrs);
  }
  var batchToSpaceND;
  var init_batch_to_space_nd = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      batchToSpaceND = /* @__PURE__ */ op({ batchToSpaceND_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm_util.js
  function xAs4D(x) {
    let x4D;
    if (x.rank === 0 || x.rank === 1) {
      x4D = reshape(x, [1, 1, 1, x.size]);
    } else if (x.rank === 2) {
      x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);
    } else if (x.rank === 3) {
      x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
    } else {
      x4D = x;
    }
    return x4D;
  }
  var init_batchnorm_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm_util.js"() {
      init_reshape();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js
  function batchNorm_(x, mean3, variance, offset, scale2, varianceEpsilon) {
    if (varianceEpsilon == null) {
      varianceEpsilon = 1e-3;
    }
    const $x = convertToTensor(x, "x", "batchNorm");
    const $mean = convertToTensor(mean3, "mean", "batchNorm");
    const $variance = convertToTensor(variance, "variance", "batchNorm");
    let $scale;
    if (scale2 != null) {
      $scale = convertToTensor(scale2, "scale", "batchNorm");
    }
    let $offset;
    if (offset != null) {
      $offset = convertToTensor(offset, "offset", "batchNorm");
    }
    assert($mean.rank === $variance.rank, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
    assert($offset == null || $mean.rank === $offset.rank, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
    assert($scale == null || $mean.rank === $scale.rank, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
    const x4D = xAs4D($x);
    const inputs = {
      x: x4D,
      scale: $scale,
      offset: $offset,
      mean: $mean,
      variance: $variance
    };
    const attrs = { varianceEpsilon };
    const res = ENGINE.runKernel(FusedBatchNorm, inputs, attrs);
    return reshape(res, $x.shape);
  }
  var batchNorm;
  var init_batchnorm = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_batchnorm_util();
      init_operation();
      init_reshape();
      batchNorm = /* @__PURE__ */ op({ batchNorm_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm2d.js
  function batchNorm2d_(x, mean3, variance, offset, scale2, varianceEpsilon) {
    const $x = convertToTensor(x, "x", "batchNorm");
    const $mean = convertToTensor(mean3, "mean", "batchNorm");
    const $variance = convertToTensor(variance, "variance", "batchNorm");
    let $scale;
    if (scale2 != null) {
      $scale = convertToTensor(scale2, "scale", "batchNorm");
    }
    let $offset;
    if (offset != null) {
      $offset = convertToTensor(offset, "offset", "batchNorm");
    }
    assert($x.rank === 2, () => `Error in batchNorm2D: x must be rank 2 but got rank ${$x.rank}.`);
    assert($mean.rank === 2 || $mean.rank === 1, () => `Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${$mean.rank}.`);
    assert($variance.rank === 2 || $variance.rank === 1, () => `Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${$variance.rank}.`);
    if ($scale != null) {
      assert($scale.rank === 2 || $scale.rank === 1, () => `Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${$scale.rank}.`);
    }
    if ($offset != null) {
      assert($offset.rank === 2 || $offset.rank === 1, () => `Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${$offset.rank}.`);
    }
    return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
  }
  var batchNorm2d;
  var init_batchnorm2d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm2d.js"() {
      init_tensor_util_env();
      init_util();
      init_batchnorm();
      init_operation();
      batchNorm2d = /* @__PURE__ */ op({ batchNorm2d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm3d.js
  function batchNorm3d_(x, mean3, variance, offset, scale2, varianceEpsilon) {
    const $x = convertToTensor(x, "x", "batchNorm");
    const $mean = convertToTensor(mean3, "mean", "batchNorm");
    const $variance = convertToTensor(variance, "variance", "batchNorm");
    let $scale;
    if (scale2 != null) {
      $scale = convertToTensor(scale2, "scale", "batchNorm");
    }
    let $offset;
    if (offset != null) {
      $offset = convertToTensor(offset, "offset", "batchNorm");
    }
    assert($x.rank === 3, () => `Error in batchNorm3D: x must be rank 3 but got rank ${$x.rank}.`);
    assert($mean.rank === 3 || $mean.rank === 1, () => `Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${$mean.rank}.`);
    assert($variance.rank === 3 || $variance.rank === 1, () => `Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${$variance.rank}.`);
    if ($scale != null) {
      assert($scale.rank === 3 || $scale.rank === 1, () => `Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${$scale.rank}.`);
    }
    if ($offset != null) {
      assert($offset.rank === 3 || $offset.rank === 1, () => `Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${$offset.rank}.`);
    }
    return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
  }
  var batchNorm3d;
  var init_batchnorm3d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm3d.js"() {
      init_tensor_util_env();
      init_util();
      init_batchnorm();
      init_operation();
      batchNorm3d = /* @__PURE__ */ op({ batchNorm3d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm4d.js
  function batchNorm4d_(x, mean3, variance, offset, scale2, varianceEpsilon) {
    const $x = convertToTensor(x, "x", "batchNorm");
    const $mean = convertToTensor(mean3, "mean", "batchNorm");
    const $variance = convertToTensor(variance, "variance", "batchNorm");
    let $scale;
    if (scale2 != null) {
      $scale = convertToTensor(scale2, "scale", "batchNorm");
    }
    let $offset;
    if (offset != null) {
      $offset = convertToTensor(offset, "offset", "batchNorm");
    }
    assert($x.rank === 4, () => `Error in batchNorm4D: x must be rank 4 but got rank ${$x.rank}.`);
    assert($mean.rank === 4 || $mean.rank === 1, () => `Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${$mean.rank}.`);
    assert($variance.rank === 4 || $variance.rank === 1, () => `Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${$variance.rank}.`);
    if ($scale != null) {
      assert($scale.rank === 4 || $scale.rank === 1, () => `Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${$scale.rank}.`);
    }
    if ($offset != null) {
      assert($offset.rank === 4 || $offset.rank === 1, () => `Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${$offset.rank}.`);
    }
    return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
  }
  var batchNorm4d;
  var init_batchnorm4d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm4d.js"() {
      init_tensor_util_env();
      init_util();
      init_batchnorm();
      init_operation();
      batchNorm4d = /* @__PURE__ */ op({ batchNorm4d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/bincount.js
  function bincount_(x, weights, size) {
    const $x = convertToTensor(x, "x", "bincount");
    const $weights = convertToTensor(weights, "weights", "bincount");
    assert($x.dtype === "int32", () => `Error in bincount: input dtype must be int32, but got ${$x.dtype}`);
    assert(size >= 0, () => `size must be non-negative, but got ${size}.`);
    assert($weights.size === $x.size || $weights.size === 0, () => `Error in bincount: weights must have the same size as input or0-length, but got input shape: ${$x.shape}, weights shape: ${$weights.shape}.`);
    const inputs = { x: $x, weights: $weights };
    const attrs = { size };
    return ENGINE.runKernel(Bincount, inputs, attrs);
  }
  var bincount;
  var init_bincount = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/bincount.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      bincount = /* @__PURE__ */ op({ bincount_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_args.js
  function broadcastArgs_(s0, s1) {
    const shape1Input = convertToTensor(s0, "s0", "broadcastArgs", "int32");
    const shape2Input = convertToTensor(s1, "s1", "broadcastArgs", "int32");
    if (shape1Input.rank !== 1) {
      throw new Error(`broadcastArgs(): first input must be a vector (rank=1). Has rank ${shape1Input.rank}`);
    }
    if (shape2Input.rank !== 1) {
      throw new Error(`broadcastArgs(): second input must be a vector (rank=1). Has rank ${shape2Input.rank}`);
    }
    const inputs = { s0: shape1Input, s1: shape2Input };
    return ENGINE.runKernel(BroadcastArgs, inputs);
  }
  var broadcastArgs;
  var init_broadcast_args = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_args.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      broadcastArgs = /* @__PURE__ */ op({ broadcastArgs_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_to.js
  function broadcastTo_(x, shape) {
    let input = convertToTensor(x, "broadcastTo", "x");
    const xShape = input.shape;
    assertNonNegativeIntegerDimensions(shape);
    if (shape.length < input.rank) {
      throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input.rank}.`);
    }
    if (shape.length > input.rank) {
      const newShape = input.shape.slice();
      while (newShape.length < shape.length) {
        newShape.unshift(1);
      }
      input = reshape(input, newShape);
    }
    const inputShape = input.shape;
    const reps = Array.from(shape);
    for (let i = shape.length - 1; i >= 0; i--) {
      if (inputShape[i] === shape[i]) {
        reps[i] = 1;
      } else if (input.shape[i] !== 1) {
        throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);
      }
    }
    const axes = reps.map((n, i) => n > 1 ? i : -1).filter((i) => i >= 0);
    if (axes.length === 0) {
      return clone(input);
    }
    const inputs = { x: input };
    const attrs = { reps };
    return ENGINE.runKernel(Tile, inputs, attrs);
  }
  var broadcastTo;
  var init_broadcast_to = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_to.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util_base();
      init_clone();
      init_operation();
      init_reshape();
      broadcastTo = /* @__PURE__ */ op({ broadcastTo_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/ceil.js
  function ceil_(x) {
    const $x = convertToTensor(x, "x", "ceil", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Ceil, inputs);
  }
  var ceil;
  var init_ceil = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/ceil.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      ceil = /* @__PURE__ */ op({ ceil_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/fill.js
  function fill(shape, value, dtype) {
    assertNonNegativeIntegerDimensions(shape);
    const attrs = { shape, value, dtype };
    return ENGINE.runKernel(Fill, {}, attrs);
  }
  var init_fill = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/fill.js"() {
      init_engine();
      init_kernel_names();
      init_util_base();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/clip_by_value.js
  function clipByValue_(x, clipValueMin, clipValueMax) {
    const $x = convertToTensor(x, "x", "clipByValue");
    assert(clipValueMin <= clipValueMax, () => `Error in clip: min (${clipValueMin}) must be less than or equal to max (${clipValueMax}).`);
    if (clipValueMin === clipValueMax) {
      return fill($x.shape, clipValueMin, $x.dtype);
    }
    const inputs = { x: $x };
    const attrs = { clipValueMin, clipValueMax };
    return ENGINE.runKernel(ClipByValue, inputs, attrs);
  }
  var clipByValue;
  var init_clip_by_value = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/clip_by_value.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_fill();
      init_operation();
      clipByValue = /* @__PURE__ */ op({ clipByValue_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/concat_1d.js
  function concat1d_(tensors) {
    return concat(
      tensors,
      0
      /* axis */
    );
  }
  var concat1d;
  var init_concat_1d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/concat_1d.js"() {
      init_concat();
      init_operation();
      concat1d = /* @__PURE__ */ op({ concat1d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/concat_2d.js
  function concat2d_(tensors, axis) {
    return concat(tensors, axis);
  }
  var concat2d;
  var init_concat_2d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/concat_2d.js"() {
      init_concat();
      init_operation();
      concat2d = /* @__PURE__ */ op({ concat2d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/concat_3d.js
  function concat3d_(tensors, axis) {
    return concat(tensors, axis);
  }
  var concat3d;
  var init_concat_3d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/concat_3d.js"() {
      init_concat();
      init_operation();
      concat3d = /* @__PURE__ */ op({ concat3d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/concat_4d.js
  function concat4d_(tensors, axis) {
    return concat(tensors, axis);
  }
  var concat4d;
  var init_concat_4d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/concat_4d.js"() {
      init_concat();
      init_operation();
      concat4d = /* @__PURE__ */ op({ concat4d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv2d.js
  function conv2d_(x, filter, strides, pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode) {
    const $x = convertToTensor(x, "x", "conv2d", "float32");
    const $filter = convertToTensor(filter, "filter", "conv2d", "float32");
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${x4D.rank}.`);
    assert($filter.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
    checkPadOnDimRoundingMode("conv2d", pad2, dimRoundingMode);
    const inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
    assert(inDepth === $filter.shape[2], () => `Error in conv2d: depth of input (${inDepth}) must match input depth for filter ${$filter.shape[2]}.`);
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    assert(stridesOrDilationsArePositive(dilations), () => "Error in conv2D: Dilated rates should be larger than 0.");
    assert(stridesOrDilationsArePositive(strides), () => "Error in conv2D: Strides should be larger than 0.");
    const inputs = { x: x4D, filter: $filter };
    const attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
    const res = ENGINE.runKernel(Conv2D, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var conv2d;
  var init_conv2d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/conv2d.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_conv_util();
      init_operation();
      init_reshape();
      conv2d = /* @__PURE__ */ op({ conv2d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv1d.js
  function conv1d_(x, filter, stride, pad2, dataFormat = "NWC", dilation = 1, dimRoundingMode) {
    const $x = convertToTensor(x, "x", "conv1d");
    const $filter = convertToTensor(filter, "filter", "conv1d");
    let x3D = $x;
    let reshapedTo3D = false;
    if ($x.rank === 2) {
      reshapedTo3D = true;
      x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);
    }
    assert(x3D.rank === 3, () => `Error in conv1d: input must be rank 3, but got rank ${x3D.rank}.`);
    assert($filter.rank === 3, () => `Error in conv1d: filter must be rank 3, but got rank ${$filter.rank}.`);
    checkPadOnDimRoundingMode("conv1d", pad2, dimRoundingMode);
    assert(x3D.shape[2] === $filter.shape[1], () => `Error in conv1d: depth of input (${x3D.shape[2]}) must match input depth for filter ${$filter.shape[1]}.`);
    assert(eitherStridesOrDilationsAreOne(stride, dilation), () => `Error in conv1D: Either stride or dilation must be 1. Got stride ${stride} and dilation '${dilation}'`);
    assert(stridesOrDilationsArePositive(dilation), () => "Error in conv1D: Dilated rates should be larger than 0.");
    assert(stridesOrDilationsArePositive(stride), () => "Error in conv1D: Stride should be larger than 0.");
    assert(dataFormat === "NWC", () => `Error in conv1d: got dataFormat of ${dataFormat} but only NWC is currently supported.`);
    const filter4D = reshape($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);
    const input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);
    const strides = [1, stride];
    const dilations = [1, dilation];
    const conv2dDataFormat = "NHWC";
    const res = conv2d(input4D, filter4D, strides, pad2, conv2dDataFormat, dilations, dimRoundingMode);
    if (reshapedTo3D) {
      return reshape(res, [res.shape[2], res.shape[3]]);
    }
    return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]);
  }
  var conv1d;
  var init_conv1d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/conv1d.js"() {
      init_tensor_util_env();
      init_util();
      init_conv2d();
      init_conv_util();
      init_operation();
      init_reshape();
      conv1d = /* @__PURE__ */ op({ conv1d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js
  function conv2DBackpropInput_(xShape, dy, filter, strides, pad2, dataFormat = "NHWC", dimRoundingMode) {
    assert(xShape.length === dy.rank, () => `Length of inShape (${xShape.length}) and rank of dy (${dy.rank}) must match`);
    let xShape4D = xShape;
    let dy4D = dy;
    let reshapedTo4D = false;
    if (dy.rank === 3) {
      reshapedTo4D = true;
      dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      xShape4D = [1, xShape[0], xShape[1], xShape[2]];
    }
    assert(xShape4D.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ${xShape4D.length}.`);
    assert(dy4D.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got rank ${dy4D.rank}`);
    assert(filter.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got rank ${filter.rank}`);
    const inDepth = dataFormat === "NHWC" ? xShape4D[3] : xShape4D[1];
    const outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
    assert(inDepth === filter.shape[2], () => `Error in conv2dDerInput: depth of input (${inDepth}) must match input depth for filter ${filter.shape[2]}.`);
    assert(outDepth === filter.shape[3], () => `Error in conv2dDerInput: depth of output (${outDepth}) must match output depth for filter ${filter.shape[3]}.`);
    checkPadOnDimRoundingMode("conv2dDerInput", pad2, dimRoundingMode);
    const inputs = { dy: dy4D, filter };
    const attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, inputShape: xShape4D };
    const res = ENGINE.runKernel(Conv2DBackpropInput, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var conv2DBackpropInput;
  var init_conv2d_backprop_input = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js"() {
      init_engine();
      init_kernel_names();
      init_util();
      init_conv_util();
      init_operation();
      init_reshape();
      conv2DBackpropInput = /* @__PURE__ */ op({ conv2DBackpropInput_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_transpose.js
  function conv2dTranspose_(x, filter, outputShape, strides, pad2, dimRoundingMode) {
    const $x = convertToTensor(x, "x", "conv2dTranspose");
    const $filter = convertToTensor(filter, "filter", "conv2dTranspose");
    return conv2DBackpropInput(outputShape, $x, $filter, strides, pad2, "NHWC", dimRoundingMode);
  }
  var conv2dTranspose;
  var init_conv2d_transpose = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_transpose.js"() {
      init_tensor_util_env();
      init_conv2d_backprop_input();
      init_operation();
      conv2dTranspose = /* @__PURE__ */ op({ conv2dTranspose_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv3d.js
  function conv3d_(x, filter, strides, pad2, dataFormat = "NDHWC", dilations = [1, 1, 1]) {
    const $x = convertToTensor(x, "x", "conv3d");
    const $filter = convertToTensor(filter, "filter", "conv3d");
    let x5D = $x;
    let reshapedTo5D = false;
    if ($x.rank === 4) {
      reshapedTo5D = true;
      x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
    }
    assert(x5D.rank === 5, () => `Error in conv3d: input must be rank 5, but got rank ${x5D.rank}.`);
    assert($filter.rank === 5, () => `Error in conv3d: filter must be rank 5, but got rank ${$filter.rank}.`);
    assert(x5D.shape[4] === $filter.shape[3], () => `Error in conv3d: depth of input (${x5D.shape[4]}) must match input depth for filter ${$filter.shape[3]}.`);
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv3D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    assert(dataFormat === "NDHWC", () => `Error in conv3d: got dataFormat of ${dataFormat} but only NDHWC is currently supported.`);
    assert(stridesOrDilationsArePositive(dilations), () => "Error in conv3D: Dilated rates should be larger than 0.");
    assert(stridesOrDilationsArePositive(strides), () => "Error in conv3D: Strides should be larger than 0.");
    const inputs = { x: x5D, filter: $filter };
    const attrs = { strides, pad: pad2, dataFormat, dilations };
    const res = ENGINE.runKernel(Conv3D, inputs, attrs);
    if (reshapedTo5D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
    }
    return res;
  }
  var conv3d;
  var init_conv3d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/conv3d.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_conv_util();
      init_operation();
      init_reshape();
      conv3d = /* @__PURE__ */ op({ conv3d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js
  function conv3DBackpropInput_(xShape, dy, filter, strides, pad2) {
    assert(xShape.length === dy.rank, () => `Length of inShape (${xShape.length}) and rank of dy (${dy.rank}) must match`);
    let xShape5D = xShape;
    let dy5D = dy;
    let reshapedTo5D = false;
    if (dy.rank === 4) {
      reshapedTo5D = true;
      dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
      xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];
    }
    const inDepth = xShape5D[4];
    const outDepth = dy5D.shape[4];
    assert(xShape5D.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ${xShape5D.length}.`);
    assert(dy5D.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got rank ${dy5D.rank}`);
    assert(filter.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got rank ${filter.rank}`);
    assert(inDepth === filter.shape[3], () => `Error in conv3dDerInput: depth of input (${inDepth}) must match input depth for filter ${filter.shape[3]}.`);
    assert(outDepth === filter.shape[4], () => `Error in conv3dDerInput: depth of output (${outDepth}) must match output depth for filter ${filter.shape[4]}.`);
    const inputs = { dy: dy5D, filter };
    const attrs = { pad: pad2, strides, inputShape: xShape5D };
    const res = ENGINE.runKernel(Conv3DBackpropInputV2, inputs, attrs);
    if (reshapedTo5D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
    }
    return res;
  }
  var conv3DBackpropInput;
  var init_conv3d_backprop_input = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js"() {
      init_engine();
      init_kernel_names();
      init_util();
      init_operation();
      init_reshape();
      conv3DBackpropInput = /* @__PURE__ */ op({ conv3DBackpropInput_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_transpose.js
  function conv3dTranspose_(x, filter, outputShape, strides, pad2) {
    const $x = convertToTensor(x, "x", "conv3dTranspose");
    const $filter = convertToTensor(filter, "filter", "conv3dTranspose");
    return conv3DBackpropInput(outputShape, $x, $filter, strides, pad2);
  }
  var conv3dTranspose;
  var init_conv3d_transpose = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_transpose.js"() {
      init_tensor_util_env();
      init_conv3d_backprop_input();
      init_operation();
      conv3dTranspose = /* @__PURE__ */ op({ conv3dTranspose_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/cos.js
  function cos_(x) {
    const $x = convertToTensor(x, "x", "cos", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Cos, inputs);
  }
  var cos;
  var init_cos = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/cos.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      cos = /* @__PURE__ */ op({ cos_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/cosh.js
  function cosh_(x) {
    const $x = convertToTensor(x, "x", "cosh", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Cosh, inputs);
  }
  var cosh;
  var init_cosh = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/cosh.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      cosh = /* @__PURE__ */ op({ cosh_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/cumprod.js
  function cumprod_(x, axis = 0, exclusive = false, reverse3 = false) {
    const $x = convertToTensor(x, "x", "cumprod");
    const inputs = { x: $x };
    const attrs = { axis, exclusive, reverse: reverse3 };
    return ENGINE.runKernel(Cumprod, inputs, attrs);
  }
  var cumprod;
  var init_cumprod = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/cumprod.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      cumprod = /* @__PURE__ */ op({ cumprod_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/cumsum.js
  function cumsum_(x, axis = 0, exclusive = false, reverse3 = false) {
    const $x = convertToTensor(x, "x", "cumsum");
    const inputs = { x: $x };
    const attrs = { axis, exclusive, reverse: reverse3 };
    return ENGINE.runKernel(Cumsum, inputs, attrs);
  }
  var cumsum;
  var init_cumsum = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/cumsum.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      cumsum = /* @__PURE__ */ op({ cumsum_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/dense_bincount.js
  function denseBincount_(x, weights, size, binaryOutput = false) {
    const $x = convertToTensor(x, "x", "denseBincount");
    const $weights = convertToTensor(weights, "weights", "denseBincount");
    assert($x.dtype === "int32", () => `Error in denseBincount: input dtype must be int32, but got ${$x.dtype}`);
    assert($x.rank <= 2, () => `Error in denseBincount: input must be at most rank 2, but got rank ${$x.rank}.`);
    assert(size >= 0, () => `size must be non-negative, but got ${size}.`);
    assert($weights.size === $x.size || $weights.size === 0, () => `Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${$x.shape}, weights shape: ${$weights.shape}.`);
    const inputs = { x: $x, weights: $weights };
    const attrs = { size, binaryOutput };
    return ENGINE.runKernel(DenseBincount, inputs, attrs);
  }
  var denseBincount;
  var init_dense_bincount = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/dense_bincount.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      denseBincount = /* @__PURE__ */ op({ denseBincount_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/depth_to_space.js
  function depthToSpace_(x, blockSize, dataFormat = "NHWC") {
    const $x = convertToTensor(x, "x", "depthToSpace", "float32");
    const inputHeight = dataFormat === "NHWC" ? $x.shape[1] : $x.shape[2];
    const inputWidth = dataFormat === "NHWC" ? $x.shape[2] : $x.shape[3];
    const inputDepth = dataFormat === "NHWC" ? $x.shape[3] : $x.shape[1];
    assert(blockSize > 1, () => `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);
    assert(inputHeight * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${inputHeight} and ${blockSize}  for depthToSpace with input shape
    ${$x.shape}`);
    assert(inputWidth * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${inputWidth} and ${blockSize} for depthToSpace with input shape
        ${$x.shape}`);
    assert(inputDepth % (blockSize * blockSize) === 0, () => `Dimension size must be evenly divisible by ${blockSize * blockSize} but is ${inputDepth} for depthToSpace with input shape ${$x.shape}`);
    const inputs = { x: $x };
    const attrs = { blockSize, dataFormat };
    return ENGINE.runKernel(DepthToSpace, inputs, attrs);
  }
  var depthToSpace;
  var init_depth_to_space = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/depth_to_space.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      depthToSpace = /* @__PURE__ */ op({ depthToSpace_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js
  function depthwiseConv2d_(x, filter, strides, pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode) {
    const $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
    const $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
    assert($filter.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
    const inChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
    assert(inChannels === $filter.shape[2], () => `Error in depthwiseConv2d: number of input channels (${inChannels}) must match the inChannels dimension in filter ${$filter.shape[2]}.`);
    checkPadOnDimRoundingMode("depthwiseConv2d", pad2, dimRoundingMode);
    const inputs = { x: x4D, filter: $filter };
    const attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
    const res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var depthwiseConv2d;
  var init_depthwise_conv2d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_conv_util();
      init_operation();
      init_reshape();
      depthwiseConv2d = /* @__PURE__ */ op({ depthwiseConv2d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/diag.js
  function diag_(x) {
    const $x = convertToTensor(x, "x", "diag");
    const inputs = { x: $x };
    return ENGINE.runKernel(Diag, inputs);
  }
  var diag;
  var init_diag = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/diag.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      diag = /* @__PURE__ */ op({ diag_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/dilation2d.js
  function dilation2d_(x, filter, strides, pad2, dilations = [1, 1], dataFormat = "NHWC") {
    const $x = convertToTensor(x, "x", "dilation2d");
    const $filter = convertToTensor(filter, "filter", "dilation2d");
    assert($x.rank === 3 || $x.rank === 4, () => `Error in dilation2d: input must be rank 3 or 4, but got rank ${$x.rank}.`);
    assert($filter.rank === 3, () => `Error in dilation2d: filter must be rank 3, but got rank ${$filter.rank}.`);
    assert(dataFormat === "NHWC", () => `Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${dataFormat}`);
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      reshapedTo4D = true;
    }
    assert(x4D.shape[3] === $filter.shape[2], () => `Error in dilation2d:  input and filter must have the same depth: ${x4D.shape[3]} vs ${$filter.shape[2]}`);
    const inputs = { x: x4D, filter: $filter };
    const attrs = { strides, pad: pad2, dilations };
    const res = ENGINE.runKernel(Dilation2D, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var dilation2d;
  var init_dilation2d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/dilation2d.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      init_reshape();
      dilation2d = /* @__PURE__ */ op({ dilation2d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js
  var broadcast_util_exports = {};
  __export(broadcast_util_exports, {
    assertAndGetBroadcastShape: () => assertAndGetBroadcastShape,
    getBroadcastDims: () => getBroadcastDims,
    getReductionAxes: () => getReductionAxes
  });
  function getBroadcastDims(inShape, outShape) {
    const inRank = inShape.length;
    const dims = [];
    for (let i = 0; i < inRank; i++) {
      const dim = inRank - 1 - i;
      const a = inShape[dim] || 1;
      const b = outShape[outShape.length - 1 - i] || 1;
      if (b > 1 && a === 1) {
        dims.unshift(dim);
      }
    }
    return dims;
  }
  function getReductionAxes(inShape, outShape) {
    const result = [];
    for (let i = 0; i < outShape.length; i++) {
      const inDim = inShape[inShape.length - i - 1];
      const outAxis = outShape.length - i - 1;
      const outDim = outShape[outAxis];
      if (inDim == null || inDim === 1 && outDim > 1) {
        result.unshift(outAxis);
      }
    }
    return result;
  }
  function assertAndGetBroadcastShape(shapeA, shapeB) {
    const result = [];
    const l = Math.max(shapeA.length, shapeB.length);
    for (let i = 0; i < l; i++) {
      let a = shapeA[shapeA.length - i - 1];
      if (a == null) {
        a = 1;
      }
      let b = shapeB[shapeB.length - i - 1];
      if (b == null) {
        b = 1;
      }
      if (a === 1) {
        result.unshift(b);
      } else if (b === 1) {
        result.unshift(a);
      } else if (a !== b) {
        const errMsg = `Operands could not be broadcast together with shapes ${shapeA} and ${shapeB}.`;
        throw Error(errMsg);
      } else {
        result.unshift(a);
      }
    }
    return result;
  }
  var init_broadcast_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/equal.js
  function equal_(a, b) {
    let $a = convertToTensor(a, "a", "equal", "string_or_numeric");
    let $b = convertToTensor(b, "b", "equal", "string_or_numeric");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Equal, inputs);
  }
  var equal;
  var init_equal = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/equal.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_broadcast_util();
      init_operation();
      equal = /* @__PURE__ */ op({ equal_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/where.js
  function where_(condition, a, b) {
    const $a = convertToTensor(a, "a", "where");
    const $b = convertToTensor(b, "b", "where");
    const $condition = convertToTensor(condition, "condition", "where", "bool");
    const broadcastShape = assertAndGetBroadcastShape(assertAndGetBroadcastShape($condition.shape, $a.shape), $b.shape);
    const $broadcastedCondition = broadcastTo($condition, broadcastShape);
    const $broadcastedA = broadcastTo($a, broadcastShape);
    const $broadcastedB = broadcastTo($b, broadcastShape);
    const inputs = {
      condition: $broadcastedCondition,
      t: $broadcastedA,
      e: $broadcastedB
    };
    return ENGINE.runKernel(Select, inputs);
  }
  var where;
  var init_where = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/where.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_broadcast_to();
      init_broadcast_util();
      init_operation();
      where = /* @__PURE__ */ op({ where_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/zeros_like.js
  function zerosLike_(x) {
    const $x = convertToTensor(x, "x", "zerosLike");
    const inputs = { x: $x };
    return ENGINE.runKernel(ZerosLike, inputs);
  }
  var zerosLike;
  var init_zeros_like = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/zeros_like.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      zerosLike = /* @__PURE__ */ op({ zerosLike_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/div_no_nan.js
  function divNoNan_(a, b) {
    let $a = convertToTensor(a, "a", "div");
    let $b = convertToTensor(b, "b", "div");
    [$a, $b] = makeTypesMatch($a, $b);
    const divResult = div($a, $b);
    const zeros3 = zerosLike(divResult);
    const bEqualsZero = equal($b, zeros3);
    return where(bEqualsZero, zeros3, divResult);
  }
  var divNoNan;
  var init_div_no_nan = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/div_no_nan.js"() {
      init_tensor_util();
      init_tensor_util_env();
      init_div();
      init_equal();
      init_operation();
      init_where();
      init_zeros_like();
      divNoNan = /* @__PURE__ */ op({ divNoNan_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/dot.js
  function dot_(t1, t2) {
    const $t1 = convertToTensor(t1, "t1", "dot");
    const $t2 = convertToTensor(t2, "t2", "dot");
    assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ${$t1.rank} and ${$t2.rank}.`);
    const t1Inner = $t1.rank === 1 ? $t1.size : $t1.shape[1];
    const t2Inner = $t2.rank === 1 ? $t2.size : $t2.shape[0];
    assert(t1Inner === t2Inner, () => `Error in dot: inner dimensions of inputs must match, but got ${t1Inner} and ${t2Inner}.`);
    if ($t1.rank === 1 && $t2.rank === 1) {
      const t12D = reshape($t1, [1, -1]);
      const t22D = reshape($t2, [-1, 1]);
      const t1t2 = matMul(t12D, t22D);
      return reshape(t1t2, []);
    } else if ($t1.rank === 1 && $t2.rank === 2) {
      const t12D = reshape($t1, [1, -1]);
      const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
      const t1t2 = matMul(t12D, t22D);
      return reshape(t1t2, [t1t2.size]);
    } else if ($t1.rank === 2 && $t2.rank === 1) {
      const t22D = reshape($t2, [-1, 1]);
      const t1t2 = matMul($t1, t22D);
      return reshape(t1t2, [t1t2.size]);
    } else {
      const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
      const t1t2 = matMul($t1, t22D);
      return t1t2;
    }
  }
  var dot;
  var init_dot = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/dot.js"() {
      init_tensor_util_env();
      init_util();
      init_mat_mul();
      init_operation();
      init_reshape();
      dot = /* @__PURE__ */ op({ dot_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/einsum.js
  function einsum_(equation, ...tensors) {
    const $tensors = tensors.map((t2, i) => convertToTensor(t2, `tensors${i}`, "einsum"));
    const attrs = { equation };
    return ENGINE.runKernel(Einsum, $tensors, attrs);
  }
  var einsum;
  var init_einsum = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/einsum.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      einsum = /* @__PURE__ */ op({ einsum_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/elu.js
  function elu_(x) {
    const $x = convertToTensor(x, "x", "elu", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Elu, inputs);
  }
  var elu;
  var init_elu = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/elu.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      elu = /* @__PURE__ */ op({ elu_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/erf.js
  function erf_(x) {
    let $x = convertToTensor(x, "x", "erf");
    assert($x.dtype === "int32" || $x.dtype === "float32", () => "Input dtype must be `int32` or `float32`.");
    if ($x.dtype === "int32") {
      $x = cast($x, "float32");
    }
    const inputs = { x: $x };
    return ENGINE.runKernel(Erf, inputs);
  }
  var erf;
  var init_erf = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/erf.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_cast();
      init_operation();
      erf = /* @__PURE__ */ op({ erf_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js
  function axesAreInnerMostDims(axes, rank) {
    for (let i = 0; i < axes.length; ++i) {
      if (axes[axes.length - i - 1] !== rank - 1 - i) {
        return false;
      }
    }
    return true;
  }
  function combineLocations(outputLoc, reduceLoc, axes) {
    const rank = outputLoc.length + reduceLoc.length;
    const loc = [];
    let outIdx = 0;
    let reduceIdx = 0;
    for (let dim = 0; dim < rank; dim++) {
      if (axes.indexOf(dim) === -1) {
        loc.push(outputLoc[outIdx++]);
      } else {
        loc.push(reduceLoc[reduceIdx++]);
      }
    }
    return loc;
  }
  function computeOutAndReduceShapes(aShape, axes) {
    const outShape = [];
    const rank = aShape.length;
    for (let dim = 0; dim < rank; dim++) {
      if (axes.indexOf(dim) === -1) {
        outShape.push(aShape[dim]);
      }
    }
    const reduceShape = axes.map((dim) => aShape[dim]);
    return [outShape, reduceShape];
  }
  function expandShapeToKeepDim(shape, axes) {
    const reduceSubShape = axes.map((x) => 1);
    return combineLocations(shape, reduceSubShape, axes);
  }
  function assertAxesAreInnerMostDims(msg, axes, rank) {
    assert(axesAreInnerMostDims(axes, rank), () => `${msg} supports only inner-most axes for now. Got axes ${axes} and rank-${rank} input.`);
  }
  function getAxesPermutation(axes, rank) {
    if (axesAreInnerMostDims(axes, rank)) {
      return null;
    }
    const result = [];
    for (let i = 0; i < rank; ++i) {
      if (axes.indexOf(i) === -1) {
        result.push(i);
      }
    }
    axes.forEach((axis) => result.push(axis));
    return result;
  }
  function getUndoAxesPermutation(axes) {
    return axes.map((axis, i) => [i, axis]).sort((a, b) => a[1] - b[1]).map((x) => x[0]);
  }
  function getInnerMostAxes(numAxes, rank) {
    const res = [];
    for (let i = rank - numAxes; i < rank; ++i) {
      res.push(i);
    }
    return res;
  }
  var init_axis_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js"() {
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/max.js
  function max_(x, axis = null, keepDims = false) {
    const $x = convertToTensor(x, "x", "max");
    const inputs = { x: $x };
    const attrs = { reductionIndices: axis, keepDims };
    return ENGINE.runKernel(Max, inputs, attrs);
  }
  var max;
  var init_max = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/max.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      max = /* @__PURE__ */ op({ max_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/min.js
  function min_(x, axis = null, keepDims = false) {
    const $x = convertToTensor(x, "x", "min");
    const inputs = { x: $x };
    const attrs = { axis, keepDims };
    return ENGINE.runKernel(Min, inputs, attrs);
  }
  var min;
  var init_min = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/min.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      min = /* @__PURE__ */ op({ min_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/pow.js
  function pow_(base, exp3) {
    let $base = convertToTensor(base, "base", "pow");
    let $exp = convertToTensor(exp3, "exp", "pow");
    [$base, $exp] = makeTypesMatch($base, $exp);
    const inputs = { a: $base, b: $exp };
    return ENGINE.runKernel(Pow, inputs);
  }
  var pow;
  var init_pow = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/pow.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_operation();
      pow = /* @__PURE__ */ op({ pow_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/scalar.js
  function scalar(value, dtype) {
    if ((isTypedArray(value) && dtype !== "string" || Array.isArray(value)) && dtype !== "complex64") {
      throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
    }
    if (dtype === "string" && isTypedArray(value) && !(value instanceof Uint8Array)) {
      throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
    }
    const shape = [];
    const inferredShape = [];
    return makeTensor(value, shape, inferredShape, dtype);
  }
  var init_scalar = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/scalar.js"() {
      init_util();
      init_tensor_ops_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sqrt.js
  function sqrt_(x) {
    const $x = convertToTensor(x, "x", "sqrt", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Sqrt, inputs);
  }
  var sqrt;
  var init_sqrt = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sqrt.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      sqrt = /* @__PURE__ */ op({ sqrt_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/square.js
  function square_(x) {
    const $x = convertToTensor(x, "x", "square");
    const attrs = {};
    return ENGINE.runKernel("Square", { x: $x }, attrs);
  }
  var square;
  var init_square = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/square.js"() {
      init_engine();
      init_tensor_util_env();
      init_operation();
      square = /* @__PURE__ */ op({ square_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sum.js
  function sum_(x, axis = null, keepDims = false) {
    let $x = convertToTensor(x, "x", "sum");
    if ($x.dtype === "bool") {
      $x = cast($x, "int32");
    }
    const inputs = { x: $x };
    const attrs = { axis, keepDims };
    return ENGINE.runKernel(Sum, inputs, attrs);
  }
  var sum2;
  var init_sum = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sum.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_cast();
      init_operation();
      sum2 = /* @__PURE__ */ op({ sum_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/norm.js
  function norm_(x, ord = "euclidean", axis = null, keepDims = false) {
    x = convertToTensor(x, "x", "norm");
    const norm2 = normImpl(x, ord, axis);
    let keepDimsShape = norm2.shape;
    if (keepDims) {
      const axes = parseAxisParam(axis, x.shape);
      keepDimsShape = expandShapeToKeepDim(norm2.shape, axes);
    }
    return reshape(norm2, keepDimsShape);
  }
  function normImpl(x, p2, axis = null) {
    if (x.rank === 0) {
      return abs(x);
    }
    if (x.rank !== 1 && axis === null) {
      return normImpl(reshape(x, [-1]), p2, axis);
    }
    if (x.rank === 1 || typeof axis === "number" || Array.isArray(axis) && axis.length === 1) {
      if (p2 === 1) {
        return sum2(abs(x), axis);
      }
      if (p2 === Infinity) {
        return max(abs(x), axis);
      }
      if (p2 === -Infinity) {
        return min(abs(x), axis);
      }
      if (p2 === "euclidean" || p2 === 2) {
        return sqrt(sum2(pow(abs(x), scalar(2, "int32")), axis));
      }
      throw new Error(`Error in norm: invalid ord value: ${p2}`);
    }
    if (Array.isArray(axis) && axis.length === 2) {
      if (p2 === 1) {
        return max(sum2(abs(x), axis[0]), axis[1] - 1);
      }
      if (p2 === Infinity) {
        return max(sum2(abs(x), axis[1]), axis[0]);
      }
      if (p2 === -Infinity) {
        return min(sum2(abs(x), axis[1]), axis[0]);
      }
      if (p2 === "fro" || p2 === "euclidean") {
        return sqrt(sum2(square(x), axis));
      }
      throw new Error(`Error in norm: invalid ord value: ${p2}`);
    }
    throw new Error(`Error in norm: invalid axis: ${axis}`);
  }
  var norm;
  var init_norm = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/norm.js"() {
      init_tensor_util_env();
      init_util();
      init_abs();
      init_axis_util();
      init_max();
      init_min();
      init_operation();
      init_pow();
      init_reshape();
      init_scalar();
      init_sqrt();
      init_square();
      init_sum();
      norm = /* @__PURE__ */ op({ norm_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/euclidean_norm.js
  function euclideanNorm_(x, axis = null, keepDims = false) {
    return norm(x, "euclidean", axis, keepDims);
  }
  var euclideanNorm;
  var init_euclidean_norm = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/euclidean_norm.js"() {
      init_norm();
      init_operation();
      euclideanNorm = /* @__PURE__ */ op({ euclideanNorm_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/exp.js
  function exp_(x) {
    const $x = convertToTensor(x, "x", "exp");
    const inputs = { x: $x };
    return ENGINE.runKernel(Exp, inputs);
  }
  var exp;
  var init_exp = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/exp.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      exp = /* @__PURE__ */ op({ exp_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/expand_dims.js
  function expandDims_(x, axis = 0) {
    const $x = convertToTensor(x, "x", "expandDims", "string_or_numeric");
    assert(axis <= $x.rank, () => "Axis must be <= rank of the tensor");
    const inputs = { input: $x };
    const attrs = { dim: axis };
    return ENGINE.runKernel(ExpandDims, inputs, attrs);
  }
  var expandDims;
  var init_expand_dims = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/expand_dims.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      expandDims = /* @__PURE__ */ op({ expandDims_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/expm1.js
  function expm1_(x) {
    const $x = convertToTensor(x, "x", "expm1");
    const inputs = { x: $x };
    return ENGINE.runKernel(Expm1, inputs);
  }
  var expm1;
  var init_expm1 = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/expm1.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      expm1 = /* @__PURE__ */ op({ expm1_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tile.js
  function tile_(x, reps) {
    const $x = convertToTensor(x, "x", "tile", "string_or_numeric");
    assert($x.rank === reps.length, () => `Error in transpose: rank of input ${$x.rank} must match length of reps ${reps}.`);
    const inputs = { x: $x };
    const attrs = { reps };
    return ENGINE.runKernel(Tile, inputs, attrs);
  }
  var tile;
  var init_tile = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/tile.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      tile = /* @__PURE__ */ op({ tile_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/eye.js
  function eye_(numRows, numColumns, batchShape, dtype = "float32") {
    if (numColumns == null) {
      numColumns = numRows;
    }
    const buff = buffer([numRows, numColumns], dtype);
    const n = numRows <= numColumns ? numRows : numColumns;
    for (let i = 0; i < n; ++i) {
      buff.set(1, i, i);
    }
    const out = reshape(buff.toTensor(), [numRows, numColumns]);
    if (batchShape == null) {
      return out;
    } else {
      if (batchShape.length === 1) {
        return tile(expandDims(out, 0), [batchShape[0], 1, 1]);
      } else if (batchShape.length === 2) {
        return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);
      } else if (batchShape.length === 3) {
        return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [
          batchShape[0],
          batchShape[1],
          batchShape[2],
          1,
          1
        ]);
      } else {
        throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${batchShape.length}D.`);
      }
    }
  }
  var eye;
  var init_eye = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/eye.js"() {
      init_buffer();
      init_expand_dims();
      init_operation();
      init_reshape();
      init_tile();
      eye = /* @__PURE__ */ op({ eye_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/floor.js
  function floor_(x) {
    const $x = convertToTensor(x, "x", "floor", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Floor, inputs);
  }
  var floor;
  var init_floor = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/floor.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      floor = /* @__PURE__ */ op({ floor_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/gather.js
  function gather_(x, indices, axis = 0, batchDims = 0) {
    const $x = convertToTensor(x, "x", "gather");
    const $indices = convertToTensor(indices, "indices", "gather", "int32");
    const inputs = { x: $x, indices: $indices };
    const attrs = { axis, batchDims };
    return ENGINE.runKernel(GatherV2, inputs, attrs);
  }
  var gather;
  var init_gather = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/gather.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      gather = /* @__PURE__ */ op({ gather_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/greater.js
  function greater_(a, b) {
    let $a = convertToTensor(a, "a", "greater", "string_or_numeric");
    let $b = convertToTensor(b, "b", "greater", "string_or_numeric");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Greater, inputs);
  }
  var greater;
  var init_greater = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/greater.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_broadcast_util();
      init_operation();
      greater = /* @__PURE__ */ op({ greater_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/greater_equal.js
  function greaterEqual_(a, b) {
    let $a = convertToTensor(a, "a", "greaterEqual", "string_or_numeric");
    let $b = convertToTensor(b, "b", "greaterEqual", "string_or_numeric");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(GreaterEqual, inputs);
  }
  var greaterEqual;
  var init_greater_equal = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/greater_equal.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_broadcast_util();
      init_operation();
      greaterEqual = /* @__PURE__ */ op({ greaterEqual_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/imag.js
  function imag_(input) {
    const $input = convertToTensor(input, "input", "imag");
    const inputs = { input: $input };
    return ENGINE.runKernel(Imag, inputs);
  }
  var imag;
  var init_imag = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/imag.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      imag = /* @__PURE__ */ op({ imag_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/is_finite.js
  function isFinite_(x) {
    const $x = convertToTensor(x, "x", "isFinite");
    const inputs = { x: $x };
    return ENGINE.runKernel(IsFinite, inputs);
  }
  var isFinite2;
  var init_is_finite = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/is_finite.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      isFinite2 = /* @__PURE__ */ op({ isFinite_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/is_inf.js
  function isInf_(x) {
    const $x = convertToTensor(x, "x", "isInf");
    const inputs = { x: $x };
    return ENGINE.runKernel(IsInf, inputs);
  }
  var isInf;
  var init_is_inf = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/is_inf.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      isInf = /* @__PURE__ */ op({ isInf_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/is_nan.js
  function isNaN_(x) {
    const $x = convertToTensor(x, "x", "isNaN");
    const inputs = { x: $x };
    return ENGINE.runKernel(IsNan, inputs);
  }
  var isNaN2;
  var init_is_nan = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/is_nan.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      isNaN2 = /* @__PURE__ */ op({ isNaN_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/leaky_relu.js
  function leakyRelu_(x, alpha = 0.2) {
    const $x = convertToTensor(x, "x", "leakyRelu");
    const inputs = { x: $x };
    const attrs = { alpha };
    return ENGINE.runKernel(LeakyRelu, inputs, attrs);
  }
  var leakyRelu;
  var init_leaky_relu = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/leaky_relu.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      leakyRelu = /* @__PURE__ */ op({ leakyRelu_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/less.js
  function less_(a, b) {
    let $a = convertToTensor(a, "a", "less", "string_or_numeric");
    let $b = convertToTensor(b, "b", "less", "string_or_numeric");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Less, inputs);
  }
  var less;
  var init_less = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/less.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_broadcast_util();
      init_operation();
      less = /* @__PURE__ */ op({ less_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/less_equal.js
  function lessEqual_(a, b) {
    let $a = convertToTensor(a, "a", "lessEqual", "string_or_numeric");
    let $b = convertToTensor(b, "b", "lessEqual", "string_or_numeric");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(LessEqual, inputs);
  }
  var lessEqual;
  var init_less_equal = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/less_equal.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_broadcast_util();
      init_operation();
      lessEqual = /* @__PURE__ */ op({ lessEqual_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/linspace.js
  function linspace(start, stop, num) {
    if (num <= 0) {
      throw new Error("The number of values should be positive.");
    }
    const attrs = { start, stop, num };
    return ENGINE.runKernel(LinSpace, {}, attrs);
  }
  var init_linspace = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/linspace.js"() {
      init_engine();
      init_kernel_names();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/local_response_normalization.js
  function localResponseNormalization_(x, depthRadius = 5, bias = 1, alpha = 1, beta = 0.5) {
    const $x = convertToTensor(x, "x", "localResponseNormalization");
    assert($x.rank === 4 || $x.rank === 3, () => `Error in localResponseNormalization: x must be rank 3 or 4 but got
               rank ${$x.rank}.`);
    assert(isInt(depthRadius), () => `Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${depthRadius}.`);
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    const inputs = { x: x4D };
    const attrs = { depthRadius, bias, alpha, beta };
    const res = ENGINE.runKernel(LRN, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    } else {
      return res;
    }
  }
  var localResponseNormalization;
  var init_local_response_normalization = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/local_response_normalization.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      init_reshape();
      localResponseNormalization = /* @__PURE__ */ op({ localResponseNormalization_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/log.js
  function log_(x) {
    const $x = convertToTensor(x, "x", "log", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Log, inputs);
  }
  var log2;
  var init_log2 = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/log.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      log2 = /* @__PURE__ */ op({ log_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/log1p.js
  function log1p_(x) {
    const $x = convertToTensor(x, "x", "log1p");
    const inputs = { x: $x };
    return ENGINE.runKernel(Log1p, inputs);
  }
  var log1p;
  var init_log1p = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/log1p.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      log1p = /* @__PURE__ */ op({ log1p_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/gradients.js
  function variableGrads(f, varList) {
    assert(isFunction(f), () => "The f passed in variableGrads(f) must be a function");
    assert(varList == null || Array.isArray(varList) && varList.every((v) => v instanceof Variable), () => "The varList passed in variableGrads(f, varList) must be an array of variables");
    const specifiedVarList = varList != null;
    if (!specifiedVarList) {
      varList = [];
      for (const varName in ENGINE.registeredVariables) {
        varList.push(ENGINE.registeredVariables[varName]);
      }
    }
    const specifiedNonTrainable = specifiedVarList ? varList.filter((variable2) => !variable2.trainable) : null;
    const originalVarCount = varList.length;
    varList = varList.filter((variable2) => variable2.trainable);
    assert(varList.length > 0, () => `variableGrads() expects at least one of the input variables to be trainable, but none of the ${originalVarCount} variables is trainable.`);
    const allowNoGradients = true;
    const { value, grads } = ENGINE.gradients(f, varList, null, allowNoGradients);
    assert(grads.some((g) => g != null), () => "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().");
    assert(value.rank === 0, () => `The f passed in variableGrads(f) must return a scalar, but it returned a rank-${value.rank} tensor`);
    const namedGrads = {};
    varList.forEach((v, i) => {
      if (grads[i] != null) {
        namedGrads[v.name] = grads[i];
      }
    });
    if (specifiedNonTrainable != null) {
      specifiedNonTrainable.forEach((v) => namedGrads[v.name] = null);
    }
    return { value, grads: namedGrads };
  }
  function customGrad(f) {
    return ENGINE.customGrad(f);
  }
  var init_gradients = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/gradients.js"() {
      init_engine();
      init_tensor();
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/neg.js
  function neg_(x) {
    const $x = convertToTensor(x, "x", "neg");
    const inputs = { x: $x };
    return ENGINE.runKernel(Neg, inputs);
  }
  var neg;
  var init_neg = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/neg.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      neg = /* @__PURE__ */ op({ neg_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/softplus.js
  function softplus_(x) {
    const $x = convertToTensor(x, "x", "softplus");
    const inputs = { x: $x };
    return ENGINE.runKernel(Softplus, inputs);
  }
  var softplus;
  var init_softplus = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/softplus.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      softplus = /* @__PURE__ */ op({ softplus_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/log_sigmoid.js
  function logSigmoid_(x) {
    const $x = convertToTensor(x, "x", "logSigmoid");
    const customOp = customGrad((x2) => {
      const value = neg(softplus(neg(x2)));
      const gradFunc = (dy) => {
        const derX = mul(dy, sigmoid(neg(x2)));
        return derX;
      };
      return { value, gradFunc };
    });
    return customOp($x);
  }
  var logSigmoid;
  var init_log_sigmoid = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/log_sigmoid.js"() {
      init_gradients();
      init_tensor_util_env();
      init_mul();
      init_neg();
      init_operation();
      init_sigmoid();
      init_softplus();
      logSigmoid = /* @__PURE__ */ op({ logSigmoid_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sub.js
  function sub_(a, b) {
    let $a = convertToTensor(a, "a", "sub");
    let $b = convertToTensor(b, "b", "sub");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Sub, inputs);
  }
  var sub;
  var init_sub = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sub.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_operation();
      sub = /* @__PURE__ */ op({ sub_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/log_softmax.js
  function logSoftmax_(logits, axis = -1) {
    const $logits = convertToTensor(logits, "logits", "logSoftmax");
    if (axis === -1) {
      axis = $logits.rank - 1;
    }
    if (axis !== $logits.rank - 1) {
      throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${$logits.rank} and axis was ${axis}`);
    }
    const customOp = customGrad((logits2, save) => {
      const keepDims = true;
      const xMax = max(logits2, axis, true);
      const shifted = sub(logits2, xMax);
      const value = sub(cast(shifted, "float32"), log2(sum2(exp(shifted), axis, keepDims)));
      save([value]);
      const gradFunc = (dy, saved) => {
        const [value2] = saved;
        const keepDims2 = true;
        const softmax3 = exp(value2);
        return sub(dy, mul(sum2(dy, axis, keepDims2), softmax3));
      };
      return { value, gradFunc };
    });
    return customOp($logits);
  }
  var logSoftmax;
  var init_log_softmax = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/log_softmax.js"() {
      init_gradients();
      init_tensor_util_env();
      init_cast();
      init_exp();
      init_log2();
      init_max();
      init_mul();
      init_operation();
      init_sub();
      init_sum();
      logSoftmax = /* @__PURE__ */ op({ logSoftmax_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/log_sum_exp.js
  function logSumExp_(x, axis = null, keepDims = false) {
    const $x = convertToTensor(x, "x", "logSumExp");
    const axes = parseAxisParam(axis, $x.shape);
    const xMax = max(
      $x,
      axes,
      true
      /* keepDims */
    );
    const a = sub($x, xMax);
    const b = exp(a);
    const c = sum2(b, axes);
    const d = log2(c);
    const res = add2(reshape(xMax, d.shape), d);
    if (keepDims) {
      const newShape = expandShapeToKeepDim(res.shape, axes);
      return reshape(res, newShape);
    }
    return res;
  }
  var logSumExp;
  var init_log_sum_exp = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/log_sum_exp.js"() {
      init_tensor_util_env();
      init_util();
      init_add();
      init_axis_util();
      init_exp();
      init_log2();
      init_max();
      init_operation();
      init_reshape();
      init_sub();
      init_sum();
      logSumExp = /* @__PURE__ */ op({ logSumExp_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/logical_and.js
  function logicalAnd_(a, b) {
    const $a = convertToTensor(a, "a", "logicalAnd", "bool");
    const $b = convertToTensor(b, "b", "logicalAnd", "bool");
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(LogicalAnd, inputs);
  }
  var logicalAnd;
  var init_logical_and = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/logical_and.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_broadcast_util();
      init_operation();
      logicalAnd = /* @__PURE__ */ op({ logicalAnd_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/logical_not.js
  function logicalNot_(x) {
    const $x = convertToTensor(x, "x", "logicalNot", "bool");
    const inputs = { x: $x };
    return ENGINE.runKernel(LogicalNot, inputs);
  }
  var logicalNot;
  var init_logical_not = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/logical_not.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      logicalNot = /* @__PURE__ */ op({ logicalNot_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/logical_or.js
  function logicalOr_(a, b) {
    const $a = convertToTensor(a, "a", "logicalOr", "bool");
    const $b = convertToTensor(b, "b", "logicalOr", "bool");
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(LogicalOr, inputs);
  }
  var logicalOr;
  var init_logical_or = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/logical_or.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_broadcast_util();
      init_operation();
      logicalOr = /* @__PURE__ */ op({ logicalOr_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/logical_xor.js
  function logicalXor_(a, b) {
    const $a = convertToTensor(a, "a", "logicalXor", "bool");
    const $b = convertToTensor(b, "b", "logicalXor", "bool");
    assertAndGetBroadcastShape($a.shape, $b.shape);
    return logicalAnd(logicalOr(a, b), logicalNot(logicalAnd(a, b)));
  }
  var logicalXor;
  var init_logical_xor = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/logical_xor.js"() {
      init_tensor_util_env();
      init_broadcast_util();
      init_logical_and();
      init_logical_not();
      init_logical_or();
      init_operation();
      logicalXor = /* @__PURE__ */ op({ logicalXor_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/search_sorted.js
  function searchSorted_(sortedSequence, values, side = "left") {
    const $sortedSequence = convertToTensor(sortedSequence, "sortedSequence", "searchSorted");
    const $values = convertToTensor(values, "values", "searchSorted");
    const sequenceSize = $sortedSequence.shape[$sortedSequence.shape.length - 1];
    const valuesSize = $values.shape[$values.shape.length - 1];
    const $sortedSequence2D = reshape($sortedSequence, [-1, sequenceSize]);
    const $values2D = reshape($values, [-1, valuesSize]);
    if ($sortedSequence2D.rank < 2) {
      throw new Error(`Sorted input argument must be at least 2-dimensional`);
    }
    if ($sortedSequence2D.shape[0] !== $values2D.shape[0]) {
      throw new Error(`Leading dimension of 'sortedSequence' and 'values' must match.`);
    }
    if (sizeFromShape($values2D.shape) >= INT32_MAX) {
      throw new Error(`values tensor size must less than ${INT32_MAX}`);
    }
    if ($sortedSequence2D.shape[1] >= INT32_MAX) {
      throw new Error(`trailing dim_size must less than ${INT32_MAX} for int32 output type, was ${$sortedSequence2D.shape[1]}`);
    }
    const inputs = {
      sortedSequence: $sortedSequence2D,
      values: $values2D
    };
    const attrs = { side };
    return ENGINE.runKernel(SearchSorted, inputs, attrs);
  }
  var INT32_MAX, searchSorted;
  var init_search_sorted = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/search_sorted.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util_base();
      init_operation();
      init_reshape();
      INT32_MAX = 2147483648;
      searchSorted = /* @__PURE__ */ op({ searchSorted_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/lower_bound.js
  function lowerBound(sortedSequence, values) {
    return searchSorted(sortedSequence, values, "left");
  }
  var init_lower_bound = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/lower_bound.js"() {
      init_search_sorted();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/max_pool.js
  function maxPool_(x, filterSize, strides, pad2, dimRoundingMode) {
    const $x = convertToTensor(x, "x", "maxPool");
    const dilations = 1;
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in maxPool: input must be rank 4 but got rank ${x4D.rank}.`);
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    checkPadOnDimRoundingMode("maxPool", pad2, dimRoundingMode);
    const inputs = { x: x4D };
    const attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
    const res = ENGINE.runKernel(MaxPool, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var maxPool;
  var init_max_pool = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/max_pool.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_conv_util();
      init_operation();
      init_reshape();
      maxPool = /* @__PURE__ */ op({ maxPool_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_3d.js
  function maxPool3d_(x, filterSize = [1, 1, 1], strides, pad2, dimRoundingMode, dataFormat = "NDHWC") {
    const $x = convertToTensor(x, "x", "maxPool3d");
    let x5D = $x;
    let reshapedTo5D = false;
    if ($x.rank === 4) {
      reshapedTo5D = true;
      x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
    }
    assert(x5D.rank === 5, () => `Error in maxPool3d: x must be rank 5 but got rank ${x5D.rank}.`);
    assert(dataFormat === "NDHWC", () => `Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${dataFormat}`);
    checkPadOnDimRoundingMode("maxPool3d", pad2, dimRoundingMode);
    const inputs = { x: x5D };
    const attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
    const res = ENGINE.runKernel(MaxPool3D, inputs, attrs);
    if (reshapedTo5D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
    }
    return res;
  }
  var maxPool3d;
  var init_max_pool_3d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_3d.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_conv_util();
      init_operation();
      init_reshape();
      maxPool3d = /* @__PURE__ */ op({ maxPool3d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_with_argmax.js
  function maxPoolWithArgmax_(x, filterSize, strides, pad2, includeBatchInIndex = false) {
    const $x = convertToTensor(x, "x", "maxPoolWithArgmax");
    const inputs = { x: $x };
    const attrs = { filterSize, strides, pad: pad2, includeBatchInIndex };
    const result = ENGINE.runKernel(MaxPoolWithArgmax, inputs, attrs);
    return { result: result[0], indexes: result[1] };
  }
  var maxPoolWithArgmax;
  var init_max_pool_with_argmax = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_with_argmax.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      maxPoolWithArgmax = /* @__PURE__ */ op({ maxPoolWithArgmax_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/maximum.js
  function maximum_(a, b) {
    let $a = convertToTensor(a, "a", "maximum");
    let $b = convertToTensor(b, "b", "maximum");
    [$a, $b] = makeTypesMatch($a, $b);
    if ($a.dtype === "bool") {
      $a = cast($a, "int32");
      $b = cast($b, "int32");
    }
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Maximum, inputs);
  }
  var maximum;
  var init_maximum = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/maximum.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_broadcast_util();
      init_cast();
      init_operation();
      maximum = /* @__PURE__ */ op({ maximum_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/mean.js
  function mean_(x, axis = null, keepDims = false) {
    const $x = convertToTensor(x, "x", "mean");
    const inputs = { x: $x };
    const attrs = { axis, keepDims };
    return ENGINE.runKernel(Mean, inputs, attrs);
  }
  var mean;
  var init_mean = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/mean.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      mean = /* @__PURE__ */ op({ mean_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/zeros.js
  function zeros(shape, dtype = "float32") {
    assertNonNegativeIntegerDimensions(shape);
    if (dtype === "complex64") {
      const real3 = zeros(shape, "float32");
      const imag3 = zeros(shape, "float32");
      return complex(real3, imag3);
    }
    const values = makeZerosTypedArray(sizeFromShape(shape), dtype);
    return ENGINE.makeTensor(values, shape, dtype);
  }
  var init_zeros = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/zeros.js"() {
      init_engine();
      init_util();
      init_complex();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/ones.js
  function ones2(shape, dtype = "float32") {
    assertNonNegativeIntegerDimensions(shape);
    if (dtype === "complex64") {
      const real3 = ones2(shape, "float32");
      const imag3 = zeros(shape, "float32");
      return complex(real3, imag3);
    }
    const values = makeOnesTypedArray(sizeFromShape(shape), dtype);
    return ENGINE.makeTensor(values, shape, dtype);
  }
  var init_ones = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/ones.js"() {
      init_engine();
      init_util();
      init_util_base();
      init_complex();
      init_zeros();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/meshgrid.js
  function meshgrid(x, y, { indexing = "xy" } = {}) {
    if (indexing !== "xy" && indexing !== "ij") {
      throw new TypeError(`${indexing} is not a valid third argument to meshgrid`);
    }
    if (x === void 0) {
      return [];
    }
    let $x = convertToTensor(x, "x", "meshgrid", x instanceof Tensor ? x.dtype : "float32");
    if (y === void 0) {
      return [$x];
    }
    let $y = convertToTensor(y, "y", "meshgrid", y instanceof Tensor ? y.dtype : "float32");
    const w = sizeFromShape($x.shape);
    const h = sizeFromShape($y.shape);
    if (indexing === "xy") {
      $x = reshape($x, [1, -1]);
      $y = reshape($y, [-1, 1]);
      return [
        matMul(ones2([h, 1], $x.dtype), $x),
        matMul($y, ones2([1, w], $y.dtype))
      ];
    }
    $x = reshape($x, [-1, 1]);
    $y = reshape($y, [1, -1]);
    return [
      matMul($x, ones2([1, h], $x.dtype)),
      matMul(ones2([w, 1], $y.dtype), $y)
    ];
  }
  var init_meshgrid = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/meshgrid.js"() {
      init_mat_mul();
      init_ones();
      init_reshape();
      init_tensor();
      init_tensor_util_env();
      init_util_base();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/minimum.js
  function minimum_(a, b) {
    let $a = convertToTensor(a, "a", "minimum");
    let $b = convertToTensor(b, "b", "minimum");
    [$a, $b] = makeTypesMatch($a, $b);
    if ($a.dtype === "bool") {
      $a = cast($a, "int32");
      $b = cast($b, "int32");
    }
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Minimum, inputs);
  }
  var minimum;
  var init_minimum = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/minimum.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_broadcast_util();
      init_cast();
      init_operation();
      minimum = /* @__PURE__ */ op({ minimum_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/mirror_pad.js
  function mirrorPad_(x, paddings, mode) {
    assert(mode === "reflect" || mode === "symmetric", () => `Invalid mode. Mode must be either reflect or symmetric. Got ${mode}.`);
    const $x = convertToTensor(x, "x", "mirrorPad");
    if ($x.rank === 0) {
      throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
    }
    assert(paddings.length === $x.rank, () => `Padding doesn't match input. Must be ${$x.rank}. Got ${paddings.length}.`);
    const shapeOffset = mode === "reflect" ? 1 : 0;
    for (let i = 0; i < $x.rank; i++) {
      assert(paddings[i].length === 2, () => `Invalid number of paddings. Must be length of 2 each.`);
      assert(paddings[i][0] >= 0 && paddings[i][0] <= $x.shape[i] - shapeOffset && paddings[i][1] >= 0 && paddings[i][1] <= $x.shape[i] - shapeOffset, () => `Padding in dimension ${i} cannot be greater than or equal to ${$x.shape[i] - shapeOffset} or less than 0 for input of shape ${$x.shape}`);
    }
    const attrs = { paddings, mode };
    const inputs = { x: $x };
    return ENGINE.runKernel(MirrorPad, inputs, attrs);
  }
  var mirrorPad;
  var init_mirror_pad = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/mirror_pad.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      mirrorPad = /* @__PURE__ */ op({ mirrorPad_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/mod.js
  function mod_(a, b) {
    let $a = convertToTensor(a, "a", "mod");
    let $b = convertToTensor(b, "b", "mod");
    [$a, $b] = makeTypesMatch($a, $b);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(Mod, inputs);
  }
  var mod;
  var init_mod = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/mod.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_operation();
      mod = /* @__PURE__ */ op({ mod_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/moments.js
  function moments_(x, axis = null, keepDims = false) {
    x = convertToTensor(x, "x", "moments");
    const axes = parseAxisParam(axis, x.shape);
    const xMean = mean(x, axes, keepDims);
    let keepDimsShape = xMean.shape;
    if (!keepDims) {
      keepDimsShape = expandShapeToKeepDim(xMean.shape, axes);
    }
    const devSquared = square(sub(cast(x, "float32"), reshape(xMean, keepDimsShape)));
    const variance = mean(devSquared, axes, keepDims);
    return { mean: xMean, variance };
  }
  var moments;
  var init_moments = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/moments.js"() {
      init_tensor_util_env();
      init_util();
      init_axis_util();
      init_cast();
      init_mean();
      init_operation();
      init_reshape();
      init_square();
      init_sub();
      moments = /* @__PURE__ */ op({ moments_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/multi_rnn_cell.js
  function multiRNNCell_(lstmCells, data, c, h) {
    const $data = convertToTensor(data, "data", "multiRNNCell");
    const $c = convertToTensorArray(c, "c", "multiRNNCell");
    const $h = convertToTensorArray(h, "h", "multiRNNCell");
    let input = $data;
    const newStates = [];
    for (let i = 0; i < lstmCells.length; i++) {
      const output = lstmCells[i](input, $c[i], $h[i]);
      newStates.push(output[0]);
      newStates.push(output[1]);
      input = output[1];
    }
    const newC = [];
    const newH = [];
    for (let i = 0; i < newStates.length; i += 2) {
      newC.push(newStates[i]);
      newH.push(newStates[i + 1]);
    }
    return [newC, newH];
  }
  var multiRNNCell;
  var init_multi_rnn_cell = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/multi_rnn_cell.js"() {
      init_tensor_util_env();
      init_operation();
      multiRNNCell = /* @__PURE__ */ op({ multiRNNCell_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/multinomial.js
  function multinomial_(logits, numSamples, seed, normalized = false) {
    const $logits = convertToTensor(logits, "logits", "multinomial");
    const numOutcomes = $logits.size;
    const origRank = $logits.rank;
    if (numOutcomes < 2) {
      throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${numOutcomes}.`);
    }
    if (origRank > 2) {
      throw new Error(`Rank of probabilities must be 1 or 2, but is ${origRank}`);
    }
    seed = seed || Math.random();
    const logits2D = origRank === 1 ? reshape($logits, [1, -1]) : $logits;
    const inputs = { logits: logits2D };
    const attrs = { numSamples, seed, normalized };
    const res = ENGINE.runKernel(Multinomial, inputs, attrs);
    return origRank === 1 ? reshape(res, [res.size]) : res;
  }
  var multinomial;
  var init_multinomial = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/multinomial.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      init_reshape();
      multinomial = /* @__PURE__ */ op({ multinomial_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js
  function notEqual_(a, b) {
    let $a = convertToTensor(a, "a", "notEqual", "string_or_numeric");
    let $b = convertToTensor(b, "b", "notEqual", "string_or_numeric");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    return ENGINE.runKernel(NotEqual, inputs);
  }
  var notEqual;
  var init_not_equal = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_broadcast_util();
      init_operation();
      notEqual = /* @__PURE__ */ op({ notEqual_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/one_hot.js
  function oneHot_(indices, depth, onValue = 1, offValue = 0, dtype = "int32") {
    if (depth < 2) {
      throw new Error(`Error in oneHot: depth must be >=2, but it is ${depth}`);
    }
    const $indices = convertToTensor(indices, "indices", "oneHot", "int32");
    const inputs = { indices: $indices };
    const attrs = { dtype, depth, onValue, offValue };
    return ENGINE.runKernel(OneHot, inputs, attrs);
  }
  var oneHot;
  var init_one_hot = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/one_hot.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      oneHot = /* @__PURE__ */ op({ oneHot_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/ones_like.js
  function onesLike_(x) {
    const $x = convertToTensor(x, "x", "onesLike");
    const inputs = { x: $x };
    return ENGINE.runKernel(OnesLike, inputs);
  }
  var onesLike;
  var init_ones_like = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/ones_like.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      onesLike = /* @__PURE__ */ op({ onesLike_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/outer_product.js
  function outerProduct_(v1, v2) {
    const $v1 = convertToTensor(v1, "v1", "outerProduct");
    const $v2 = convertToTensor(v2, "v2", "outerProduct");
    assert($v1.rank === 1 && $v2.rank === 1, () => `Error in outerProduct: inputs must be rank 1, but got ranks ${$v1.rank} and ${$v2.rank}.`);
    const v12D = reshape($v1, [-1, 1]);
    const v22D = reshape($v2, [1, -1]);
    return matMul(v12D, v22D);
  }
  var outerProduct;
  var init_outer_product = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/outer_product.js"() {
      init_tensor_util_env();
      init_util();
      init_mat_mul();
      init_operation();
      init_reshape();
      outerProduct = /* @__PURE__ */ op({ outerProduct_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/pad.js
  function pad_(x, paddings, constantValue = 0) {
    const $x = convertToTensor(x, "x", "pad");
    if ($x.rank === 0) {
      throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
    }
    const attrs = { paddings, constantValue };
    const inputs = { x: $x };
    return ENGINE.runKernel(PadV2, inputs, attrs);
  }
  var pad;
  var init_pad = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/pad.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      pad = /* @__PURE__ */ op({ pad_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/pad1d.js
  function pad1d_(x, paddings, constantValue = 0) {
    assert(paddings.length === 2, () => "Invalid number of paddings. Must be length of 2.");
    return pad(x, [paddings], constantValue);
  }
  var pad1d;
  var init_pad1d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/pad1d.js"() {
      init_util();
      init_operation();
      init_pad();
      pad1d = /* @__PURE__ */ op({ pad1d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/pad2d.js
  function pad2d_(x, paddings, constantValue = 0) {
    assert(paddings.length === 2 && paddings[0].length === 2 && paddings[1].length === 2, () => "Invalid number of paddings. Must be length of 2 each.");
    return pad(x, paddings, constantValue);
  }
  var pad2d;
  var init_pad2d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/pad2d.js"() {
      init_util();
      init_operation();
      init_pad();
      pad2d = /* @__PURE__ */ op({ pad2d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/pad3d.js
  function pad3d_(x, paddings, constantValue = 0) {
    assert(paddings.length === 3 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2, () => "Invalid number of paddings. Must be length of 2 each.");
    return pad(x, paddings, constantValue);
  }
  var pad3d;
  var init_pad3d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/pad3d.js"() {
      init_util();
      init_operation();
      init_pad();
      pad3d = /* @__PURE__ */ op({ pad3d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/pad4d.js
  function pad4d_(x, paddings, constantValue = 0) {
    assert(paddings.length === 4 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2 && paddings[3].length === 2, () => "Invalid number of paddings. Must be length of 2 each.");
    return pad(x, paddings, constantValue);
  }
  var pad4d;
  var init_pad4d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/pad4d.js"() {
      init_util();
      init_operation();
      init_pad();
      pad4d = /* @__PURE__ */ op({ pad4d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js
  function spaceToBatchND_(x, blockShape, paddings) {
    const $x = convertToTensor(x, "x", "spaceToBatchND");
    assert($x.rank >= 1 + blockShape.length, () => `input rank ${$x.rank} should be > than [blockShape] ${blockShape.length}`);
    assert(paddings.length === blockShape.length, () => `paddings.shape[0] ${paddings.length} must be equal to [blockShape] ${blockShape.length}`);
    assert($x.shape.reduce((a, b, i) => {
      if (i > 0 && i <= blockShape.length) {
        return a && (b + paddings[i - 1][0] + paddings[i - 1][1]) % blockShape[i - 1] === 0;
      }
      return a;
    }, true), () => `input spatial dimensions ${$x.shape.slice(1)} with paddings ${paddings.toString()} must be divisible by blockShapes ${blockShape.toString()}`);
    const inputs = { x: $x };
    const attrs = { blockShape, paddings };
    return ENGINE.runKernel(SpaceToBatchND, inputs, attrs);
  }
  var spaceToBatchND;
  var init_space_to_batch_nd = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      spaceToBatchND = /* @__PURE__ */ op({ spaceToBatchND_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/pool.js
  function pool_(input, windowShape, poolingType, pad2, dilations, strides, dimRoundingMode) {
    if (dilations == null) {
      dilations = [1, 1];
    }
    if (strides == null) {
      strides = 1;
    }
    if (pad2 === 0) {
      pad2 = "valid";
    }
    const $x = convertToTensor(input, "x", "maxPool");
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in pool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    const convInfo = computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad2);
    const dilation = [convInfo.dilationHeight, convInfo.dilationWidth];
    let basePadding;
    if (pad2 === "same") {
      basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);
    } else {
      basePadding = [[0, 0], [0, 0]];
    }
    const isDilationOne = dilation[0] === 1 && dilation[1] === 1;
    const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding);
    const convertedPad = isDilationOne ? pad2 : "valid";
    const convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);
    const forwardOp = poolingType === "avg" ? () => avgPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode) : () => maxPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode);
    const y = forwardOp();
    const res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  function requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {
    const padStart = basePadding.map((b) => b[0]);
    const origPadEnd = basePadding.map((b) => b[1]);
    const fullInputShape = inputShape.concat(padStart, origPadEnd);
    const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);
    const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);
    const paddings = blockShape.map((_2, i) => [padStart[i], padEnd[i]]);
    const crops = blockShape.map((_2, i) => [0, padEndExtra[i]]);
    return [paddings, crops];
  }
  function withSpaceToBatchBasePaddings(filterShape, dilation) {
    const dilatedFilterShape = filterShape.map((s, i) => {
      return s + (s - 1) * (dilation[i] - 1);
    });
    const padExtraShape = dilatedFilterShape.map((s) => s - 1);
    const padExtraStart = padExtraShape.map((s) => Math.floor(s / 2));
    const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);
    return padExtraShape.map((_2, i) => {
      return [padExtraStart[i], padExtraEnd[i]];
    });
  }
  var pool;
  var init_pool = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/pool.js"() {
      init_tensor_util_env();
      init_util();
      init_avg_pool();
      init_batch_to_space_nd();
      init_conv_util();
      init_max_pool();
      init_operation();
      init_reshape();
      init_space_to_batch_nd();
      pool = /* @__PURE__ */ op({ pool_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/prelu.js
  function prelu_(x, alpha) {
    const $x = convertToTensor(x, "x", "prelu");
    const $alpha = convertToTensor(alpha, "alpha", "prelu");
    const inputs = { x: $x, alpha: $alpha };
    return ENGINE.runKernel(Prelu, inputs);
  }
  var prelu;
  var init_prelu = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/prelu.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      prelu = /* @__PURE__ */ op({ prelu_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/prod.js
  function prod_(x, axis = null, keepDims = false) {
    let $x = convertToTensor(x, "x", "prod");
    if ($x.dtype === "bool") {
      $x = cast($x, "int32");
    }
    const inputs = { x: $x };
    const attrs = { axis, keepDims };
    return ENGINE.runKernel(Prod, inputs, attrs);
  }
  var prod;
  var init_prod = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/prod.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_cast();
      init_operation();
      prod = /* @__PURE__ */ op({ prod_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/ragged_gather.js
  function raggedGather_(paramsNestedSplits, paramsDenseValues, indices, outputRaggedRank) {
    const $paramsNestedSplits = paramsNestedSplits.map((t2, i) => convertToTensor(t2, `tensors${i}`, "raggedGather", "int32"));
    const $paramsDenseValues = convertToTensor(paramsDenseValues, "paramsDenseValues", "raggedGather");
    const $indices = convertToTensor(indices, "indices", "raggedGather", "int32");
    const inputs = {
      paramsNestedSplits: $paramsNestedSplits,
      paramsDenseValues: $paramsDenseValues,
      indices: $indices
    };
    const attrs = { outputRaggedRank };
    const result = ENGINE.runKernel(RaggedGather, inputs, attrs);
    return {
      outputNestedSplits: result.slice(0, result.length - 1),
      outputDenseValues: result[result.length - 1]
    };
  }
  var raggedGather;
  var init_ragged_gather = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/ragged_gather.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      raggedGather = /* @__PURE__ */ op({ raggedGather_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/ragged_range.js
  function raggedRange_(starts, limits, deltas) {
    const $starts = convertToTensor(starts, "starts", "raggedRange");
    const $limits = convertToTensor(limits, "limits", "raggedRange", $starts.dtype);
    const $deltas = convertToTensor(deltas, "deltas", "raggedRange", $starts.dtype);
    const inputs = {
      starts: $starts,
      limits: $limits,
      deltas: $deltas
    };
    const result = ENGINE.runKernel(RaggedRange, inputs);
    return {
      rtNestedSplits: result[0],
      rtDenseValues: result[1]
    };
  }
  var raggedRange;
  var init_ragged_range = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/ragged_range.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      raggedRange = /* @__PURE__ */ op({ raggedRange_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/ragged_tensor_to_tensor.js
  function raggedTensorToTensor_(shape, values, defaultValue, rowPartitionTensors, rowPartitionTypes) {
    const $shape = convertToTensor(shape, "shape", "raggedTensorToTensor", "int32");
    const $values = convertToTensor(values, "values", "raggedTensorToTensor");
    const $defaultValue = convertToTensor(defaultValue, "defaultValue", "raggedTensorToTensor", $values.dtype);
    const $rowPartitionTensors = rowPartitionTensors.map((t2, i) => convertToTensor(t2, `tensors${i}`, "raggedTensorToTensor", "int32"));
    const inputs = {
      shape: $shape,
      values: $values,
      defaultValue: $defaultValue,
      rowPartitionTensors: $rowPartitionTensors
    };
    const attrs = { rowPartitionTypes };
    return ENGINE.runKernel(RaggedTensorToTensor, inputs, attrs);
  }
  var raggedTensorToTensor;
  var init_ragged_tensor_to_tensor = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/ragged_tensor_to_tensor.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      raggedTensorToTensor = /* @__PURE__ */ op({ raggedTensorToTensor_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/rand.js
  function rand_(shape, randFunction, dtype) {
    assertNonNegativeIntegerDimensions(shape);
    const size = sizeFromShape(shape);
    let values = null;
    if (dtype == null || dtype === "float32") {
      values = new Float32Array(size);
    } else if (dtype === "int32") {
      values = new Int32Array(size);
    } else if (dtype === "bool") {
      values = new Uint8Array(size);
    } else {
      throw new Error(`Unknown data type ${dtype}`);
    }
    for (let i = 0; i < size; i++) {
      values[i] = randFunction();
    }
    return ENGINE.makeTensor(values, shape, dtype);
  }
  var rand;
  var init_rand = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/rand.js"() {
      init_engine();
      init_util();
      init_util_base();
      init_operation();
      rand = /* @__PURE__ */ op({ rand_ });
    }
  });

  // node_modules/seedrandom/lib/alea.js
  var require_alea = __commonJS({
    "node_modules/seedrandom/lib/alea.js"(exports, module) {
      (function(global2, module2, define2) {
        function Alea(seed) {
          var me = this, mash = Mash();
          me.next = function() {
            var t2 = 2091639 * me.s0 + me.c * 23283064365386963e-26;
            me.s0 = me.s1;
            me.s1 = me.s2;
            return me.s2 = t2 - (me.c = t2 | 0);
          };
          me.c = 1;
          me.s0 = mash(" ");
          me.s1 = mash(" ");
          me.s2 = mash(" ");
          me.s0 -= mash(seed);
          if (me.s0 < 0) {
            me.s0 += 1;
          }
          me.s1 -= mash(seed);
          if (me.s1 < 0) {
            me.s1 += 1;
          }
          me.s2 -= mash(seed);
          if (me.s2 < 0) {
            me.s2 += 1;
          }
          mash = null;
        }
        function copy(f, t2) {
          t2.c = f.c;
          t2.s0 = f.s0;
          t2.s1 = f.s1;
          t2.s2 = f.s2;
          return t2;
        }
        function impl(seed, opts) {
          var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
          prng.int32 = function() {
            return xg.next() * 4294967296 | 0;
          };
          prng.double = function() {
            return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
          };
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        function Mash() {
          var n = 4022871197;
          var mash = function(data) {
            data = String(data);
            for (var i = 0; i < data.length; i++) {
              n += data.charCodeAt(i);
              var h = 0.02519603282416938 * n;
              n = h >>> 0;
              h -= n;
              h *= n;
              n = h >>> 0;
              h -= n;
              n += h * 4294967296;
            }
            return (n >>> 0) * 23283064365386963e-26;
          };
          return mash;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.alea = impl;
        }
      })(
        exports,
        typeof module == "object" && module,
        // present in node.js
        typeof define == "function" && define
        // present with an AMD loader
      );
    }
  });

  // node_modules/seedrandom/lib/xor128.js
  var require_xor128 = __commonJS({
    "node_modules/seedrandom/lib/xor128.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.next = function() {
            var t2 = me.x ^ me.x << 11;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            return me.w ^= me.w >>> 19 ^ t2 ^ t2 >>> 8;
          };
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k3 = 0; k3 < strseed.length + 64; k3++) {
            me.x ^= strseed.charCodeAt(k3) | 0;
            me.next();
          }
        }
        function copy(f, t2) {
          t2.x = f.x;
          t2.y = f.y;
          t2.z = f.z;
          t2.w = f.w;
          return t2;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xor128 = impl;
        }
      })(
        exports,
        typeof module == "object" && module,
        // present in node.js
        typeof define == "function" && define
        // present with an AMD loader
      );
    }
  });

  // node_modules/seedrandom/lib/xorwow.js
  var require_xorwow = __commonJS({
    "node_modules/seedrandom/lib/xorwow.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var t2 = me.x ^ me.x >>> 2;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            me.w = me.v;
            return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t2 ^ t2 << 1)) | 0;
          };
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.v = 0;
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k3 = 0; k3 < strseed.length + 64; k3++) {
            me.x ^= strseed.charCodeAt(k3) | 0;
            if (k3 == strseed.length) {
              me.d = me.x << 10 ^ me.x >>> 4;
            }
            me.next();
          }
        }
        function copy(f, t2) {
          t2.x = f.x;
          t2.y = f.y;
          t2.z = f.z;
          t2.w = f.w;
          t2.v = f.v;
          t2.d = f.d;
          return t2;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xorwow = impl;
        }
      })(
        exports,
        typeof module == "object" && module,
        // present in node.js
        typeof define == "function" && define
        // present with an AMD loader
      );
    }
  });

  // node_modules/seedrandom/lib/xorshift7.js
  var require_xorshift7 = __commonJS({
    "node_modules/seedrandom/lib/xorshift7.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var X2 = me.x, i = me.i, t2, v, w;
            t2 = X2[i];
            t2 ^= t2 >>> 7;
            v = t2 ^ t2 << 24;
            t2 = X2[i + 1 & 7];
            v ^= t2 ^ t2 >>> 10;
            t2 = X2[i + 3 & 7];
            v ^= t2 ^ t2 >>> 3;
            t2 = X2[i + 4 & 7];
            v ^= t2 ^ t2 << 7;
            t2 = X2[i + 7 & 7];
            t2 = t2 ^ t2 << 13;
            v ^= t2 ^ t2 << 9;
            X2[i] = v;
            me.i = i + 1 & 7;
            return v;
          };
          function init(me2, seed2) {
            var j2, w, X2 = [];
            if (seed2 === (seed2 | 0)) {
              w = X2[0] = seed2;
            } else {
              seed2 = "" + seed2;
              for (j2 = 0; j2 < seed2.length; ++j2) {
                X2[j2 & 7] = X2[j2 & 7] << 15 ^ seed2.charCodeAt(j2) + X2[j2 + 1 & 7] << 13;
              }
            }
            while (X2.length < 8)
              X2.push(0);
            for (j2 = 0; j2 < 8 && X2[j2] === 0; ++j2)
              ;
            if (j2 == 8)
              w = X2[7] = -1;
            else
              w = X2[j2];
            me2.x = X2;
            me2.i = 0;
            for (j2 = 256; j2 > 0; --j2) {
              me2.next();
            }
          }
          init(me, seed);
        }
        function copy(f, t2) {
          t2.x = f.x.slice();
          t2.i = f.i;
          return t2;
        }
        function impl(seed, opts) {
          if (seed == null)
            seed = +/* @__PURE__ */ new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.x)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xorshift7 = impl;
        }
      })(
        exports,
        typeof module == "object" && module,
        // present in node.js
        typeof define == "function" && define
        // present with an AMD loader
      );
    }
  });

  // node_modules/seedrandom/lib/xor4096.js
  var require_xor4096 = __commonJS({
    "node_modules/seedrandom/lib/xor4096.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var w = me.w, X2 = me.X, i = me.i, t2, v;
            me.w = w = w + 1640531527 | 0;
            v = X2[i + 34 & 127];
            t2 = X2[i = i + 1 & 127];
            v ^= v << 13;
            t2 ^= t2 << 17;
            v ^= v >>> 15;
            t2 ^= t2 >>> 12;
            v = X2[i] = v ^ t2;
            me.i = i;
            return v + (w ^ w >>> 16) | 0;
          };
          function init(me2, seed2) {
            var t2, v, i, j2, w, X2 = [], limit = 128;
            if (seed2 === (seed2 | 0)) {
              v = seed2;
              seed2 = null;
            } else {
              seed2 = seed2 + "\0";
              v = 0;
              limit = Math.max(limit, seed2.length);
            }
            for (i = 0, j2 = -32; j2 < limit; ++j2) {
              if (seed2)
                v ^= seed2.charCodeAt((j2 + 32) % seed2.length);
              if (j2 === 0)
                w = v;
              v ^= v << 10;
              v ^= v >>> 15;
              v ^= v << 4;
              v ^= v >>> 13;
              if (j2 >= 0) {
                w = w + 1640531527 | 0;
                t2 = X2[j2 & 127] ^= v + w;
                i = 0 == t2 ? i + 1 : 0;
              }
            }
            if (i >= 128) {
              X2[(seed2 && seed2.length || 0) & 127] = -1;
            }
            i = 127;
            for (j2 = 4 * 128; j2 > 0; --j2) {
              v = X2[i + 34 & 127];
              t2 = X2[i = i + 1 & 127];
              v ^= v << 13;
              t2 ^= t2 << 17;
              v ^= v >>> 15;
              t2 ^= t2 >>> 12;
              X2[i] = v ^ t2;
            }
            me2.w = w;
            me2.X = X2;
            me2.i = i;
          }
          init(me, seed);
        }
        function copy(f, t2) {
          t2.i = f.i;
          t2.w = f.w;
          t2.X = f.X.slice();
          return t2;
        }
        ;
        function impl(seed, opts) {
          if (seed == null)
            seed = +/* @__PURE__ */ new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.X)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xor4096 = impl;
        }
      })(
        exports,
        // window object or global
        typeof module == "object" && module,
        // present in node.js
        typeof define == "function" && define
        // present with an AMD loader
      );
    }
  });

  // node_modules/seedrandom/lib/tychei.js
  var require_tychei = __commonJS({
    "node_modules/seedrandom/lib/tychei.js"(exports, module) {
      (function(global2, module2, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var b = me.b, c = me.c, d = me.d, a = me.a;
            b = b << 25 ^ b >>> 7 ^ c;
            c = c - d | 0;
            d = d << 24 ^ d >>> 8 ^ a;
            a = a - b | 0;
            me.b = b = b << 20 ^ b >>> 12 ^ c;
            me.c = c = c - d | 0;
            me.d = d << 16 ^ c >>> 16 ^ a;
            return me.a = a - b | 0;
          };
          me.a = 0;
          me.b = 0;
          me.c = 2654435769 | 0;
          me.d = 1367130551;
          if (seed === Math.floor(seed)) {
            me.a = seed / 4294967296 | 0;
            me.b = seed | 0;
          } else {
            strseed += seed;
          }
          for (var k3 = 0; k3 < strseed.length + 20; k3++) {
            me.b ^= strseed.charCodeAt(k3) | 0;
            me.next();
          }
        }
        function copy(f, t2) {
          t2.a = f.a;
          t2.b = f.b;
          t2.c = f.c;
          t2.d = f.d;
          return t2;
        }
        ;
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module2 && module2.exports) {
          module2.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.tychei = impl;
        }
      })(
        exports,
        typeof module == "object" && module,
        // present in node.js
        typeof define == "function" && define
        // present with an AMD loader
      );
    }
  });

  // (disabled):crypto
  var require_crypto = __commonJS({
    "(disabled):crypto"() {
    }
  });

  // node_modules/seedrandom/seedrandom.js
  var require_seedrandom = __commonJS({
    "node_modules/seedrandom/seedrandom.js"(exports, module) {
      (function(global2, pool3, math) {
        var width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math.pow(width, chunks), significance = math.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
        function seedrandom3(seed, options, callback) {
          var key = [];
          options = options == true ? { entropy: true } : options || {};
          var shortseed = mixkey(flatten2(
            options.entropy ? [seed, tostring(pool3)] : seed == null ? autoseed() : seed,
            3
          ), key);
          var arc4 = new ARC4(key);
          var prng = function() {
            var n = arc4.g(chunks), d = startdenom, x = 0;
            while (n < significance) {
              n = (n + x) * width;
              d *= width;
              x = arc4.g(1);
            }
            while (n >= overflow) {
              n /= 2;
              d /= 2;
              x >>>= 1;
            }
            return (n + x) / d;
          };
          prng.int32 = function() {
            return arc4.g(4) | 0;
          };
          prng.quick = function() {
            return arc4.g(4) / 4294967296;
          };
          prng.double = prng;
          mixkey(tostring(arc4.S), pool3);
          return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
            if (state) {
              if (state.S) {
                copy(state, arc4);
              }
              prng2.state = function() {
                return copy(arc4, {});
              };
            }
            if (is_math_call) {
              math[rngname] = prng2;
              return seed2;
            } else
              return prng2;
          })(
            prng,
            shortseed,
            "global" in options ? options.global : this == math,
            options.state
          );
        }
        function ARC4(key) {
          var t2, keylen = key.length, me = this, i = 0, j2 = me.i = me.j = 0, s = me.S = [];
          if (!keylen) {
            key = [keylen++];
          }
          while (i < width) {
            s[i] = i++;
          }
          for (i = 0; i < width; i++) {
            s[i] = s[j2 = mask & j2 + key[i % keylen] + (t2 = s[i])];
            s[j2] = t2;
          }
          (me.g = function(count) {
            var t3, r = 0, i2 = me.i, j3 = me.j, s2 = me.S;
            while (count--) {
              t3 = s2[i2 = mask & i2 + 1];
              r = r * width + s2[mask & (s2[i2] = s2[j3 = mask & j3 + t3]) + (s2[j3] = t3)];
            }
            me.i = i2;
            me.j = j3;
            return r;
          })(width);
        }
        function copy(f, t2) {
          t2.i = f.i;
          t2.j = f.j;
          t2.S = f.S.slice();
          return t2;
        }
        ;
        function flatten2(obj, depth) {
          var result = [], typ = typeof obj, prop;
          if (depth && typ == "object") {
            for (prop in obj) {
              try {
                result.push(flatten2(obj[prop], depth - 1));
              } catch (e) {
              }
            }
          }
          return result.length ? result : typ == "string" ? obj : obj + "\0";
        }
        function mixkey(seed, key) {
          var stringseed = seed + "", smear, j2 = 0;
          while (j2 < stringseed.length) {
            key[mask & j2] = mask & (smear ^= key[mask & j2] * 19) + stringseed.charCodeAt(j2++);
          }
          return tostring(key);
        }
        function autoseed() {
          try {
            var out;
            if (nodecrypto && (out = nodecrypto.randomBytes)) {
              out = out(width);
            } else {
              out = new Uint8Array(width);
              (global2.crypto || global2.msCrypto).getRandomValues(out);
            }
            return tostring(out);
          } catch (e) {
            var browser = global2.navigator, plugins = browser && browser.plugins;
            return [+/* @__PURE__ */ new Date(), global2, plugins, global2.screen, tostring(pool3)];
          }
        }
        function tostring(a) {
          return String.fromCharCode.apply(0, a);
        }
        mixkey(math.random(), pool3);
        if (typeof module == "object" && module.exports) {
          module.exports = seedrandom3;
          try {
            nodecrypto = require_crypto();
          } catch (ex) {
          }
        } else if (typeof define == "function" && define.amd) {
          define(function() {
            return seedrandom3;
          });
        } else {
          math["seed" + rngname] = seedrandom3;
        }
      })(
        // global: `self` in browsers (including strict mode and web workers),
        // otherwise `this` in Node and other environments
        typeof self !== "undefined" ? self : exports,
        [],
        // pool: entropy pool starts empty
        Math
        // math: package containing random, pow, and seedrandom
      );
    }
  });

  // node_modules/seedrandom/index.js
  var require_seedrandom2 = __commonJS({
    "node_modules/seedrandom/index.js"(exports, module) {
      var alea3 = require_alea();
      var xor128 = require_xor128();
      var xorwow = require_xorwow();
      var xorshift7 = require_xorshift7();
      var xor4096 = require_xor4096();
      var tychei = require_tychei();
      var sr = require_seedrandom();
      sr.alea = alea3;
      sr.xor128 = xor128;
      sr.xorwow = xorwow;
      sr.xorshift7 = xorshift7;
      sr.xor4096 = xor4096;
      sr.tychei = tychei;
      module.exports = sr;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/rand_util.js
  var seedrandom, MPRandGauss, RandGamma, UniformRandom;
  var init_rand_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/rand_util.js"() {
      seedrandom = __toESM(require_seedrandom2());
      MPRandGauss = class {
        constructor(mean3, stdDeviation, dtype, truncated, seed) {
          this.mean = mean3;
          this.stdDev = stdDeviation;
          this.dtype = dtype;
          this.nextVal = NaN;
          this.truncated = truncated;
          if (this.truncated) {
            this.upper = this.mean + this.stdDev * 2;
            this.lower = this.mean - this.stdDev * 2;
          }
          const seedValue = seed ? seed : Math.random();
          this.random = seedrandom.alea(seedValue.toString());
        }
        /** Returns next sample from a Gaussian distribution. */
        nextValue() {
          if (!isNaN(this.nextVal)) {
            const value = this.nextVal;
            this.nextVal = NaN;
            return value;
          }
          let resultX, resultY;
          let isValid = false;
          while (!isValid) {
            let v1, v2, s;
            do {
              v1 = 2 * this.random() - 1;
              v2 = 2 * this.random() - 1;
              s = v1 * v1 + v2 * v2;
            } while (s >= 1 || s === 0);
            const mul2 = Math.sqrt(-2 * Math.log(s) / s);
            resultX = this.mean + this.stdDev * v1 * mul2;
            resultY = this.mean + this.stdDev * v2 * mul2;
            if (!this.truncated || this.isValidTruncated(resultX)) {
              isValid = true;
            }
          }
          if (!this.truncated || this.isValidTruncated(resultY)) {
            this.nextVal = this.convertValue(resultY);
          }
          return this.convertValue(resultX);
        }
        /** Handles proper rounding for non-floating-point numbers. */
        convertValue(value) {
          if (this.dtype == null || this.dtype === "float32") {
            return value;
          }
          return Math.round(value);
        }
        /** Returns true if less than 2-standard-deviations from the mean. */
        isValidTruncated(value) {
          return value <= this.upper && value >= this.lower;
        }
      };
      RandGamma = class {
        constructor(alpha, beta, dtype, seed) {
          this.alpha = alpha;
          this.beta = 1 / beta;
          this.dtype = dtype;
          const seedValue = seed ? seed : Math.random();
          this.randu = seedrandom.alea(seedValue.toString());
          this.randn = new MPRandGauss(0, 1, dtype, false, this.randu());
          if (alpha < 1) {
            this.d = alpha + 2 / 3;
          } else {
            this.d = alpha - 1 / 3;
          }
          this.c = 1 / Math.sqrt(9 * this.d);
        }
        /** Returns next sample from a gamma distribution. */
        nextValue() {
          let x2, v0, v1, x, u, v;
          while (true) {
            do {
              x = this.randn.nextValue();
              v = 1 + this.c * x;
            } while (v <= 0);
            v *= v * v;
            x2 = x * x;
            v0 = 1 - 0.331 * x2 * x2;
            v1 = 0.5 * x2 + this.d * (1 - v + Math.log(v));
            u = this.randu();
            if (u < v0 || Math.log(u) < v1) {
              break;
            }
          }
          v = 1 / this.beta * this.d * v;
          if (this.alpha < 1) {
            v *= Math.pow(this.randu(), 1 / this.alpha);
          }
          return this.convertValue(v);
        }
        /** Handles proper rounding for non-floating-point numbers. */
        convertValue(value) {
          if (this.dtype === "float32") {
            return value;
          }
          return Math.round(value);
        }
      };
      UniformRandom = class {
        constructor(min3 = 0, max3 = 1, dtype, seed) {
          this.canReturnFloat = () => this.dtype == null || this.dtype === "float32";
          this.min = min3;
          this.range = max3 - min3;
          this.dtype = dtype;
          if (seed == null) {
            seed = Math.random();
          }
          if (typeof seed === "number") {
            seed = seed.toString();
          }
          if (!this.canReturnFloat() && this.range <= 1) {
            throw new Error(`The difference between ${min3} - ${max3} <= 1 and dtype is not float`);
          }
          this.random = seedrandom.alea(seed);
        }
        convertValue(value) {
          if (this.canReturnFloat()) {
            return value;
          }
          return Math.round(value);
        }
        nextValue() {
          return this.convertValue(this.min + this.range * this.random());
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/random_gamma.js
  function randomGamma_(shape, alpha, beta = 1, dtype = "float32", seed) {
    assertNonNegativeIntegerDimensions(shape);
    if (beta == null) {
      beta = 1;
    }
    if (dtype == null) {
      dtype = "float32";
    }
    if (dtype !== "float32" && dtype !== "int32") {
      throw new Error(`Unsupported data type ${dtype}`);
    }
    const rgamma = new RandGamma(alpha, beta, dtype, seed);
    const res = buffer(shape, dtype);
    for (let i = 0; i < res.values.length; i++) {
      res.values[i] = rgamma.nextValue();
    }
    return res.toTensor();
  }
  var randomGamma;
  var init_random_gamma = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/random_gamma.js"() {
      init_util_base();
      init_buffer();
      init_operation();
      init_rand_util();
      randomGamma = /* @__PURE__ */ op({ randomGamma_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/random_normal.js
  function randomNormal_(shape, mean3 = 0, stdDev = 1, dtype, seed) {
    assertNonNegativeIntegerDimensions(shape);
    if (dtype != null && dtype === "bool") {
      throw new Error(`Unsupported data type ${dtype}`);
    }
    const randGauss = new MPRandGauss(mean3, stdDev, dtype, false, seed);
    const res = buffer(shape, dtype);
    for (let i = 0; i < res.values.length; i++) {
      res.values[i] = randGauss.nextValue();
    }
    return res.toTensor();
  }
  var randomNormal;
  var init_random_normal = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/random_normal.js"() {
      init_util_base();
      init_buffer();
      init_operation();
      init_rand_util();
      randomNormal = /* @__PURE__ */ op({ randomNormal_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/random_standard_normal.js
  function randomStandardNormal_(shape, dtype, seed) {
    if (dtype != null && dtype === "bool") {
      throw new Error(`Unsupported data type ${dtype}`);
    }
    return randomNormal(shape, 0, 1, dtype, seed);
  }
  var randomStandardNormal;
  var init_random_standard_normal = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/random_standard_normal.js"() {
      init_operation();
      init_random_normal();
      randomStandardNormal = /* @__PURE__ */ op({ randomStandardNormal_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/random_uniform.js
  function randomUniform_(shape, minval = 0, maxval = 1, dtype = "float32", seed) {
    assertNonNegativeIntegerDimensions(shape);
    const res = buffer(shape, dtype);
    const random = new UniformRandom(minval, maxval, null, seed);
    for (let i = 0; i < res.values.length; i++) {
      res.values[i] = random.nextValue();
    }
    return res.toTensor();
  }
  var randomUniform;
  var init_random_uniform = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/random_uniform.js"() {
      init_util_base();
      init_buffer();
      init_operation();
      init_rand_util();
      randomUniform = /* @__PURE__ */ op({ randomUniform_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/range.js
  function range(start, stop, step3 = 1, dtype = "float32") {
    if (step3 === 0) {
      throw new Error("Cannot have a step of zero");
    }
    const attrs = { start, stop, step: step3, dtype };
    return ENGINE.runKernel(Range, {}, attrs);
  }
  var init_range = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/range.js"() {
      init_engine();
      init_kernel_names();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/real.js
  function real_(input) {
    const $input = convertToTensor(input, "input", "real");
    const inputs = { input: $input };
    return ENGINE.runKernel(Real, inputs);
  }
  var real;
  var init_real = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/real.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      real = /* @__PURE__ */ op({ real_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/reciprocal.js
  function reciprocal_(x) {
    const $x = convertToTensor(x, "x", "reciprocal");
    const inputs = { x: $x };
    return ENGINE.runKernel(Reciprocal, inputs);
  }
  var reciprocal;
  var init_reciprocal = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/reciprocal.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      reciprocal = /* @__PURE__ */ op({ reciprocal_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/relu.js
  function relu_(x) {
    const $x = convertToTensor(x, "x", "relu");
    const inputs = { x: $x };
    return ENGINE.runKernel(Relu, inputs);
  }
  var relu;
  var init_relu = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/relu.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      relu = /* @__PURE__ */ op({ relu_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/relu6.js
  function relu6_(x) {
    const $x = convertToTensor(x, "x", "relu6");
    const inputs = { x: $x };
    return ENGINE.runKernel(Relu6, inputs);
  }
  var relu6;
  var init_relu6 = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/relu6.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      relu6 = /* @__PURE__ */ op({ relu6_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js
  function reverse_(x, axis) {
    const $x = convertToTensor(x, "x", "reverse");
    const inputs = { x: $x };
    const attrs = { dims: axis };
    return ENGINE.runKernel(Reverse, inputs, attrs);
  }
  var reverse;
  var init_reverse = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      reverse = /* @__PURE__ */ op({ reverse_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/reverse_1d.js
  function reverse1d_(x) {
    const $x = convertToTensor(x, "x", "reverse");
    assert($x.rank === 1, () => `Error in reverse1D: x must be rank 1 but got rank ${$x.rank}.`);
    return reverse($x, 0);
  }
  var reverse1d;
  var init_reverse_1d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/reverse_1d.js"() {
      init_tensor_util_env();
      init_util();
      init_operation();
      init_reverse();
      reverse1d = /* @__PURE__ */ op({ reverse1d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/reverse_2d.js
  function reverse2d_(x, axis) {
    const $x = convertToTensor(x, "x", "reverse");
    assert($x.rank === 2, () => `Error in reverse2D: x must be rank 2 but got rank ${$x.rank}.`);
    return reverse($x, axis);
  }
  var reverse2d;
  var init_reverse_2d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/reverse_2d.js"() {
      init_tensor_util_env();
      init_util();
      init_operation();
      init_reverse();
      reverse2d = /* @__PURE__ */ op({ reverse2d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/reverse_3d.js
  function reverse3d_(x, axis) {
    const $x = convertToTensor(x, "x", "reverse");
    assert($x.rank === 3, () => `Error in reverse3D: x must be rank 3 but got rank ${$x.rank}.`);
    return reverse($x, axis);
  }
  var reverse3d;
  var init_reverse_3d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/reverse_3d.js"() {
      init_tensor_util_env();
      init_util();
      init_operation();
      init_reverse();
      reverse3d = /* @__PURE__ */ op({ reverse3d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/reverse_4d.js
  function reverse4d_(x, axis) {
    const $x = convertToTensor(x, "x", "reverse");
    assert($x.rank === 4, () => `Error in reverse4D: x must be rank 4 but got rank ${$x.rank}.`);
    return reverse($x, axis);
  }
  var reverse4d;
  var init_reverse_4d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/reverse_4d.js"() {
      init_tensor_util_env();
      init_util();
      init_operation();
      init_reverse();
      reverse4d = /* @__PURE__ */ op({ reverse4d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/round.js
  function round_(x) {
    const $x = convertToTensor(x, "x", "round");
    const inputs = { x: $x };
    return ENGINE.runKernel(Round, inputs);
  }
  var round2;
  var init_round = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/round.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      round2 = /* @__PURE__ */ op({ round_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/rsqrt.js
  function rsqrt_(x) {
    const $x = convertToTensor(x, "x", "rsqrt", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Rsqrt, inputs);
  }
  var rsqrt;
  var init_rsqrt = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/rsqrt.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      rsqrt = /* @__PURE__ */ op({ rsqrt_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/selu.js
  function selu_(x) {
    const $x = convertToTensor(x, "x", "selu");
    const inputs = { x: $x };
    return ENGINE.runKernel(Selu, inputs);
  }
  var selu;
  var init_selu = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/selu.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      selu = /* @__PURE__ */ op({ selu_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/separable_conv2d.js
  function separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad2, dilation = [1, 1], dataFormat = "NHWC") {
    const $x = convertToTensor(x, "x", "separableConv2d");
    const $depthwiseFilter = convertToTensor(depthwiseFilter, "depthwiseFilter", "separableConv2d");
    const $pointwiseFilter = convertToTensor(pointwiseFilter, "pointwiseFilter", "separableConv2d");
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    if (dataFormat === "NCHW") {
      throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
    }
    assert(x4D.rank === 4, () => `Error in separableConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
    assert($depthwiseFilter.rank === 4, () => `Error in separableConv2d: depthwise filter must be rank 4, but got rank ${$depthwiseFilter.rank}.`);
    assert($pointwiseFilter.rank === 4, () => `Error in separableConv2d: pointwise filter must be rank 4, but got rank ${$depthwiseFilter.rank}.`);
    assert($pointwiseFilter.shape[0] === 1, () => `Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${$pointwiseFilter.shape[0]}.`);
    assert($pointwiseFilter.shape[1] === 1, () => `Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${$pointwiseFilter.shape[1]}.`);
    const inChannels = $depthwiseFilter.shape[2];
    const channelMultiplier = $depthwiseFilter.shape[3];
    assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, () => `Error in separableConv2d: the third dimension of pointwise filter must be ${inChannels * channelMultiplier}, but got ${$pointwiseFilter.shape[2]}.`);
    const depthwise = depthwiseConv2d(x4D, $depthwiseFilter, strides, pad2, dataFormat, dilation);
    const pointwiseStride = 1;
    const res = conv2d(depthwise, $pointwiseFilter, pointwiseStride, "valid", dataFormat);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var separableConv2d;
  var init_separable_conv2d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/separable_conv2d.js"() {
      init_tensor_util_env();
      init_util();
      init_conv2d();
      init_depthwise_conv2d();
      init_operation();
      init_reshape();
      separableConv2d = /* @__PURE__ */ op({ separableConv2d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/setdiff1d_async.js
  function setdiff1dAsync_(x, y) {
    return __async(this, null, function* () {
      const $x = convertToTensor(x, "x", "setdiff1d");
      const $y = convertToTensor(y, "y", "setdiff1d");
      assert($x.dtype === $y.dtype, () => `x and y should have the same dtype, but got x (${$x.dtype}) and y (${$y.dtype}).`);
      assert($x.rank === 1, () => `x should be 1D tensor, but got x (${$x.shape}).`);
      assert($y.rank === 1, () => `y should be 1D tensor, but got y (${$y.shape}).`);
      const xVals = yield $x.data();
      const yVals = yield $y.data();
      const ySet = new Set(yVals);
      let outputSize = 0;
      for (let i = 0; i < xVals.length; i++) {
        if (!ySet.has(xVals[i])) {
          outputSize++;
        }
      }
      const buffer2 = new TensorBuffer([outputSize], $x.dtype);
      const indices = new TensorBuffer([outputSize], "int32");
      for (let i = 0, p2 = 0; i < xVals.length; i++) {
        if (!ySet.has(xVals[i])) {
          buffer2.values[p2] = xVals[i];
          indices.values[p2] = i;
          p2++;
        }
      }
      return [buffer2.toTensor(), indices.toTensor()];
    });
  }
  var setdiff1dAsync;
  var init_setdiff1d_async = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/setdiff1d_async.js"() {
      init_tensor();
      init_tensor_util_env();
      init_util();
      setdiff1dAsync = setdiff1dAsync_;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sign.js
  function sign_(x) {
    const $x = convertToTensor(x, "x", "sign");
    const inputs = { x: $x };
    return ENGINE.runKernel(Sign, inputs);
  }
  var sign;
  var init_sign = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sign.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      sign = /* @__PURE__ */ op({ sign_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sin.js
  function sin_(x) {
    const $x = convertToTensor(x, "x", "sin", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Sin, inputs);
  }
  var sin;
  var init_sin = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sin.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      sin = /* @__PURE__ */ op({ sin_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sinh.js
  function sinh_(x) {
    const $x = convertToTensor(x, "x", "sinh");
    const inputs = { x: $x };
    return ENGINE.runKernel(Sinh, inputs);
  }
  var sinh;
  var init_sinh = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sinh.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      sinh = /* @__PURE__ */ op({ sinh_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/slice1d.js
  function slice1d_(x, begin, size) {
    const $x = convertToTensor(x, "x", "slice1d");
    assert($x.rank === 1, () => `slice1d expects a rank-1 tensor, but got a rank-${$x.rank} tensor`);
    return slice($x, [begin], [size]);
  }
  var slice1d;
  var init_slice1d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/slice1d.js"() {
      init_tensor_util_env();
      init_util();
      init_operation();
      init_slice();
      slice1d = /* @__PURE__ */ op({ slice1d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/slice2d.js
  function slice2d_(x, begin, size) {
    const $x = convertToTensor(x, "x", "slice2d");
    assert($x.rank === 2, () => `slice2d expects a rank-2 tensor, but got a rank-${$x.rank} tensor`);
    return slice($x, begin, size);
  }
  var slice2d;
  var init_slice2d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/slice2d.js"() {
      init_tensor_util_env();
      init_util();
      init_operation();
      init_slice();
      slice2d = /* @__PURE__ */ op({ slice2d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/slice3d.js
  function slice3d_(x, begin, size) {
    const $x = convertToTensor(x, "x", "slice3d");
    assert($x.rank === 3, () => `slice3d expects a rank-3 tensor, but got a rank-${$x.rank} tensor`);
    return slice($x, begin, size);
  }
  var slice3d;
  var init_slice3d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/slice3d.js"() {
      init_tensor_util_env();
      init_util();
      init_operation();
      init_slice();
      slice3d = /* @__PURE__ */ op({ slice3d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/slice4d.js
  function slice4d_(x, begin, size) {
    const $x = convertToTensor(x, "x", "slice4d");
    assert($x.rank === 4, () => `slice4d expects a rank-4 tensor, but got a rank-${$x.rank} tensor`);
    return slice($x, begin, size);
  }
  var slice4d;
  var init_slice4d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/slice4d.js"() {
      init_tensor_util_env();
      init_util();
      init_operation();
      init_slice();
      slice4d = /* @__PURE__ */ op({ slice4d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js
  function softmax_(logits, dim = -1) {
    const $logits = convertToTensor(logits, "logits", "softmax", "float32");
    if (dim === -1) {
      dim = $logits.rank - 1;
    }
    if (dim !== $logits.rank - 1) {
      throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${$logits.rank} and dim was ${dim}`);
    }
    const inputs = { logits: $logits };
    const attrs = { dim };
    return ENGINE.runKernel(Softmax, inputs, attrs);
  }
  var softmax;
  var init_softmax = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      softmax = /* @__PURE__ */ op({ softmax_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/spectral/fft.js
  function fft_(input) {
    assert(input.dtype === "complex64", () => `The dtype for tf.spectral.fft() must be complex64 but got ${input.dtype}.`);
    const inputs = { input };
    return ENGINE.runKernel(FFT, inputs);
  }
  var fft;
  var init_fft = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/spectral/fft.js"() {
      init_engine();
      init_kernel_names();
      init_util();
      init_operation();
      fft = /* @__PURE__ */ op({ fft_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/spectral/ifft.js
  function ifft_(input) {
    assert(input.dtype === "complex64", () => `The dtype for tf.spectral.ifft() must be complex64 but got ${input.dtype}.`);
    const inputs = { input };
    return ENGINE.runKernel(IFFT, inputs);
  }
  var ifft;
  var init_ifft = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/spectral/ifft.js"() {
      init_engine();
      init_kernel_names();
      init_util();
      init_operation();
      ifft = /* @__PURE__ */ op({ ifft_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/spectral/irfft.js
  function irfft_(input) {
    const innerDimensionSize = input.shape[input.shape.length - 1];
    const batch = input.size / innerDimensionSize;
    let ret;
    if (innerDimensionSize <= 2) {
      const complexInput = reshape(input, [batch, innerDimensionSize]);
      ret = ifft(complexInput);
    } else {
      const outputShape = [batch, 2 * (innerDimensionSize - 1)];
      const realInput = reshape(real(input), [batch, innerDimensionSize]);
      const imagInput = reshape(imag(input), [batch, innerDimensionSize]);
      const realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);
      const imagConjugate = mul(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));
      const r = concat([realInput, realConjugate], 1);
      const i = concat([imagInput, imagConjugate], 1);
      const complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);
      ret = ifft(complexInput);
    }
    ret = real(ret);
    if (input.rank === 3 && input.shape[0] !== 0) {
      const temp = ret;
      const batch2 = input.shape[0];
      ret = reshape(ret, [batch2, ret.shape[0] / batch2, ret.shape[1]]);
      temp.dispose();
    }
    return ret;
  }
  var irfft;
  var init_irfft = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/spectral/irfft.js"() {
      init_complex();
      init_concat();
      init_imag();
      init_mul();
      init_operation();
      init_real();
      init_reshape();
      init_reverse();
      init_scalar();
      init_slice();
      init_ifft();
      irfft = /* @__PURE__ */ op({ irfft_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/split.js
  function split_(x, numOrSizeSplits, axis = 0) {
    const $x = convertToTensor(x, "x", "split");
    const inputs = { x: $x };
    const attr = { numOrSizeSplits, axis };
    return ENGINE.runKernel(SplitV, inputs, attr);
  }
  var split;
  var init_split = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/split.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      split = /* @__PURE__ */ op({ split_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/spectral/rfft.js
  function rfft_(input, fftLength) {
    assert(input.dtype === "float32", () => `The dtype for rfft() must be real value but got ${input.dtype}`);
    let innerDimensionSize = input.shape[input.shape.length - 1];
    const batch = input.size / innerDimensionSize;
    let adjustedInput;
    if (fftLength != null && fftLength < innerDimensionSize) {
      const begin = input.shape.map((v) => 0);
      const size = input.shape.map((v) => v);
      size[input.shape.length - 1] = fftLength;
      adjustedInput = slice(input, begin, size);
      innerDimensionSize = fftLength;
    } else if (fftLength != null && fftLength > innerDimensionSize) {
      const zerosShape = input.shape.map((v) => v);
      zerosShape[input.shape.length - 1] = fftLength - innerDimensionSize;
      adjustedInput = concat([input, zeros(zerosShape)], input.shape.length - 1);
      innerDimensionSize = fftLength;
    } else {
      adjustedInput = input;
    }
    const zerosInput = zerosLike(adjustedInput);
    const complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);
    const ret = fft(complexInput);
    const half = Math.floor(innerDimensionSize / 2) + 1;
    const realValues = real(ret);
    const imagValues = imag(ret);
    const realComplexConjugate = split(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);
    const imagComplexConjugate = split(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);
    const outputShape = adjustedInput.shape.slice();
    outputShape[adjustedInput.shape.length - 1] = half;
    return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);
  }
  var rfft;
  var init_rfft = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/spectral/rfft.js"() {
      init_util();
      init_complex();
      init_concat();
      init_imag();
      init_operation();
      init_real();
      init_reshape();
      init_slice();
      init_split();
      init_zeros();
      init_zeros_like();
      init_fft();
      rfft = /* @__PURE__ */ op({ rfft_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js
  function squaredDifference_(a, b) {
    let $a = convertToTensor(a, "a", "squaredDifference");
    let $b = convertToTensor(b, "b", "squaredDifference");
    [$a, $b] = makeTypesMatch($a, $b);
    assertAndGetBroadcastShape($a.shape, $b.shape);
    const inputs = { a: $a, b: $b };
    const attrs = {};
    return ENGINE.runKernel(SquaredDifference, inputs, attrs);
  }
  var squaredDifference;
  var init_squared_difference = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_broadcast_util();
      init_operation();
      squaredDifference = /* @__PURE__ */ op({ squaredDifference_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/squeeze.js
  function squeeze_(x, axis) {
    const $x = convertToTensor(x, "x", "squeeze", "string_or_numeric");
    return reshape($x, squeezeShape($x.shape, axis).newShape);
  }
  var squeeze;
  var init_squeeze = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/squeeze.js"() {
      init_tensor_util_env();
      init_util();
      init_operation();
      init_reshape();
      squeeze = /* @__PURE__ */ op({ squeeze_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/stack.js
  function stack_(tensors, axis = 0) {
    const $tensors = convertToTensorArray(tensors, "tensors", "stack", "string_or_numeric");
    assert($tensors.length >= 1, () => "Pass at least one tensor to tf.stack");
    if ($tensors.length > 0) {
      assert(axis <= $tensors[0].rank, () => "Axis must be <= rank of the tensor");
    }
    const inputs = $tensors;
    const attrs = { axis };
    return ENGINE.runKernel(Pack, inputs, attrs);
  }
  var stack;
  var init_stack = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/stack.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      stack = /* @__PURE__ */ op({ stack_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/step.js
  function step_(x, alpha = 0) {
    const $x = convertToTensor(x, "x", "step");
    const inputs = { x: $x };
    const attrs = { alpha };
    return ENGINE.runKernel(Step, inputs, attrs);
  }
  var step;
  var init_step = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/step.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      step = /* @__PURE__ */ op({ step_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js
  function stridedSlice_(x, begin, end, strides, beginMask = 0, endMask = 0, ellipsisMask = 0, newAxisMask = 0, shrinkAxisMask = 0) {
    const $x = convertToTensor(x, "x", "stridedSlice", "string_or_numeric");
    const inputs = { x: $x };
    const attrs = {
      begin,
      end,
      strides,
      beginMask,
      endMask,
      ellipsisMask,
      newAxisMask,
      shrinkAxisMask
    };
    return ENGINE.runKernel(StridedSlice, inputs, attrs);
  }
  var stridedSlice;
  var init_strided_slice = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      stridedSlice = /* @__PURE__ */ op({ stridedSlice_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tan.js
  function tan_(x) {
    const $x = convertToTensor(x, "x", "tan", "float32");
    const inputs = { x: $x };
    return ENGINE.runKernel(Tan, inputs);
  }
  var tan;
  var init_tan = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/tan.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      tan = /* @__PURE__ */ op({ tan_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tensor1d.js
  function tensor1d(values, dtype) {
    assertNonNull(values);
    const inferredShape = inferShape(values, dtype);
    if (inferredShape.length !== 1) {
      throw new Error("tensor1d() requires values to be a flat/TypedArray");
    }
    const shape = null;
    return makeTensor(values, shape, inferredShape, dtype);
  }
  var init_tensor1d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/tensor1d.js"() {
      init_tensor_util_env();
      init_util();
      init_tensor_ops_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tensor2d.js
  function tensor2d(values, shape, dtype) {
    assertNonNull(values);
    if (shape != null && shape.length !== 2) {
      throw new Error("tensor2d() requires shape to have two numbers");
    }
    const inferredShape = inferShape(values, dtype);
    if (inferredShape.length !== 2 && inferredShape.length !== 1) {
      throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
    }
    if (inferredShape.length === 1 && shape == null) {
      throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
    }
    return makeTensor(values, shape, inferredShape, dtype);
  }
  var init_tensor2d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/tensor2d.js"() {
      init_tensor_util_env();
      init_util();
      init_tensor_ops_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tensor3d.js
  function tensor3d(values, shape, dtype) {
    assertNonNull(values);
    if (shape != null && shape.length !== 3) {
      throw new Error("tensor3d() requires shape to have three numbers");
    }
    const inferredShape = inferShape(values, dtype);
    if (inferredShape.length !== 3 && inferredShape.length !== 1) {
      throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
    }
    if (inferredShape.length === 1 && shape == null) {
      throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
    }
    return makeTensor(values, shape, inferredShape, dtype);
  }
  var init_tensor3d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/tensor3d.js"() {
      init_tensor_util_env();
      init_util();
      init_tensor_ops_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tensor4d.js
  function tensor4d(values, shape, dtype) {
    assertNonNull(values);
    if (shape != null && shape.length !== 4) {
      throw new Error("tensor4d() requires shape to have four numbers");
    }
    const inferredShape = inferShape(values, dtype);
    if (inferredShape.length !== 4 && inferredShape.length !== 1) {
      throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");
    }
    if (inferredShape.length === 1 && shape == null) {
      throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");
    }
    return makeTensor(values, shape, inferredShape, dtype);
  }
  var init_tensor4d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/tensor4d.js"() {
      init_tensor_util_env();
      init_util();
      init_tensor_ops_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tensor5d.js
  function tensor5d(values, shape, dtype) {
    assertNonNull(values);
    if (shape != null && shape.length !== 5) {
      throw new Error("tensor5d() requires shape to have five numbers");
    }
    const inferredShape = inferShape(values, dtype);
    if (inferredShape.length !== 5 && inferredShape.length !== 1) {
      throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");
    }
    if (inferredShape.length === 1 && shape == null) {
      throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");
    }
    return makeTensor(values, shape, inferredShape, dtype);
  }
  var init_tensor5d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/tensor5d.js"() {
      init_tensor_util_env();
      init_util();
      init_tensor_ops_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/tensor6d.js
  function tensor6d(values, shape, dtype) {
    assertNonNull(values);
    if (shape != null && shape.length !== 6) {
      throw new Error("tensor6d() requires shape to have six numbers");
    }
    const inferredShape = inferShape(values, dtype);
    if (inferredShape.length !== 6 && inferredShape.length !== 1) {
      throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");
    }
    if (inferredShape.length === 1 && shape == null) {
      throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");
    }
    shape = shape || inferredShape;
    return makeTensor(values, shape, inferredShape, dtype);
  }
  var init_tensor6d = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/tensor6d.js"() {
      init_tensor_util_env();
      init_util();
      init_tensor_ops_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/topk.js
  function topk_(x, k3 = 1, sorted = true) {
    const $x = convertToTensor(x, "x", "topk");
    if ($x.rank === 0) {
      throw new Error("topk() expects the input to be of rank 1 or higher");
    }
    const lastDim = $x.shape[$x.shape.length - 1];
    if (k3 < 0) {
      throw new Error(`'k' passed to topk() must be >= 0 but got ${k3}`);
    }
    if (k3 > lastDim) {
      throw new Error(`'k' passed to topk() must be <= the last dimension (${lastDim}) but got ${k3}`);
    }
    const inputs = { x: $x };
    const attrs = { k: k3, sorted };
    const [values, indices] = ENGINE.runKernel(TopK, inputs, attrs);
    return { values, indices };
  }
  var topk;
  var init_topk = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/topk.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      topk = /* @__PURE__ */ op({ topk_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/truncated_normal.js
  function truncatedNormal_(shape, mean3 = 0, stdDev = 1, dtype, seed) {
    assertNonNegativeIntegerDimensions(shape);
    if (dtype != null && dtype === "bool") {
      throw new Error(`Unsupported data type $ { dtype }`);
    }
    const randGauss = new MPRandGauss(mean3, stdDev, dtype, true, seed);
    const res = buffer(shape, dtype);
    for (let i = 0; i < res.values.length; i++) {
      res.values[i] = randGauss.nextValue();
    }
    return res.toTensor();
  }
  var truncatedNormal;
  var init_truncated_normal = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/truncated_normal.js"() {
      init_util_base();
      init_buffer();
      init_operation();
      init_rand_util();
      truncatedNormal = /* @__PURE__ */ op({ truncatedNormal_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/unique.js
  function unique_(x, axis = 0) {
    const $x = convertToTensor(x, "x", "unique", "string_or_numeric");
    assert($x.rank > 0, () => "The input tensor must be at least 1D");
    const inputs = { x: $x };
    const attrs = { axis };
    const [values, indices] = ENGINE.runKernel(Unique, inputs, attrs);
    return { values, indices };
  }
  var unique;
  var init_unique = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/unique.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      unique = /* @__PURE__ */ op({ unique_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js
  function unsortedSegmentSum_(x, segmentIds, numSegments) {
    const $x = convertToTensor(x, "x", "unsortedSegmentSum");
    const $segmentIds = convertToTensor(segmentIds, "segmentIds", "unsortedSegmentSum", "int32");
    assert(isInt(numSegments), () => "numSegments must be of dtype int");
    const inputs = { x: $x, segmentIds: $segmentIds };
    const attrs = { numSegments };
    return ENGINE.runKernel(UnsortedSegmentSum, inputs, attrs);
  }
  var unsortedSegmentSum;
  var init_unsorted_segment_sum = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      unsortedSegmentSum = /* @__PURE__ */ op({ unsortedSegmentSum_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/unstack.js
  function unstack_(x, axis = 0) {
    const $x = convertToTensor(x, "x", "unstack", "string_or_numeric");
    assert(axis >= -$x.shape.length && axis < $x.shape.length, () => `Axis = ${axis} is not in [-${$x.shape.length}, ${$x.shape.length})`);
    const inputs = { value: $x };
    const attrs = { axis };
    return ENGINE.runKernel(Unpack, inputs, attrs);
  }
  var unstack;
  var init_unstack = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/unstack.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      unstack = /* @__PURE__ */ op({ unstack_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/upper_bound.js
  function upperBound(sortedSequence, values) {
    return searchSorted(sortedSequence, values, "right");
  }
  var init_upper_bound = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/upper_bound.js"() {
      init_search_sorted();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/variable.js
  function variable(initialValue, trainable = true, name, dtype) {
    return ENGINE.makeVariable(initialValue, trainable, name, dtype);
  }
  var init_variable = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/variable.js"() {
      init_engine();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js
  function whereImpl(condShape, condVals) {
    const indices = [];
    for (let i = 0; i < condVals.length; i++) {
      if (condVals[i]) {
        indices.push(i);
      }
    }
    const inBuffer = buffer(condShape, "int32");
    const out = buffer([indices.length, condShape.length], "int32");
    for (let i = 0; i < indices.length; i++) {
      const loc = inBuffer.indexToLoc(indices[i]);
      const offset = i * condShape.length;
      out.values.set(loc, offset);
    }
    return out.toTensor();
  }
  var init_where_impl = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js"() {
      init_buffer();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/where_async.js
  function whereAsync_(condition) {
    return __async(this, null, function* () {
      const $condition = convertToTensor(condition, "condition", "whereAsync", "bool");
      const vals = yield $condition.data();
      const res = whereImpl($condition.shape, vals);
      if (condition !== $condition) {
        $condition.dispose();
      }
      return res;
    });
  }
  var whereAsync;
  var init_where_async = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/where_async.js"() {
      init_where_impl();
      init_tensor_util_env();
      whereAsync = whereAsync_;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/boolean_mask.js
  function booleanMaskAsync_(tensor2, mask, axis) {
    return __async(this, null, function* () {
      const $tensor = convertToTensor(tensor2, "tensor", "boolMask");
      const $mask = convertToTensor(mask, "mask", "boolMask", "bool");
      const axisFrom = axis == null ? 0 : axis;
      const maskDim = $mask.rank;
      const tensorShape = $tensor.shape;
      assert(maskDim > 0, () => "mask cannot be scalar");
      assertShapesMatch(tensorShape.slice(axisFrom, axisFrom + maskDim), $mask.shape, `mask's shape must match the first K dimensions of tensor's shape,`);
      let leadingSize = 1;
      for (let i = axisFrom; i < axisFrom + maskDim; i++) {
        leadingSize *= tensorShape[i];
      }
      const targetTensorShape = tensorShape.slice(0, axisFrom).concat([leadingSize], tensorShape.slice(axisFrom + maskDim));
      const reshapedTensor = reshape($tensor, targetTensorShape);
      const reshapedMask = reshape($mask, [-1]);
      const positivePositions = yield whereAsync(reshapedMask);
      const indices = squeeze(positivePositions, [1]);
      const res = gather(reshapedTensor, indices, axisFrom);
      if (tensor2 !== $tensor) {
        $tensor.dispose();
      }
      if (mask !== $mask) {
        $mask.dispose();
      }
      indices.dispose();
      reshapedTensor.dispose();
      reshapedMask.dispose();
      positivePositions.dispose();
      return res;
    });
  }
  var booleanMaskAsync;
  var init_boolean_mask = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/boolean_mask.js"() {
      init_tensor_util_env();
      init_util();
      init_gather();
      init_reshape();
      init_squeeze();
      init_where_async();
      booleanMaskAsync = booleanMaskAsync_;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js
  function transpose_(x, perm, conjugate) {
    const $x = convertToTensor(x, "x", "transpose");
    if (perm == null) {
      perm = $x.shape.map((s, i) => i).reverse();
    }
    assert($x.rank === perm.length, () => `Error in transpose: rank of input ${$x.rank} must match length of perm ${perm}.`);
    perm.forEach((axis) => {
      assert(axis >= 0 && axis < $x.rank, () => `All entries in 'perm' must be between 0 and ${$x.rank - 1} but got ${perm}`);
    });
    if ($x.rank <= 1) {
      return $x.clone();
    }
    const inputs = { x: $x };
    const attrs = { perm };
    if ($x.dtype === "complex64") {
      return tidy(() => {
        let $real = real($x);
        let $imag = imag($x);
        $real = ENGINE.runKernel(Transpose, { x: $real }, attrs);
        $imag = ENGINE.runKernel(Transpose, { x: $imag }, attrs);
        if (conjugate) {
          $imag = neg($imag);
        }
        return complex($real, $imag);
      });
    }
    return ENGINE.runKernel(Transpose, inputs, attrs);
  }
  var transpose;
  var init_transpose = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js"() {
      init_engine();
      init_globals();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_complex();
      init_imag();
      init_neg();
      init_operation();
      init_real();
      transpose = /* @__PURE__ */ op({ transpose_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/moving_average.js
  function movingAverage_(v, x, decay, step3, zeroDebias = true) {
    const $v = convertToTensor(v, "v", "movingAverage");
    const $x = convertToTensor(x, "x", "movingAverage");
    const $decay = convertToTensor(decay, "decay", "movingAverage");
    assertTypesMatch($v, $x);
    assert(arraysEqual($v.shape, $x.shape), () => "Shape mismatch in v and x");
    const one = scalar(1);
    const oneMinusDecay = sub(one, $decay);
    let update = mul(sub($x, $v), oneMinusDecay);
    if (zeroDebias) {
      assert(step3 != null, () => "When using zeroDebias: true, step is required.");
      const $step = convertToTensor(step3, "step", "movingAverage");
      update = div(update, sub(one, pow($decay, $step)));
    }
    return add2($v, update);
  }
  var movingAverage;
  var init_moving_average = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/moving_average.js"() {
      init_tensor_util();
      init_tensor_util_env();
      init_util();
      init_add();
      init_div();
      init_mul();
      init_operation();
      init_pow();
      init_scalar();
      init_sub();
      movingAverage = /* @__PURE__ */ op({ movingAverage_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js
  function validateUpdateShape(shape, indices, updates) {
    const sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;
    const batchDim = indices.rank > 1 ? indices.rank - 1 : 1;
    const shapeError = `Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${updates.shape}, indices.shape: ${indices.shape}, shape: ${shape}, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;
    if (updates.rank < batchDim) {
      throw new Error(shapeError + ` update.rank < ${batchDim}. `);
    }
    if (shape.length < sliceDim + (updates.rank - batchDim)) {
      throw new Error(shapeError + ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);
    }
    if (updates.rank !== batchDim + shape.length - sliceDim) {
      throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);
    }
    for (let d = 0; d < batchDim; ++d) {
      if (updates.shape[d] !== indices.shape[d]) {
        throw new Error(shapeError + ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);
      }
    }
    for (let d = 0; d < updates.rank - batchDim; ++d) {
      if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {
        throw new Error(shapeError + ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);
      }
    }
  }
  function validateInput(updates, indices, shape) {
    if (indices.rank < 1) {
      throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${indices.rank}.`);
    }
    if (updates.rank < 1) {
      throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${updates.rank}.`);
    }
    if (indices.dtype !== "int32") {
      throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);
    }
    if (shape.length < 1) {
      throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);
    }
    if (shape.length === 0) {
      if (indices.size === 0) {
        throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);
      }
      if (updates.size === 0) {
        throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);
      }
    }
    validateUpdateShape(shape, indices, updates);
  }
  function calculateShapes(updates, indices, shape) {
    const indicesRank = indices.shape.length;
    const sliceRank = indicesRank > 1 ? indices.shape[indicesRank - 1] : 1;
    const totalNd = shape.length;
    let sliceSize = 1;
    for (let i = sliceRank; i < totalNd; ++i) {
      sliceSize *= shape[i];
    }
    const safeSliceDim = sliceRank < 1 ? 1 : sliceRank;
    const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;
    const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];
    const outputSize = sizeFromShape(shape);
    return { sliceRank, numUpdates, sliceSize, strides, outputSize };
  }
  var init_scatter_nd_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js"() {
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd.js
  function scatterND_(indices, updates, shape) {
    assertNonNegativeIntegerDimensions(shape);
    const $indices = convertToTensor(indices, "indices", "scatterND", "int32");
    const $updates = convertToTensor(updates, "updates", "scatterND");
    validateInput($updates, $indices, shape);
    const inputs = { indices: $indices, updates: $updates };
    const attrs = { shape };
    return ENGINE.runKernel(ScatterNd, inputs, attrs);
  }
  var scatterND;
  var init_scatter_nd = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util_base();
      init_operation();
      init_scatter_nd_util();
      scatterND = /* @__PURE__ */ op({ scatterND_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense_util.js
  function validateInput2(sparseIndices, sparseValues, outputShape, defaultValues) {
    if (sparseIndices.dtype !== "int32") {
      throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${sparseIndices.dtype}.`);
    }
    if (sparseIndices.rank > 2) {
      throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${sparseIndices.shape}.`);
    }
    const numElems = sparseIndices.rank > 0 ? sparseIndices.shape[0] : 1;
    const numDims = sparseIndices.rank > 1 ? sparseIndices.shape[1] : 1;
    if (outputShape.length !== numDims) {
      throw new Error(`outputShape has incorrect number of elements:, ${outputShape.length}, should be: ${numDims}.`);
    }
    const numValues = sparseValues.size;
    if (!(sparseValues.rank === 0 || sparseValues.rank === 1 && numValues === numElems)) {
      throw new Error(`sparseValues has incorrect shape ${sparseValues.shape}, should be [] or [${numElems}]`);
    }
    if (sparseValues.dtype !== defaultValues.dtype) {
      throw new Error("sparseValues.dtype must match defaultValues.dtype");
    }
  }
  var init_sparse_to_dense_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense_util.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js
  function sparseToDense_(sparseIndices, sparseValues, outputShape, defaultValue = 0) {
    assertNonNegativeIntegerDimensions(outputShape);
    const $sparseIndices = convertToTensor(sparseIndices, "sparseIndices", "sparseToDense", "int32");
    const $sparseValues = convertToTensor(sparseValues, "sparseValues", "sparseToDense", "string_or_numeric");
    const $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseToDense", $sparseValues.dtype);
    validateInput2($sparseIndices, $sparseValues, outputShape, $defaultValue);
    const inputs = {
      sparseIndices: $sparseIndices,
      sparseValues: $sparseValues,
      defaultValue: $defaultValue
    };
    const attrs = { outputShape };
    return ENGINE.runKernel(SparseToDense, inputs, attrs);
  }
  var sparseToDense;
  var init_sparse_to_dense = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js"() {
      init_engine();
      init_kernel_names();
      init_sparse_to_dense_util();
      init_tensor_util_env();
      init_util_base();
      init_operation();
      sparseToDense = /* @__PURE__ */ op({ sparseToDense_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd.js
  function gatherND_(x, indices) {
    const $indices = convertToTensor(indices, "indices", "gatherND", "int32");
    const $x = convertToTensor(x, "x", "gatherND", "string_or_numeric");
    const inputs = { params: $x, indices: $indices };
    return ENGINE.runKernel(GatherNd, inputs);
  }
  var gatherND;
  var init_gather_nd = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      gatherND = /* @__PURE__ */ op({ gatherND_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/dropout_util.js
  function getNoiseShape(x, noiseShape) {
    if (noiseShape == null) {
      return x.shape.slice();
    }
    if (arraysEqual(x.shape, noiseShape)) {
      return noiseShape;
    }
    if (x.shape.length === noiseShape.length) {
      const newDimension = [];
      for (let i = 0; i < x.shape.length; i++) {
        if (noiseShape[i] == null && x.shape[i] != null) {
          newDimension.push(x.shape[i]);
        } else {
          newDimension.push(noiseShape[i]);
        }
      }
      return newDimension;
    }
    return noiseShape;
  }
  var init_dropout_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/dropout_util.js"() {
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/dropout.js
  function dropout_(x, rate, noiseShape, seed) {
    const $x = convertToTensor(x, "x", "dropout");
    assert($x.dtype === "float32", () => `x has to be a floating point tensor since it's going to be scaled, but got a ${$x.dtype} tensor instead.`);
    assert(rate >= 0 && rate < 1, () => `rate must be a float in the range [0, 1), but got ${rate}.`);
    if (rate === 0) {
      return x instanceof Tensor ? $x.clone() : $x;
    }
    const $noiseShape = getNoiseShape($x, noiseShape);
    const keepProb = 1 - rate;
    const multiplier = div(floor(add2(randomUniform($noiseShape, 0, 1, "float32", seed), keepProb)), keepProb);
    return mul($x, multiplier);
  }
  var dropout;
  var init_dropout = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/dropout.js"() {
      init_tensor();
      init_tensor_util_env();
      init_util();
      init_add();
      init_div();
      init_dropout_util();
      init_floor();
      init_mul();
      init_operation();
      init_random_uniform();
      dropout = /* @__PURE__ */ op({ dropout_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops_util.js
  function enclosingPowerOfTwo(value) {
    return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2))));
  }
  function cosineWindow(windowLength, a, b) {
    const even = 1 - windowLength % 2;
    const newValues = new Float32Array(windowLength);
    for (let i = 0; i < windowLength; ++i) {
      const cosArg = 2 * Math.PI * i / (windowLength + even - 1);
      newValues[i] = a - b * Math.cos(cosArg);
    }
    return tensor1d(newValues, "float32");
  }
  var init_signal_ops_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops_util.js"() {
      init_tensor1d();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/in_top_k.js
  function inTopKAsync_(predictions, targets, k3 = 1) {
    return __async(this, null, function* () {
      const $predictions = convertToTensor(predictions, "predictions", "inTopK");
      const $targets = convertToTensor(targets, "targets", "inTopK");
      assert($predictions.rank > 1, () => `inTopK() expects the predictions to be of rank 2 or higher, but got ${$predictions.rank}`);
      assert($predictions.rank - 1 === $targets.rank, () => `predictions rank should be 1 larger than targets rank, but got predictions rank ${$predictions.rank} and targets rank ${$targets.rank}`);
      assertShapesMatch($predictions.shape.slice(0, $predictions.shape.length - 1), $targets.shape, `predictions's shape should be align with the targets' shape, except the last dimension.`);
      const lastDim = $predictions.shape[$predictions.shape.length - 1];
      assert(k3 > 0 && k3 <= lastDim, () => `'k' passed to inTopK() must be > 0 && <= the predictions last dimension (${lastDim}), but got ${k3}`);
      const predictionsVals = yield $predictions.data();
      const targetsVals = yield $targets.data();
      const [batch, size] = [predictionsVals.length / lastDim, lastDim];
      const precision = getTypedArrayFromDType("bool", batch);
      for (let b = 0; b < batch; b++) {
        const offset = b * size;
        const vals = predictionsVals.subarray(offset, offset + size);
        const valAndInd = [];
        for (let i = 0; i < vals.length; i++) {
          valAndInd.push({ value: vals[i], index: i });
        }
        valAndInd.sort((a, b2) => b2.value - a.value);
        precision[b] = 0;
        for (let i = 0; i < k3; i++) {
          if (valAndInd[i].index === targetsVals[b]) {
            precision[b] = 1;
            break;
          }
        }
      }
      if (predictions !== $predictions) {
        $predictions.dispose();
      }
      if (targets !== $targets) {
        $targets.dispose();
      }
      return tensor(precision, $targets.shape, "bool");
    });
  }
  var inTopKAsync;
  var init_in_top_k = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/in_top_k.js"() {
      init_tensor_util_env();
      init_util();
      init_tensor2();
      inTopKAsync = inTopKAsync_;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js
  function conv2DBackpropFilter_(x, dy, filterShape, strides, pad2, dataFormat = "NHWC", dimRoundingMode) {
    let x4D = x;
    if (x.rank === 3) {
      x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
    }
    let dy4D = dy;
    if (dy4D.rank === 3) {
      dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ${x4D.shape}.`);
    assert(dy4D.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ${dy4D.shape}.`);
    assert(filterShape.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ${filterShape}.`);
    const inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
    const outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
    assert(inDepth === filterShape[2], () => `Error in conv2dDerFilter: depth of input ${inDepth}) must match input depth in filter (${filterShape[2]}.`);
    assert(outDepth === filterShape[3], () => `Error in conv2dDerFilter: depth of dy (${outDepth}) must match output depth for filter (${filterShape[3]}).`);
    checkPadOnDimRoundingMode("conv2dDerFilter", pad2, dimRoundingMode);
    const inputs = { x: x4D, dy: dy4D };
    const attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape };
    return ENGINE.runKernel(Conv2DBackpropFilter, inputs, attrs);
  }
  var conv2DBackpropFilter;
  var init_conv2d_backprop_filter = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js"() {
      init_engine();
      init_kernel_names();
      init_util();
      init_conv_util();
      init_operation();
      init_reshape();
      conv2DBackpropFilter = /* @__PURE__ */ op({ conv2DBackpropFilter_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/fused_util.js
  function getFusedDyActivation(dy, y, activation) {
    if (activation == null || activation === "linear") {
      return dy;
    }
    if (activation === "relu") {
      return mul(dy, step(y));
    }
    throw new Error(`Cannot compute gradient for fused activation ${activation}.`);
  }
  function getFusedBiasGradient(bias, dyActivation) {
    let res = dyActivation;
    const reduceAxes = getReductionAxes(bias.shape, dyActivation.shape);
    if (reduceAxes.length > 0) {
      res = sum2(res, reduceAxes);
    }
    return reshape(res, bias.shape);
  }
  function applyActivation(x, activation, preluActivationWeights, leakyreluAlpha) {
    if (activation === "linear") {
      return x;
    } else if (activation === "relu") {
      return relu(x);
    } else if (activation === "elu") {
      return elu(x);
    } else if (activation === "relu6") {
      return relu6(x);
    } else if (activation === "prelu") {
      return prelu(x, preluActivationWeights);
    } else if (activation === "leakyrelu") {
      return leakyRelu(x, leakyreluAlpha);
    } else if (activation === "sigmoid") {
      return sigmoid(x);
    }
    throw new Error(`Unknown fused activation ${activation}.`);
  }
  var shouldFuse;
  var init_fused_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/fused_util.js"() {
      init_broadcast_util();
      init_elu();
      init_leaky_relu();
      init_mul();
      init_prelu();
      init_relu();
      init_relu6();
      init_reshape();
      init_sigmoid();
      init_step();
      init_sum();
      shouldFuse = (gradientDepth, activation) => {
        const gradientMode = gradientDepth > 0;
        return !gradientMode || activation === "linear";
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/fused/conv2d.js
  function fusedConv2d_({ x, filter, strides, pad: pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode, bias, activation = "linear", preluActivationWeights, leakyreluAlpha }) {
    activation = activation || "linear";
    if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
      assert(dataFormat === "NHWC", () => `Error in fused conv2d: got dataFormat of ${dataFormat} but only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.`);
      let result = conv2d(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
      if (bias != null) {
        result = add2(result, bias);
      }
      return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
    }
    const $x = convertToTensor(x, "x", "conv2d", "float32");
    const $filter = convertToTensor(filter, "filter", "conv2d", "float32");
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in fused conv2d: input must be rank 4, but got rank ${x4D.rank}.`);
    assert($filter.rank === 4, () => `Error in fused conv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
    checkPadOnDimRoundingMode("fused conv2d", pad2, dimRoundingMode);
    const inputChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
    assert($filter.shape[2] === inputChannels, () => `Error in conv2d: depth of input (${inputChannels}) must match input depth for filter ${$filter.shape[2]}.`);
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    const convInfo = computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad2, dimRoundingMode);
    let $bias;
    if (bias != null) {
      $bias = convertToTensor(bias, "bias", "fused conv2d");
      [$bias] = makeTypesMatch($bias, $x);
      if (dataFormat === "NHWC") {
        assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
      } else {
        assert($bias.shape.length <= 1, () => `Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of rank-${$bias.shape.length}.`);
        assert($bias.shape.length === 0 || $bias.shape[0] === convInfo.outChannels || $bias.shape[0] === 1, () => `Error in fused conv2d: bias shape (${$bias.shape}) is not compatible with the number of output channels (${convInfo.outChannels})`);
      }
    }
    let $preluActivationWeights;
    if (preluActivationWeights != null) {
      const alphaShape = preluActivationWeights.shape;
      assert(alphaShape.length <= 1 || alphaShape.length === 3, () => `Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of rank-${alphaShape.length}.`);
      if (alphaShape.length === 1) {
        assert(alphaShape[0] === 1 || alphaShape[0] === convInfo.outChannels, () => `Error in fused conv2d: PReLU activation weights (${alphaShape}) is not compatible with the number of output channels (${convInfo.outChannels}).`);
      } else if (alphaShape.length === 3) {
        try {
          assertAndGetBroadcastShape(alphaShape, convInfo.outShape);
        } catch (e) {
          const errMsg = `Error in fused conv2d: PReLU activation weights (${alphaShape}) is not compatible with the output shape of the conv2d (${convInfo.outShape}).`;
          throw Error(errMsg);
        }
      }
      $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused conv2d");
    }
    const grad = (dy, saved) => {
      assert(dataFormat === "NHWC", () => `Error in gradient of fused conv2D: got dataFormat of ${dataFormat} but only NHWC is currently supported.`);
      const [$filter2, x4D2, y, $bias2] = saved;
      const dyActivation = getFusedDyActivation(dy, y, activation);
      assert(tupleValuesAreOne(dilations), () => `Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);
      const xDer = conv2DBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2);
      const filterDer = conv2DBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2);
      const der = [xDer, filterDer];
      if ($bias2 != null) {
        const biasDer = getFusedBiasGradient($bias2, dyActivation);
        der.push(biasDer);
      }
      return der;
    };
    const inputs = {
      x: x4D,
      filter: $filter,
      bias: $bias,
      preluActivationWeights: $preluActivationWeights
    };
    const attrs = {
      strides,
      pad: pad2,
      dataFormat,
      dilations,
      dimRoundingMode,
      activation,
      leakyreluAlpha
    };
    if (bias == null) {
      const customOp = customGrad((x4D2, filter2, save) => {
        let res = (
          // tslint:disable-next-line: no-unnecessary-type-assertion
          ENGINE.runKernel(FusedConv2D, inputs, attrs)
        );
        save([filter2, x4D2, res]);
        if (reshapedTo4D) {
          res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
        }
        return { value: res, gradFunc: grad };
      });
      return customOp(x4D, $filter);
    } else {
      const customOpWithBias = customGrad((x4D2, filter2, bias2, save) => {
        let res = ENGINE.runKernel(FusedConv2D, inputs, attrs);
        save([filter2, x4D2, res, bias2]);
        if (reshapedTo4D) {
          res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
        }
        return { value: res, gradFunc: grad };
      });
      return customOpWithBias(x4D, $filter, $bias);
    }
  }
  var conv2d2;
  var init_conv2d2 = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/fused/conv2d.js"() {
      init_engine();
      init_gradients();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_util();
      init_add();
      init_broadcast_util();
      init_conv2d();
      init_conv2d_backprop_filter();
      init_conv2d_backprop_input();
      init_conv_util();
      init_fused_util();
      init_operation();
      init_reshape();
      conv2d2 = /* @__PURE__ */ op({ fusedConv2d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js
  function depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, strides, pad2, dilations = [1, 1], dimRoundingMode) {
    let x4D = x;
    if (x.rank === 3) {
      x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
    }
    let dy4D = dy;
    if (dy4D.rank === 3) {
      dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
    }
    const inputs = { x: x4D, dy: dy4D };
    const attrs = { strides, pad: pad2, dimRoundingMode, dilations, filterShape };
    return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, inputs, attrs);
  }
  var depthwiseConv2dNativeBackpropFilter;
  var init_depthwise_conv2d_native_backprop_filter = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js"() {
      init_engine();
      init_kernel_names();
      init_operation();
      init_reshape();
      depthwiseConv2dNativeBackpropFilter = op({ depthwiseConv2dNativeBackpropFilter_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js
  function depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, strides, pad2, dilations = [1, 1], dimRoundingMode) {
    let dy4D = dy;
    let reshapedTo4D = false;
    if (dy.rank === 3) {
      reshapedTo4D = true;
      dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
    }
    const inputs = { dy: dy4D, filter };
    const attrs = { strides, pad: pad2, dimRoundingMode, dilations, inputShape: xShape };
    const res = (
      // tslint:disable-next-line: no-unnecessary-type-assertion
      ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, inputs, attrs)
    );
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var depthwiseConv2dNativeBackpropInput;
  var init_depthwise_conv2d_native_backprop_input = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js"() {
      init_engine();
      init_kernel_names();
      init_operation();
      init_reshape();
      depthwiseConv2dNativeBackpropInput = op({ depthwiseConv2dNativeBackpropInput_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/fused/depthwise_conv2d.js
  function fusedDepthwiseConv2d_({ x, filter, strides, pad: pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode, bias, activation = "linear", preluActivationWeights, leakyreluAlpha }) {
    if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
      let result = depthwiseConv2d(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
      if (bias != null) {
        result = add2(result, bias);
      }
      return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
    }
    const $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
    const $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
    let x4D = $x;
    let reshapedTo4D = false;
    if ($x.rank === 3) {
      reshapedTo4D = true;
      x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    }
    assert(x4D.rank === 4, () => `Error in fused depthwiseConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
    assert($filter.rank === 4, () => `Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
    assert(x4D.shape[3] === $filter.shape[2], () => `Error in fused depthwiseConv2d: number of input channels (${x4D.shape[3]}) must match the inChannels dimension in filter ${$filter.shape[2]}.`);
    if (dilations == null) {
      dilations = [1, 1];
    }
    assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    checkPadOnDimRoundingMode("fused depthwiseConv2d", pad2, dimRoundingMode);
    const convInfo = computeConv2DInfo(
      x4D.shape,
      $filter.shape,
      strides,
      dilations,
      pad2,
      dimRoundingMode,
      true
      /* depthwise */
    );
    let $bias;
    if (bias != null) {
      $bias = convertToTensor(bias, "bias", "fused conv2d");
      [$bias] = makeTypesMatch($bias, $x);
      assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
    }
    let $preluActivationWeights;
    if (preluActivationWeights != null) {
      $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused depthwiseConv2d");
    }
    const grad = (dy, saved) => {
      assert(tupleValuesAreOne(dilations), () => `Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${dilations}'`);
      const [$filter2, x4D2, y, bias2] = saved;
      const dyActivation = getFusedDyActivation(dy, y, activation);
      const xDer = depthwiseConv2dNativeBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2, dilations, dimRoundingMode);
      const filterDer = depthwiseConv2dNativeBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2, dilations, dimRoundingMode);
      if (bias2 != null) {
        const biasDer = getFusedBiasGradient($bias, dyActivation);
        return [xDer, filterDer, biasDer];
      }
      return [xDer, filterDer];
    };
    const inputs = {
      x: x4D,
      filter: $filter,
      bias: $bias,
      preluActivationWeights: $preluActivationWeights
    };
    const attrs = {
      strides,
      pad: pad2,
      dataFormat,
      dilations,
      dimRoundingMode,
      activation,
      leakyreluAlpha
    };
    if (bias == null) {
      const customOp = customGrad((x4D2, filter2, save) => {
        let res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
        save([filter2, x4D2, res]);
        if (reshapedTo4D) {
          res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
        }
        return { value: res, gradFunc: grad };
      });
      return customOp(x4D, $filter);
    } else {
      const customOpWithBias = customGrad((x4D2, filter2, bias2, save) => {
        let res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
        save([filter2, x4D2, res, bias2]);
        if (reshapedTo4D) {
          res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
        }
        return { value: res, gradFunc: grad };
      });
      return customOpWithBias(x4D, $filter, $bias);
    }
  }
  var depthwiseConv2d2;
  var init_depthwise_conv2d2 = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/fused/depthwise_conv2d.js"() {
      init_engine();
      init_gradients();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_util();
      init_add();
      init_broadcast_util();
      init_conv_util();
      init_depthwise_conv2d();
      init_depthwise_conv2d_native_backprop_filter();
      init_depthwise_conv2d_native_backprop_input();
      init_fused_util();
      init_operation();
      init_reshape();
      depthwiseConv2d2 = /* @__PURE__ */ op({ fusedDepthwiseConv2d_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/fused/mat_mul.js
  function fusedMatMul_({ a, b, transposeA = false, transposeB = false, bias, activation = "linear", preluActivationWeights, leakyreluAlpha = 0.2 }) {
    if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
      let result = matMul(a, b, transposeA, transposeB);
      if (bias != null) {
        result = add2(result, bias);
      }
      return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
    }
    let $a = convertToTensor(a, "a", "fused matMul");
    let $b = convertToTensor(b, "b", "fused matMul");
    [$a, $b] = makeTypesMatch($a, $b);
    const innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];
    const innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];
    const outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];
    const outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];
    const outerDimsA = $a.shape.slice(0, -2);
    const outerDimsB = $b.shape.slice(0, -2);
    const batchDimA = sizeFromShape(outerDimsA);
    const batchDimB = sizeFromShape(outerDimsB);
    assert(innerShapeA === innerShapeB, () => `Error in fused matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${$a.shape} and ${$b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
    const outShapeOuterDims = assertAndGetBroadcastShape($a.shape.slice(0, -2), $b.shape.slice(0, -2));
    const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
    const a3D = transposeA ? reshape($a, [batchDimA, innerShapeA, outerShapeA]) : reshape($a, [batchDimA, outerShapeA, innerShapeA]);
    const b3D = transposeB ? reshape($b, [batchDimB, outerShapeB, innerShapeB]) : reshape($b, [batchDimB, innerShapeB, outerShapeB]);
    let $bias;
    if (bias != null) {
      $bias = convertToTensor(bias, "bias", "fused matMul");
      [$bias] = makeTypesMatch($bias, $a);
      assertAndGetBroadcastShape(outShape, $bias.shape);
    }
    let $preluActivationWeights;
    if (preluActivationWeights != null) {
      $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused matMul");
    }
    const grad = (dy, saved) => {
      const [a3D2, b3D2, y, $bias2] = saved;
      const dyActivation = getFusedDyActivation(reshape(dy, y.shape), y, activation);
      let aDer;
      let bDer;
      if (!transposeA && !transposeB) {
        aDer = matMul(dyActivation, b3D2, false, true);
        bDer = matMul(a3D2, dyActivation, true, false);
      } else if (!transposeA && transposeB) {
        aDer = matMul(dyActivation, b3D2, false, false);
        bDer = matMul(dyActivation, a3D2, true, false);
      } else if (transposeA && !transposeB) {
        aDer = matMul(b3D2, dyActivation, false, true);
        bDer = matMul(a3D2, dyActivation, false, false);
      } else {
        aDer = matMul(b3D2, dyActivation, true, true);
        bDer = matMul(dyActivation, a3D2, true, true);
      }
      if (bias != null) {
        const biasDer = getFusedBiasGradient($bias2, dyActivation);
        return [aDer, bDer, biasDer];
      } else {
        return [aDer, bDer];
      }
    };
    const inputs = {
      a: a3D,
      b: b3D,
      bias: $bias,
      preluActivationWeights: $preluActivationWeights
    };
    const attrs = { transposeA, transposeB, activation, leakyreluAlpha };
    if (bias == null) {
      const customOp = customGrad((a3D2, b3D2, save) => {
        const res = (
          // tslint:disable-next-line: no-unnecessary-type-assertion
          ENGINE.runKernel(_FusedMatMul, inputs, attrs)
        );
        save([a3D2, b3D2, res]);
        return { value: reshape(res, outShape), gradFunc: grad };
      });
      return customOp(a3D, b3D);
    } else {
      const customOpWithBias = customGrad((a3D2, b3D2, $bias2, save) => {
        const res = (
          // tslint:disable-next-line: no-unnecessary-type-assertion
          ENGINE.runKernel(_FusedMatMul, inputs, attrs)
        );
        save([a3D2, b3D2, res, $bias2]);
        return { value: reshape(res, outShape), gradFunc: grad };
      });
      return customOpWithBias(a3D, b3D, $bias);
    }
  }
  var matMul2;
  var init_mat_mul2 = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/fused/mat_mul.js"() {
      init_engine();
      init_gradients();
      init_kernel_names();
      init_tensor_util();
      init_tensor_util_env();
      init_util();
      init_add();
      init_broadcast_util();
      init_fused_util();
      init_mat_mul();
      init_operation();
      init_reshape();
      matMul2 = /* @__PURE__ */ op({ fusedMatMul_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/fused_ops.js
  var fused_ops_exports = {};
  __export(fused_ops_exports, {
    conv2d: () => conv2d2,
    depthwiseConv2d: () => depthwiseConv2d2,
    matMul: () => matMul2
  });
  var init_fused_ops = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/fused_ops.js"() {
      init_conv2d2();
      init_depthwise_conv2d2();
      init_mat_mul2();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/signal/hamming_window.js
  function hammingWindow_(windowLength) {
    return cosineWindow(windowLength, 0.54, 0.46);
  }
  var hammingWindow;
  var init_hamming_window = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/signal/hamming_window.js"() {
      init_operation();
      init_signal_ops_util();
      hammingWindow = /* @__PURE__ */ op({ hammingWindow_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/signal/hann_window.js
  function hannWindow_(windowLength) {
    return cosineWindow(windowLength, 0.5, 0.5);
  }
  var hannWindow;
  var init_hann_window = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/signal/hann_window.js"() {
      init_operation();
      init_signal_ops_util();
      hannWindow = /* @__PURE__ */ op({ hannWindow_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/signal/frame.js
  function frame_(signal2, frameLength, frameStep, padEnd = false, padValue = 0) {
    let start = 0;
    const output = [];
    while (start + frameLength <= signal2.size) {
      output.push(slice(signal2, start, frameLength));
      start += frameStep;
    }
    if (padEnd) {
      while (start < signal2.size) {
        const padLen = start + frameLength - signal2.size;
        const pad2 = concat([
          slice(signal2, start, frameLength - padLen),
          fill([padLen], padValue)
        ]);
        output.push(pad2);
        start += frameStep;
      }
    }
    if (output.length === 0) {
      return tensor2d([], [0, frameLength]);
    }
    return reshape(concat(output), [output.length, frameLength]);
  }
  var frame;
  var init_frame = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/signal/frame.js"() {
      init_concat();
      init_fill();
      init_operation();
      init_reshape();
      init_slice();
      init_tensor2d();
      frame = /* @__PURE__ */ op({ frame_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/signal/stft.js
  function stft_(signal2, frameLength, frameStep, fftLength, windowFn = hannWindow) {
    if (fftLength == null) {
      fftLength = enclosingPowerOfTwo(frameLength);
    }
    const framedSignal = frame(signal2, frameLength, frameStep);
    const windowedSignal = mul(framedSignal, windowFn(frameLength));
    return rfft(windowedSignal, fftLength);
  }
  var stft;
  var init_stft = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/signal/stft.js"() {
      init_mul();
      init_operation();
      init_signal_ops_util();
      init_rfft();
      init_frame();
      init_hann_window();
      stft = /* @__PURE__ */ op({ stft_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/crop_and_resize.js
  function cropAndResize_(image2, boxes, boxInd, cropSize, method = "bilinear", extrapolationValue = 0) {
    const $image = convertToTensor(image2, "image", "cropAndResize");
    const $boxes = convertToTensor(boxes, "boxes", "cropAndResize", "float32");
    const $boxInd = convertToTensor(boxInd, "boxInd", "cropAndResize", "int32");
    const numBoxes = $boxes.shape[0];
    assert($image.rank === 4, () => `Error in cropAndResize: image must be rank 4,but got rank ${$image.rank}.`);
    assert($boxes.rank === 2 && $boxes.shape[1] === 4, () => `Error in cropAndResize: boxes must be have size [${numBoxes},4] but had shape ${$boxes.shape}.`);
    assert($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, () => `Error in cropAndResize: boxInd must be have size [${numBoxes}] but had shape ${$boxes.shape}.`);
    assert(cropSize.length === 2, () => `Error in cropAndResize: cropSize must be of length 2, but got length ${cropSize.length}.`);
    assert(cropSize[0] >= 1 && cropSize[1] >= 1, () => `cropSize must be atleast [1,1], but was ${cropSize}`);
    assert(method === "bilinear" || method === "nearest", () => `method must be bilinear or nearest, but was ${method}`);
    const inputs = { image: $image, boxes: $boxes, boxInd: $boxInd };
    const attrs = { method, extrapolationValue, cropSize };
    const res = ENGINE.runKernel(CropAndResize, inputs, attrs);
    return res;
  }
  var cropAndResize;
  var init_crop_and_resize = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/crop_and_resize.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      cropAndResize = /* @__PURE__ */ op({ cropAndResize_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/flip_left_right.js
  function flipLeftRight_(image2) {
    const $image = convertToTensor(image2, "image", "flipLeftRight", "float32");
    assert($image.rank === 4, () => `Error in flipLeftRight: image must be rank 4,but got rank ${$image.rank}.`);
    const inputs = { image: $image };
    const res = ENGINE.runKernel(FlipLeftRight, inputs, {});
    return res;
  }
  var flipLeftRight;
  var init_flip_left_right = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/flip_left_right.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      flipLeftRight = /* @__PURE__ */ op({ flipLeftRight_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/grayscale_to_rgb.js
  function grayscaleToRGB_(image2) {
    const $image = convertToTensor(image2, "image", "grayscaleToRGB");
    const lastDimsIdx = $image.rank - 1;
    const lastDims = $image.shape[lastDimsIdx];
    assert($image.rank >= 2, () => `Error in grayscaleToRGB: images must be at least rank 2, but got rank ${$image.rank}.`);
    assert(lastDims === 1, () => `Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size ${lastDims}.`);
    const reps = new Array($image.rank);
    reps.fill(1, 0, lastDimsIdx);
    reps[lastDimsIdx] = 3;
    return tile($image, reps);
  }
  var grayscaleToRGB;
  var init_grayscale_to_rgb = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/grayscale_to_rgb.js"() {
      init_tensor_util_env();
      init_util();
      init_operation();
      init_tile();
      grayscaleToRGB = /* @__PURE__ */ op({ grayscaleToRGB_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/rotate_with_offset.js
  function rotateWithOffset_(image2, radians, fillValue = 0, center = 0.5) {
    const $image = convertToTensor(image2, "image", "rotateWithOffset", "float32");
    assert($image.rank === 4, () => `Error in rotateWithOffset: image must be rank 4,but got rank ${$image.rank}.`);
    const inputs = { image: $image };
    const attrs = { radians, fillValue, center };
    const res = ENGINE.runKernel(RotateWithOffset, inputs, attrs);
    return res;
  }
  var rotateWithOffset;
  var init_rotate_with_offset = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/rotate_with_offset.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      rotateWithOffset = /* @__PURE__ */ op({ rotateWithOffset_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/nonmax_util.js
  function nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
    if (iouThreshold == null) {
      iouThreshold = 0.5;
    }
    if (scoreThreshold == null) {
      scoreThreshold = Number.NEGATIVE_INFINITY;
    }
    if (softNmsSigma == null) {
      softNmsSigma = 0;
    }
    const numBoxes = boxes.shape[0];
    maxOutputSize = Math.min(maxOutputSize, numBoxes);
    assert(0 <= iouThreshold && iouThreshold <= 1, () => `iouThreshold must be in [0, 1], but was '${iouThreshold}'`);
    assert(boxes.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${boxes.rank}'`);
    assert(boxes.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`);
    assert(scores.rank === 1, () => "scores must be a 1D tensor");
    assert(scores.shape[0] === numBoxes, () => `scores has incompatible shape with boxes. Expected ${numBoxes}, but was ${scores.shape[0]}`);
    assert(0 <= softNmsSigma && softNmsSigma <= 1, () => `softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`);
    return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
  }
  var init_nonmax_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/nonmax_util.js"() {
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression.js
  function nonMaxSuppression_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {
    const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression", "float32");
    const $scores = convertToTensor(scores, "scores", "nonMaxSuppression", "float32");
    const inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
    maxOutputSize = inputs.maxOutputSize;
    iouThreshold = inputs.iouThreshold;
    scoreThreshold = inputs.scoreThreshold;
    const attrs = { maxOutputSize, iouThreshold, scoreThreshold };
    return ENGINE.runKernel(NonMaxSuppressionV3, { boxes: $boxes, scores: $scores }, attrs);
  }
  var nonMaxSuppression;
  var init_non_max_suppression = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_nonmax_util();
      init_operation();
      nonMaxSuppression = /* @__PURE__ */ op({ nonMaxSuppression_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js
  function binaryInsert(arr, element, comparator) {
    const index = binarySearch(arr, element, comparator);
    const insertionPoint = index < 0 ? -(index + 1) : index;
    arr.splice(insertionPoint, 0, element);
  }
  function binarySearch(arr, target, comparator) {
    return binarySearch_(arr, target, comparator || defaultComparator);
  }
  function defaultComparator(a, b) {
    return a > b ? 1 : a < b ? -1 : 0;
  }
  function binarySearch_(arr, target, comparator) {
    let left = 0;
    let right = arr.length;
    let middle = 0;
    let found = false;
    while (left < right) {
      middle = left + (right - left >>> 1);
      const compareResult = comparator(target, arr[middle]);
      if (compareResult > 0) {
        left = middle + 1;
      } else {
        right = middle;
        found = !compareResult;
      }
    }
    return found ? left : -left - 1;
  }
  var init_non_max_suppression_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js
  function nonMaxSuppressionV3Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
    return nonMaxSuppressionImpl_(
      boxes,
      scores,
      maxOutputSize,
      iouThreshold,
      scoreThreshold,
      0
      /* softNmsSigma */
    );
  }
  function nonMaxSuppressionV4Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
    return nonMaxSuppressionImpl_(
      boxes,
      scores,
      maxOutputSize,
      iouThreshold,
      scoreThreshold,
      0,
      false,
      padToMaxOutputSize,
      true
      /* returnValidOutputs */
    );
  }
  function nonMaxSuppressionV5Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
    return nonMaxSuppressionImpl_(
      boxes,
      scores,
      maxOutputSize,
      iouThreshold,
      scoreThreshold,
      softNmsSigma,
      true
      /* returnScoresTensor */
    );
  }
  function nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor = false, padToMaxOutputSize = false, returnValidOutputs = false) {
    const candidates = [];
    for (let i = 0; i < scores.length; i++) {
      if (scores[i] > scoreThreshold) {
        candidates.push({ score: scores[i], boxIndex: i, suppressBeginIndex: 0 });
      }
    }
    candidates.sort(ascendingComparator);
    const scale2 = softNmsSigma > 0 ? -0.5 / softNmsSigma : 0;
    const selectedIndices = [];
    const selectedScores = [];
    while (selectedIndices.length < maxOutputSize && candidates.length > 0) {
      const candidate = candidates.pop();
      const { score: originalScore, boxIndex, suppressBeginIndex } = candidate;
      if (originalScore < scoreThreshold) {
        break;
      }
      let ignoreCandidate = false;
      for (let j2 = selectedIndices.length - 1; j2 >= suppressBeginIndex; --j2) {
        const iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j2]);
        if (iou >= iouThreshold) {
          ignoreCandidate = true;
          break;
        }
        candidate.score = candidate.score * suppressWeight(iouThreshold, scale2, iou);
        if (candidate.score <= scoreThreshold) {
          break;
        }
      }
      candidate.suppressBeginIndex = selectedIndices.length;
      if (!ignoreCandidate) {
        if (candidate.score === originalScore) {
          selectedIndices.push(boxIndex);
          selectedScores.push(candidate.score);
        } else if (candidate.score > scoreThreshold) {
          binaryInsert(candidates, candidate, ascendingComparator);
        }
      }
    }
    const validOutputs = selectedIndices.length;
    const elemsToPad = maxOutputSize - validOutputs;
    if (padToMaxOutputSize && elemsToPad > 0) {
      selectedIndices.push(...new Array(elemsToPad).fill(0));
      selectedScores.push(...new Array(elemsToPad).fill(0));
    }
    const result = { selectedIndices };
    if (returnScoresTensor) {
      result["selectedScores"] = selectedScores;
    }
    if (returnValidOutputs) {
      result["validOutputs"] = validOutputs;
    }
    return result;
  }
  function intersectionOverUnion(boxes, i, j2) {
    const iCoord = boxes.subarray(i * 4, i * 4 + 4);
    const jCoord = boxes.subarray(j2 * 4, j2 * 4 + 4);
    const yminI = Math.min(iCoord[0], iCoord[2]);
    const xminI = Math.min(iCoord[1], iCoord[3]);
    const ymaxI = Math.max(iCoord[0], iCoord[2]);
    const xmaxI = Math.max(iCoord[1], iCoord[3]);
    const yminJ = Math.min(jCoord[0], jCoord[2]);
    const xminJ = Math.min(jCoord[1], jCoord[3]);
    const ymaxJ = Math.max(jCoord[0], jCoord[2]);
    const xmaxJ = Math.max(jCoord[1], jCoord[3]);
    const areaI = (ymaxI - yminI) * (xmaxI - xminI);
    const areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);
    if (areaI <= 0 || areaJ <= 0) {
      return 0;
    }
    const intersectionYmin = Math.max(yminI, yminJ);
    const intersectionXmin = Math.max(xminI, xminJ);
    const intersectionYmax = Math.min(ymaxI, ymaxJ);
    const intersectionXmax = Math.min(xmaxI, xmaxJ);
    const intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0) * Math.max(intersectionXmax - intersectionXmin, 0);
    return intersectionArea / (areaI + areaJ - intersectionArea);
  }
  function suppressWeight(iouThreshold, scale2, iou) {
    const weight = Math.exp(scale2 * iou * iou);
    return iou <= iouThreshold ? weight : 0;
  }
  function ascendingComparator(c1, c2) {
    return c1.score - c2.score || c1.score === c2.score && c2.boxIndex - c1.boxIndex;
  }
  var init_non_max_suppression_impl = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js"() {
      init_non_max_suppression_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_async.js
  function nonMaxSuppressionAsync_(_0, _1, _2) {
    return __async(this, arguments, function* (boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {
      const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
      const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
      const inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
      maxOutputSize = inputs.maxOutputSize;
      iouThreshold = inputs.iouThreshold;
      scoreThreshold = inputs.scoreThreshold;
      const boxesAndScores = yield Promise.all([$boxes.data(), $scores.data()]);
      const boxesVals = boxesAndScores[0];
      const scoresVals = boxesAndScores[1];
      const { selectedIndices } = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
      if ($boxes !== boxes) {
        $boxes.dispose();
      }
      if ($scores !== scores) {
        $scores.dispose();
      }
      return tensor1d(selectedIndices, "int32");
    });
  }
  var nonMaxSuppressionAsync;
  var init_non_max_suppression_async = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_async.js"() {
      init_non_max_suppression_impl();
      init_tensor_util_env();
      init_nonmax_util();
      init_tensor1d();
      nonMaxSuppressionAsync = nonMaxSuppressionAsync_;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score.js
  function nonMaxSuppressionWithScore_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0) {
    const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
    const $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
    const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
    maxOutputSize = params.maxOutputSize;
    iouThreshold = params.iouThreshold;
    scoreThreshold = params.scoreThreshold;
    softNmsSigma = params.softNmsSigma;
    const inputs = { boxes: $boxes, scores: $scores };
    const attrs = { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
    const result = ENGINE.runKernel(NonMaxSuppressionV5, inputs, attrs);
    return { selectedIndices: result[0], selectedScores: result[1] };
  }
  var nonMaxSuppressionWithScore;
  var init_non_max_suppression_with_score = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_nonmax_util();
      init_operation();
      nonMaxSuppressionWithScore = /* @__PURE__ */ op({ nonMaxSuppressionWithScore_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score_async.js
  function nonMaxSuppressionWithScoreAsync_(_0, _1, _2) {
    return __async(this, arguments, function* (boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0) {
      const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
      const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
      const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
      maxOutputSize = params.maxOutputSize;
      iouThreshold = params.iouThreshold;
      scoreThreshold = params.scoreThreshold;
      softNmsSigma = params.softNmsSigma;
      const boxesAndScores = yield Promise.all([$boxes.data(), $scores.data()]);
      const boxesVals = boxesAndScores[0];
      const scoresVals = boxesAndScores[1];
      const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
      if ($boxes !== boxes) {
        $boxes.dispose();
      }
      if ($scores !== scores) {
        $scores.dispose();
      }
      return {
        selectedIndices: tensor1d(selectedIndices, "int32"),
        selectedScores: tensor1d(selectedScores)
      };
    });
  }
  var nonMaxSuppressionWithScoreAsync;
  var init_non_max_suppression_with_score_async = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score_async.js"() {
      init_non_max_suppression_impl();
      init_tensor_util_env();
      init_nonmax_util();
      init_tensor1d();
      nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded.js
  function nonMaxSuppressionPadded_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {
    const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
    const $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
    const params = nonMaxSuppSanityCheck(
      $boxes,
      $scores,
      maxOutputSize,
      iouThreshold,
      scoreThreshold,
      null
      /* softNmsSigma */
    );
    const $maxOutputSize = params.maxOutputSize;
    const $iouThreshold = params.iouThreshold;
    const $scoreThreshold = params.scoreThreshold;
    const inputs = { boxes: $boxes, scores: $scores };
    const attrs = {
      maxOutputSize: $maxOutputSize,
      iouThreshold: $iouThreshold,
      scoreThreshold: $scoreThreshold,
      padToMaxOutputSize
    };
    const result = ENGINE.runKernel(NonMaxSuppressionV4, inputs, attrs);
    return { selectedIndices: result[0], validOutputs: result[1] };
  }
  var nonMaxSuppressionPadded;
  var init_non_max_suppression_padded = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_nonmax_util();
      init_operation();
      nonMaxSuppressionPadded = /* @__PURE__ */ op({ nonMaxSuppressionPadded_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded_async.js
  function nonMaxSuppressionPaddedAsync_(_0, _1, _2) {
    return __async(this, arguments, function* (boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {
      const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
      const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
      const params = nonMaxSuppSanityCheck(
        $boxes,
        $scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        null
        /* softNmsSigma */
      );
      const $maxOutputSize = params.maxOutputSize;
      const $iouThreshold = params.iouThreshold;
      const $scoreThreshold = params.scoreThreshold;
      const [boxesVals, scoresVals] = yield Promise.all([$boxes.data(), $scores.data()]);
      const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl(boxesVals, scoresVals, $maxOutputSize, $iouThreshold, $scoreThreshold, padToMaxOutputSize);
      if ($boxes !== boxes) {
        $boxes.dispose();
      }
      if ($scores !== scores) {
        $scores.dispose();
      }
      return {
        selectedIndices: tensor1d(selectedIndices, "int32"),
        validOutputs: scalar(validOutputs, "int32")
      };
    });
  }
  var nonMaxSuppressionPaddedAsync;
  var init_non_max_suppression_padded_async = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded_async.js"() {
      init_non_max_suppression_impl();
      init_tensor_util_env();
      init_nonmax_util();
      init_scalar();
      init_tensor1d();
      nonMaxSuppressionPaddedAsync = nonMaxSuppressionPaddedAsync_;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js
  function resizeBilinear_(images, size, alignCorners = false, halfPixelCenters = false) {
    const $images = convertToTensor(images, "images", "resizeBilinear");
    assert($images.rank === 3 || $images.rank === 4, () => `Error in resizeBilinear: x must be rank 3 or 4, but got rank ${$images.rank}.`);
    assert(size.length === 2, () => `Error in resizeBilinear: new shape must 2D, but got shape ${size}.`);
    assert(halfPixelCenters === false || alignCorners === false, () => `Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.`);
    let batchImages = $images;
    let reshapedTo4D = false;
    if ($images.rank === 3) {
      reshapedTo4D = true;
      batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
    }
    const [] = size;
    const inputs = { images: batchImages };
    const attrs = { alignCorners, halfPixelCenters, size };
    const res = ENGINE.runKernel(ResizeBilinear, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var resizeBilinear;
  var init_resize_bilinear = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      init_reshape();
      resizeBilinear = /* @__PURE__ */ op({ resizeBilinear_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js
  function resizeNearestNeighbor_(images, size, alignCorners = false, halfPixelCenters = false) {
    const $images = convertToTensor(images, "images", "resizeNearestNeighbor");
    assert($images.rank === 3 || $images.rank === 4, () => `Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${$images.rank}.`);
    assert(size.length === 2, () => `Error in resizeNearestNeighbor: new shape must 2D, but got shape ${size}.`);
    assert($images.dtype === "float32" || $images.dtype === "int32", () => "`images` must have `int32` or `float32` as dtype");
    assert(halfPixelCenters === false || alignCorners === false, () => `Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.`);
    let batchImages = $images;
    let reshapedTo4D = false;
    if ($images.rank === 3) {
      reshapedTo4D = true;
      batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
    }
    const [] = size;
    const inputs = { images: batchImages };
    const attrs = { alignCorners, halfPixelCenters, size };
    const res = ENGINE.runKernel(ResizeNearestNeighbor, inputs, attrs);
    if (reshapedTo4D) {
      return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
    }
    return res;
  }
  var resizeNearestNeighbor;
  var init_resize_nearest_neighbor = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      init_reshape();
      resizeNearestNeighbor = /* @__PURE__ */ op({ resizeNearestNeighbor_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/threshold.js
  function threshold_(image2, method = "binary", inverted = false, threshValue = 0.5) {
    const $image = convertToTensor(image2, "image", "threshold");
    const RED_INTENCITY_COEF = 0.2989;
    const GREEN_INTENCITY_COEF = 0.587;
    const BLUE_INTENCITY_COEF = 0.114;
    const totalPixelsInImage = $image.shape[0] * $image.shape[1];
    let $threshold = mul(tensor1d([threshValue]), 255);
    let r, g, b, grayscale;
    assert($image.rank === 3, () => `Error in threshold: image must be rank 3,but got rank ${$image.rank}.`);
    assert($image.shape[2] === 3 || $image.shape[2] === 1, () => `Error in threshold: image color channel must be equal to 3 or 1but got ${$image.shape[2]}.`);
    assert($image.dtype === "int32" || $image.dtype === "float32", () => `Error in dtype: image dtype must be int32 or float32,but got dtype ${$image.dtype}.`);
    assert(method === "otsu" || method === "binary", () => `Method must be binary or otsu, but was ${method}`);
    if ($image.shape[2] === 3) {
      [r, g, b] = split($image, [1, 1, 1], -1);
      const $r = mul(r, RED_INTENCITY_COEF);
      const $g = mul(g, GREEN_INTENCITY_COEF);
      const $b = mul(b, BLUE_INTENCITY_COEF);
      grayscale = add2(add2($r, $g), $b);
    } else {
      grayscale = image2;
    }
    if (method === "otsu") {
      const $histogram = bincount(cast(round2(grayscale), "int32"), tensor([]), 256);
      $threshold = otsu($histogram, totalPixelsInImage);
    }
    const invCondition = inverted ? lessEqual(grayscale, $threshold) : greater(grayscale, $threshold);
    const result = cast(mul(invCondition, 255), "int32");
    return result;
  }
  function otsu(histogram, total) {
    let bestThresh = tensor1d([-1]);
    let bestInBetVar = tensor1d([0]);
    let cInBetVar = tensor1d([0]);
    let classFirst, classSecond, meanFirst, meanSec, weightForeground, weightBack;
    for (let index = 0; index < histogram.size - 1; index++) {
      classFirst = slice(histogram, 0, index + 1);
      classSecond = slice(histogram, index + 1);
      weightForeground = div(sum2(classFirst), total);
      weightBack = div(sum2(classSecond), total);
      const meanFirstDivA = sum2(mul(classFirst, range(0, classFirst.size)));
      meanFirst = div(meanFirstDivA, sum2(classFirst));
      const meanSecFill = fill(classSecond.shape, classFirst.size);
      const meanSecAdd = add2(range(0, classSecond.size), meanSecFill);
      const meanSecMul = mul(classSecond, meanSecAdd);
      meanSec = div(sum2(meanSecMul), sum2(classSecond));
      const cInBetVarSubA = sub(meanFirst, meanSec);
      const cInBetVarSubB = sub(meanFirst, meanSec);
      const cInBetVarMul = mul(weightForeground, weightBack);
      cInBetVar = mul(mul(cInBetVarMul, cInBetVarSubA), cInBetVarSubB);
      const condition = greater(cInBetVar, bestInBetVar);
      bestInBetVar = where(condition, cInBetVar, bestInBetVar);
      bestThresh = where(condition, tensor1d([index]), bestThresh);
    }
    return bestThresh;
  }
  var threshold;
  var init_threshold = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/threshold.js"() {
      init_tensor1d();
      init_operation();
      init_cast();
      init_split();
      init_bincount();
      init_less_equal();
      init_greater();
      init_sum();
      init_add();
      init_mul();
      init_div();
      init_sub();
      init_round();
      init_where();
      init_fill();
      init_slice();
      init_range();
      init_tensor2();
      init_util();
      init_tensor_util_env();
      threshold = /* @__PURE__ */ op({ threshold_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/image/transform.js
  function transform_(image2, transforms, interpolation = "nearest", fillMode = "constant", fillValue = 0, outputShape) {
    const $image = convertToTensor(image2, "image", "transform", "float32");
    const $transforms = convertToTensor(transforms, "transforms", "transform", "float32");
    assert($image.rank === 4, () => `Error in transform: image must be rank 4,but got rank ${$image.rank}.`);
    assert($transforms.rank === 2 && ($transforms.shape[0] === $image.shape[0] || $transforms.shape[0] === 1) && $transforms.shape[1] === 8, () => `Error in transform: Input transform should be batch x 8 or 1 x 8`);
    assert(outputShape == null || outputShape.length === 2, () => `Error in transform: outputShape must be [height, width] or null, but got ${outputShape}.`);
    const inputs = { image: $image, transforms: $transforms };
    const attrs = { interpolation, fillMode, fillValue, outputShape };
    return ENGINE.runKernel(Transform, inputs, attrs);
  }
  var transform;
  var init_transform = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/image/transform.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_util();
      init_operation();
      transform = /* @__PURE__ */ op({ transform_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/linalg/band_part.js
  function bandPart_(a, numLower, numUpper) {
    assert(numLower % 1 === 0, () => `bandPart(): numLower must be an integer, got ${numLower}.`);
    assert(numUpper % 1 === 0, () => `bandPart(): numUpper must be an integer, got ${numUpper}.`);
    const $a = convertToTensor(a, "a", "bandPart");
    assert($a.rank >= 2, () => `bandPart(): Rank must be at least 2, got ${$a.rank}.`);
    const shape = $a.shape;
    const [M, N2] = $a.shape.slice(-2);
    if (!(numLower <= M)) {
      throw new Error(`bandPart(): numLower (${numLower}) must not be greater than the number of rows (${M}).`);
    }
    if (!(numUpper <= N2)) {
      throw new Error(`bandPart(): numUpper (${numUpper}) must not be greater than the number of columns (${N2}).`);
    }
    if (numLower < 0) {
      numLower = M;
    }
    if (numUpper < 0) {
      numUpper = N2;
    }
    const i = reshape(range(0, M, 1, "int32"), [-1, 1]);
    const j2 = range(0, N2, 1, "int32");
    const ij = sub(i, j2);
    const inBand = logicalAnd(lessEqual(ij, scalar(+numLower, "int32")), greaterEqual(ij, scalar(-numUpper, "int32")));
    const zero = zeros([M, N2], $a.dtype);
    return reshape(stack(unstack(reshape($a, [-1, M, N2])).map((mat) => where(inBand, mat, zero))), shape);
  }
  var bandPart;
  var init_band_part = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/linalg/band_part.js"() {
      init_tensor_util_env();
      init_util();
      init_greater_equal();
      init_less_equal();
      init_logical_and();
      init_operation();
      init_range();
      init_reshape();
      init_scalar();
      init_stack();
      init_sub();
      init_unstack();
      init_where();
      init_zeros();
      bandPart = /* @__PURE__ */ op({ bandPart_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/linalg/gram_schmidt.js
  function gramSchmidt_(xs) {
    let inputIsTensor2D;
    if (Array.isArray(xs)) {
      inputIsTensor2D = false;
      assert(xs != null && xs.length > 0, () => "Gram-Schmidt process: input must not be null, undefined, or empty");
      const dim = xs[0].shape[0];
      for (let i = 1; i < xs.length; ++i) {
        assert(xs[i].shape[0] === dim, () => `Gram-Schmidt: Non-unique lengths found in the input vectors: (${xs[i].shape[0]} vs. ${dim})`);
      }
    } else {
      inputIsTensor2D = true;
      xs = split(xs, xs.shape[0], 0).map((x) => squeeze(x, [0]));
    }
    assert(xs.length <= xs[0].shape[0], () => `Gram-Schmidt: Number of vectors (${xs.length}) exceeds number of dimensions (${xs[0].shape[0]}).`);
    const ys = [];
    const xs1d = xs;
    for (let i = 0; i < xs.length; ++i) {
      ys.push(ENGINE.tidy(() => {
        let x = xs1d[i];
        if (i > 0) {
          for (let j2 = 0; j2 < i; ++j2) {
            const proj = mul(sum2(mul(ys[j2], x)), ys[j2]);
            x = sub(x, proj);
          }
        }
        return div(x, norm(x, "euclidean"));
      }));
    }
    if (inputIsTensor2D) {
      return stack(ys, 0);
    } else {
      return ys;
    }
  }
  var gramSchmidt;
  var init_gram_schmidt = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/linalg/gram_schmidt.js"() {
      init_engine();
      init_util();
      init_div();
      init_mul();
      init_norm();
      init_operation();
      init_split();
      init_squeeze();
      init_stack();
      init_sub();
      init_sum();
      gramSchmidt = /* @__PURE__ */ op({ gramSchmidt_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/linalg/qr.js
  function qr_(x, fullMatrices = false) {
    assert(x.rank >= 2, () => `qr() requires input tensor to have a rank >= 2, but got rank ${x.rank}`);
    if (x.rank === 2) {
      return qr2d(x, fullMatrices);
    } else {
      const outerDimsProd = x.shape.slice(0, x.shape.length - 2).reduce((value, prev) => value * prev);
      const x2ds = unstack(reshape(x, [
        outerDimsProd,
        x.shape[x.shape.length - 2],
        x.shape[x.shape.length - 1]
      ]), 0);
      const q2ds = [];
      const r2ds = [];
      x2ds.forEach((x2d) => {
        const [q2d, r2d] = qr2d(x2d, fullMatrices);
        q2ds.push(q2d);
        r2ds.push(r2d);
      });
      const q2 = reshape(stack(q2ds, 0), x.shape);
      const r = reshape(stack(r2ds, 0), x.shape);
      return [q2, r];
    }
  }
  function qr2d(x, fullMatrices = false) {
    return ENGINE.tidy(() => {
      assert(x.shape.length === 2, () => `qr2d() requires a 2D Tensor, but got a ${x.shape.length}D Tensor.`);
      const m = x.shape[0];
      const n = x.shape[1];
      let q2 = eye(m);
      let r = clone(x);
      const one2D = tensor2d([[1]], [1, 1]);
      let w = clone(one2D);
      const iters = m >= n ? n : m;
      for (let j2 = 0; j2 < iters; ++j2) {
        const rTemp = r;
        const wTemp = w;
        const qTemp = q2;
        [w, r, q2] = ENGINE.tidy(() => {
          const rjEnd1 = slice(r, [j2, j2], [m - j2, 1]);
          const normX = norm(rjEnd1);
          const rjj = slice(r, [j2, j2], [1, 1]);
          const s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));
          const u1 = sub(rjj, mul(s, normX));
          const wPre = div(rjEnd1, u1);
          if (wPre.shape[0] === 1) {
            w = clone(one2D);
          } else {
            w = concat([
              one2D,
              slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])
            ], 0);
          }
          const tau = neg(div(matMul(s, u1), normX));
          const rjEndAll = slice(r, [j2, 0], [m - j2, n]);
          const tauTimesW = mul(tau, w);
          const wT = transpose(w);
          if (j2 === 0) {
            r = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));
          } else {
            const rTimesTau = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));
            r = concat([slice(r, [0, 0], [j2, n]), rTimesTau], 0);
          }
          const tawTimesWT = transpose(tauTimesW);
          const qAllJEnd = slice(q2, [0, j2], [m, q2.shape[1] - j2]);
          if (j2 === 0) {
            q2 = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));
          } else {
            const qTimesTau = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));
            q2 = concat([slice(q2, [0, 0], [m, j2]), qTimesTau], 1);
          }
          return [w, r, q2];
        });
        dispose([rTemp, wTemp, qTemp]);
      }
      if (!fullMatrices && m > n) {
        q2 = slice(q2, [0, 0], [m, n]);
        r = slice(r, [0, 0], [n, n]);
      }
      return [q2, r];
    });
  }
  var qr;
  var init_qr = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/linalg/qr.js"() {
      init_engine();
      init_globals();
      init_util();
      init_clone();
      init_concat();
      init_div();
      init_eye();
      init_greater();
      init_mat_mul();
      init_mul();
      init_neg();
      init_norm();
      init_operation();
      init_reshape();
      init_slice();
      init_stack();
      init_sub();
      init_tensor2d();
      init_transpose();
      init_unstack();
      init_where();
      qr = /* @__PURE__ */ op({ qr_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/loss_ops_utils.js
  var Reduction;
  var init_loss_ops_utils = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/loss_ops_utils.js"() {
      (function(Reduction2) {
        Reduction2[Reduction2["NONE"] = 0] = "NONE";
        Reduction2[Reduction2["MEAN"] = 1] = "MEAN";
        Reduction2[Reduction2["SUM"] = 2] = "SUM";
        Reduction2[Reduction2["SUM_BY_NONZERO_WEIGHTS"] = 3] = "SUM_BY_NONZERO_WEIGHTS";
      })(Reduction || (Reduction = {}));
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/losses/compute_weighted_loss.js
  function computeWeightedLoss_(losses2, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
    const $losses = convertToTensor(losses2, "losses", "computeWeightedLoss");
    let $weights = null;
    if (weights != null) {
      $weights = convertToTensor(weights, "weights", "computeWeightedLoss");
    }
    const weightedLoss = $weights == null ? $losses : mul($losses, $weights);
    if (reduction === Reduction.NONE) {
      return weightedLoss;
    }
    if (reduction === Reduction.SUM) {
      return sum2(weightedLoss);
    }
    if (reduction === Reduction.MEAN) {
      if ($weights == null) {
        return mean(weightedLoss);
      } else {
        const broadcastFactor = $losses.size / $weights.size;
        const result = div(sum2(weightedLoss), sum2($weights));
        return broadcastFactor > 1 ? div(result, scalar(broadcastFactor)) : result;
      }
    }
    if (reduction === Reduction.SUM_BY_NONZERO_WEIGHTS) {
      if ($weights == null) {
        return div(sum2(weightedLoss), scalar($losses.size));
      } else {
        const broadcastedWeights = mul($weights, ones2($losses.shape));
        const numNonZeros = cast(sum2(notEqual(broadcastedWeights, scalar(0))), "float32");
        return div(sum2(weightedLoss), numNonZeros);
      }
    }
    throw Error(`Unknown reduction: ${reduction}`);
  }
  var computeWeightedLoss;
  var init_compute_weighted_loss = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/losses/compute_weighted_loss.js"() {
      init_tensor_util_env();
      init_cast();
      init_div();
      init_loss_ops_utils();
      init_mean();
      init_mul();
      init_not_equal();
      init_ones();
      init_operation();
      init_scalar();
      init_sum();
      computeWeightedLoss = /* @__PURE__ */ op({ computeWeightedLoss_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/losses/absolute_difference.js
  function absoluteDifference_(labels, predictions, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
    const $labels = convertToTensor(labels, "labels", "absoluteDifference");
    const $predictions = convertToTensor(predictions, "predictions", "absoluteDifference");
    let $weights = null;
    if (weights != null) {
      $weights = convertToTensor(weights, "weights", "absoluteDifference");
    }
    assertShapesMatch($labels.shape, $predictions.shape, "Error in absoluteDifference: ");
    const losses2 = abs(sub($labels, $predictions));
    return computeWeightedLoss(losses2, $weights, reduction);
  }
  var absoluteDifference;
  var init_absolute_difference = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/losses/absolute_difference.js"() {
      init_tensor_util_env();
      init_util();
      init_abs();
      init_loss_ops_utils();
      init_operation();
      init_sub();
      init_compute_weighted_loss();
      absoluteDifference = /* @__PURE__ */ op({ absoluteDifference_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/losses/cosine_distance.js
  function cosineDistance_(labels, predictions, axis, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
    const $labels = convertToTensor(labels, "labels", "cosineDistance");
    const $predictions = convertToTensor(predictions, "predictions", "cosineDistance");
    let $weights = null;
    if (weights != null) {
      $weights = convertToTensor(weights, "weights", "cosineDistance");
    }
    assertShapesMatch($labels.shape, $predictions.shape, "Error in cosineDistance: ");
    const one = scalar(1);
    const losses2 = sub(one, sum2(mul($labels, $predictions), axis, true));
    return computeWeightedLoss(losses2, $weights, reduction);
  }
  var cosineDistance;
  var init_cosine_distance = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/losses/cosine_distance.js"() {
      init_tensor_util_env();
      init_util();
      init_loss_ops_utils();
      init_mul();
      init_operation();
      init_scalar();
      init_sub();
      init_sum();
      init_compute_weighted_loss();
      cosineDistance = /* @__PURE__ */ op({ cosineDistance_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/losses/hinge_loss.js
  function hingeLoss_(labels, predictions, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
    let $labels = convertToTensor(labels, "labels", "hingeLoss");
    const $predictions = convertToTensor(predictions, "predictions", "hingeLoss");
    let $weights = null;
    if (weights != null) {
      $weights = convertToTensor(weights, "weights", "hingeLoss");
    }
    assertShapesMatch($labels.shape, $predictions.shape, "Error in hingeLoss: ");
    const one = scalar(1);
    $labels = sub(mul(scalar(2), $labels), one);
    const losses2 = relu(sub(one, mul($labels, $predictions)));
    return computeWeightedLoss(losses2, $weights, reduction);
  }
  var hingeLoss;
  var init_hinge_loss = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/losses/hinge_loss.js"() {
      init_tensor_util_env();
      init_util();
      init_loss_ops_utils();
      init_mul();
      init_operation();
      init_relu();
      init_scalar();
      init_sub();
      init_compute_weighted_loss();
      hingeLoss = /* @__PURE__ */ op({ hingeLoss_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/losses/huber_loss.js
  function huberLoss_(labels, predictions, weights, delta = 1, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
    const $labels = convertToTensor(labels, "labels", "huberLoss");
    const $predictions = convertToTensor(predictions, "predictions", "huberLoss");
    let $weights = null;
    if (weights != null) {
      $weights = convertToTensor(weights, "weights", "huberLoss");
    }
    assertShapesMatch($labels.shape, $predictions.shape, "Error in huberLoss: ");
    const deltaScalar = scalar(delta);
    const error = abs(sub($predictions, $labels));
    const quadratic = minimum(error, deltaScalar);
    const linear = sub(error, quadratic);
    const losses2 = add2(mul(scalar(0.5), square(quadratic)), mul(deltaScalar, linear));
    return computeWeightedLoss(losses2, $weights, reduction);
  }
  var huberLoss;
  var init_huber_loss = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/losses/huber_loss.js"() {
      init_tensor_util_env();
      init_util();
      init_abs();
      init_add();
      init_loss_ops_utils();
      init_minimum();
      init_mul();
      init_operation();
      init_scalar();
      init_square();
      init_sub();
      init_compute_weighted_loss();
      huberLoss = /* @__PURE__ */ op({ huberLoss_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/losses/log_loss.js
  function logLoss_(labels, predictions, weights, epsilon2 = 1e-7, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
    const $labels = convertToTensor(labels, "labels", "logLoss");
    const $predictions = convertToTensor(predictions, "predictions", "logLoss");
    let $weights = null;
    if (weights != null) {
      $weights = convertToTensor(weights, "weights", "logLoss");
    }
    assertShapesMatch($labels.shape, $predictions.shape, "Error in logLoss: ");
    const one = scalar(1);
    const epsilonScalar = scalar(epsilon2);
    const l1 = neg(mul($labels, log2(add2($predictions, epsilonScalar))));
    const l2 = mul(sub(one, $labels), log2(add2(sub(one, $predictions), epsilonScalar)));
    const losses2 = sub(l1, l2);
    return computeWeightedLoss(losses2, $weights, reduction);
  }
  var logLoss;
  var init_log_loss = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/losses/log_loss.js"() {
      init_tensor_util_env();
      init_util();
      init_add();
      init_log2();
      init_loss_ops_utils();
      init_mul();
      init_neg();
      init_operation();
      init_scalar();
      init_sub();
      init_compute_weighted_loss();
      logLoss = /* @__PURE__ */ op({ logLoss_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/losses/mean_squared_error.js
  function meanSquaredError_(labels, predictions, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
    const $labels = convertToTensor(labels, "labels", "meanSquaredError");
    const $predictions = convertToTensor(predictions, "predictions", "meanSquaredError");
    let $weights = null;
    if (weights != null) {
      $weights = convertToTensor(weights, "weights", "meanSquaredError");
    }
    assertShapesMatch($labels.shape, $predictions.shape, "Error in meanSquaredError: ");
    const losses2 = squaredDifference($labels, $predictions);
    return computeWeightedLoss(losses2, $weights, reduction);
  }
  var meanSquaredError;
  var init_mean_squared_error = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/losses/mean_squared_error.js"() {
      init_tensor_util_env();
      init_util();
      init_loss_ops_utils();
      init_operation();
      init_squared_difference();
      init_compute_weighted_loss();
      meanSquaredError = /* @__PURE__ */ op({ meanSquaredError_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/losses/sigmoid_cross_entropy.js
  function sigmoidCrossEntropyWithLogits_(labels, logits) {
    const $labels = convertToTensor(labels, "labels", "sigmoidCrossEntropyWithLogits");
    const $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropyWithLogits");
    assertShapesMatch($labels.shape, $logits.shape, "Error in sigmoidCrossEntropyWithLogits: ");
    const maxOutput = relu($logits);
    const outputXTarget = mul($logits, $labels);
    const sigmoidOutput = log1p(exp(neg(abs($logits))));
    return add2(sub(maxOutput, outputXTarget), sigmoidOutput);
  }
  function sigmoidCrossEntropy_(multiClassLabels, logits, weights, labelSmoothing = 0, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
    let $multiClassLabels = convertToTensor(multiClassLabels, "multiClassLabels", "sigmoidCrossEntropy");
    const $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropy");
    let $weights = null;
    if (weights != null) {
      $weights = convertToTensor(weights, "weights", "sigmoidCrossEntropy");
    }
    assertShapesMatch($multiClassLabels.shape, $logits.shape, "Error in sigmoidCrossEntropy: ");
    if (labelSmoothing > 0) {
      const labelSmoothingScalar = scalar(labelSmoothing);
      const one = scalar(1);
      const half = scalar(0.5);
      $multiClassLabels = add2(mul($multiClassLabels, sub(one, labelSmoothingScalar)), mul(half, labelSmoothingScalar));
    }
    const losses2 = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);
    return computeWeightedLoss(losses2, $weights, reduction);
  }
  var sigmoidCrossEntropy;
  var init_sigmoid_cross_entropy = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/losses/sigmoid_cross_entropy.js"() {
      init_tensor_util_env();
      init_util();
      init_abs();
      init_add();
      init_exp();
      init_log1p();
      init_loss_ops_utils();
      init_mul();
      init_neg();
      init_operation();
      init_relu();
      init_scalar();
      init_sub();
      init_compute_weighted_loss();
      sigmoidCrossEntropy = /* @__PURE__ */ op({ sigmoidCrossEntropy_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/losses/softmax_cross_entropy.js
  function softmaxCrossEntropyWithLogits_(labels, logits, dim = -1) {
    if (dim === -1) {
      dim = logits.rank - 1;
    }
    if (dim !== logits.rank - 1) {
      throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${logits.rank} and dim was ${dim}`);
    }
    const customOp = customGrad((labels2, logits2, save) => {
      const keepDims = true;
      const lse = logSumExp(logits2, [dim], keepDims);
      const logResult = sub(cast(logits2, "float32"), lse);
      save([labels2, logResult]);
      const costVector = neg(mul(logResult, labels2));
      const value = sum2(costVector, [dim]);
      const gradFunc = (dy, saved) => {
        const [labels3, logResult2] = saved;
        const dyShape = expandShapeToKeepDim(dy.shape, [dim]);
        return [
          mul(reshape(dy, dyShape), sub(cast(labels3, "float32"), exp(logResult2))),
          mul(reshape(dy, dyShape), sub(exp(logResult2), cast(labels3, "float32")))
        ];
      };
      return { value, gradFunc };
    });
    return customOp(labels, logits);
  }
  function softmaxCrossEntropy_(onehotLabels, logits, weights, labelSmoothing = 0, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {
    let $onehotLabels = convertToTensor(onehotLabels, "onehotLabels", "softmaxCrossEntropy");
    const $logits = convertToTensor(logits, "logits", "softmaxCrossEntropy");
    let $weights = null;
    if (weights != null) {
      $weights = convertToTensor(weights, "weights", "softmaxCrossEntropy");
    }
    assertShapesMatch($onehotLabels.shape, $logits.shape, "Error in softmaxCrossEntropy: ");
    if (labelSmoothing > 0) {
      const labelSmoothingScalar = scalar(labelSmoothing);
      const one = scalar(1);
      const numClasses = scalar($onehotLabels.shape[1]);
      $onehotLabels = add2(mul($onehotLabels, sub(one, labelSmoothingScalar)), div(labelSmoothingScalar, numClasses));
    }
    const losses2 = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);
    return computeWeightedLoss(losses2, $weights, reduction);
  }
  var softmaxCrossEntropy;
  var init_softmax_cross_entropy = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/losses/softmax_cross_entropy.js"() {
      init_gradients();
      init_tensor_util_env();
      init_util();
      init_add();
      init_axis_util();
      init_cast();
      init_div();
      init_exp();
      init_log_sum_exp();
      init_loss_ops_utils();
      init_mul();
      init_neg();
      init_operation();
      init_reshape();
      init_scalar();
      init_sub();
      init_sum();
      init_compute_weighted_loss();
      softmaxCrossEntropy = /* @__PURE__ */ op({ softmaxCrossEntropy_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows.js
  function sparseFillEmptyRows_(indices, values, denseShape, defaultValue) {
    const $indices = convertToTensor(indices, "indices", "sparseFillEmptyRows", "int32");
    const $values = convertToTensor(values, "values", "sparseFillEmptyRows");
    const $denseShape = convertToTensor(denseShape, "denseShape", "sparseFillEmptyRows", "int32");
    const $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseFillEmptyRows", $values.dtype);
    if ($indices.rank !== 2) {
      throw new Error(`Indices should be Tensor2D but received shape
        ${$indices.shape}`);
    }
    if ($values.rank !== 1) {
      throw new Error(`Values should be Tensor1D but received shape ${$values.shape}`);
    }
    if ($denseShape.rank !== 1) {
      throw new Error(`Dense shape should be Tensor1D but received shape ${$denseShape.shape}`);
    }
    if ($defaultValue.rank !== 0) {
      throw new Error(`Default value should be a scalar but received shape ${$defaultValue.shape}`);
    }
    const inputs = {
      indices: $indices,
      values: $values,
      denseShape: $denseShape,
      defaultValue: $defaultValue
    };
    const result = ENGINE.runKernel(SparseFillEmptyRows, inputs);
    return {
      outputIndices: result[0],
      outputValues: result[1],
      emptyRowIndicator: result[2],
      reverseIndexMap: result[3]
    };
  }
  var sparseFillEmptyRows;
  var init_sparse_fill_empty_rows = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      sparseFillEmptyRows = /* @__PURE__ */ op({ sparseFillEmptyRows_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape.js
  function sparseReshape_(inputIndices, inputShape, newShape) {
    const $inputIndices = convertToTensor(inputIndices, "inputIndices", "sparseReshape", "int32");
    const $inputShape = convertToTensor(inputShape, "inputShape", "sparseReshape", "int32");
    const $newShape = convertToTensor(newShape, "newShape", "sparseReshape", "int32");
    if ($inputIndices.rank !== 2) {
      throw new Error(`Input indices should be Tensor2D but received shape
        ${$inputIndices.shape}`);
    }
    if ($inputShape.rank !== 1) {
      throw new Error(`Input shape should be Tensor1D but received shape ${$inputShape.shape}`);
    }
    if ($newShape.rank !== 1) {
      throw new Error(`New shape should be Tensor1D but received shape ${$newShape.shape}`);
    }
    const inputs = {
      inputIndices: $inputIndices,
      inputShape: $inputShape,
      newShape: $newShape
    };
    const result = ENGINE.runKernel(SparseReshape, inputs);
    return { outputIndices: result[0], outputShape: result[1] };
  }
  var sparseReshape;
  var init_sparse_reshape = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      sparseReshape = /* @__PURE__ */ op({ sparseReshape_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_mean.js
  function sparseSegmentMean_(data, indices, segmentIds) {
    const $data = convertToTensor(data, "data", "sparseSegmentMean");
    const $indices = convertToTensor(indices, "indices", "sparseSegmentMean", "int32");
    const $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentMean", "int32");
    if ($data.rank < 1) {
      throw new Error(`Data should be at least 1 dimensional but received scalar`);
    }
    if ($indices.rank !== 1) {
      throw new Error(`Indices should be Tensor1D but received shape
          ${$indices.shape}`);
    }
    if ($segmentIds.rank !== 1) {
      throw new Error(`Segment ids should be Tensor1D but received shape
          ${$segmentIds.shape}`);
    }
    const inputs = {
      data: $data,
      indices: $indices,
      segmentIds: $segmentIds
    };
    return ENGINE.runKernel(SparseSegmentMean, inputs);
  }
  var sparseSegmentMean;
  var init_sparse_segment_mean = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_mean.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      sparseSegmentMean = /* @__PURE__ */ op({ sparseSegmentMean_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_sum.js
  function sparseSegmentSum_(data, indices, segmentIds) {
    const $data = convertToTensor(data, "data", "sparseSegmentSum");
    const $indices = convertToTensor(indices, "indices", "sparseSegmentSum", "int32");
    const $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentSum", "int32");
    if ($data.rank < 1) {
      throw new Error(`Data should be at least 1 dimensional but received scalar`);
    }
    if ($indices.rank !== 1) {
      throw new Error(`Indices should be Tensor1D but received shape
         ${$indices.shape}`);
    }
    if ($segmentIds.rank !== 1) {
      throw new Error(`Segment ids should be Tensor1D but received shape
         ${$segmentIds.shape}`);
    }
    const inputs = {
      data: $data,
      indices: $indices,
      segmentIds: $segmentIds
    };
    return ENGINE.runKernel(SparseSegmentSum, inputs);
  }
  var sparseSegmentSum;
  var init_sparse_segment_sum = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_sum.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      sparseSegmentSum = /* @__PURE__ */ op({ sparseSegmentSum_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/string/string_n_grams.js
  function stringNGrams_(data, dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
    const $data = convertToTensor(data, "data", "stringNGrams", "string");
    if ($data.dtype !== "string") {
      throw new Error("Data must be of datatype string");
    }
    if ($data.shape.length !== 1) {
      throw new Error(`Data must be a vector, saw: ${$data.shape}`);
    }
    const $dataSplits = convertToTensor(dataSplits, "dataSplits", "stringNGrams");
    if ($dataSplits.dtype !== "int32") {
      throw new Error("Data splits must be of datatype int32");
    }
    const attrs = {
      separator,
      nGramWidths,
      leftPad,
      rightPad: rightPad2,
      padWidth,
      preserveShortSequences
    };
    const inputs = { data: $data, dataSplits: $dataSplits };
    const result = ENGINE.runKernel(StringNGrams, inputs, attrs);
    return { nGrams: result[0], nGramsSplits: result[1] };
  }
  var stringNGrams;
  var init_string_n_grams = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/string/string_n_grams.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      stringNGrams = /* @__PURE__ */ op({ stringNGrams_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/string/string_split.js
  function stringSplit_(input, delimiter, skipEmpty = true) {
    const $input = convertToTensor(input, "input", "stringSplit", "string");
    const $delimiter = convertToTensor(delimiter, "delimiter", "stringSplit", "string");
    if ($input.rank !== 1) {
      throw new Error(`Input should be Tensor1D but received shape ${$input.shape}`);
    }
    if ($delimiter.rank !== 0) {
      throw new Error(`Delimiter should be a scalar but received shape ${$delimiter.shape}`);
    }
    const attrs = { skipEmpty };
    const inputs = { input: $input, delimiter: $delimiter };
    const result = ENGINE.runKernel(StringSplit, inputs, attrs);
    return { indices: result[0], values: result[1], shape: result[2] };
  }
  var stringSplit;
  var init_string_split = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/string/string_split.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      stringSplit = /* @__PURE__ */ op({ stringSplit_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/string/string_to_hash_bucket_fast.js
  function stringToHashBucketFast_(input, numBuckets) {
    const $input = convertToTensor(input, "input", "stringToHashBucketFast", "string");
    const attrs = { numBuckets };
    if (numBuckets <= 0) {
      throw new Error(`Number of buckets must be at least 1`);
    }
    const inputs = { input: $input };
    return ENGINE.runKernel(StringToHashBucketFast, inputs, attrs);
  }
  var stringToHashBucketFast;
  var init_string_to_hash_bucket_fast = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/string/string_to_hash_bucket_fast.js"() {
      init_engine();
      init_kernel_names();
      init_tensor_util_env();
      init_operation();
      stringToHashBucketFast = /* @__PURE__ */ op({ stringToHashBucketFast_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/ops.js
  var spectral, signal, image, linalg, losses, sparse, string;
  var init_ops = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/ops.js"() {
      init_abs();
      init_acos();
      init_acosh();
      init_add();
      init_add_n();
      init_all();
      init_any();
      init_arg_max();
      init_arg_min();
      init_asin();
      init_asinh();
      init_atan();
      init_atan2();
      init_atanh();
      init_avg_pool();
      init_avg_pool_3d();
      init_basic_lstm_cell();
      init_batch_to_space_nd();
      init_batchnorm();
      init_batchnorm2d();
      init_batchnorm3d();
      init_batchnorm4d();
      init_bincount();
      init_broadcast_args();
      init_broadcast_to();
      init_buffer();
      init_cast();
      init_ceil();
      init_clip_by_value();
      init_clone();
      init_complex();
      init_concat();
      init_concat_1d();
      init_concat_2d();
      init_concat_3d();
      init_concat_4d();
      init_conv1d();
      init_conv2d();
      init_conv2d_transpose();
      init_conv3d();
      init_conv3d_transpose();
      init_cos();
      init_cosh();
      init_cumprod();
      init_cumsum();
      init_dense_bincount();
      init_depth_to_space();
      init_depthwise_conv2d();
      init_diag();
      init_dilation2d();
      init_div();
      init_div_no_nan();
      init_dot();
      init_einsum();
      init_elu();
      init_equal();
      init_erf();
      init_euclidean_norm();
      init_exp();
      init_expand_dims();
      init_expm1();
      init_eye();
      init_fill();
      init_floor();
      init_floorDiv();
      init_gather();
      init_greater();
      init_greater_equal();
      init_imag();
      init_is_finite();
      init_is_inf();
      init_is_nan();
      init_leaky_relu();
      init_less();
      init_less_equal();
      init_linspace();
      init_local_response_normalization();
      init_log2();
      init_log1p();
      init_log_sigmoid();
      init_log_softmax();
      init_log_sum_exp();
      init_logical_and();
      init_logical_not();
      init_logical_or();
      init_logical_xor();
      init_lower_bound();
      init_mat_mul();
      init_max();
      init_max_pool();
      init_max_pool_3d();
      init_max_pool_with_argmax();
      init_maximum();
      init_mean();
      init_meshgrid();
      init_min();
      init_minimum();
      init_mirror_pad();
      init_mod();
      init_moments();
      init_mul();
      init_multi_rnn_cell();
      init_multinomial();
      init_neg();
      init_not_equal();
      init_one_hot();
      init_ones();
      init_ones_like();
      init_outer_product();
      init_pad();
      init_pad1d();
      init_pad2d();
      init_pad3d();
      init_pad4d();
      init_pool();
      init_pow();
      init_prelu();
      init_print();
      init_prod();
      init_ragged_gather();
      init_ragged_range();
      init_ragged_tensor_to_tensor();
      init_rand();
      init_random_gamma();
      init_random_normal();
      init_random_standard_normal();
      init_random_uniform();
      init_range();
      init_real();
      init_reciprocal();
      init_relu();
      init_relu6();
      init_reshape();
      init_reverse();
      init_reverse_1d();
      init_reverse_2d();
      init_reverse_3d();
      init_reverse_4d();
      init_round();
      init_rsqrt();
      init_scalar();
      init_selu();
      init_separable_conv2d();
      init_setdiff1d_async();
      init_sigmoid();
      init_sign();
      init_sin();
      init_sinh();
      init_slice();
      init_slice1d();
      init_slice2d();
      init_slice3d();
      init_slice4d();
      init_softmax();
      init_softplus();
      init_space_to_batch_nd();
      init_fft();
      init_ifft();
      init_irfft();
      init_rfft();
      init_split();
      init_sqrt();
      init_square();
      init_squared_difference();
      init_squeeze();
      init_stack();
      init_step();
      init_strided_slice();
      init_sub();
      init_sum();
      init_tan();
      init_tanh();
      init_tensor2();
      init_tensor1d();
      init_tensor2d();
      init_tensor3d();
      init_tensor4d();
      init_tensor5d();
      init_tensor6d();
      init_tile();
      init_topk();
      init_truncated_normal();
      init_unique();
      init_unsorted_segment_sum();
      init_unstack();
      init_upper_bound();
      init_variable();
      init_where();
      init_where_async();
      init_zeros();
      init_zeros_like();
      init_boolean_mask();
      init_transpose();
      init_norm();
      init_moving_average();
      init_scatter_nd();
      init_search_sorted();
      init_sparse_to_dense();
      init_gather_nd();
      init_dropout();
      init_signal_ops_util();
      init_in_top_k();
      init_operation();
      init_rfft();
      init_fft();
      init_ifft();
      init_irfft();
      init_fused_ops();
      init_hamming_window();
      init_hann_window();
      init_frame();
      init_stft();
      init_crop_and_resize();
      init_flip_left_right();
      init_grayscale_to_rgb();
      init_rotate_with_offset();
      init_non_max_suppression();
      init_non_max_suppression_async();
      init_non_max_suppression_with_score();
      init_non_max_suppression_with_score_async();
      init_non_max_suppression_padded();
      init_non_max_suppression_padded_async();
      init_resize_bilinear();
      init_resize_nearest_neighbor();
      init_threshold();
      init_transform();
      init_band_part();
      init_gram_schmidt();
      init_qr();
      init_absolute_difference();
      init_compute_weighted_loss();
      init_cosine_distance();
      init_hinge_loss();
      init_huber_loss();
      init_log_loss();
      init_mean_squared_error();
      init_sigmoid_cross_entropy();
      init_softmax_cross_entropy();
      init_sparse_fill_empty_rows();
      init_sparse_reshape();
      init_sparse_segment_mean();
      init_sparse_segment_sum();
      init_string_n_grams();
      init_string_split();
      init_string_to_hash_bucket_fast();
      spectral = {
        fft,
        ifft,
        rfft,
        irfft
      };
      signal = {
        hammingWindow,
        hannWindow,
        frame,
        stft
      };
      image = {
        flipLeftRight,
        grayscaleToRGB,
        resizeNearestNeighbor,
        resizeBilinear,
        rotateWithOffset,
        cropAndResize,
        nonMaxSuppression,
        nonMaxSuppressionAsync,
        nonMaxSuppressionWithScore,
        nonMaxSuppressionWithScoreAsync,
        nonMaxSuppressionPadded,
        nonMaxSuppressionPaddedAsync,
        threshold,
        transform
      };
      linalg = {
        bandPart,
        gramSchmidt,
        qr
      };
      losses = {
        absoluteDifference,
        computeWeightedLoss,
        cosineDistance,
        hingeLoss,
        huberLoss,
        logLoss,
        meanSquaredError,
        sigmoidCrossEntropy,
        softmaxCrossEntropy
      };
      sparse = {
        sparseFillEmptyRows,
        sparseReshape,
        sparseSegmentMean,
        sparseSegmentSum
      };
      string = {
        stringNGrams,
        stringSplit,
        stringToHashBucketFast
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/serialization.js
  function registerClass(cls) {
    assert(cls.className != null, () => `Class being registered does not have the static className property defined.`);
    assert(typeof cls.className === "string", () => `className is required to be a string, but got type ` + typeof cls.className);
    assert(cls.className.length > 0, () => `Class being registered has an empty-string as its className, which is disallowed.`);
    SerializationMap.register(cls);
  }
  var Serializable, SerializationMap;
  var init_serialization = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/serialization.js"() {
      init_util();
      Serializable = class {
        /**
         * Return the class name for this class to use in serialization contexts.
         *
         * Generally speaking this will be the same thing that constructor.name
         * would have returned.  However, the class name needs to be robust
         * against minification for serialization/deserialization to work properly.
         *
         * There's also places such as initializers.VarianceScaling, where
         * implementation details between different languages led to different
         * class hierarchies and a non-leaf node is used for serialization purposes.
         */
        getClassName() {
          return this.constructor.className;
        }
        /**
         * Creates an instance of T from a ConfigDict.
         *
         * This works for most descendants of serializable.  A few need to
         * provide special handling.
         * @param cls A Constructor for the class to instantiate.
         * @param config The Configuration for the object.
         */
        /** @nocollapse */
        static fromConfig(cls, config) {
          return new cls(config);
        }
      };
      SerializationMap = class {
        constructor() {
          this.classNameMap = {};
        }
        /**
         * Returns the singleton instance of the map.
         */
        static getMap() {
          if (SerializationMap.instance == null) {
            SerializationMap.instance = new SerializationMap();
          }
          return SerializationMap.instance;
        }
        /**
         * Registers the class as serializable.
         */
        static register(cls) {
          SerializationMap.getMap().classNameMap[cls.className] = [cls, cls.fromConfig];
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js
  var Optimizer;
  var init_optimizer = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js"() {
      init_globals();
      init_gradients();
      init_ops();
      init_serialization();
      Optimizer = class extends Serializable {
        /**
         * Executes `f()` and minimizes the scalar output of `f()` by computing
         * gradients of y with respect to the list of trainable variables provided by
         * `varList`. If no list is provided, it defaults to all trainable variables.
         *
         * @param f The function to execute and whose output to minimize.
         * @param returnCost Whether to return the scalar cost value produced by
         * executing `f()`.
         * @param varList An optional list of variables to update. If specified, only
         * the trainable variables in varList will be updated by minimize. Defaults to
         * all trainable variables.
         *
         * @doc {heading: 'Training', subheading: 'Optimizers'}
         */
        minimize(f, returnCost = false, varList) {
          const { value, grads } = this.computeGradients(f, varList);
          if (varList != null) {
            const gradArray = varList.map((v) => ({ name: v.name, tensor: grads[v.name] }));
            this.applyGradients(gradArray);
          } else {
            this.applyGradients(grads);
          }
          dispose(grads);
          if (returnCost) {
            return value;
          } else {
            value.dispose();
            return null;
          }
        }
        /**
         * The number of iterations that this optimizer instance has been invoked for.
         */
        get iterations() {
          if (this.iterations_ == null) {
            this.iterations_ = 0;
          }
          return this.iterations_;
        }
        incrementIterations() {
          this.iterations_ = this.iterations + 1;
        }
        /**
         * Executes f() and computes the gradient of the scalar output of f() with
         * respect to the list of trainable variables provided by `varList`. If no
         * list is provided, it defaults to all trainable variables.
         *
         * @param f The function to execute and whose output to use for computing
         * gradients with respect to variables.
         * @param varList An optional list of variables to compute gradients with
         * respect to. If specified, only the trainable variables in varList will have
         * gradients computed with respect to. Defaults to all trainable variables.
         *
         * @doc {heading: 'Training', subheading: 'Optimizers'}
         */
        computeGradients(f, varList) {
          return variableGrads(f, varList);
        }
        /**
         * Dispose the variables (if any) owned by this optimizer instance.
         */
        dispose() {
          if (this.iterations_ != null) {
            dispose(this.iterations_);
          }
        }
        saveIterations() {
          return __async(this, null, function* () {
            if (this.iterations_ == null) {
              this.iterations_ = 0;
            }
            return {
              name: "iter",
              // TODO(cais): Use 'int64' type when available.
              tensor: scalar(this.iterations_, "int32")
            };
          });
        }
        getWeights() {
          return __async(this, null, function* () {
            throw new Error("getWeights() is not implemented for this optimizer yet.");
          });
        }
        setWeights(weightValues) {
          return __async(this, null, function* () {
            throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`);
          });
        }
        /**
         * Extract the first element of the weight values and set it
         * as the iterations counter variable of this instance of optimizer.
         *
         * @param weightValues
         * @returns Weight values with the first element consumed and excluded.
         */
        extractIterations(weightValues) {
          return __async(this, null, function* () {
            this.iterations_ = (yield weightValues[0].tensor.data())[0];
            return weightValues.slice(1);
          });
        }
      };
      Object.defineProperty(Optimizer, Symbol.hasInstance, {
        value: (instance) => {
          return instance.minimize != null && instance.computeGradients != null && instance.applyGradients != null;
        }
      });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js
  var AdadeltaOptimizer;
  var init_adadelta_optimizer = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js"() {
      init_engine();
      init_globals();
      init_add();
      init_div();
      init_mul();
      init_ops();
      init_square();
      init_zeros_like();
      init_optimizer();
      AdadeltaOptimizer = class extends Optimizer {
        constructor(learningRate, rho, epsilon2 = null) {
          super();
          this.learningRate = learningRate;
          this.rho = rho;
          this.epsilon = epsilon2;
          this.accumulatedGrads = [];
          this.accumulatedUpdates = [];
          if (epsilon2 == null) {
            this.epsilon = ENGINE.backend.epsilon();
          }
        }
        /** @nocollapse */
        static get className() {
          return "Adadelta";
        }
        applyGradients(variableGradients) {
          const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
          variableNames.forEach((name, i) => {
            const value = ENGINE.registeredVariables[name];
            const trainable = false;
            if (this.accumulatedGrads[i] == null) {
              this.accumulatedGrads[i] = {
                originalName: `${name}/accum_grad`,
                variable: tidy(() => zerosLike(value).variable(trainable))
              };
            }
            if (this.accumulatedUpdates[i] == null) {
              this.accumulatedUpdates[i] = {
                originalName: `${name}/accum_var`,
                variable: tidy(() => zerosLike(value).variable(trainable))
              };
            }
            const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            const accumulatedGrad = this.accumulatedGrads[i].variable;
            const accumulatedUpdate = this.accumulatedUpdates[i].variable;
            tidy(() => {
              const newAccumulatedGrad = add2(mul(accumulatedGrad, this.rho), mul(square(gradient), 1 - this.rho));
              const updates = mul(div(sqrt(add2(accumulatedUpdate, this.epsilon)), sqrt(add2(accumulatedGrad, this.epsilon))), gradient);
              const newAccumulatedUpdate = add2(mul(accumulatedUpdate, this.rho), mul(square(updates), 1 - this.rho));
              accumulatedGrad.assign(newAccumulatedGrad);
              accumulatedUpdate.assign(newAccumulatedUpdate);
              const newValue = add2(mul(updates, -this.learningRate), value);
              value.assign(newValue);
            });
          });
          this.incrementIterations();
        }
        dispose() {
          if (this.accumulatedUpdates != null) {
            dispose(this.accumulatedGrads.map((v) => v.variable));
            dispose(this.accumulatedUpdates.map((v) => v.variable));
          }
        }
        getWeights() {
          return __async(this, null, function* () {
            const variables = [...this.accumulatedGrads, ...this.accumulatedUpdates];
            return [yield this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
          });
        }
        setWeights(weightValues) {
          return __async(this, null, function* () {
            weightValues = yield this.extractIterations(weightValues);
            const variableCount = weightValues.length / 2;
            const trainable = false;
            this.accumulatedGrads = weightValues.slice(0, variableCount).map((v) => ({
              originalName: v.name,
              variable: v.tensor.variable(trainable)
            }));
            this.accumulatedUpdates = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
              originalName: v.name,
              variable: v.tensor.variable(trainable)
            }));
          });
        }
        getConfig() {
          return {
            "learningRate": this.learningRate,
            "rho": this.rho,
            "epsilon": this.epsilon
          };
        }
        /** @nocollapse */
        static fromConfig(cls, config) {
          return new cls(config["learningRate"], config["rho"], config["epsilon"]);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js
  var AdagradOptimizer;
  var init_adagrad_optimizer = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js"() {
      init_engine();
      init_globals();
      init_add();
      init_div();
      init_fill();
      init_mul();
      init_sqrt();
      init_square();
      init_optimizer();
      AdagradOptimizer = class extends Optimizer {
        constructor(learningRate, initialAccumulatorValue = 0.1) {
          super();
          this.learningRate = learningRate;
          this.initialAccumulatorValue = initialAccumulatorValue;
          this.accumulatedGrads = [];
        }
        /** @nocollapse */
        static get className() {
          return "Adagrad";
        }
        applyGradients(variableGradients) {
          const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
          variableNames.forEach((name, i) => {
            const value = ENGINE.registeredVariables[name];
            if (this.accumulatedGrads[i] == null) {
              const trainable = false;
              this.accumulatedGrads[i] = {
                originalName: `${name}/accumulator`,
                variable: tidy(() => fill(value.shape, this.initialAccumulatorValue).variable(trainable))
              };
            }
            const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            const accumulatedGrad = this.accumulatedGrads[i].variable;
            tidy(() => {
              const newAccumulatedGrad = add2(accumulatedGrad, square(gradient));
              accumulatedGrad.assign(newAccumulatedGrad);
              const newValue = add2(mul(div(gradient, sqrt(add2(newAccumulatedGrad, ENGINE.backend.epsilon()))), -this.learningRate), value);
              value.assign(newValue);
            });
          });
          this.incrementIterations();
        }
        dispose() {
          if (this.accumulatedGrads != null) {
            dispose(this.accumulatedGrads.map((v) => v.variable));
          }
        }
        getWeights() {
          return __async(this, null, function* () {
            return [yield this.saveIterations()].concat(this.accumulatedGrads.map((v) => ({ name: v.originalName, tensor: v.variable })));
          });
        }
        setWeights(weightValues) {
          return __async(this, null, function* () {
            weightValues = yield this.extractIterations(weightValues);
            const trainable = false;
            this.accumulatedGrads = weightValues.map((v) => ({ originalName: v.name, variable: v.tensor.variable(trainable) }));
          });
        }
        getConfig() {
          return {
            "learningRate": this.learningRate,
            "initialAccumulatorValue": this.initialAccumulatorValue
          };
        }
        /** @nocollapse */
        static fromConfig(cls, config) {
          return new cls(config["learningRate"], config["initialAccumulatorValue"]);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js
  var AdamOptimizer;
  var init_adam_optimizer = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js"() {
      init_engine();
      init_globals();
      init_add();
      init_div();
      init_mul();
      init_pow();
      init_scalar();
      init_sqrt();
      init_square();
      init_sub();
      init_zeros_like();
      init_optimizer();
      AdamOptimizer = class extends Optimizer {
        constructor(learningRate, beta1, beta2, epsilon2 = null) {
          super();
          this.learningRate = learningRate;
          this.beta1 = beta1;
          this.beta2 = beta2;
          this.epsilon = epsilon2;
          this.accumulatedFirstMoment = [];
          this.accumulatedSecondMoment = [];
          tidy(() => {
            this.accBeta1 = scalar(beta1).variable();
            this.accBeta2 = scalar(beta2).variable();
          });
          if (epsilon2 == null) {
            this.epsilon = ENGINE.backend.epsilon();
          }
        }
        /** @nocollapse */
        static get className() {
          return "Adam";
        }
        applyGradients(variableGradients) {
          const varNames = Array.isArray(variableGradients) ? variableGradients.map((v) => v.name) : Object.keys(variableGradients);
          tidy(() => {
            const oneMinusAccBeta1 = sub(1, this.accBeta1);
            const oneMinusAccBeta2 = sub(1, this.accBeta2);
            varNames.forEach((name, i) => {
              const value = ENGINE.registeredVariables[name];
              const trainable = false;
              if (this.accumulatedFirstMoment[i] == null) {
                this.accumulatedFirstMoment[i] = {
                  originalName: `${name}/m`,
                  variable: tidy(() => zerosLike(value).variable(trainable))
                };
              }
              if (this.accumulatedSecondMoment[i] == null) {
                this.accumulatedSecondMoment[i] = {
                  originalName: `${name}/v`,
                  variable: tidy(() => zerosLike(value).variable(trainable))
                };
              }
              const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
              if (gradient == null) {
                return;
              }
              const firstMoment = this.accumulatedFirstMoment[i].variable;
              const secondMoment = this.accumulatedSecondMoment[i].variable;
              const newFirstMoment = add2(mul(firstMoment, this.beta1), mul(gradient, 1 - this.beta1));
              const newSecondMoment = add2(mul(secondMoment, this.beta2), mul(square(gradient), 1 - this.beta2));
              const biasCorrectedFirstMoment = div(newFirstMoment, oneMinusAccBeta1);
              const biasCorrectedSecondMoment = div(newSecondMoment, oneMinusAccBeta2);
              firstMoment.assign(newFirstMoment);
              secondMoment.assign(newSecondMoment);
              const newValue = add2(mul(div(biasCorrectedFirstMoment, add2(sqrt(biasCorrectedSecondMoment), this.epsilon)), -this.learningRate), value);
              value.assign(newValue);
            });
            this.accBeta1.assign(mul(this.accBeta1, this.beta1));
            this.accBeta2.assign(mul(this.accBeta2, this.beta2));
          });
          this.incrementIterations();
        }
        dispose() {
          this.accBeta1.dispose();
          this.accBeta2.dispose();
          if (this.accumulatedFirstMoment != null) {
            dispose(this.accumulatedFirstMoment.map((v) => v.variable));
          }
          if (this.accumulatedSecondMoment != null) {
            dispose(this.accumulatedSecondMoment.map((v) => v.variable));
          }
        }
        getWeights() {
          return __async(this, null, function* () {
            const variables = [...this.accumulatedFirstMoment, ...this.accumulatedSecondMoment];
            return [yield this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
          });
        }
        setWeights(weightValues) {
          return __async(this, null, function* () {
            weightValues = yield this.extractIterations(weightValues);
            tidy(() => {
              this.accBeta1.assign(pow(this.beta1, this.iterations_ + 1));
              this.accBeta2.assign(pow(this.beta2, this.iterations_ + 1));
            });
            const variableCount = weightValues.length / 2;
            const trainable = false;
            this.accumulatedFirstMoment = weightValues.slice(0, variableCount).map((v) => ({
              originalName: v.name,
              variable: v.tensor.variable(trainable)
            }));
            this.accumulatedSecondMoment = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
              originalName: v.name,
              variable: v.tensor.variable(trainable)
            }));
          });
        }
        getConfig() {
          return {
            "learningRate": this.learningRate,
            "beta1": this.beta1,
            "beta2": this.beta2,
            "epsilon": this.epsilon
          };
        }
        /** @nocollapse */
        static fromConfig(cls, config) {
          return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"]);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js
  var AdamaxOptimizer;
  var init_adamax_optimizer = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js"() {
      init_engine();
      init_globals();
      init_abs();
      init_add();
      init_div();
      init_maximum();
      init_mul();
      init_scalar();
      init_sub();
      init_zeros_like();
      init_optimizer();
      AdamaxOptimizer = class extends Optimizer {
        constructor(learningRate, beta1, beta2, epsilon2 = null, decay = 0) {
          super();
          this.learningRate = learningRate;
          this.beta1 = beta1;
          this.beta2 = beta2;
          this.epsilon = epsilon2;
          this.decay = decay;
          this.accumulatedFirstMoment = [];
          this.accumulatedWeightedInfNorm = [];
          tidy(() => {
            this.iteration = scalar(0).variable();
            this.accBeta1 = scalar(beta1).variable();
          });
          if (epsilon2 == null) {
            this.epsilon = ENGINE.backend.epsilon();
          }
        }
        /** @nocollapse */
        static get className() {
          return "Adamax";
        }
        applyGradients(variableGradients) {
          const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
          tidy(() => {
            const oneMinusAccBeta1 = sub(1, this.accBeta1);
            const lr = div(-this.learningRate, add2(mul(this.iteration, this.decay), 1));
            variableNames.forEach((name, i) => {
              const value = ENGINE.registeredVariables[name];
              const trainable = false;
              if (this.accumulatedFirstMoment[i] == null) {
                this.accumulatedFirstMoment[i] = {
                  originalName: `${name}/m`,
                  variable: zerosLike(value).variable(trainable)
                };
              }
              if (this.accumulatedWeightedInfNorm[i] == null) {
                this.accumulatedWeightedInfNorm[i] = {
                  originalName: `${name}/v`,
                  variable: zerosLike(value).variable(trainable)
                };
              }
              const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
              if (gradient == null) {
                return;
              }
              const firstMoment = this.accumulatedFirstMoment[i].variable;
              const weightedInfNorm = this.accumulatedWeightedInfNorm[i].variable;
              const newFirstMoment = add2(mul(firstMoment, this.beta1), mul(gradient, 1 - this.beta1));
              const ut0 = mul(weightedInfNorm, this.beta2);
              const ut1 = abs(gradient);
              const newWeightedInfNorm = maximum(ut0, ut1);
              firstMoment.assign(newFirstMoment);
              weightedInfNorm.assign(newWeightedInfNorm);
              const newValue = add2(mul(div(lr, oneMinusAccBeta1), div(newFirstMoment, add2(newWeightedInfNorm, this.epsilon))), value);
              value.assign(newValue);
            });
            this.iteration.assign(add2(this.iteration, 1));
            this.accBeta1.assign(mul(this.accBeta1, this.beta1));
          });
          this.incrementIterations();
        }
        dispose() {
          this.accBeta1.dispose();
          this.iteration.dispose();
          if (this.accumulatedFirstMoment != null) {
            dispose(this.accumulatedFirstMoment.map((v) => v.variable));
          }
          if (this.accumulatedWeightedInfNorm != null) {
            dispose(this.accumulatedWeightedInfNorm.map((v) => v.variable));
          }
        }
        getWeights() {
          return __async(this, null, function* () {
            throw new Error("getWeights() is not implemented for Adamax yet.");
          });
        }
        setWeights(weightValues) {
          return __async(this, null, function* () {
            throw new Error("setWeights() is not implemented for Adamax yet.");
          });
        }
        getConfig() {
          return {
            "learningRate": this.learningRate,
            "beta1": this.beta1,
            "beta2": this.beta2,
            "epsilon": this.epsilon,
            "decay": this.decay
          };
        }
        /** @nocollapse */
        static fromConfig(cls, config) {
          return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"], config["decay"]);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js
  var SGDOptimizer;
  var init_sgd_optimizer = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js"() {
      init_engine();
      init_globals();
      init_add();
      init_mul();
      init_scalar();
      init_optimizer();
      SGDOptimizer = class extends Optimizer {
        constructor(learningRate) {
          super();
          this.learningRate = learningRate;
          this.setLearningRate(learningRate);
        }
        /** @nocollapse */
        static get className() {
          return "SGD";
        }
        applyGradients(variableGradients) {
          const varNames = Array.isArray(variableGradients) ? variableGradients.map((v) => v.name) : Object.keys(variableGradients);
          varNames.forEach((name, i) => {
            const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            const value = ENGINE.registeredVariables[name];
            tidy(() => {
              const newValue = add2(mul(this.c, gradient), value);
              value.assign(newValue);
            });
          });
          this.incrementIterations();
        }
        /**
         * Sets the learning rate of the optimizer.
         */
        setLearningRate(learningRate) {
          this.learningRate = learningRate;
          if (this.c != null) {
            this.c.dispose();
          }
          this.c = keep(scalar(-learningRate));
        }
        dispose() {
          this.c.dispose();
        }
        getWeights() {
          return __async(this, null, function* () {
            return [yield this.saveIterations()];
          });
        }
        setWeights(weightValues) {
          return __async(this, null, function* () {
            weightValues = yield this.extractIterations(weightValues);
            if (weightValues.length !== 0) {
              throw new Error("SGD optimizer does not have settable weights.");
            }
          });
        }
        getConfig() {
          return { "learningRate": this.learningRate };
        }
        /** @nocollapse */
        static fromConfig(cls, config) {
          return new cls(config["learningRate"]);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js
  var MomentumOptimizer;
  var init_momentum_optimizer = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js"() {
      init_engine();
      init_globals();
      init_add();
      init_mul();
      init_scalar();
      init_zeros_like();
      init_sgd_optimizer();
      MomentumOptimizer = class extends SGDOptimizer {
        constructor(learningRate, momentum, useNesterov = false) {
          super(learningRate);
          this.learningRate = learningRate;
          this.momentum = momentum;
          this.useNesterov = useNesterov;
          this.accumulations = [];
          this.m = scalar(this.momentum);
        }
        /** @nocollapse */
        // Name matters for Python compatibility.
        static get className() {
          return "Momentum";
        }
        applyGradients(variableGradients) {
          const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
          variableNames.forEach((name, i) => {
            const value = ENGINE.registeredVariables[name];
            if (this.accumulations[i] == null) {
              const trainable = false;
              this.accumulations[i] = {
                originalName: `${name}/momentum`,
                variable: tidy(() => zerosLike(value).variable(trainable))
              };
            }
            const accumulation = this.accumulations[i].variable;
            const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            tidy(() => {
              let newValue;
              const newAccumulation = add2(mul(this.m, accumulation), gradient);
              if (this.useNesterov) {
                newValue = add2(mul(this.c, add2(gradient, mul(newAccumulation, this.m))), value);
              } else {
                newValue = add2(mul(this.c, newAccumulation), value);
              }
              accumulation.assign(newAccumulation);
              value.assign(newValue);
            });
          });
          this.incrementIterations();
        }
        dispose() {
          this.m.dispose();
          if (this.accumulations != null) {
            dispose(this.accumulations.map((v) => v.variable));
          }
        }
        /**
         * Sets the momentum of the optimizer.
         *
         * @param momentum
         */
        setMomentum(momentum) {
          this.momentum = momentum;
        }
        getWeights() {
          return __async(this, null, function* () {
            return [yield this.saveIterations()].concat(this.accumulations.map((v) => ({ name: v.originalName, tensor: v.variable })));
          });
        }
        setWeights(weightValues) {
          return __async(this, null, function* () {
            weightValues = yield this.extractIterations(weightValues);
            const trainable = false;
            this.accumulations = weightValues.map((v) => ({ originalName: v.name, variable: v.tensor.variable(trainable) }));
          });
        }
        getConfig() {
          return {
            "learningRate": this.learningRate,
            "momentum": this.momentum,
            "useNesterov": this.useNesterov
          };
        }
        /** @nocollapse */
        static fromConfig(cls, config) {
          return new cls(config["learningRate"], config["momentum"], config["useNesterov"]);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js
  var RMSPropOptimizer;
  var init_rmsprop_optimizer = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js"() {
      init_engine();
      init_globals();
      init_add();
      init_div();
      init_mul();
      init_sqrt();
      init_square();
      init_sub();
      init_zeros_like();
      init_optimizer();
      RMSPropOptimizer = class extends Optimizer {
        constructor(learningRate, decay = 0.9, momentum = 0, epsilon2 = null, centered = false) {
          super();
          this.learningRate = learningRate;
          this.decay = decay;
          this.momentum = momentum;
          this.epsilon = epsilon2;
          this.accumulatedMeanSquares = [];
          this.accumulatedMoments = [];
          this.accumulatedMeanGrads = [];
          this.centered = centered;
          if (epsilon2 == null) {
            this.epsilon = ENGINE.backend.epsilon();
          }
          if (learningRate == null) {
            throw new Error(`learningRate for RMSPropOptimizer must be defined.`);
          }
        }
        /** @nocollapse */
        static get className() {
          return "RMSProp";
        }
        applyGradients(variableGradients) {
          const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
          variableNames.forEach((name, i) => {
            const value = ENGINE.registeredVariables[name];
            const trainable = false;
            if (this.accumulatedMeanSquares[i] == null) {
              this.accumulatedMeanSquares[i] = {
                originalName: `${name}/rms`,
                variable: tidy(() => zerosLike(value).variable(trainable))
              };
            }
            if (this.accumulatedMoments[i] == null) {
              this.accumulatedMoments[i] = {
                originalName: `${name}/momentum`,
                variable: tidy(() => zerosLike(value).variable(trainable))
              };
            }
            if (this.accumulatedMeanGrads[i] == null && this.centered) {
              this.accumulatedMeanGrads[i] = {
                originalName: `${name}/mg`,
                variable: tidy(() => zerosLike(value).variable(trainable))
              };
            }
            const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            const accumulatedMeanSquare = this.accumulatedMeanSquares[i].variable;
            const accumulatedMoments = this.accumulatedMoments[i].variable;
            tidy(() => {
              const newAccumulatedMeanSquare = add2(mul(accumulatedMeanSquare, this.decay), mul(square(gradient), 1 - this.decay));
              if (this.centered) {
                const accumulatedMeanGrad = this.accumulatedMeanGrads[i].variable;
                const newAccumulatedMeanGrad = add2(mul(accumulatedMeanGrad, this.decay), mul(gradient, 1 - this.decay));
                const gradContribution = div(mul(gradient, this.learningRate), sqrt(sub(newAccumulatedMeanSquare, add2(square(newAccumulatedMeanGrad), this.epsilon))));
                const newAccumulatedMoments = add2(mul(accumulatedMoments, this.momentum), gradContribution);
                accumulatedMeanSquare.assign(newAccumulatedMeanSquare);
                accumulatedMeanGrad.assign(newAccumulatedMeanGrad);
                accumulatedMoments.assign(newAccumulatedMoments);
                const newValue = sub(value, newAccumulatedMoments);
                value.assign(newValue);
              } else {
                const newAccumulatedMeanSquare2 = add2(mul(accumulatedMeanSquare, this.decay), mul(square(gradient), 1 - this.decay));
                const newAccumulatedMoments = add2(mul(accumulatedMoments, this.momentum), div(mul(gradient, this.learningRate), sqrt(add2(newAccumulatedMeanSquare2, this.epsilon))));
                accumulatedMeanSquare.assign(newAccumulatedMeanSquare2);
                accumulatedMoments.assign(newAccumulatedMoments);
                const newValue = sub(value, newAccumulatedMoments);
                value.assign(newValue);
              }
            });
          });
          this.incrementIterations();
        }
        dispose() {
          if (this.accumulatedMeanSquares != null) {
            dispose(this.accumulatedMeanSquares.map((v) => v.variable));
          }
          if (this.accumulatedMeanGrads != null && this.centered) {
            dispose(this.accumulatedMeanGrads.map((v) => v.variable));
          }
          if (this.accumulatedMoments != null) {
            dispose(this.accumulatedMoments.map((v) => v.variable));
          }
        }
        getWeights() {
          return __async(this, null, function* () {
            const variables = [...this.accumulatedMeanSquares, ...this.accumulatedMoments];
            if (this.centered) {
              variables.push(...this.accumulatedMeanGrads);
            }
            return [yield this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
          });
        }
        setWeights(weightValues) {
          return __async(this, null, function* () {
            weightValues = yield this.extractIterations(weightValues);
            const variableCount = this.centered ? weightValues.length / 3 : weightValues.length / 2;
            const trainable = false;
            this.accumulatedMeanSquares = weightValues.slice(0, variableCount).map((v) => ({
              originalName: v.name,
              variable: v.tensor.variable(trainable)
            }));
            this.accumulatedMoments = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
              originalName: v.name,
              variable: v.tensor.variable(trainable)
            }));
            if (this.centered) {
              this.accumulatedMeanGrads = weightValues.slice(variableCount * 2, variableCount * 3).map((v) => ({
                originalName: v.name,
                variable: v.tensor.variable(trainable)
              }));
            }
          });
        }
        getConfig() {
          return {
            "learningRate": this.learningRate,
            "decay": this.decay,
            "momentum": this.momentum,
            "epsilon": this.epsilon,
            "centered": this.centered
          };
        }
        /** @nocollapse */
        static fromConfig(cls, config) {
          return new cls(config["learningRate"], config["decay"], config["momentum"], config["epsilon"], config["centered"]);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/optimizers/register_optimizers.js
  function registerOptimizers() {
    for (const optimizer of OPTIMIZERS) {
      registerClass(optimizer);
    }
  }
  var OPTIMIZERS;
  var init_register_optimizers = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/optimizers/register_optimizers.js"() {
      init_adadelta_optimizer();
      init_adagrad_optimizer();
      init_adam_optimizer();
      init_adamax_optimizer();
      init_momentum_optimizer();
      init_rmsprop_optimizer();
      init_sgd_optimizer();
      init_serialization();
      OPTIMIZERS = [
        AdadeltaOptimizer,
        AdagradOptimizer,
        AdamOptimizer,
        AdamaxOptimizer,
        MomentumOptimizer,
        RMSPropOptimizer,
        SGDOptimizer
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js
  function defer(f) {
    return new Promise((resolve) => setTimeout(resolve)).then(f);
  }
  function browserDownloads(fileNamePrefix = "model") {
    return new BrowserDownloads(fileNamePrefix);
  }
  function browserFiles(files) {
    return new BrowserFiles(files);
  }
  var DEFAULT_FILE_NAME_PREFIX, DEFAULT_JSON_EXTENSION_NAME, DEFAULT_WEIGHT_DATA_EXTENSION_NAME, BrowserDownloads, BrowserFiles, browserDownloadsRouter;
  var init_browser_files = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js"() {
      init_flags();
      init_environment();
      init_io_utils();
      init_router_registry();
      DEFAULT_FILE_NAME_PREFIX = "model";
      DEFAULT_JSON_EXTENSION_NAME = ".json";
      DEFAULT_WEIGHT_DATA_EXTENSION_NAME = ".weights.bin";
      BrowserDownloads = class {
        constructor(fileNamePrefix) {
          if (!env().getBool("IS_BROWSER")) {
            throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
          }
          if (fileNamePrefix.startsWith(BrowserDownloads.URL_SCHEME)) {
            fileNamePrefix = fileNamePrefix.slice(BrowserDownloads.URL_SCHEME.length);
          }
          if (fileNamePrefix == null || fileNamePrefix.length === 0) {
            fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;
          }
          this.modelJsonFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;
          this.weightDataFileName = fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;
        }
        save(modelArtifacts) {
          return __async(this, null, function* () {
            if (typeof document === "undefined") {
              throw new Error("Browser downloads are not supported in this environment since `document` is not present");
            }
            const weightsURL = window.URL.createObjectURL(new Blob([modelArtifacts.weightData], { type: "application/octet-stream" }));
            if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
              throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
            } else {
              const weightsManifest = [{
                paths: ["./" + this.weightDataFileName],
                weights: modelArtifacts.weightSpecs
              }];
              const modelJSON = getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);
              const modelJsonURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelJSON)], { type: "application/json" }));
              const jsonAnchor = this.modelJsonAnchor == null ? document.createElement("a") : this.modelJsonAnchor;
              jsonAnchor.download = this.modelJsonFileName;
              jsonAnchor.href = modelJsonURL;
              yield defer(() => jsonAnchor.dispatchEvent(new MouseEvent("click")));
              if (modelArtifacts.weightData != null) {
                const weightDataAnchor = this.weightDataAnchor == null ? document.createElement("a") : this.weightDataAnchor;
                weightDataAnchor.download = this.weightDataFileName;
                weightDataAnchor.href = weightsURL;
                yield defer(() => weightDataAnchor.dispatchEvent(new MouseEvent("click")));
              }
              return { modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts) };
            }
          });
        }
      };
      BrowserDownloads.URL_SCHEME = "downloads://";
      BrowserFiles = class {
        constructor(files) {
          if (files == null || files.length < 1) {
            throw new Error(`When calling browserFiles, at least 1 file is required, but received ${files}`);
          }
          this.jsonFile = files[0];
          this.weightsFiles = files.slice(1);
        }
        load() {
          return __async(this, null, function* () {
            return new Promise((resolve, reject) => {
              const jsonReader = new FileReader();
              jsonReader.onload = (event) => {
                const modelJSON = JSON.parse(event.target.result);
                const modelTopology = modelJSON.modelTopology;
                if (modelTopology == null) {
                  reject(new Error(`modelTopology field is missing from file ${this.jsonFile.name}`));
                  return;
                }
                const weightsManifest = modelJSON.weightsManifest;
                if (weightsManifest == null) {
                  reject(new Error(`weightManifest field is missing from file ${this.jsonFile.name}`));
                  return;
                }
                if (this.weightsFiles.length === 0) {
                  resolve({ modelTopology });
                  return;
                }
                const modelArtifactsPromise = getModelArtifactsForJSON(modelJSON, (weightsManifest2) => this.loadWeights(weightsManifest2));
                resolve(modelArtifactsPromise);
              };
              jsonReader.onerror = (error) => reject(`Failed to read model topology and weights manifest JSON from file '${this.jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`);
              jsonReader.readAsText(this.jsonFile);
            });
          });
        }
        loadWeights(weightsManifest) {
          const weightSpecs = [];
          const paths = [];
          for (const entry of weightsManifest) {
            weightSpecs.push(...entry.weights);
            paths.push(...entry.paths);
          }
          const pathToFile = this.checkManifestAndWeightFiles(weightsManifest);
          const promises = paths.map((path) => this.loadWeightsFile(path, pathToFile[path]));
          return Promise.all(promises).then((buffers) => [weightSpecs, concatenateArrayBuffers(buffers)]);
        }
        loadWeightsFile(path, file) {
          return new Promise((resolve, reject) => {
            const weightFileReader = new FileReader();
            weightFileReader.onload = (event) => {
              const weightData = event.target.result;
              resolve(weightData);
            };
            weightFileReader.onerror = (error) => reject(`Failed to weights data from file of path '${path}'.`);
            weightFileReader.readAsArrayBuffer(file);
          });
        }
        /**
         * Check the compatibility between weights manifest and weight files.
         */
        checkManifestAndWeightFiles(manifest) {
          const basenames = [];
          const fileNames = this.weightsFiles.map((file) => basename(file.name));
          const pathToFile = {};
          for (const group of manifest) {
            group.paths.forEach((path) => {
              const pathBasename = basename(path);
              if (basenames.indexOf(pathBasename) !== -1) {
                throw new Error(`Duplicate file basename found in weights manifest: '${pathBasename}'`);
              }
              basenames.push(pathBasename);
              if (fileNames.indexOf(pathBasename) === -1) {
                throw new Error(`Weight file with basename '${pathBasename}' is not provided.`);
              } else {
                pathToFile[path] = this.weightsFiles[fileNames.indexOf(pathBasename)];
              }
            });
          }
          if (basenames.length !== this.weightsFiles.length) {
            throw new Error(`Mismatch in the number of files in weights manifest (${basenames.length}) and the number of weight files provided (${this.weightsFiles.length}).`);
          }
          return pathToFile;
        }
      };
      browserDownloadsRouter = (url) => {
        if (!env().getBool("IS_BROWSER")) {
          return null;
        } else {
          if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {
            return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));
          } else {
            return null;
          }
        }
      };
      IORouterRegistry.registerSaveRouter(browserDownloadsRouter);
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/progress.js
  function monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {
    checkPromises(promises);
    startFraction = startFraction == null ? 0 : startFraction;
    endFraction = endFraction == null ? 1 : endFraction;
    checkFraction(startFraction, endFraction);
    let resolvedPromise = 0;
    const registerMonitor = (promise) => {
      promise.then((value) => {
        const fraction = startFraction + ++resolvedPromise / promises.length * (endFraction - startFraction);
        onProgress(fraction);
        return value;
      });
      return promise;
    };
    function checkPromises(promises2) {
      assert(promises2 != null && Array.isArray(promises2) && promises2.length > 0, () => "promises must be a none empty array");
    }
    function checkFraction(startFraction2, endFraction2) {
      assert(startFraction2 >= 0 && startFraction2 <= 1, () => `Progress fraction must be in range [0, 1], but got startFraction ${startFraction2}`);
      assert(endFraction2 >= 0 && endFraction2 <= 1, () => `Progress fraction must be in range [0, 1], but got endFraction ${endFraction2}`);
      assert(endFraction2 >= startFraction2, () => `startFraction must be no more than endFraction, but got startFraction ${startFraction2} and endFraction ${endFraction2}`);
    }
    return Promise.all(promises.map(registerMonitor));
  }
  var init_progress = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/io/progress.js"() {
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js
  function loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {
    return __async(this, null, function* () {
      if (loadOptions == null) {
        loadOptions = {};
      }
      const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc;
      const requests = fetchURLs.map((fetchURL) => fetchFunc(fetchURL, loadOptions.requestInit, { isBinary: true }));
      const fetchStartFraction = 0;
      const fetchEndFraction = 0.5;
      const responses = loadOptions.onProgress == null ? yield Promise.all(requests) : yield monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);
      const bufferPromises = responses.map((response) => response.arrayBuffer());
      const bufferStartFraction = 0.5;
      const bufferEndFraction = 1;
      const buffers = loadOptions.onProgress == null ? yield Promise.all(bufferPromises) : yield monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);
      return buffers;
    });
  }
  function loadWeights(manifest, filePathPrefix = "", weightNames, requestInit) {
    return __async(this, null, function* () {
      const fetchWeights = (fetchUrls) => loadWeightsAsArrayBuffer(fetchUrls, { requestInit });
      const loadWeights2 = weightsLoaderFactory(fetchWeights);
      return loadWeights2(manifest, filePathPrefix, weightNames);
    });
  }
  function weightsLoaderFactory(fetchWeightsFunction) {
    return (manifest, filePathPrefix = "", weightNames) => __async(this, null, function* () {
      const groupIndicesToFetchMap = manifest.map(() => false);
      const groupWeightsToFetch = {};
      const weightsFound = weightNames != null ? weightNames.map(() => false) : [];
      const allManifestWeightNames = [];
      manifest.forEach((manifestGroupConfig, groupIndex) => {
        let groupOffset = 0;
        manifestGroupConfig.weights.forEach((weightsEntry) => {
          const rawDtype = "quantization" in weightsEntry ? weightsEntry.quantization.dtype : weightsEntry.dtype;
          const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] * sizeFromShape(weightsEntry.shape);
          const enqueueWeightsForFetchingFn = () => {
            groupIndicesToFetchMap[groupIndex] = true;
            if (groupWeightsToFetch[groupIndex] == null) {
              groupWeightsToFetch[groupIndex] = [];
            }
            groupWeightsToFetch[groupIndex].push({
              manifestEntry: weightsEntry,
              groupOffset,
              sizeBytes: weightsBytes
            });
          };
          if (weightNames != null) {
            weightNames.forEach((weightName, weightIndex) => {
              if (weightName === weightsEntry.name) {
                enqueueWeightsForFetchingFn();
                weightsFound[weightIndex] = true;
              }
            });
          } else {
            enqueueWeightsForFetchingFn();
          }
          allManifestWeightNames.push(weightsEntry.name);
          groupOffset += weightsBytes;
        });
      });
      if (!weightsFound.every((found) => found)) {
        const weightsNotFound = weightNames.filter((_2, i) => !weightsFound[i]);
        throw new Error(`Could not find weights in manifest with names: ${weightsNotFound.join(", ")}. 
Manifest JSON has weights with names: ${allManifestWeightNames.join(", ")}.`);
      }
      const groupIndicesToFetch = groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {
        if (shouldFetch) {
          accumulator.push(i);
        }
        return accumulator;
      }, []);
      const fetchUrls = [];
      groupIndicesToFetch.forEach((i) => {
        manifest[i].paths.forEach((filepath) => {
          const fetchUrl = filePathPrefix + (!filePathPrefix.endsWith("/") ? "/" : "") + filepath;
          fetchUrls.push(fetchUrl);
        });
      });
      const buffers = yield fetchWeightsFunction(fetchUrls);
      const weightsTensorMap = {};
      let bufferIndexOffset = 0;
      groupIndicesToFetch.forEach((i) => {
        const numBuffers = manifest[i].paths.length;
        let groupBytes = 0;
        for (let i2 = 0; i2 < numBuffers; i2++) {
          groupBytes += buffers[bufferIndexOffset + i2].byteLength;
        }
        const groupBuffer = new ArrayBuffer(groupBytes);
        const groupByteBuffer = new Uint8Array(groupBuffer);
        let groupBufferOffset = 0;
        for (let i2 = 0; i2 < numBuffers; i2++) {
          const buffer2 = new Uint8Array(buffers[bufferIndexOffset + i2]);
          groupByteBuffer.set(buffer2, groupBufferOffset);
          groupBufferOffset += buffer2.byteLength;
        }
        const weightsEntries = groupWeightsToFetch[i];
        weightsEntries.forEach((weightsEntry) => {
          const byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);
          const nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);
          for (const name in nameToTensorMap) {
            weightsTensorMap[name] = nameToTensorMap[name];
          }
        });
        bufferIndexOffset += numBuffers;
      });
      return weightsTensorMap;
    });
  }
  var init_weights_loader = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js"() {
      init_environment();
      init_util();
      init_io_utils();
      init_progress();
      init_types2();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/http.js
  function parseUrl(url) {
    const lastSlash = url.lastIndexOf("/");
    const lastSearchParam = url.lastIndexOf("?");
    const prefix = url.substring(0, lastSlash);
    const suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : "";
    return [prefix + "/", suffix];
  }
  function isHTTPScheme(url) {
    return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;
  }
  function http(path, loadOptions) {
    return new HTTPRequest(path, loadOptions);
  }
  function browserHTTPRequest(path, loadOptions) {
    return http(path, loadOptions);
  }
  var OCTET_STREAM_MIME_TYPE, JSON_TYPE, HTTPRequest, httpRouter;
  var init_http = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/io/http.js"() {
      init_environment();
      init_util();
      init_io_utils();
      init_router_registry();
      init_weights_loader();
      OCTET_STREAM_MIME_TYPE = "application/octet-stream";
      JSON_TYPE = "application/json";
      HTTPRequest = class {
        constructor(path, loadOptions) {
          this.DEFAULT_METHOD = "POST";
          if (loadOptions == null) {
            loadOptions = {};
          }
          this.weightPathPrefix = loadOptions.weightPathPrefix;
          this.onProgress = loadOptions.onProgress;
          this.weightUrlConverter = loadOptions.weightUrlConverter;
          if (loadOptions.fetchFunc != null) {
            assert(typeof loadOptions.fetchFunc === "function", () => "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)");
            this.fetch = loadOptions.fetchFunc;
          } else {
            this.fetch = env().platform.fetch;
          }
          assert(path != null && path.length > 0, () => "URL path for http must not be null, undefined or empty.");
          if (Array.isArray(path)) {
            assert(path.length === 2, () => `URL paths for http must have a length of 2, (actual length is ${path.length}).`);
          }
          this.path = path;
          if (loadOptions.requestInit != null && loadOptions.requestInit.body != null) {
            throw new Error("requestInit is expected to have no pre-existing body, but has one.");
          }
          this.requestInit = loadOptions.requestInit || {};
        }
        save(modelArtifacts) {
          return __async(this, null, function* () {
            if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
              throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
            }
            const init = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);
            init.body = new FormData();
            const weightsManifest = [{
              paths: ["./model.weights.bin"],
              weights: modelArtifacts.weightSpecs
            }];
            const modelTopologyAndWeightManifest = getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);
            init.body.append("model.json", new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE }), "model.json");
            if (modelArtifacts.weightData != null) {
              init.body.append("model.weights.bin", new Blob([modelArtifacts.weightData], { type: OCTET_STREAM_MIME_TYPE }), "model.weights.bin");
            }
            const response = yield this.fetch(this.path, init);
            if (response.ok) {
              return {
                modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts),
                responses: [response]
              };
            } else {
              throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${response.status}.`);
            }
          });
        }
        /**
         * Load model artifacts via HTTP request(s).
         *
         * See the documentation to `tf.io.http` for details on the saved
         * artifacts.
         *
         * @returns The loaded model artifacts (if loading succeeds).
         */
        load() {
          return __async(this, null, function* () {
            const modelConfigRequest = yield this.fetch(this.path, this.requestInit);
            if (!modelConfigRequest.ok) {
              throw new Error(`Request to ${this.path} failed with status code ${modelConfigRequest.status}. Please verify this URL points to the model JSON of the model to load.`);
            }
            let modelJSON;
            try {
              modelJSON = yield modelConfigRequest.json();
            } catch (e) {
              let message = `Failed to parse model JSON of response from ${this.path}.`;
              if (this.path.endsWith(".pb")) {
                message += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.";
              } else {
                message += " Please make sure the server is serving valid JSON for this request.";
              }
              throw new Error(message);
            }
            const modelTopology = modelJSON.modelTopology;
            const weightsManifest = modelJSON.weightsManifest;
            if (modelTopology == null && weightsManifest == null) {
              throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);
            }
            return getModelArtifactsForJSON(modelJSON, (weightsManifest2) => this.loadWeights(weightsManifest2));
          });
        }
        loadWeights(weightsManifest) {
          return __async(this, null, function* () {
            const weightPath = Array.isArray(this.path) ? this.path[1] : this.path;
            const [prefix, suffix] = parseUrl(weightPath);
            const pathPrefix = this.weightPathPrefix || prefix;
            const weightSpecs = getWeightSpecs(weightsManifest);
            const fetchURLs = [];
            const urlPromises = [];
            for (const weightsGroup of weightsManifest) {
              for (const path of weightsGroup.paths) {
                if (this.weightUrlConverter != null) {
                  urlPromises.push(this.weightUrlConverter(path));
                } else {
                  fetchURLs.push(pathPrefix + path + suffix);
                }
              }
            }
            if (this.weightUrlConverter) {
              fetchURLs.push(...yield Promise.all(urlPromises));
            }
            const buffers = yield loadWeightsAsArrayBuffer(fetchURLs, {
              requestInit: this.requestInit,
              fetchFunc: this.fetch,
              onProgress: this.onProgress
            });
            return [weightSpecs, concatenateArrayBuffers(buffers)];
          });
        }
      };
      HTTPRequest.URL_SCHEME_REGEX = /^https?:\/\//;
      httpRouter = (url, loadOptions) => {
        if (typeof fetch === "undefined" && (loadOptions == null || loadOptions.fetchFunc == null)) {
          return null;
        } else {
          let isHTTP = true;
          if (Array.isArray(url)) {
            isHTTP = url.every((urlItem) => isHTTPScheme(urlItem));
          } else {
            isHTTP = isHTTPScheme(url);
          }
          if (isHTTP) {
            return http(url, loadOptions);
          }
        }
        return null;
      };
      IORouterRegistry.registerSaveRouter(httpRouter);
      IORouterRegistry.registerLoadRouter(httpRouter);
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js
  function fromMemory(modelArtifacts, weightSpecs, weightData, trainingConfig) {
    const args = arguments;
    return new PassthroughAsync(fromMemorySync(...args));
  }
  function fromMemorySync(modelArtifacts, weightSpecs, weightData, trainingConfig) {
    if (arguments.length === 1) {
      const isModelArtifacts = modelArtifacts.modelTopology != null || modelArtifacts.weightSpecs != null;
      if (isModelArtifacts) {
        return new PassthroughLoader(modelArtifacts);
      } else {
        console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
        return new PassthroughLoader({ modelTopology: modelArtifacts });
      }
    } else {
      console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
      return new PassthroughLoader({
        modelTopology: modelArtifacts,
        weightSpecs,
        weightData,
        trainingConfig
      });
    }
  }
  function withSaveHandler(saveHandler) {
    return new PassthroughSaver(saveHandler);
  }
  function withSaveHandlerSync(saveHandler) {
    return new PassthroughSaver(saveHandler);
  }
  var PassthroughLoader, PassthroughSaver, PassthroughAsync;
  var init_passthrough = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js"() {
      PassthroughLoader = class {
        constructor(modelArtifacts) {
          this.modelArtifacts = modelArtifacts;
        }
        load() {
          return this.modelArtifacts;
        }
      };
      PassthroughSaver = class {
        constructor(saveHandler) {
          this.saveHandler = saveHandler;
        }
        save(modelArtifacts) {
          return this.saveHandler(modelArtifacts);
        }
      };
      PassthroughAsync = class {
        constructor(handler) {
          if (handler.load) {
            this.load = () => Promise.resolve(handler.load());
          }
          if (handler.save) {
            this.save = (modelArtifacts) => Promise.resolve(handler.save(modelArtifacts));
          }
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/io/io.js
  var io_exports = {};
  __export(io_exports, {
    browserFiles: () => browserFiles,
    browserHTTPRequest: () => browserHTTPRequest,
    concatenateArrayBuffers: () => concatenateArrayBuffers,
    copyModel: () => copyModel,
    decodeWeights: () => decodeWeights,
    encodeWeights: () => encodeWeights,
    fromMemory: () => fromMemory,
    fromMemorySync: () => fromMemorySync,
    getLoadHandlers: () => getLoadHandlers,
    getModelArtifactsForJSON: () => getModelArtifactsForJSON,
    getModelArtifactsForJSONSync: () => getModelArtifactsForJSONSync,
    getModelArtifactsInfoForJSON: () => getModelArtifactsInfoForJSON,
    getSaveHandlers: () => getSaveHandlers,
    getWeightSpecs: () => getWeightSpecs,
    http: () => http,
    isHTTPScheme: () => isHTTPScheme,
    listModels: () => listModels,
    loadWeights: () => loadWeights,
    moveModel: () => moveModel,
    registerLoadRouter: () => registerLoadRouter,
    registerSaveRouter: () => registerSaveRouter,
    removeModel: () => removeModel,
    weightsLoaderFactory: () => weightsLoaderFactory,
    withSaveHandler: () => withSaveHandler,
    withSaveHandlerSync: () => withSaveHandlerSync
  });
  var init_io = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/io/io.js"() {
      init_indexed_db();
      init_local_storage();
      init_browser_files();
      init_http();
      init_io_utils();
      init_passthrough();
      init_router_registry();
      init_weights_loader();
      init_model_management();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/browser.js
  var browser_exports = {};
  __export(browser_exports, {
    fromPixels: () => fromPixels,
    fromPixelsAsync: () => fromPixelsAsync,
    toPixels: () => toPixels
  });
  function fromPixels_(pixels, numChannels = 3) {
    if (numChannels > 4) {
      throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");
    }
    if (pixels == null) {
      throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
    }
    let isPixelData2 = false;
    let isImageData = false;
    let isVideo = false;
    let isImage = false;
    let isCanvasLike = false;
    let isImageBitmap = false;
    if (pixels.data instanceof Uint8Array) {
      isPixelData2 = true;
    } else if (typeof ImageData !== "undefined" && pixels instanceof ImageData) {
      isImageData = true;
    } else if (typeof HTMLVideoElement !== "undefined" && pixels instanceof HTMLVideoElement) {
      isVideo = true;
    } else if (typeof HTMLImageElement !== "undefined" && pixels instanceof HTMLImageElement) {
      isImage = true;
    } else if (pixels.getContext != null) {
      isCanvasLike = true;
    } else if (typeof ImageBitmap !== "undefined" && pixels instanceof ImageBitmap) {
      isImageBitmap = true;
    } else {
      throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${pixels.constructor.name}`);
    }
    const kernel = getKernel(FromPixels, ENGINE.backendName);
    if (kernel != null) {
      const inputs = { pixels };
      const attrs = { numChannels };
      return ENGINE.runKernel(FromPixels, inputs, attrs);
    }
    const [width, height] = isVideo ? [
      pixels.videoWidth,
      pixels.videoHeight
    ] : [pixels.width, pixels.height];
    let vals;
    if (isCanvasLike) {
      vals = // tslint:disable-next-line:no-any
      pixels.getContext("2d").getImageData(0, 0, width, height).data;
    } else if (isImageData || isPixelData2) {
      vals = pixels.data;
    } else if (isImage || isVideo || isImageBitmap) {
      if (fromPixels2DContext == null) {
        if (typeof document === "undefined") {
          if (typeof OffscreenCanvas !== "undefined" && typeof OffscreenCanvasRenderingContext2D !== "undefined") {
            fromPixels2DContext = new OffscreenCanvas(1, 1).getContext("2d");
          } else {
            throw new Error("Cannot parse input in current context. Reason: OffscreenCanvas Context2D rendering is not supported.");
          }
        } else {
          fromPixels2DContext = document.createElement("canvas").getContext("2d", { willReadFrequently: true });
        }
      }
      fromPixels2DContext.canvas.width = width;
      fromPixels2DContext.canvas.height = height;
      fromPixels2DContext.drawImage(pixels, 0, 0, width, height);
      vals = fromPixels2DContext.getImageData(0, 0, width, height).data;
    }
    let values;
    if (numChannels === 4) {
      values = new Int32Array(vals);
    } else {
      const numPixels = width * height;
      values = new Int32Array(numPixels * numChannels);
      for (let i = 0; i < numPixels; i++) {
        for (let channel = 0; channel < numChannels; ++channel) {
          values[i * numChannels + channel] = vals[i * 4 + channel];
        }
      }
    }
    const outShape = [height, width, numChannels];
    return tensor3d(values, outShape, "int32");
  }
  function isPixelData(pixels) {
    return pixels != null && pixels.data instanceof Uint8Array;
  }
  function isImageBitmapFullySupported() {
    return typeof window !== "undefined" && typeof ImageBitmap !== "undefined" && window.hasOwnProperty("createImageBitmap");
  }
  function isNonEmptyPixels(pixels) {
    return pixels != null && pixels.width !== 0 && pixels.height !== 0;
  }
  function canWrapPixelsToImageBitmap(pixels) {
    return isImageBitmapFullySupported() && !(pixels instanceof ImageBitmap) && isNonEmptyPixels(pixels) && !isPixelData(pixels);
  }
  function fromPixelsAsync(pixels, numChannels = 3) {
    return __async(this, null, function* () {
      let inputs = null;
      if (env().getBool("WRAP_TO_IMAGEBITMAP") && canWrapPixelsToImageBitmap(pixels)) {
        let imageBitmap;
        try {
          imageBitmap = yield createImageBitmap(pixels, { premultiplyAlpha: "none" });
        } catch (e) {
          imageBitmap = null;
        }
        if (imageBitmap != null && imageBitmap.width === pixels.width && imageBitmap.height === pixels.height) {
          inputs = imageBitmap;
        } else {
          inputs = pixels;
        }
      } else {
        inputs = pixels;
      }
      return fromPixels_(inputs, numChannels);
    });
  }
  function toPixels(img, canvas) {
    return __async(this, null, function* () {
      let $img = convertToTensor(img, "img", "toPixels");
      if (!(img instanceof Tensor)) {
        const originalImgTensor = $img;
        $img = cast(originalImgTensor, "int32");
        originalImgTensor.dispose();
      }
      if ($img.rank !== 2 && $img.rank !== 3) {
        throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${$img.rank}.`);
      }
      const [height, width] = $img.shape.slice(0, 2);
      const depth = $img.rank === 2 ? 1 : $img.shape[2];
      if (depth > 4 || depth === 2) {
        throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${depth}`);
      }
      if ($img.dtype !== "float32" && $img.dtype !== "int32") {
        throw new Error(`Unsupported type for toPixels: ${$img.dtype}. Please use float32 or int32 tensors.`);
      }
      const data = yield $img.data();
      const multiplier = $img.dtype === "float32" ? 255 : 1;
      const bytes = new Uint8ClampedArray(width * height * 4);
      for (let i = 0; i < height * width; ++i) {
        const rgba = [0, 0, 0, 255];
        for (let d = 0; d < depth; d++) {
          const value = data[i * depth + d];
          if ($img.dtype === "float32") {
            if (value < 0 || value > 1) {
              throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${value}.`);
            }
          } else if ($img.dtype === "int32") {
            if (value < 0 || value > 255) {
              throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${value}.`);
            }
          }
          if (depth === 1) {
            rgba[0] = value * multiplier;
            rgba[1] = value * multiplier;
            rgba[2] = value * multiplier;
          } else {
            rgba[d] = value * multiplier;
          }
        }
        const j2 = i * 4;
        bytes[j2 + 0] = Math.round(rgba[0]);
        bytes[j2 + 1] = Math.round(rgba[1]);
        bytes[j2 + 2] = Math.round(rgba[2]);
        bytes[j2 + 3] = Math.round(rgba[3]);
      }
      if (canvas != null) {
        canvas.width = width;
        canvas.height = height;
        const ctx = canvas.getContext("2d");
        const imageData = new ImageData(bytes, width, height);
        ctx.putImageData(imageData, 0, 0);
      }
      if ($img !== img) {
        $img.dispose();
      }
      return bytes;
    });
  }
  var fromPixels2DContext, fromPixels;
  var init_browser = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/browser.js"() {
      init_engine();
      init_environment();
      init_kernel_names();
      init_kernel_registry();
      init_tensor();
      init_tensor_util_env();
      init_cast();
      init_operation();
      init_tensor3d();
      fromPixels = /* @__PURE__ */ op({ fromPixels_ });
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js
  function prepareAndValidate(tensor2, indices) {
    const tensorRank = tensor2.shape.length;
    const indicesRank = indices.shape.length;
    if (tensorRank < 1) {
      throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${tensorRank}.`);
    }
    if (indicesRank < 1) {
      throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${indicesRank}.`);
    }
    if (indices.dtype !== "int32") {
      throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${indices.dtype}.`);
    }
    if (indices.shape[indicesRank - 1] > tensorRank) {
      throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${indices.shape[indicesRank - 1]} vs. ${tensorRank}`);
    }
    if (sizeFromShape(tensor2.shape) === 0) {
      throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${tensor2.shape}.`);
    }
    const indicesShape = indices.shape;
    const sliceRank = indicesShape[indicesShape.length - 1];
    let nResult = 1;
    for (let i = 0; i < indicesShape.length - 1; ++i) {
      nResult *= indicesShape[i];
    }
    const inputShape = tensor2.shape;
    const resultShape = indicesShape.slice();
    resultShape.pop();
    let sliceSize = 1;
    for (let i = sliceRank; i < tensorRank; ++i) {
      sliceSize *= inputShape[i];
      resultShape.push(inputShape[i]);
    }
    const strides = [
      ...computeStrides(tensor2.shape).map((stride) => stride / sliceSize),
      1
    ].slice(0, sliceRank);
    return [resultShape, nResult, sliceSize, strides];
  }
  var init_gather_nd_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js"() {
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js
  var slice_util_exports = {};
  __export(slice_util_exports, {
    assertParamsValid: () => assertParamsValid,
    computeFlatOffset: () => computeFlatOffset,
    computeOutShape: () => computeOutShape,
    getNormalizedAxes: () => getNormalizedAxes,
    isSliceContinous: () => isSliceContinous,
    maskToAxes: () => maskToAxes,
    parseSliceParams: () => parseSliceParams,
    sliceInfo: () => sliceInfo,
    startForAxis: () => startForAxis,
    startIndicesWithElidedDims: () => startIndicesWithElidedDims,
    stopForAxis: () => stopForAxis,
    stopIndicesWithElidedDims: () => stopIndicesWithElidedDims,
    stridesForAxis: () => stridesForAxis,
    stridesWithElidedDims: () => stridesWithElidedDims
  });
  function assertParamsValid(input, begin, size) {
    const inputRank = input.shape.length;
    assert(inputRank === begin.length, () => `Error in slice${inputRank}D: Length of begin ${begin} must match the rank of the array (${inputRank}).`);
    assert(inputRank === size.length, () => `Error in slice${inputRank}D: Length of size ${size} must match the rank of the array (${inputRank}).`);
    for (let i = 0; i < inputRank; ++i) {
      assert(begin[i] + size[i] <= input.shape[i], () => `Error in slice${inputRank}D: begin[${i}] + size[${i}] (${begin[i] + size[i]}) would overflow input.shape[${i}] (${input.shape[i]})`);
    }
  }
  function maskToAxes(mask) {
    const axes = [];
    let axis = 0;
    while (mask > 0) {
      if (mask & 1) {
        axes.push(axis);
      }
      mask /= 2;
      axis++;
    }
    return axes;
  }
  function computeOutShape(begin, end, strides) {
    const size = [];
    for (let axis = 0; axis < begin.length; axis++) {
      size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);
    }
    return size;
  }
  function stridesWithElidedDims(strides, ellipsisInsertionIndex, numElidedAxes, inputShape) {
    const newStrides = [...strides];
    for (let i = newStrides.length; i < inputShape.length; i++) {
      newStrides.push(1);
    }
    for (let i = 0; i < numElidedAxes; i++) {
      if (i === 0) {
        newStrides[ellipsisInsertionIndex] = 1;
      } else {
        newStrides.splice(
          ellipsisInsertionIndex,
          0,
          1
          /* element to add */
        );
        newStrides.pop();
      }
    }
    return newStrides;
  }
  function unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, normalizedAxis) {
    if (normalizedAxis <= ellipsisInsertionIndex) {
      return normalizedAxis;
    }
    return normalizedAxis - (numElidedAxes - 1);
  }
  function getElidedAxes(numElidedAxes, ellipsisInsertionIndex) {
    const elidedAxes = [];
    for (let i = 0; i < numElidedAxes; i++) {
      elidedAxes.push(ellipsisInsertionIndex + i);
    }
    return elidedAxes;
  }
  function getNormalizedAxes(inputShape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask) {
    const inputRank = inputShape.length;
    let normalizedBegin = new Array(inputRank), normalizedEnd = new Array(inputRank), normalizedStrides = new Array(inputRank);
    if (ellipsisAxes.length && numInterpolatedAxes > 0) {
      const fullIndex = ellipsisAxes[0];
      const numElidedAxes = numInterpolatedAxes + 1;
      normalizedBegin = startIndicesWithElidedDims(beginMask, fullIndex, numElidedAxes, begin, inputShape);
      normalizedEnd = stopIndicesWithElidedDims(endMask, fullIndex, numElidedAxes, end, inputShape);
      normalizedStrides = stridesWithElidedDims(strides, fullIndex, numElidedAxes, inputShape);
    } else {
      for (let axis = 0; axis < inputRank; axis++) {
        normalizedBegin[axis] = startForAxis(beginMask, begin, strides, inputShape, axis, ellipsisMask);
        normalizedEnd[axis] = stopForAxis(endMask, end, strides, inputShape, axis, ellipsisMask);
        normalizedStrides[axis] = stridesForAxis(strides, axis, ellipsisMask);
      }
    }
    return {
      begin: normalizedBegin,
      end: normalizedEnd,
      strides: normalizedStrides
    };
  }
  function startIndicesWithElidedDims(beginMask, ellipsisInsertionIndex, numElidedAxes, originalBegin, inputShape) {
    const newIndices = [...inputShape];
    const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
    for (let axis = 0; axis < newIndices.length; axis++) {
      if (elidedAxes.indexOf(axis) > -1) {
        newIndices[axis] = 0;
      } else {
        const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
        let originalValue = originalBegin[originalAxis];
        if (beginMask & 1 << originalAxis) {
          originalValue = 0;
        }
        newIndices[axis] = originalValue;
      }
    }
    return newIndices;
  }
  function stopIndicesWithElidedDims(endMask, ellipsisInsertionIndex, numElidedAxes, originalEnd, inputShape) {
    const newIndices = [...inputShape];
    const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
    for (let axis = 0; axis < newIndices.length; axis++) {
      if (elidedAxes.indexOf(axis) > -1) {
        newIndices[axis] = Number.MAX_SAFE_INTEGER;
      } else {
        const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
        let originalValue = originalEnd[originalAxis];
        if (endMask & 1 << originalAxis) {
          originalValue = Number.MAX_SAFE_INTEGER;
        }
        newIndices[axis] = originalValue;
      }
    }
    for (let i = 0; i < newIndices.length; i++) {
      const axisSize = inputShape[i];
      if (newIndices[i] < 0) {
        newIndices[i] += axisSize;
      }
      newIndices[i] = clamp(0, newIndices[i], inputShape[i]);
    }
    return newIndices;
  }
  function stridesForAxis(strides, axis, ellipsisMask) {
    let stride = strides[axis];
    if (ellipsisMask & 1 << axis || stride == null) {
      stride = 1;
    }
    return stride;
  }
  function startForAxis(beginMask, startIndices, strides, inputShape, axis, ellipsisMask) {
    let start = startIndices[axis];
    const stride = strides[axis] || 1;
    if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {
      if (stride > 0) {
        start = Number.MIN_SAFE_INTEGER;
      } else {
        start = Number.MAX_SAFE_INTEGER;
      }
    }
    const axisSize = inputShape[axis];
    if (start < 0) {
      start += axisSize;
    }
    start = clamp(0, start, axisSize - 1);
    return start;
  }
  function stopForAxis(endMask, stopIndices, strides, inputShape, axis, ellipsisMask) {
    let stop = stopIndices[axis];
    const stride = strides[axis] || 1;
    if (endMask & 1 << axis || ellipsisMask & 1 << axis || stop == null) {
      if (stride > 0) {
        stop = Number.MAX_SAFE_INTEGER;
      } else {
        stop = Number.MIN_SAFE_INTEGER;
      }
    }
    const axisSize = inputShape[axis];
    if (stop < 0) {
      stop += axisSize;
    }
    if (stride > 0) {
      stop = clamp(0, stop, axisSize);
    } else {
      stop = clamp(-1, stop, axisSize - 1);
    }
    return stop;
  }
  function isSliceContinous(shape, begin, size) {
    let firstNonOneAxis = size.length;
    for (let i = 0; i < size.length; i++) {
      if (size[i] > 1) {
        firstNonOneAxis = i;
        break;
      }
    }
    for (let i = firstNonOneAxis + 1; i < size.length; i++) {
      if (begin[i] > 0 || size[i] !== shape[i]) {
        return false;
      }
    }
    return true;
  }
  function computeFlatOffset(begin, strides) {
    let flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;
    for (let i = 0; i < begin.length - 1; i++) {
      flatOffset += begin[i] * strides[i];
    }
    return flatOffset;
  }
  function parseSliceParams(x, begin, size) {
    let begin_;
    const xRank = x.shape.length;
    if (typeof begin === "number") {
      begin_ = [begin, ...new Array(xRank - 1).fill(0)];
    } else if (begin.length < xRank) {
      begin_ = begin.concat(new Array(xRank - begin.length).fill(0));
    } else {
      begin_ = begin.slice();
    }
    begin_.forEach((d) => {
      assert(d !== -1, () => "slice() does not support negative begin indexing.");
    });
    let size_;
    if (size == null) {
      size_ = new Array(xRank).fill(-1);
    } else if (typeof size === "number") {
      size_ = [size, ...new Array(xRank - 1).fill(-1)];
    } else if (size.length < xRank) {
      size_ = size.concat(new Array(xRank - size.length).fill(-1));
    } else {
      size_ = size;
    }
    size_ = size_.map((d, i) => {
      if (d >= 0) {
        return d;
      } else {
        assert(d === -1, () => `Negative size values should be exactly -1 but got ${d} for the slice() size at index ${i}.`);
        return x.shape[i] - begin_[i];
      }
    });
    return [begin_, size_];
  }
  function sliceInfo(xShape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
    let stridesNonNull;
    if (strides == null) {
      stridesNonNull = new Array(begin.length);
      stridesNonNull.fill(1);
    } else {
      stridesNonNull = strides;
    }
    if (ellipsisMask != null && (ellipsisMask & ellipsisMask - 1) !== 0) {
      throw new Error("Multiple ellipses in slice is not allowed.");
    }
    let ellipsisSeen = false;
    const sparseSpec = {
      dims: stridesNonNull.length,
      numAddAxisAfterEllipsis: 0,
      begin: begin.slice(),
      end: end.slice(),
      strides: stridesNonNull.slice(),
      beginMask,
      endMask,
      ellipsisMask,
      newAxisMask,
      shrinkAxisMask
    };
    for (let i = 0; i < sparseSpec.dims; i++) {
      if (ellipsisSeen && (1 << i & newAxisMask) !== 0) {
        sparseSpec.numAddAxisAfterEllipsis++;
      }
      if (1 << i & ellipsisMask) {
        ellipsisSeen = true;
      }
    }
    if (!ellipsisSeen) {
      sparseSpec.ellipsisMask |= 1 << sparseSpec.dims;
      sparseSpec.dims++;
    }
    const denseSpec = {
      dims: xShape.length,
      beginMask: 0,
      endMask: 0,
      beginValid: false,
      endValid: false
    };
    buildDenseSpec(sparseSpec, denseSpec);
    let isIdentity = true;
    let sliceDim0 = true;
    let isSimpleSlice = true;
    const processingShape = [];
    const finalShape = [];
    for (let i = 0; i < xShape.length; ++i) {
      if (denseSpec.strides[i] === 0) {
        throw Error(`strides[${i}] must be non-zero`);
      }
      const shrinkI = !!(denseSpec.shrinkAxisMask & 1 << i);
      const dimI = xShape[i];
      if (dimI === -1) {
        processingShape.push(shrinkI ? 1 : -1);
        continue;
      }
      const masks = [denseSpec.beginMask & 1 << i, denseSpec.endMask & 1 << i];
      const validRange = [
        denseSpec.strides[i] > 0 ? 0 : -1,
        denseSpec.strides[i] > 0 ? dimI : dimI - 1
      ];
      if (shrinkI && denseSpec.strides[i] <= 0) {
        throw Error("only stride 1 allowed on non-range indexing.");
      }
      isSimpleSlice = isSimpleSlice && denseSpec.strides[i] === 1;
      const beginAndEndMasked = !!(denseSpec.beginMask & 1 << i && denseSpec.endMask & 1 << i);
      if (denseSpec.beginValid && denseSpec.endValid) {
        if (shrinkI) {
          const xFwd = denseSpec.begin[i] < 0 ? dimI + denseSpec.begin[i] : denseSpec.begin[i];
          denseSpec.begin[i] = xFwd;
          denseSpec.end[i] = denseSpec.begin[i] + 1;
          if (xFwd < 0 || xFwd >= dimI) {
            throw Error(`slice index ${denseSpec.begin[i]} of dimension ${i} out of bounds.`);
          }
        } else {
          denseSpec.begin[i] = canonical(denseSpec.begin[i], 0, denseSpec.strides[i], dimI, masks, validRange);
          denseSpec.end[i] = canonical(denseSpec.end[i], 1, denseSpec.strides[i], dimI, masks, validRange);
        }
        const takeAllInDimension = denseSpec.strides[i] === 1 && denseSpec.begin[i] === 0 && denseSpec.end[i] === dimI;
        isIdentity = isIdentity && takeAllInDimension;
        sliceDim0 = sliceDim0 && (i === 0 && denseSpec.strides[i] === 1 || takeAllInDimension);
      } else {
        isIdentity = isIdentity && (denseSpec.strides[i] === 1 && beginAndEndMasked);
        sliceDim0 = sliceDim0 && (i === 0 && denseSpec.strides[i] === 1 || beginAndEndMasked);
      }
      let intervalLength;
      let knownInterval = false;
      if (denseSpec.beginValid && denseSpec.endValid) {
        intervalLength = denseSpec.end[i] - denseSpec.begin[i];
        knownInterval = true;
      } else if (shrinkI) {
        intervalLength = 1;
        knownInterval = true;
      } else if (beginAndEndMasked) {
        if (dimI >= 0) {
          if (denseSpec.strides[i] < 0) {
            intervalLength = -dimI;
          } else {
            intervalLength = dimI;
          }
          knownInterval = true;
        }
      }
      if (knownInterval) {
        let sizeI;
        if (intervalLength === 0 || intervalLength < 0 !== denseSpec.strides[i] < 0) {
          sizeI = 0;
        } else {
          sizeI = Math.trunc(intervalLength / denseSpec.strides[i]) + (intervalLength % denseSpec.strides[i] !== 0 ? 1 : 0);
        }
        processingShape.push(sizeI);
      } else {
        processingShape.push(-1);
      }
    }
    for (let denseDim = 0; denseDim < denseSpec.finalShapeGatherIndices.length; ++denseDim) {
      const gatherIndex = denseSpec.finalShapeGatherIndices[denseDim];
      if (gatherIndex >= 0) {
        finalShape.push(processingShape[gatherIndex]);
      } else if (gatherIndex === NEW_AXIS) {
        finalShape.push(1);
      }
    }
    const finalShapeSparse = finalShape.filter((dim, i) => denseSpec.finalShapeGatherIndices[i] !== NEW_AXIS);
    return {
      finalShapeSparse,
      finalShape,
      isIdentity,
      sliceDim0,
      isSimpleSlice,
      begin: denseSpec.begin,
      end: denseSpec.end,
      strides: denseSpec.strides
    };
  }
  function buildDenseSpec(sparse2, dense) {
    dense.beginMask = 0;
    dense.endMask = 0;
    dense.shrinkAxisMask = 0;
    let fullIndex = 0;
    dense.beginValid = sparse2.begin != null;
    dense.endValid = sparse2.end != null;
    dense.begin = new Array(dense.dims);
    dense.end = new Array(dense.dims);
    dense.strides = new Array(dense.dims);
    dense.finalShapeGatherIndices = [];
    dense.finalShapeGatherIndicesSparse = [];
    dense.inputShapeGatherIndicesSparse = new Array(dense.dims);
    for (let i = 0; i < sparse2.dims; i++) {
      if (1 << i & sparse2.ellipsisMask) {
        const nextIndex = Math.min(dense.dims - (sparse2.dims - i) + 1 + sparse2.numAddAxisAfterEllipsis, dense.dims);
        for (; fullIndex < nextIndex; fullIndex++) {
          dense.begin[fullIndex] = 0;
          dense.end[fullIndex] = 0;
          dense.strides[fullIndex] = 1;
          dense.beginMask |= 1 << fullIndex;
          dense.endMask |= 1 << fullIndex;
          dense.finalShapeGatherIndices.push(fullIndex);
          dense.finalShapeGatherIndicesSparse.push(-1);
          dense.inputShapeGatherIndicesSparse[fullIndex] = i;
        }
      } else if (1 << i & sparse2.newAxisMask) {
        dense.finalShapeGatherIndices.push(NEW_AXIS);
        dense.finalShapeGatherIndicesSparse.push(-1);
      } else {
        if (fullIndex === dense.begin.length) {
          throw Error(`Index out of range using input dim ${fullIndex}; input has only ${dense.dims} dims, ${dense.begin.length}.`);
        }
        if (sparse2.begin != null) {
          dense.begin[fullIndex] = sparse2.begin[i];
        }
        if (sparse2.end != null) {
          dense.end[fullIndex] = sparse2.end[i];
        }
        dense.strides[fullIndex] = sparse2.strides[i];
        if (sparse2.beginMask & 1 << i) {
          dense.beginMask |= 1 << fullIndex;
        }
        if (sparse2.endMask & 1 << i) {
          dense.endMask |= 1 << fullIndex;
        }
        if (sparse2.shrinkAxisMask & 1 << i) {
          dense.finalShapeGatherIndices.push(SHRINK_AXIS);
          dense.finalShapeGatherIndicesSparse.push(-1);
          dense.shrinkAxisMask |= 1 << fullIndex;
        } else {
          dense.finalShapeGatherIndices.push(fullIndex);
          dense.finalShapeGatherIndicesSparse.push(i);
        }
        dense.inputShapeGatherIndicesSparse[fullIndex] = i;
        fullIndex++;
      }
    }
  }
  function canonical(x, c, strideI, dimI, masks, validRange) {
    if (masks[c]) {
      return strideI > 0 ? validRange[c] : validRange[c + 1 & 1];
    } else {
      const xFwd = x < 0 ? dimI + x : x;
      return xFwd < validRange[0] ? validRange[0] : xFwd > validRange[1] ? validRange[1] : xFwd;
    }
  }
  var NEW_AXIS, SHRINK_AXIS;
  var init_slice_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js"() {
      init_util();
      NEW_AXIS = -2;
      SHRINK_AXIS = -1;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/train.js
  var init_train = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/train.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js
  function assertParamsConsistent(shapes, axis) {
    const rank = shapes[0].length;
    shapes.forEach((shape, i) => {
      assert(shape.length === rank, () => `Error in concat${rank}D: rank of tensors[${i}] must be the same as the rank of the rest (${rank})`);
    });
    assert(axis >= 0 && axis < rank, () => `Error in concat${rank}D: axis must be between 0 and ${rank - 1}.`);
    const firstShape = shapes[0];
    shapes.forEach((shape, i) => {
      for (let r = 0; r < rank; r++) {
        assert(r === axis || shape[r] === firstShape[r], () => `Error in concat${rank}D: Shape of tensors[${i}] (${shape}) does not match the shape of the rest (${firstShape}) along the non-concatenated axis ${i}.`);
      }
    });
  }
  function computeOutShape2(shapes, axis) {
    const outputShape = shapes[0].slice();
    for (let i = 1; i < shapes.length; i++) {
      outputShape[axis] += shapes[i][axis];
    }
    return outputShape;
  }
  var init_concat_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js"() {
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/fused_types.js
  var init_fused_types = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/fused_types.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/ragged_to_dense_util.js
  function combineRaggedTensorToTensorShapes(raggedRank, shape, valueShape) {
    let outputShape = new Array();
    if (valueShape == null && shape == null) {
      return outputShape;
    }
    if (shape == null) {
      while (outputShape.length < raggedRank + valueShape.length) {
        outputShape.push(-1);
      }
    } else {
      outputShape = shape.slice();
    }
    if (valueShape == null) {
      return outputShape;
    }
    if (raggedRank + valueShape.length !== outputShape.length) {
      throw new Error(`rt input.shape and shape=${shape} are incompatible: rt input.rank = ${raggedRank + valueShape.length}, but shape.rank = ${outputShape.length}`);
    }
    for (let i = 1; i < valueShape.length; ++i) {
      const valueDim = valueShape[i];
      const outputShapeDimIndex = outputShape[outputShape.length - valueShape.length + i];
      const outputShapeDim = outputShape[outputShapeDimIndex];
      if (valueDim >= 0) {
        if (outputShapeDim >= 0) {
          if (outputShapeDim !== valueDim) {
            throw new Error(`rt input.shape and shape=${shape} are incompatible: rt input.shape[${i + raggedRank}] = ${valueDim} but shape[${i + raggedRank}] = ${outputShapeDim}`);
          }
        } else {
          outputShape[outputShapeDimIndex] = valueDim;
        }
      }
    }
    return outputShape;
  }
  function getRowPartitionTypesHelper(rowPartitionTypeStrings) {
    const stringToType = {
      "FIRST_DIM_SIZE": RowPartitionType.FIRST_DIM_SIZE,
      "VALUE_ROWIDS": RowPartitionType.VALUE_ROWIDS,
      "ROW_LENGTHS": RowPartitionType.ROW_LENGTHS,
      "ROW_SPLITS": RowPartitionType.ROW_SPLITS,
      "ROW_LIMITS": RowPartitionType.ROW_LIMITS,
      "ROW_STARTS": RowPartitionType.ROW_STARTS
    };
    const result = [];
    for (const typeStr of rowPartitionTypeStrings) {
      if (typeStr in stringToType) {
        result.push(stringToType[typeStr]);
      } else {
        break;
      }
    }
    return result;
  }
  function getRaggedRank(rowPartitionTypes) {
    if (rowPartitionTypes.length === 0) {
      return 0;
    }
    if (rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {
      return rowPartitionTypes.length - 1;
    }
    return rowPartitionTypes.length;
  }
  function validateDefaultValueShape(defaultValueShape, valueShape) {
    if (defaultValueShape == null || valueShape == null) {
      return;
    }
    const defaultNDims = defaultValueShape.length;
    const valuesNDims = valueShape.length;
    if (defaultNDims >= valuesNDims) {
      throw new Error(`defaultValue.shape=${defaultValueShape} and ragged tensor flatValues.shape=${valueShape}, are incompatible: defaultValue.rank = ${defaultNDims} must be less than ragged tensor input flatValues.rank = ${valuesNDims})`);
    }
    for (let i = 0; i < Math.min(defaultNDims, valuesNDims - 1); ++i) {
      const defaultDim = defaultValueShape[i];
      const valueDim = valueShape[i + 1];
      if (defaultDim >= 0 && valueDim >= 0 && defaultDim !== 1 && defaultDim !== valueDim) {
        throw new Error(`defaultValue.shape=${defaultValueShape}, and ragged tensor input flatValues.shape=${valueShape} are incompatible: defaultValue.shape[${i - defaultValueShape.length}] = ${defaultDim} but ragged tensor input.flatValues.shape[${i - defaultValueShape.length}] = ${valueDim}`);
      }
    }
  }
  var RowPartitionType;
  var init_ragged_to_dense_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/ragged_to_dense_util.js"() {
      (function(RowPartitionType3) {
        RowPartitionType3[RowPartitionType3["FIRST_DIM_SIZE"] = 0] = "FIRST_DIM_SIZE";
        RowPartitionType3[RowPartitionType3["VALUE_ROWIDS"] = 1] = "VALUE_ROWIDS";
        RowPartitionType3[RowPartitionType3["ROW_LENGTHS"] = 2] = "ROW_LENGTHS";
        RowPartitionType3[RowPartitionType3["ROW_SPLITS"] = 3] = "ROW_SPLITS";
        RowPartitionType3[RowPartitionType3["ROW_LIMITS"] = 4] = "ROW_LIMITS";
        RowPartitionType3[RowPartitionType3["ROW_STARTS"] = 5] = "ROW_STARTS";
      })(RowPartitionType || (RowPartitionType = {}));
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js
  function computeOptimalWindowSize(inSize) {
    if (inSize <= PARALLELIZE_THRESHOLD) {
      return inSize;
    }
    return nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
  }
  var PARALLELIZE_THRESHOLD;
  var init_reduce_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js"() {
      init_util();
      PARALLELIZE_THRESHOLD = 30;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/rotate_util.js
  function getImageCenter(center, imageHeight, imageWidth) {
    const centerX = imageWidth * (typeof center === "number" ? center : center[0]);
    const centerY = imageHeight * (typeof center === "number" ? center : center[1]);
    return [centerX, centerY];
  }
  var init_rotate_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/rotate_util.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js
  function getReshaped(inputShape, blockShape, prod3, batchToSpace = true) {
    let reshaped = [];
    if (batchToSpace) {
      reshaped = reshaped.concat(blockShape.slice(0));
      reshaped.push(inputShape[0] / prod3);
      reshaped = reshaped.concat(inputShape.slice(1));
    } else {
      reshaped = reshaped.concat(inputShape[0]);
      const spatialLength = blockShape.length;
      for (let i = 0; i < spatialLength; ++i) {
        reshaped = reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);
      }
      reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));
    }
    return reshaped;
  }
  function getPermuted(reshapedRank, blockShapeRank, batchToSpace = true) {
    const permuted = [];
    if (batchToSpace) {
      permuted.push(blockShapeRank);
      for (let i = blockShapeRank + 1; i < reshapedRank; ++i) {
        if (i <= 2 * blockShapeRank) {
          permuted.push(i);
          permuted.push(i - (blockShapeRank + 1));
        } else {
          permuted.push(i);
        }
      }
    } else {
      const permutedBeforeBatch = [];
      const permutedAfterBatch = [];
      for (let i = 1; i < reshapedRank; ++i) {
        if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {
          permutedAfterBatch.push(i);
        } else {
          permutedBeforeBatch.push(i);
        }
      }
      permuted.push(...permutedBeforeBatch);
      permuted.push(0);
      permuted.push(...permutedAfterBatch);
    }
    return permuted;
  }
  function getReshapedPermuted(inputShape, blockShape, prod3, batchToSpace = true) {
    const reshapedPermuted = [];
    if (batchToSpace) {
      reshapedPermuted.push(inputShape[0] / prod3);
    } else {
      reshapedPermuted.push(inputShape[0] * prod3);
    }
    for (let i = 1; i < inputShape.length; ++i) {
      if (i <= blockShape.length) {
        if (batchToSpace) {
          reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);
        } else {
          reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);
        }
      } else {
        reshapedPermuted.push(inputShape[i]);
      }
    }
    return reshapedPermuted;
  }
  function getSliceBeginCoords(crops, blockShape) {
    const sliceBeginCoords = [0];
    for (let i = 0; i < blockShape; ++i) {
      sliceBeginCoords.push(crops[i][0]);
    }
    return sliceBeginCoords;
  }
  function getSliceSize(uncroppedShape, crops, blockShape) {
    const sliceSize = uncroppedShape.slice(0, 1);
    for (let i = 0; i < blockShape; ++i) {
      sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);
    }
    return sliceSize;
  }
  var init_array_ops_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js
  var SELU_SCALEALPHA, SELU_SCALE;
  var init_selu_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js"() {
      SELU_SCALEALPHA = 1.7580993408473768;
      SELU_SCALE = 1.0507009873554805;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js
  var ERF_P, ERF_A1, ERF_A2, ERF_A3, ERF_A4, ERF_A5;
  var init_erf_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js"() {
      ERF_P = 0.3275911;
      ERF_A1 = 0.254829592;
      ERF_A2 = -0.284496736;
      ERF_A3 = 1.421413741;
      ERF_A4 = -1.453152027;
      ERF_A5 = 1.061405429;
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js
  function mergeRealAndImagArrays(real3, imag3) {
    if (real3.length !== imag3.length) {
      throw new Error(`Cannot merge real and imag arrays of different lengths. real:${real3.length}, imag: ${imag3.length}.`);
    }
    const result = new Float32Array(real3.length * 2);
    for (let i = 0; i < result.length; i += 2) {
      result[i] = real3[i / 2];
      result[i + 1] = imag3[i / 2];
    }
    return result;
  }
  function splitRealAndImagArrays(complex3) {
    const real3 = new Float32Array(complex3.length / 2);
    const imag3 = new Float32Array(complex3.length / 2);
    for (let i = 0; i < complex3.length; i += 2) {
      real3[i / 2] = complex3[i];
      imag3[i / 2] = complex3[i + 1];
    }
    return { real: real3, imag: imag3 };
  }
  function complexWithEvenIndex(complex3) {
    const len = Math.ceil(complex3.length / 4);
    const real3 = new Float32Array(len);
    const imag3 = new Float32Array(len);
    for (let i = 0; i < complex3.length; i += 4) {
      real3[Math.floor(i / 4)] = complex3[i];
      imag3[Math.floor(i / 4)] = complex3[i + 1];
    }
    return { real: real3, imag: imag3 };
  }
  function complexWithOddIndex(complex3) {
    const len = Math.floor(complex3.length / 4);
    const real3 = new Float32Array(len);
    const imag3 = new Float32Array(len);
    for (let i = 2; i < complex3.length; i += 4) {
      real3[Math.floor(i / 4)] = complex3[i];
      imag3[Math.floor(i / 4)] = complex3[i + 1];
    }
    return { real: real3, imag: imag3 };
  }
  function getComplexWithIndex(complex3, index) {
    const real3 = complex3[index * 2];
    const imag3 = complex3[index * 2 + 1];
    return { real: real3, imag: imag3 };
  }
  function assignToTypedArray(data, real3, imag3, index) {
    data[index * 2] = real3;
    data[index * 2 + 1] = imag3;
  }
  function exponents(n, inverse) {
    const real3 = new Float32Array(n / 2);
    const imag3 = new Float32Array(n / 2);
    for (let i = 0; i < Math.ceil(n / 2); i++) {
      const x = (inverse ? 2 : -2) * Math.PI * (i / n);
      real3[i] = Math.cos(x);
      imag3[i] = Math.sin(x);
    }
    return { real: real3, imag: imag3 };
  }
  function exponent(k3, n, inverse) {
    const x = (inverse ? 2 : -2) * Math.PI * (k3 / n);
    const real3 = Math.cos(x);
    const imag3 = Math.sin(x);
    return { real: real3, imag: imag3 };
  }
  var init_complex_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/backends/einsum_util.js
  function decodeEinsumEquation(equation, numTensors) {
    equation = equation.replace(/\s/g, "");
    const numArrows = (equation.length - equation.replace(ARROW_REGEX, "").length) / ARROW.length;
    if (numArrows < 1) {
      throw new Error("Equations without an arrow are not supported.");
    } else if (numArrows > 1) {
      throw new Error(`Equation must contain exactly one arrow ("${ARROW}").`);
    }
    const [inputString, outputString] = equation.split(ARROW);
    assert(inputString.indexOf(ELLIPSIS) === -1, () => `The ellipsis notation ("${ELLIPSIS}") is not supported yet.`);
    const inputTerms = inputString.split(COMMA);
    const numInputs = inputTerms.length;
    if (numTensors !== numInputs) {
      throw new Error(`Expected ${numInputs} input tensors, received ${numTensors}`);
    }
    if (numInputs > 2) {
      throw new Error("Support for more than 2 input tensors is not implemented yet.");
    }
    const allDims = [];
    for (let i = 0; i < outputString.length; ++i) {
      const dimName = outputString[i];
      if (!inputTerms.some((inputTerm) => inputTerm.indexOf(dimName) !== -1)) {
        throw new Error(`Output subscripts contain the label ${dimName} not present in the input subscripts.`);
      }
      if (allDims.indexOf(dimName) === -1) {
        allDims.push(dimName);
      }
    }
    for (let i = 0; i < inputString.length; ++i) {
      const dimName = inputString[i];
      if (allDims.indexOf(dimName) === -1 && dimName !== COMMA) {
        allDims.push(dimName);
      }
    }
    const idDims = new Array(inputTerms.length);
    for (let i = 0; i < numInputs; ++i) {
      if (new Set(inputTerms[i].split("")).size !== inputTerms[i].length) {
        throw new Error(`Found duplicate axes in input component ${inputTerms[i]}. Support for duplicate axes in input is not implemented yet.`);
      }
      idDims[i] = [];
      for (let j2 = 0; j2 < inputTerms[i].length; ++j2) {
        idDims[i].push(allDims.indexOf(inputTerms[i][j2]));
      }
    }
    const numDims = allDims.length;
    const numOutDims = outputString.length;
    const summedDims = [];
    for (let i = numOutDims; i < numDims; ++i) {
      summedDims.push(i);
    }
    return { allDims, summedDims, idDims };
  }
  function getEinsumPermutation(nDims, idDims) {
    let permutationIndices = new Array(nDims);
    permutationIndices.fill(-1);
    for (let i = 0; i < idDims.length; ++i) {
      permutationIndices[idDims[i]] = i;
    }
    const expandDims3 = [];
    for (let i = 0; i < nDims; ++i) {
      if (permutationIndices[i] === -1) {
        expandDims3.push(i);
      }
    }
    permutationIndices = permutationIndices.filter((d) => d !== -1);
    return { permutationIndices, expandDims: expandDims3 };
  }
  function checkEinsumDimSizes(nDims, idDims, tensors) {
    const dimSizes = new Array(nDims);
    for (let i = 0; i < tensors.length; ++i) {
      const shape = tensors[i].shape;
      for (let j2 = 0; j2 < idDims[i].length; ++j2) {
        if (dimSizes[idDims[i][j2]] === void 0) {
          dimSizes[idDims[i][j2]] = shape[j2];
        } else {
          assert(dimSizes[idDims[i][j2]] === shape[j2], () => `Expected dimension ${dimSizes[idDims[i][j2]]} at axis ${j2} of input shaped ${JSON.stringify(shape)}, but got dimension ${shape[j2]}`);
        }
      }
    }
  }
  function getEinsumComputePath(summedDims, idDims) {
    const path = summedDims;
    const steps = [];
    let nSteps = 0;
    if (summedDims.length === 0) {
      path.push(-1);
    }
    nSteps = summedDims.length + 1;
    for (let i = 0; i < nSteps; ++i) {
      steps.push([]);
    }
    const computedTermIndices = [];
    for (let i = 0; i < path.length; ++i) {
      const summedDim = path[i];
      const termIndices = findTermsWithDim(idDims, summedDim);
      for (const termIndex of termIndices) {
        if (computedTermIndices.indexOf(termIndex) === -1) {
          steps[i].push(termIndex);
          computedTermIndices.push(termIndex);
        }
      }
    }
    return { path, steps };
  }
  function isIdentityPermutation(perm) {
    return perm.every((dim, index) => dim === index);
  }
  function findTermsWithDim(idDims, dim) {
    const termIndices = [];
    for (let i = 0; i < idDims.length; ++i) {
      if (idDims[i].length === 0 || idDims[i].indexOf(dim) !== -1 || dim === -1) {
        termIndices.push(i);
      }
    }
    return termIndices;
  }
  var ARROW, ARROW_REGEX, COMMA, ELLIPSIS;
  var init_einsum_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/backends/einsum_util.js"() {
      init_util_base();
      ARROW = "->";
      ARROW_REGEX = /->/g;
      COMMA = ",";
      ELLIPSIS = "...";
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/split_util.js
  function prepareSplitSize(x, numOrSizeSplits, axis = 0) {
    let splitSizes = [];
    if (typeof numOrSizeSplits === "number") {
      assert(x.shape[axis] % numOrSizeSplits === 0, () => "Number of splits must evenly divide the axis.");
      splitSizes = new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);
    } else {
      const numOfNegs = numOrSizeSplits.reduce((count, value) => {
        if (value === -1) {
          count += 1;
        }
        return count;
      }, 0);
      assert(numOfNegs <= 1, () => "There should be only one negative value in split array.");
      const negIndex = numOrSizeSplits.indexOf(-1);
      if (negIndex !== -1) {
        const total = numOrSizeSplits.reduce((a, b) => b > 0 ? a + b : a);
        numOrSizeSplits[negIndex] = x.shape[axis] - total;
      }
      assert(x.shape[axis] === numOrSizeSplits.reduce((a, b) => a + b), () => "The sum of sizes must match the size of the axis dimension.");
      splitSizes = numOrSizeSplits;
    }
    return splitSizes;
  }
  var init_split_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/split_util.js"() {
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows_util.js
  function getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesLength) {
    return `Received SparseTensor with denseShape[0] = 0 but
  indices.shape[0] = ${indicesLength}`;
  }
  function getSparseFillEmptyRowsNegativeIndexErrorMessage(index, value) {
    return `indices(${index}, 0) is invalid: ${value} < 0`;
  }
  function getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(index, value, limit) {
    return `indices(${index}, 0) is invalid: ${value} >= ${limit}`;
  }
  var init_sparse_fill_empty_rows_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows_util.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape_util.js
  function getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(dim1, dim2) {
    return `only one output dimension may be -1, not both ${dim1} and ${dim2}`;
  }
  function getSparseReshapeNegativeOutputDimErrorMessage(dim, value) {
    return `size ${dim} must be non-negative, not ${value}`;
  }
  function getSparseReshapeEmptyTensorZeroOutputDimErrorMessage() {
    return "reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero";
  }
  function getSparseReshapeInputOutputMultipleErrorMessage(inputShape, outputShape) {
    const inputSize = sizeFromShape(inputShape);
    const outputSize = sizeFromShape(outputShape);
    return `Input to reshape is a SparseTensor with ${inputSize}
  dense values, but the requested shape requires a multiple of ${outputSize}. inputShape=${inputShape} outputShape= ${outputShape}`;
  }
  function getSparseReshapeInputOutputMismatchErrorMessage(inputShape, outputShape) {
    const inputSize = sizeFromShape(inputShape);
    const outputSize = sizeFromShape(outputShape);
    return `Input to reshape is a tensor with ${inputSize} dense values, but the requested shape has ${outputSize}. inputShape=${inputShape} outputShape=${outputShape}`;
  }
  var init_sparse_reshape_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape_util.js"() {
      init_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_reduction_util.js
  function getSparseSegmentReductionNegativeSegmentIdsErrorMessage() {
    return `segment ids must be >= 0`;
  }
  function getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage() {
    return `segment ids are not increasing`;
  }
  function getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(segmentId, outputRows) {
    return `Segment id ${segmentId} out of range [0, ${outputRows}), possibly because segmentIds input is not sorted.`;
  }
  function getSparseSegmentReductionIndicesOutOfRangeErrorMessage(index, indexValue, inputRows) {
    return `Bad: indices[${index}] == ${indexValue} out of range [0, ${inputRows})`;
  }
  var init_sparse_segment_reduction_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_reduction_util.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js
  var segment_util_exports = {};
  __export(segment_util_exports, {
    collectGatherOpShapeInfo: () => collectGatherOpShapeInfo,
    computeOutShape: () => computeOutShape3,
    segOpComputeOptimalWindowSize: () => segOpComputeOptimalWindowSize
  });
  function segOpComputeOptimalWindowSize(inSize, numSegments) {
    let done = false;
    let res;
    if (inSize <= PARALLELIZE_THRESHOLD) {
      res = inSize;
      done = true;
    } else {
      res = nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
    }
    while (!done) {
      if (res > numSegments || res === inSize) {
        done = true;
      } else {
        res = nearestDivisor(inSize, res + 1);
      }
    }
    return res;
  }
  function computeOutShape3(aShape, axis, numSegments) {
    const outShape = [];
    const rank = aShape.length;
    for (let dim = 0; dim < rank; dim++) {
      if (dim !== axis) {
        outShape.push(aShape[dim]);
      } else {
        outShape.push(numSegments);
      }
    }
    return outShape;
  }
  function collectGatherOpShapeInfo(x, indices, axis, batchDims) {
    const indicesRank = indices.shape.length;
    const xRank = x.shape.length;
    if (batchDims !== 0) {
      if (batchDims < -indicesRank || batchDims > indicesRank) {
        throw new Error(`Expect batchDims in the range of [-${indicesRank}, ${indicesRank}], but got ${batchDims}`);
      }
    }
    if (batchDims < 0) {
      batchDims += indicesRank;
    }
    if (batchDims > xRank) {
      throw new Error(`batchDims (${batchDims}) must be less than rank(x) (
    ${xRank}).`);
    }
    if (axis < batchDims) {
      throw new Error(`batchDims (${batchDims}) must be less than or equal to axis (${axis}).`);
    }
    for (let i = 0; i < batchDims; ++i) {
      if (x.shape[i] !== indices.shape[i]) {
        throw new Error(`x.shape[${i}]: ${x.shape[i]} should be equal to indices.shape[${i}]: ${indices.shape[i]}.`);
      }
    }
    const dimSize = x.shape[axis];
    const outputShape = [];
    let batchSize = 1;
    let outerSize = 1;
    let sliceSize = 1;
    for (let i = 0; i < batchDims; ++i) {
      outputShape.push(x.shape[i]);
      batchSize *= x.shape[i];
    }
    for (let i = batchDims; i < axis; i++) {
      outputShape.push(x.shape[i]);
      outerSize *= x.shape[i];
    }
    for (let i = batchDims; i < indicesRank; i++) {
      outputShape.push(indices.shape[i]);
    }
    for (let i = axis + 1; i < xRank; i++) {
      outputShape.push(x.shape[i]);
      sliceSize *= x.shape[i];
    }
    return { batchSize, sliceSize, outerSize, dimSize, outputShape };
  }
  var init_segment_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js"() {
      init_util();
      init_reduce_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js
  var backend_util_exports = {};
  __export(backend_util_exports, {
    ERF_A1: () => ERF_A1,
    ERF_A2: () => ERF_A2,
    ERF_A3: () => ERF_A3,
    ERF_A4: () => ERF_A4,
    ERF_A5: () => ERF_A5,
    ERF_P: () => ERF_P,
    PARALLELIZE_THRESHOLD: () => PARALLELIZE_THRESHOLD,
    RowPartitionType: () => RowPartitionType,
    SELU_SCALE: () => SELU_SCALE,
    SELU_SCALEALPHA: () => SELU_SCALEALPHA,
    applyActivation: () => applyActivation,
    assertAndGetBroadcastShape: () => assertAndGetBroadcastShape,
    assertAxesAreInnerMostDims: () => assertAxesAreInnerMostDims,
    assertParamsConsistent: () => assertParamsConsistent,
    assignToTypedArray: () => assignToTypedArray,
    axesAreInnerMostDims: () => axesAreInnerMostDims,
    calculateShapes: () => calculateShapes,
    checkEinsumDimSizes: () => checkEinsumDimSizes,
    checkPadOnDimRoundingMode: () => checkPadOnDimRoundingMode,
    combineLocations: () => combineLocations,
    combineRaggedTensorToTensorShapes: () => combineRaggedTensorToTensorShapes,
    complexWithEvenIndex: () => complexWithEvenIndex,
    complexWithOddIndex: () => complexWithOddIndex,
    computeConv2DInfo: () => computeConv2DInfo,
    computeConv3DInfo: () => computeConv3DInfo,
    computeDefaultPad: () => computeDefaultPad,
    computeDilation2DInfo: () => computeDilation2DInfo,
    computeOptimalWindowSize: () => computeOptimalWindowSize,
    computeOutAndReduceShapes: () => computeOutAndReduceShapes,
    computeOutShape: () => computeOutShape2,
    computePool2DInfo: () => computePool2DInfo,
    computePool3DInfo: () => computePool3DInfo,
    convertConv2DDataFormat: () => convertConv2DDataFormat,
    decodeEinsumEquation: () => decodeEinsumEquation,
    eitherStridesOrDilationsAreOne: () => eitherStridesOrDilationsAreOne,
    expandShapeToKeepDim: () => expandShapeToKeepDim,
    exponent: () => exponent,
    exponents: () => exponents,
    fromStringArrayToUint8: () => fromStringArrayToUint8,
    fromUint8ToStringArray: () => fromUint8ToStringArray,
    getAxesPermutation: () => getAxesPermutation,
    getBroadcastDims: () => getBroadcastDims,
    getComplexWithIndex: () => getComplexWithIndex,
    getEinsumComputePath: () => getEinsumComputePath,
    getEinsumPermutation: () => getEinsumPermutation,
    getFusedBiasGradient: () => getFusedBiasGradient,
    getFusedDyActivation: () => getFusedDyActivation,
    getImageCenter: () => getImageCenter,
    getInnerMostAxes: () => getInnerMostAxes,
    getPermuted: () => getPermuted,
    getRaggedRank: () => getRaggedRank,
    getReductionAxes: () => getReductionAxes,
    getReshaped: () => getReshaped,
    getReshapedPermuted: () => getReshapedPermuted,
    getRowPartitionTypesHelper: () => getRowPartitionTypesHelper,
    getSliceBeginCoords: () => getSliceBeginCoords,
    getSliceSize: () => getSliceSize,
    getSparseFillEmptyRowsIndicesDenseShapeMismatch: () => getSparseFillEmptyRowsIndicesDenseShapeMismatch,
    getSparseFillEmptyRowsNegativeIndexErrorMessage: () => getSparseFillEmptyRowsNegativeIndexErrorMessage,
    getSparseFillEmptyRowsOutOfRangeIndexErrorMessage: () => getSparseFillEmptyRowsOutOfRangeIndexErrorMessage,
    getSparseReshapeEmptyTensorZeroOutputDimErrorMessage: () => getSparseReshapeEmptyTensorZeroOutputDimErrorMessage,
    getSparseReshapeInputOutputMismatchErrorMessage: () => getSparseReshapeInputOutputMismatchErrorMessage,
    getSparseReshapeInputOutputMultipleErrorMessage: () => getSparseReshapeInputOutputMultipleErrorMessage,
    getSparseReshapeMultipleNegativeOneOutputDimErrorMessage: () => getSparseReshapeMultipleNegativeOneOutputDimErrorMessage,
    getSparseReshapeNegativeOutputDimErrorMessage: () => getSparseReshapeNegativeOutputDimErrorMessage,
    getSparseSegmentReductionIndicesOutOfRangeErrorMessage: () => getSparseSegmentReductionIndicesOutOfRangeErrorMessage,
    getSparseSegmentReductionNegativeSegmentIdsErrorMessage: () => getSparseSegmentReductionNegativeSegmentIdsErrorMessage,
    getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage: () => getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage,
    getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage: () => getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage,
    getUndoAxesPermutation: () => getUndoAxesPermutation,
    isIdentityPermutation: () => isIdentityPermutation,
    log: () => log,
    mergeRealAndImagArrays: () => mergeRealAndImagArrays,
    prepareAndValidate: () => prepareAndValidate,
    prepareSplitSize: () => prepareSplitSize,
    segment_util: () => segment_util_exports,
    shouldFuse: () => shouldFuse,
    slice_util: () => slice_util_exports,
    splitRealAndImagArrays: () => splitRealAndImagArrays,
    stridesOrDilationsArePositive: () => stridesOrDilationsArePositive,
    tupleValuesAreOne: () => tupleValuesAreOne,
    upcastType: () => upcastType,
    validateDefaultValueShape: () => validateDefaultValueShape,
    validateInput: () => validateInput,
    validateUpdateShape: () => validateUpdateShape,
    warn: () => warn
  });
  function fromUint8ToStringArray(vals) {
    try {
      return vals.map((val) => decodeString(val));
    } catch (err) {
      throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${err}`);
    }
  }
  function fromStringArrayToUint8(strings) {
    return strings.map((s) => encodeString(s));
  }
  var init_backend_util = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js"() {
      init_util();
      init_axis_util();
      init_broadcast_util();
      init_concat_util();
      init_conv_util();
      init_fused_util();
      init_fused_types();
      init_ragged_to_dense_util();
      init_reduce_util();
      init_slice_util();
      init_types();
      init_rotate_util();
      init_array_ops_util();
      init_gather_nd_util();
      init_scatter_nd_util();
      init_selu_util();
      init_fused_util();
      init_erf_util();
      init_log();
      init_complex_util();
      init_einsum_util();
      init_split_util();
      init_sparse_fill_empty_rows_util();
      init_sparse_reshape_util();
      init_sparse_segment_reduction_util();
      init_segment_util();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/backends/kernel_impls.js
  var kernel_impls_exports = {};
  __export(kernel_impls_exports, {
    nonMaxSuppressionV3Impl: () => nonMaxSuppressionV3Impl,
    nonMaxSuppressionV4Impl: () => nonMaxSuppressionV4Impl,
    nonMaxSuppressionV5Impl: () => nonMaxSuppressionV5Impl,
    whereImpl: () => whereImpl
  });
  var init_kernel_impls = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/backends/kernel_impls.js"() {
      init_non_max_suppression_impl();
      init_where_impl();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/base.js
  var init_base = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/base.js"() {
      init_io();
      init_broadcast_util();
      init_browser();
      init_slice_util();
      init_util();
      init_tensor();
      init_types();
      init_ops();
      init_train();
      init_globals();
      init_kernel_registry();
      init_environment();
      init_backend_util();
      init_kernel_impls();
      init_backend();
      init_kernel_names();
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/index.js
  var init_dist = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/index.js"() {
      init_base_side_effects();
      init_register_optimizers();
      init_base();
      registerOptimizers();
    }
  });

  // node_modules/@mediapipe/face_mesh/face_mesh.js
  var require_face_mesh = __commonJS({
    "node_modules/@mediapipe/face_mesh/face_mesh.js"(exports) {
      (function() {
        "use strict";
        var v;
        function aa(a) {
          var b = 0;
          return function() {
            return b < a.length ? { done: false, value: a[b++] } : { done: true };
          };
        }
        var ba = "function" == typeof Object.defineProperties ? Object.defineProperty : function(a, b, c) {
          if (a == Array.prototype || a == Object.prototype)
            return a;
          a[b] = c.value;
          return a;
        };
        function ca(a) {
          a = ["object" == typeof globalThis && globalThis, a, "object" == typeof window && window, "object" == typeof self && self, "object" == typeof global && global];
          for (var b = 0; b < a.length; ++b) {
            var c = a[b];
            if (c && c.Math == Math)
              return c;
          }
          throw Error("Cannot find global object");
        }
        var G2 = ca(this);
        function J2(a, b) {
          if (b)
            a: {
              var c = G2;
              a = a.split(".");
              for (var d = 0; d < a.length - 1; d++) {
                var e = a[d];
                if (!(e in c))
                  break a;
                c = c[e];
              }
              a = a[a.length - 1];
              d = c[a];
              b = b(d);
              b != d && null != b && ba(c, a, { configurable: true, writable: true, value: b });
            }
        }
        J2("Symbol", function(a) {
          function b(g) {
            if (this instanceof b)
              throw new TypeError("Symbol is not a constructor");
            return new c(d + (g || "") + "_" + e++, g);
          }
          function c(g, f) {
            this.g = g;
            ba(this, "description", { configurable: true, writable: true, value: f });
          }
          if (a)
            return a;
          c.prototype.toString = function() {
            return this.g;
          };
          var d = "jscomp_symbol_" + (1e9 * Math.random() >>> 0) + "_", e = 0;
          return b;
        });
        J2("Symbol.iterator", function(a) {
          if (a)
            return a;
          a = Symbol("Symbol.iterator");
          for (var b = "Array Int8Array Uint8Array Uint8ClampedArray Int16Array Uint16Array Int32Array Uint32Array Float32Array Float64Array".split(" "), c = 0; c < b.length; c++) {
            var d = G2[b[c]];
            "function" === typeof d && "function" != typeof d.prototype[a] && ba(d.prototype, a, { configurable: true, writable: true, value: function() {
              return da(aa(this));
            } });
          }
          return a;
        });
        function da(a) {
          a = { next: a };
          a[Symbol.iterator] = function() {
            return this;
          };
          return a;
        }
        function K2(a) {
          var b = "undefined" != typeof Symbol && Symbol.iterator && a[Symbol.iterator];
          return b ? b.call(a) : { next: aa(a) };
        }
        function L2(a) {
          if (!(a instanceof Array)) {
            a = K2(a);
            for (var b, c = []; !(b = a.next()).done; )
              c.push(b.value);
            a = c;
          }
          return a;
        }
        var ea = "function" == typeof Object.create ? Object.create : function(a) {
          function b() {
          }
          b.prototype = a;
          return new b();
        }, fa;
        if ("function" == typeof Object.setPrototypeOf)
          fa = Object.setPrototypeOf;
        else {
          var ha;
          a: {
            var ia = { a: true }, ja = {};
            try {
              ja.__proto__ = ia;
              ha = ja.a;
              break a;
            } catch (a) {
            }
            ha = false;
          }
          fa = ha ? function(a, b) {
            a.__proto__ = b;
            if (a.__proto__ !== b)
              throw new TypeError(a + " is not extensible");
            return a;
          } : null;
        }
        var ka = fa;
        function M(a, b) {
          a.prototype = ea(b.prototype);
          a.prototype.constructor = a;
          if (ka)
            ka(a, b);
          else
            for (var c in b)
              if ("prototype" != c)
                if (Object.defineProperties) {
                  var d = Object.getOwnPropertyDescriptor(b, c);
                  d && Object.defineProperty(a, c, d);
                } else
                  a[c] = b[c];
          a.ea = b.prototype;
        }
        function ma() {
          this.l = false;
          this.i = null;
          this.h = void 0;
          this.g = 1;
          this.s = this.m = 0;
          this.j = null;
        }
        function na(a) {
          if (a.l)
            throw new TypeError("Generator is already running");
          a.l = true;
        }
        ma.prototype.o = function(a) {
          this.h = a;
        };
        function oa(a, b) {
          a.j = { U: b, V: true };
          a.g = a.m || a.s;
        }
        ma.prototype.return = function(a) {
          this.j = { return: a };
          this.g = this.s;
        };
        function N2(a, b, c) {
          a.g = c;
          return { value: b };
        }
        function pa(a) {
          this.g = new ma();
          this.h = a;
        }
        function qa(a, b) {
          na(a.g);
          var c = a.g.i;
          if (c)
            return ra(a, "return" in c ? c["return"] : function(d) {
              return { value: d, done: true };
            }, b, a.g.return);
          a.g.return(b);
          return sa(a);
        }
        function ra(a, b, c, d) {
          try {
            var e = b.call(a.g.i, c);
            if (!(e instanceof Object))
              throw new TypeError("Iterator result " + e + " is not an object");
            if (!e.done)
              return a.g.l = false, e;
            var g = e.value;
          } catch (f) {
            return a.g.i = null, oa(a.g, f), sa(a);
          }
          a.g.i = null;
          d.call(a.g, g);
          return sa(a);
        }
        function sa(a) {
          for (; a.g.g; )
            try {
              var b = a.h(a.g);
              if (b)
                return a.g.l = false, { value: b.value, done: false };
            } catch (c) {
              a.g.h = void 0, oa(a.g, c);
            }
          a.g.l = false;
          if (a.g.j) {
            b = a.g.j;
            a.g.j = null;
            if (b.V)
              throw b.U;
            return { value: b.return, done: true };
          }
          return { value: void 0, done: true };
        }
        function ta(a) {
          this.next = function(b) {
            na(a.g);
            a.g.i ? b = ra(a, a.g.i.next, b, a.g.o) : (a.g.o(b), b = sa(a));
            return b;
          };
          this.throw = function(b) {
            na(a.g);
            a.g.i ? b = ra(a, a.g.i["throw"], b, a.g.o) : (oa(a.g, b), b = sa(a));
            return b;
          };
          this.return = function(b) {
            return qa(a, b);
          };
          this[Symbol.iterator] = function() {
            return this;
          };
        }
        function O2(a, b) {
          b = new ta(new pa(b));
          ka && a.prototype && ka(b, a.prototype);
          return b;
        }
        function ua(a, b) {
          a instanceof String && (a += "");
          var c = 0, d = false, e = { next: function() {
            if (!d && c < a.length) {
              var g = c++;
              return { value: b(g, a[g]), done: false };
            }
            d = true;
            return { done: true, value: void 0 };
          } };
          e[Symbol.iterator] = function() {
            return e;
          };
          return e;
        }
        var va = "function" == typeof Object.assign ? Object.assign : function(a, b) {
          for (var c = 1; c < arguments.length; c++) {
            var d = arguments[c];
            if (d)
              for (var e in d)
                Object.prototype.hasOwnProperty.call(d, e) && (a[e] = d[e]);
          }
          return a;
        };
        J2("Object.assign", function(a) {
          return a || va;
        });
        J2("Promise", function(a) {
          function b(f) {
            this.h = 0;
            this.i = void 0;
            this.g = [];
            this.o = false;
            var h = this.j();
            try {
              f(h.resolve, h.reject);
            } catch (k3) {
              h.reject(k3);
            }
          }
          function c() {
            this.g = null;
          }
          function d(f) {
            return f instanceof b ? f : new b(function(h) {
              h(f);
            });
          }
          if (a)
            return a;
          c.prototype.h = function(f) {
            if (null == this.g) {
              this.g = [];
              var h = this;
              this.i(function() {
                h.l();
              });
            }
            this.g.push(f);
          };
          var e = G2.setTimeout;
          c.prototype.i = function(f) {
            e(f, 0);
          };
          c.prototype.l = function() {
            for (; this.g && this.g.length; ) {
              var f = this.g;
              this.g = [];
              for (var h = 0; h < f.length; ++h) {
                var k3 = f[h];
                f[h] = null;
                try {
                  k3();
                } catch (l) {
                  this.j(l);
                }
              }
            }
            this.g = null;
          };
          c.prototype.j = function(f) {
            this.i(function() {
              throw f;
            });
          };
          b.prototype.j = function() {
            function f(l) {
              return function(n) {
                k3 || (k3 = true, l.call(h, n));
              };
            }
            var h = this, k3 = false;
            return { resolve: f(this.C), reject: f(this.l) };
          };
          b.prototype.C = function(f) {
            if (f === this)
              this.l(new TypeError("A Promise cannot resolve to itself"));
            else if (f instanceof b)
              this.F(f);
            else {
              a:
                switch (typeof f) {
                  case "object":
                    var h = null != f;
                    break a;
                  case "function":
                    h = true;
                    break a;
                  default:
                    h = false;
                }
              h ? this.u(f) : this.m(f);
            }
          };
          b.prototype.u = function(f) {
            var h = void 0;
            try {
              h = f.then;
            } catch (k3) {
              this.l(k3);
              return;
            }
            "function" == typeof h ? this.G(h, f) : this.m(f);
          };
          b.prototype.l = function(f) {
            this.s(2, f);
          };
          b.prototype.m = function(f) {
            this.s(1, f);
          };
          b.prototype.s = function(f, h) {
            if (0 != this.h)
              throw Error("Cannot settle(" + f + ", " + h + "): Promise already settled in state" + this.h);
            this.h = f;
            this.i = h;
            2 === this.h && this.D();
            this.A();
          };
          b.prototype.D = function() {
            var f = this;
            e(function() {
              if (f.B()) {
                var h = G2.console;
                "undefined" !== typeof h && h.error(f.i);
              }
            }, 1);
          };
          b.prototype.B = function() {
            if (this.o)
              return false;
            var f = G2.CustomEvent, h = G2.Event, k3 = G2.dispatchEvent;
            if ("undefined" === typeof k3)
              return true;
            "function" === typeof f ? f = new f("unhandledrejection", { cancelable: true }) : "function" === typeof h ? f = new h("unhandledrejection", { cancelable: true }) : (f = G2.document.createEvent("CustomEvent"), f.initCustomEvent("unhandledrejection", false, true, f));
            f.promise = this;
            f.reason = this.i;
            return k3(f);
          };
          b.prototype.A = function() {
            if (null != this.g) {
              for (var f = 0; f < this.g.length; ++f)
                g.h(this.g[f]);
              this.g = null;
            }
          };
          var g = new c();
          b.prototype.F = function(f) {
            var h = this.j();
            f.J(h.resolve, h.reject);
          };
          b.prototype.G = function(f, h) {
            var k3 = this.j();
            try {
              f.call(h, k3.resolve, k3.reject);
            } catch (l) {
              k3.reject(l);
            }
          };
          b.prototype.then = function(f, h) {
            function k3(w, r) {
              return "function" == typeof w ? function(y) {
                try {
                  l(w(y));
                } catch (m) {
                  n(m);
                }
              } : r;
            }
            var l, n, u = new b(function(w, r) {
              l = w;
              n = r;
            });
            this.J(k3(f, l), k3(h, n));
            return u;
          };
          b.prototype.catch = function(f) {
            return this.then(void 0, f);
          };
          b.prototype.J = function(f, h) {
            function k3() {
              switch (l.h) {
                case 1:
                  f(l.i);
                  break;
                case 2:
                  h(l.i);
                  break;
                default:
                  throw Error("Unexpected state: " + l.h);
              }
            }
            var l = this;
            null == this.g ? g.h(k3) : this.g.push(k3);
            this.o = true;
          };
          b.resolve = d;
          b.reject = function(f) {
            return new b(function(h, k3) {
              k3(f);
            });
          };
          b.race = function(f) {
            return new b(function(h, k3) {
              for (var l = K2(f), n = l.next(); !n.done; n = l.next())
                d(n.value).J(h, k3);
            });
          };
          b.all = function(f) {
            var h = K2(f), k3 = h.next();
            return k3.done ? d([]) : new b(function(l, n) {
              function u(y) {
                return function(m) {
                  w[y] = m;
                  r--;
                  0 == r && l(w);
                };
              }
              var w = [], r = 0;
              do
                w.push(void 0), r++, d(k3.value).J(u(w.length - 1), n), k3 = h.next();
              while (!k3.done);
            });
          };
          return b;
        });
        J2("Object.is", function(a) {
          return a ? a : function(b, c) {
            return b === c ? 0 !== b || 1 / b === 1 / c : b !== b && c !== c;
          };
        });
        J2("Array.prototype.includes", function(a) {
          return a ? a : function(b, c) {
            var d = this;
            d instanceof String && (d = String(d));
            var e = d.length;
            c = c || 0;
            for (0 > c && (c = Math.max(c + e, 0)); c < e; c++) {
              var g = d[c];
              if (g === b || Object.is(g, b))
                return true;
            }
            return false;
          };
        });
        J2("String.prototype.includes", function(a) {
          return a ? a : function(b, c) {
            if (null == this)
              throw new TypeError("The 'this' value for String.prototype.includes must not be null or undefined");
            if (b instanceof RegExp)
              throw new TypeError("First argument to String.prototype.includes must not be a regular expression");
            return -1 !== this.indexOf(b, c || 0);
          };
        });
        J2("Array.prototype.keys", function(a) {
          return a ? a : function() {
            return ua(this, function(b) {
              return b;
            });
          };
        });
        var wa = this || self;
        function P2(a, b) {
          a = a.split(".");
          var c = wa;
          a[0] in c || "undefined" == typeof c.execScript || c.execScript("var " + a[0]);
          for (var d; a.length && (d = a.shift()); )
            a.length || void 0 === b ? c[d] && c[d] !== Object.prototype[d] ? c = c[d] : c = c[d] = {} : c[d] = b;
        }
        ;
        function xa(a, b) {
          b = String.fromCharCode.apply(null, b);
          return null == a ? b : a + b;
        }
        var ya, za = "undefined" !== typeof TextDecoder, Aa, Ba = "undefined" !== typeof TextEncoder;
        function Ca(a) {
          if (Ba)
            a = (Aa || (Aa = new TextEncoder())).encode(a);
          else {
            var b = void 0;
            b = void 0 === b ? false : b;
            for (var c = 0, d = new Uint8Array(3 * a.length), e = 0; e < a.length; e++) {
              var g = a.charCodeAt(e);
              if (128 > g)
                d[c++] = g;
              else {
                if (2048 > g)
                  d[c++] = g >> 6 | 192;
                else {
                  if (55296 <= g && 57343 >= g) {
                    if (56319 >= g && e < a.length) {
                      var f = a.charCodeAt(++e);
                      if (56320 <= f && 57343 >= f) {
                        g = 1024 * (g - 55296) + f - 56320 + 65536;
                        d[c++] = g >> 18 | 240;
                        d[c++] = g >> 12 & 63 | 128;
                        d[c++] = g >> 6 & 63 | 128;
                        d[c++] = g & 63 | 128;
                        continue;
                      } else
                        e--;
                    }
                    if (b)
                      throw Error("Found an unpaired surrogate");
                    g = 65533;
                  }
                  d[c++] = g >> 12 | 224;
                  d[c++] = g >> 6 & 63 | 128;
                }
                d[c++] = g & 63 | 128;
              }
            }
            a = d.subarray(0, c);
          }
          return a;
        }
        ;
        var Da = {}, Ea = null;
        function Fa(a, b) {
          void 0 === b && (b = 0);
          Ga();
          b = Da[b];
          for (var c = Array(Math.floor(a.length / 3)), d = b[64] || "", e = 0, g = 0; e < a.length - 2; e += 3) {
            var f = a[e], h = a[e + 1], k3 = a[e + 2], l = b[f >> 2];
            f = b[(f & 3) << 4 | h >> 4];
            h = b[(h & 15) << 2 | k3 >> 6];
            k3 = b[k3 & 63];
            c[g++] = l + f + h + k3;
          }
          l = 0;
          k3 = d;
          switch (a.length - e) {
            case 2:
              l = a[e + 1], k3 = b[(l & 15) << 2] || d;
            case 1:
              a = a[e], c[g] = b[a >> 2] + b[(a & 3) << 4 | l >> 4] + k3 + d;
          }
          return c.join("");
        }
        function Ha(a) {
          var b = a.length, c = 3 * b / 4;
          c % 3 ? c = Math.floor(c) : -1 != "=.".indexOf(a[b - 1]) && (c = -1 != "=.".indexOf(a[b - 2]) ? c - 2 : c - 1);
          var d = new Uint8Array(c), e = 0;
          Ia(a, function(g) {
            d[e++] = g;
          });
          return d.subarray(0, e);
        }
        function Ia(a, b) {
          function c(k3) {
            for (; d < a.length; ) {
              var l = a.charAt(d++), n = Ea[l];
              if (null != n)
                return n;
              if (!/^[\s\xa0]*$/.test(l))
                throw Error("Unknown base64 encoding at char: " + l);
            }
            return k3;
          }
          Ga();
          for (var d = 0; ; ) {
            var e = c(-1), g = c(0), f = c(64), h = c(64);
            if (64 === h && -1 === e)
              break;
            b(e << 2 | g >> 4);
            64 != f && (b(g << 4 & 240 | f >> 2), 64 != h && b(f << 6 & 192 | h));
          }
        }
        function Ga() {
          if (!Ea) {
            Ea = {};
            for (var a = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789".split(""), b = ["+/=", "+/", "-_=", "-_.", "-_"], c = 0; 5 > c; c++) {
              var d = a.concat(b[c].split(""));
              Da[c] = d;
              for (var e = 0; e < d.length; e++) {
                var g = d[e];
                void 0 === Ea[g] && (Ea[g] = e);
              }
            }
          }
        }
        ;
        var Ja = "function" === typeof Uint8Array.prototype.slice, Ka;
        function La(a, b, c) {
          return b === c ? Ka || (Ka = new Uint8Array(0)) : Ja ? a.slice(b, c) : new Uint8Array(a.subarray(b, c));
        }
        var Q2 = 0, R2 = 0;
        function Ma(a, b) {
          b = void 0 === b ? {} : b;
          b = void 0 === b.v ? false : b.v;
          this.h = null;
          this.g = this.j = this.l = 0;
          this.m = false;
          this.v = b;
          a && Na(this, a);
        }
        function Na(a, b) {
          b = b.constructor === Uint8Array ? b : b.constructor === ArrayBuffer ? new Uint8Array(b) : b.constructor === Array ? new Uint8Array(b) : b.constructor === String ? Ha(b) : b instanceof Uint8Array ? new Uint8Array(b.buffer, b.byteOffset, b.byteLength) : new Uint8Array(0);
          a.h = b;
          a.l = 0;
          a.j = a.h.length;
          a.g = a.l;
        }
        Ma.prototype.reset = function() {
          this.g = this.l;
        };
        function Oa(a) {
          for (var b = 128, c = 0, d = 0, e = 0; 4 > e && 128 <= b; e++)
            b = a.h[a.g++], c |= (b & 127) << 7 * e;
          128 <= b && (b = a.h[a.g++], c |= (b & 127) << 28, d |= (b & 127) >> 4);
          if (128 <= b)
            for (e = 0; 5 > e && 128 <= b; e++)
              b = a.h[a.g++], d |= (b & 127) << 7 * e + 3;
          if (128 > b) {
            a = c >>> 0;
            b = d >>> 0;
            if (d = b & 2147483648)
              a = ~a + 1 >>> 0, b = ~b >>> 0, 0 == a && (b = b + 1 >>> 0);
            a = 4294967296 * b + (a >>> 0);
            return d ? -a : a;
          }
          a.m = true;
        }
        Ma.prototype.i = function() {
          var a = this.h, b = a[this.g], c = b & 127;
          if (128 > b)
            return this.g += 1, c;
          b = a[this.g + 1];
          c |= (b & 127) << 7;
          if (128 > b)
            return this.g += 2, c;
          b = a[this.g + 2];
          c |= (b & 127) << 14;
          if (128 > b)
            return this.g += 3, c;
          b = a[this.g + 3];
          c |= (b & 127) << 21;
          if (128 > b)
            return this.g += 4, c;
          b = a[this.g + 4];
          c |= (b & 15) << 28;
          if (128 > b)
            return this.g += 5, c >>> 0;
          this.g += 5;
          128 <= a[this.g++] && 128 <= a[this.g++] && 128 <= a[this.g++] && 128 <= a[this.g++] && this.g++;
          return c;
        };
        Ma.prototype.o = function() {
          var a = this.h[this.g], b = this.h[this.g + 1];
          var c = this.h[this.g + 2];
          var d = this.h[this.g + 3];
          this.g += 4;
          c = (a << 0 | b << 8 | c << 16 | d << 24) >>> 0;
          a = 2 * (c >> 31) + 1;
          b = c >>> 23 & 255;
          c &= 8388607;
          return 255 == b ? c ? NaN : Infinity * a : 0 == b ? a * Math.pow(2, -149) * c : a * Math.pow(2, b - 150) * (c + Math.pow(2, 23));
        };
        var Pa = [];
        function Qa() {
          this.g = new Uint8Array(64);
          this.h = 0;
        }
        Qa.prototype.push = function(a) {
          if (!(this.h + 1 < this.g.length)) {
            var b = this.g;
            this.g = new Uint8Array(Math.ceil(1 + 2 * this.g.length));
            this.g.set(b);
          }
          this.g[this.h++] = a;
        };
        Qa.prototype.length = function() {
          return this.h;
        };
        Qa.prototype.end = function() {
          var a = this.g, b = this.h;
          this.h = 0;
          return La(a, 0, b);
        };
        function Ra(a, b) {
          for (; 127 < b; )
            a.push(b & 127 | 128), b >>>= 7;
          a.push(b);
        }
        ;
        function Sa(a) {
          var b = {}, c = void 0 === b.N ? false : b.N;
          this.o = { v: void 0 === b.v ? false : b.v };
          this.N = c;
          b = this.o;
          Pa.length ? (c = Pa.pop(), b && (c.v = b.v), a && Na(c, a), a = c) : a = new Ma(a, b);
          this.g = a;
          this.m = this.g.g;
          this.h = this.i = this.l = -1;
          this.j = false;
        }
        Sa.prototype.reset = function() {
          this.g.reset();
          this.h = this.l = -1;
        };
        function S2(a) {
          var b = a.g;
          (b = b.g == b.j) || (b = a.j) || (b = a.g, b = b.m || 0 > b.g || b.g > b.j);
          if (b)
            return false;
          a.m = a.g.g;
          b = a.g.i();
          var c = b & 7;
          if (0 != c && 5 != c && 1 != c && 2 != c && 3 != c && 4 != c)
            return a.j = true, false;
          a.i = b;
          a.l = b >>> 3;
          a.h = c;
          return true;
        }
        function Ta(a) {
          switch (a.h) {
            case 0:
              if (0 != a.h)
                Ta(a);
              else {
                for (a = a.g; a.h[a.g] & 128; )
                  a.g++;
                a.g++;
              }
              break;
            case 1:
              1 != a.h ? Ta(a) : (a = a.g, a.g += 8);
              break;
            case 2:
              if (2 != a.h)
                Ta(a);
              else {
                var b = a.g.i();
                a = a.g;
                a.g += b;
              }
              break;
            case 5:
              5 != a.h ? Ta(a) : (a = a.g, a.g += 4);
              break;
            case 3:
              b = a.l;
              do {
                if (!S2(a)) {
                  a.j = true;
                  break;
                }
                if (4 == a.h) {
                  a.l != b && (a.j = true);
                  break;
                }
                Ta(a);
              } while (1);
              break;
            default:
              a.j = true;
          }
        }
        function Ua(a, b, c) {
          var d = a.g.j, e = a.g.i(), g = a.g.g + e;
          a.g.j = g;
          c(b, a);
          c = g - a.g.g;
          if (0 !== c)
            throw Error("Message parsing ended unexpectedly. Expected to read " + e + " bytes, instead read " + (e - c) + " bytes, either the data ended unexpectedly or the message misreported its own length");
          a.g.g = g;
          a.g.j = d;
          return b;
        }
        function T(a) {
          return a.g.o();
        }
        function Va(a) {
          var b = a.g.i();
          a = a.g;
          var c = a.g;
          a.g += b;
          a = a.h;
          var d;
          if (za)
            (d = ya) || (d = ya = new TextDecoder("utf-8", { fatal: false })), d = d.decode(a.subarray(c, c + b));
          else {
            b = c + b;
            for (var e = [], g = null, f, h, k3; c < b; )
              f = a[c++], 128 > f ? e.push(f) : 224 > f ? c >= b ? e.push(65533) : (h = a[c++], 194 > f || 128 !== (h & 192) ? (c--, e.push(65533)) : e.push((f & 31) << 6 | h & 63)) : 240 > f ? c >= b - 1 ? e.push(65533) : (h = a[c++], 128 !== (h & 192) || 224 === f && 160 > h || 237 === f && 160 <= h || 128 !== ((d = a[c++]) & 192) ? (c--, e.push(65533)) : e.push((f & 15) << 12 | (h & 63) << 6 | d & 63)) : 244 >= f ? c >= b - 2 ? e.push(65533) : (h = a[c++], 128 !== (h & 192) || 0 !== (f << 28) + (h - 144) >> 30 || 128 !== ((d = a[c++]) & 192) || 128 !== ((k3 = a[c++]) & 192) ? (c--, e.push(65533)) : (f = (f & 7) << 18 | (h & 63) << 12 | (d & 63) << 6 | k3 & 63, f -= 65536, e.push((f >> 10 & 1023) + 55296, (f & 1023) + 56320))) : e.push(65533), 8192 <= e.length && (g = xa(g, e), e.length = 0);
            d = xa(g, e);
          }
          return d;
        }
        function Wa(a, b, c) {
          var d = a.g.i();
          for (d = a.g.g + d; a.g.g < d; )
            c.push(b.call(a.g));
        }
        function Xa(a, b) {
          2 == a.h ? Wa(a, Ma.prototype.o, b) : b.push(T(a));
        }
        ;
        function Ya() {
          this.h = [];
          this.i = 0;
          this.g = new Qa();
        }
        function Za(a, b) {
          0 !== b.length && (a.h.push(b), a.i += b.length);
        }
        function $a(a) {
          var b = a.i + a.g.length();
          if (0 === b)
            return new Uint8Array(0);
          b = new Uint8Array(b);
          for (var c = a.h, d = c.length, e = 0, g = 0; g < d; g++) {
            var f = c[g];
            0 !== f.length && (b.set(f, e), e += f.length);
          }
          c = a.g;
          d = c.h;
          0 !== d && (b.set(c.g.subarray(0, d), e), c.h = 0);
          a.h = [b];
          return b;
        }
        function U2(a, b, c) {
          if (null != c) {
            Ra(a.g, 8 * b + 5);
            a = a.g;
            var d = c;
            d = (c = 0 > d ? 1 : 0) ? -d : d;
            0 === d ? 0 < 1 / d ? Q2 = R2 = 0 : (R2 = 0, Q2 = 2147483648) : isNaN(d) ? (R2 = 0, Q2 = 2147483647) : 34028234663852886e22 < d ? (R2 = 0, Q2 = (c << 31 | 2139095040) >>> 0) : 11754943508222875e-54 > d ? (d = Math.round(d / Math.pow(2, -149)), R2 = 0, Q2 = (c << 31 | d) >>> 0) : (b = Math.floor(Math.log(d) / Math.LN2), d *= Math.pow(2, -b), d = Math.round(8388608 * d), 16777216 <= d && ++b, R2 = 0, Q2 = (c << 31 | b + 127 << 23 | d & 8388607) >>> 0);
            c = Q2;
            a.push(c >>> 0 & 255);
            a.push(c >>> 8 & 255);
            a.push(c >>> 16 & 255);
            a.push(c >>> 24 & 255);
          }
        }
        ;
        var ab = "function" === typeof Uint8Array;
        function bb(a, b, c) {
          if (null != a)
            return "object" === typeof a ? ab && a instanceof Uint8Array ? c(a) : cb(a, b, c) : b(a);
        }
        function cb(a, b, c) {
          if (Array.isArray(a)) {
            for (var d = Array(a.length), e = 0; e < a.length; e++)
              d[e] = bb(a[e], b, c);
            Array.isArray(a) && a.W && db(d);
            return d;
          }
          d = {};
          for (e in a)
            d[e] = bb(a[e], b, c);
          return d;
        }
        function eb(a) {
          return "number" === typeof a ? isFinite(a) ? a : String(a) : a;
        }
        var fb = { W: { value: true, configurable: true } };
        function db(a) {
          Array.isArray(a) && !Object.isFrozen(a) && Object.defineProperties(a, fb);
          return a;
        }
        ;
        var gb;
        function V2(a, b, c) {
          var d = gb;
          gb = null;
          a || (a = d);
          d = this.constructor.ca;
          a || (a = d ? [d] : []);
          this.j = d ? 0 : -1;
          this.m = this.g = null;
          this.h = a;
          a: {
            d = this.h.length;
            a = d - 1;
            if (d && (d = this.h[a], !(null === d || "object" != typeof d || Array.isArray(d) || ab && d instanceof Uint8Array))) {
              this.l = a - this.j;
              this.i = d;
              break a;
            }
            void 0 !== b && -1 < b ? (this.l = Math.max(b, a + 1 - this.j), this.i = null) : this.l = Number.MAX_VALUE;
          }
          if (c)
            for (b = 0; b < c.length; b++)
              a = c[b], a < this.l ? (a += this.j, (d = this.h[a]) ? db(d) : this.h[a] = hb) : (ib(this), (d = this.i[a]) ? db(d) : this.i[a] = hb);
        }
        var hb = Object.freeze(db([]));
        function ib(a) {
          var b = a.l + a.j;
          a.h[b] || (a.i = a.h[b] = {});
        }
        function W2(a, b, c) {
          return -1 === b ? null : (void 0 === c ? 0 : c) || b >= a.l ? a.i ? a.i[b] : void 0 : a.h[b + a.j];
        }
        function jb(a, b) {
          var c = void 0 === c ? false : c;
          var d = W2(a, b, c);
          null == d && (d = hb);
          d === hb && (d = db([]), X2(a, b, d, c));
          return d;
        }
        function kb(a) {
          var b = jb(a, 3);
          a.m || (a.m = {});
          if (!a.m[3]) {
            for (var c = 0; c < b.length; c++)
              b[c] = +b[c];
            a.m[3] = true;
          }
          return b;
        }
        function lb(a, b, c) {
          a = W2(a, b);
          return null == a ? c : a;
        }
        function Y2(a, b, c) {
          a = W2(a, b);
          a = null == a ? a : +a;
          return null == a ? void 0 === c ? 0 : c : a;
        }
        function X2(a, b, c, d) {
          (void 0 === d ? 0 : d) || b >= a.l ? (ib(a), a.i[b] = c) : a.h[b + a.j] = c;
        }
        function mb(a, b, c) {
          if (-1 === c)
            return null;
          a.g || (a.g = {});
          if (!a.g[c]) {
            var d = W2(a, c, false);
            d && (a.g[c] = new b(d));
          }
          return a.g[c];
        }
        function nb(a, b) {
          a.g || (a.g = {});
          var c = a.g[1];
          if (!c) {
            var d = jb(a, 1);
            c = [];
            for (var e = 0; e < d.length; e++)
              c[e] = new b(d[e]);
            a.g[1] = c;
          }
          return c;
        }
        function ob(a, b, c) {
          var d = void 0 === d ? false : d;
          a.g || (a.g = {});
          var e = c ? pb(c, false) : c;
          a.g[b] = c;
          X2(a, b, e, d);
        }
        function qb(a, b, c, d) {
          var e = nb(a, c);
          b = b ? b : new c();
          a = jb(a, 1);
          void 0 != d ? (e.splice(d, 0, b), a.splice(d, 0, pb(b, false))) : (e.push(b), a.push(pb(b, false)));
        }
        V2.prototype.toJSON = function() {
          var a = pb(this, false);
          return cb(a, eb, Fa);
        };
        function pb(a, b) {
          if (a.g)
            for (var c in a.g) {
              var d = a.g[c];
              if (Array.isArray(d))
                for (var e = 0; e < d.length; e++)
                  d[e] && pb(d[e], b);
              else
                d && pb(d, b);
            }
          return a.h;
        }
        V2.prototype.toString = function() {
          return pb(this, false).toString();
        };
        function rb(a, b) {
          if (a = a.o) {
            Za(b, b.g.end());
            for (var c = 0; c < a.length; c++)
              Za(b, a[c]);
          }
        }
        function sb(a, b) {
          if (4 == b.h)
            return false;
          var c = b.m;
          Ta(b);
          b.N || (b = La(b.g.h, c, b.g.g), (c = a.o) ? c.push(b) : a.o = [b]);
          return true;
        }
        ;
        function tb(a) {
          V2.call(this, a, -1, ub);
        }
        M(tb, V2);
        tb.prototype.getRows = function() {
          return W2(this, 1);
        };
        tb.prototype.getCols = function() {
          return W2(this, 2);
        };
        tb.prototype.getPackedDataList = function() {
          return kb(this);
        };
        tb.prototype.getLayout = function() {
          return lb(this, 4, 0);
        };
        function vb(a, b) {
          for (; S2(b); )
            switch (b.i) {
              case 8:
                var c = b.g.i();
                X2(a, 1, c);
                break;
              case 16:
                c = b.g.i();
                X2(a, 2, c);
                break;
              case 29:
              case 26:
                Xa(b, a.getPackedDataList());
                break;
              case 32:
                c = Oa(b.g);
                X2(a, 4, c);
                break;
              default:
                if (!sb(a, b))
                  return a;
            }
          return a;
        }
        var ub = [3];
        function Z2(a, b) {
          var c = void 0;
          return new (c || (c = Promise))(function(d, e) {
            function g(k3) {
              try {
                h(b.next(k3));
              } catch (l) {
                e(l);
              }
            }
            function f(k3) {
              try {
                h(b["throw"](k3));
              } catch (l) {
                e(l);
              }
            }
            function h(k3) {
              k3.done ? d(k3.value) : new c(function(l) {
                l(k3.value);
              }).then(g, f);
            }
            h((b = b.apply(a, void 0)).next());
          });
        }
        ;
        function wb(a) {
          V2.call(this, a);
        }
        M(wb, V2);
        function xb(a, b) {
          for (; S2(b); )
            switch (b.i) {
              case 8:
                var c = b.g.i();
                X2(a, 1, c);
                break;
              case 21:
                c = T(b);
                X2(a, 2, c);
                break;
              case 26:
                c = Va(b);
                X2(a, 3, c);
                break;
              case 34:
                c = Va(b);
                X2(a, 4, c);
                break;
              default:
                if (!sb(a, b))
                  return a;
            }
          return a;
        }
        ;
        function yb(a) {
          V2.call(this, a, -1, zb);
        }
        M(yb, V2);
        yb.prototype.addClassification = function(a, b) {
          qb(this, a, wb, b);
          return this;
        };
        var zb = [1];
        function Ab(a) {
          V2.call(this, a);
        }
        M(Ab, V2);
        function Bb(a, b) {
          for (; S2(b); )
            switch (b.i) {
              case 13:
                var c = T(b);
                X2(a, 1, c);
                break;
              case 21:
                c = T(b);
                X2(a, 2, c);
                break;
              case 29:
                c = T(b);
                X2(a, 3, c);
                break;
              case 37:
                c = T(b);
                X2(a, 4, c);
                break;
              case 45:
                c = T(b);
                X2(a, 5, c);
                break;
              default:
                if (!sb(a, b))
                  return a;
            }
          return a;
        }
        ;
        function Cb(a) {
          V2.call(this, a, -1, Db);
        }
        M(Cb, V2);
        function Eb(a) {
          a: {
            var b = new Cb();
            for (a = new Sa(a); S2(a); )
              switch (a.i) {
                case 10:
                  var c = Ua(a, new Ab(), Bb);
                  qb(b, c, Ab, void 0);
                  break;
                default:
                  if (!sb(b, a))
                    break a;
              }
          }
          return b;
        }
        var Db = [1];
        function Fb(a) {
          V2.call(this, a);
        }
        M(Fb, V2);
        function Gb(a) {
          V2.call(this, a, -1, Hb);
        }
        M(Gb, V2);
        Gb.prototype.getVertexType = function() {
          return lb(this, 1, 0);
        };
        Gb.prototype.getPrimitiveType = function() {
          return lb(this, 2, 0);
        };
        Gb.prototype.getVertexBufferList = function() {
          return kb(this);
        };
        Gb.prototype.getIndexBufferList = function() {
          return jb(this, 4);
        };
        function Ib(a, b) {
          for (; S2(b); )
            switch (b.i) {
              case 8:
                var c = Oa(b.g);
                X2(a, 1, c);
                break;
              case 16:
                c = Oa(b.g);
                X2(a, 2, c);
                break;
              case 29:
              case 26:
                Xa(b, a.getVertexBufferList());
                break;
              case 32:
              case 34:
                c = b;
                var d = a.getIndexBufferList();
                2 == c.h ? Wa(c, Ma.prototype.i, d) : d.push(c.g.i());
                break;
              default:
                if (!sb(a, b))
                  return a;
            }
          return a;
        }
        var Hb = [3, 4];
        function Jb(a) {
          V2.call(this, a);
        }
        M(Jb, V2);
        Jb.prototype.getMesh = function() {
          return mb(this, Gb, 1);
        };
        Jb.prototype.getPoseTransformMatrix = function() {
          return mb(this, tb, 2);
        };
        function Kb(a) {
          a: {
            var b = new Jb();
            for (a = new Sa(a); S2(a); )
              switch (a.i) {
                case 10:
                  var c = Ua(a, new Gb(), Ib);
                  ob(b, 1, c);
                  break;
                case 18:
                  c = Ua(a, new tb(), vb);
                  ob(b, 2, c);
                  break;
                default:
                  if (!sb(b, a))
                    break a;
              }
          }
          return b;
        }
        ;
        function Lb(a, b, c) {
          c = a.createShader(0 === c ? a.VERTEX_SHADER : a.FRAGMENT_SHADER);
          a.shaderSource(c, b);
          a.compileShader(c);
          if (!a.getShaderParameter(c, a.COMPILE_STATUS))
            throw Error("Could not compile WebGL shader.\n\n" + a.getShaderInfoLog(c));
          return c;
        }
        ;
        function Mb(a) {
          return nb(a, wb).map(function(b) {
            return { index: lb(b, 1, 0), Y: Y2(b, 2), label: null != W2(b, 3) ? lb(b, 3, "") : void 0, displayName: null != W2(b, 4) ? lb(b, 4, "") : void 0 };
          });
        }
        ;
        function Nb(a) {
          return { x: Y2(a, 1), y: Y2(a, 2), z: Y2(a, 3), visibility: null != W2(a, 4) ? Y2(a, 4) : void 0 };
        }
        ;
        function Ob(a, b) {
          this.h = a;
          this.g = b;
          this.l = 0;
        }
        function Pb(a, b, c) {
          Qb(a, b);
          if ("function" === typeof a.g.canvas.transferToImageBitmap)
            return Promise.resolve(a.g.canvas.transferToImageBitmap());
          if (c)
            return Promise.resolve(a.g.canvas);
          if ("function" === typeof createImageBitmap)
            return createImageBitmap(a.g.canvas);
          void 0 === a.i && (a.i = document.createElement("canvas"));
          return new Promise(function(d) {
            a.i.height = a.g.canvas.height;
            a.i.width = a.g.canvas.width;
            a.i.getContext("2d", {}).drawImage(a.g.canvas, 0, 0, a.g.canvas.width, a.g.canvas.height);
            d(a.i);
          });
        }
        function Qb(a, b) {
          var c = a.g;
          if (void 0 === a.m) {
            var d = Lb(c, "\n  attribute vec2 aVertex;\n  attribute vec2 aTex;\n  varying vec2 vTex;\n  void main(void) {\n    gl_Position = vec4(aVertex, 0.0, 1.0);\n    vTex = aTex;\n  }", 0), e = Lb(c, "\n  precision mediump float;\n  varying vec2 vTex;\n  uniform sampler2D sampler0;\n  void main(){\n    gl_FragColor = texture2D(sampler0, vTex);\n  }", 1), g = c.createProgram();
            c.attachShader(g, d);
            c.attachShader(g, e);
            c.linkProgram(g);
            if (!c.getProgramParameter(g, c.LINK_STATUS))
              throw Error("Could not compile WebGL program.\n\n" + c.getProgramInfoLog(g));
            d = a.m = g;
            c.useProgram(d);
            e = c.getUniformLocation(d, "sampler0");
            a.j = { I: c.getAttribLocation(d, "aVertex"), H: c.getAttribLocation(d, "aTex"), da: e };
            a.s = c.createBuffer();
            c.bindBuffer(c.ARRAY_BUFFER, a.s);
            c.enableVertexAttribArray(a.j.I);
            c.vertexAttribPointer(a.j.I, 2, c.FLOAT, false, 0, 0);
            c.bufferData(c.ARRAY_BUFFER, new Float32Array([-1, -1, -1, 1, 1, 1, 1, -1]), c.STATIC_DRAW);
            c.bindBuffer(c.ARRAY_BUFFER, null);
            a.o = c.createBuffer();
            c.bindBuffer(c.ARRAY_BUFFER, a.o);
            c.enableVertexAttribArray(a.j.H);
            c.vertexAttribPointer(
              a.j.H,
              2,
              c.FLOAT,
              false,
              0,
              0
            );
            c.bufferData(c.ARRAY_BUFFER, new Float32Array([0, 1, 0, 0, 1, 0, 1, 1]), c.STATIC_DRAW);
            c.bindBuffer(c.ARRAY_BUFFER, null);
            c.uniform1i(e, 0);
          }
          d = a.j;
          c.useProgram(a.m);
          c.canvas.width = b.width;
          c.canvas.height = b.height;
          c.viewport(0, 0, b.width, b.height);
          c.activeTexture(c.TEXTURE0);
          a.h.bindTexture2d(b.glName);
          c.enableVertexAttribArray(d.I);
          c.bindBuffer(c.ARRAY_BUFFER, a.s);
          c.vertexAttribPointer(d.I, 2, c.FLOAT, false, 0, 0);
          c.enableVertexAttribArray(d.H);
          c.bindBuffer(c.ARRAY_BUFFER, a.o);
          c.vertexAttribPointer(
            d.H,
            2,
            c.FLOAT,
            false,
            0,
            0
          );
          c.bindFramebuffer(c.DRAW_FRAMEBUFFER ? c.DRAW_FRAMEBUFFER : c.FRAMEBUFFER, null);
          c.clearColor(0, 0, 0, 0);
          c.clear(c.COLOR_BUFFER_BIT);
          c.colorMask(true, true, true, true);
          c.drawArrays(c.TRIANGLE_FAN, 0, 4);
          c.disableVertexAttribArray(d.I);
          c.disableVertexAttribArray(d.H);
          c.bindBuffer(c.ARRAY_BUFFER, null);
          a.h.bindTexture2d(0);
        }
        function Rb(a) {
          this.g = a;
        }
        ;
        var Sb = new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 9, 1, 7, 0, 65, 0, 253, 15, 26, 11]);
        function Tb(a, b) {
          return b + a;
        }
        function Ub(a, b) {
          window[a] = b;
        }
        function Vb(a) {
          var b = document.createElement("script");
          b.setAttribute("src", a);
          b.setAttribute("crossorigin", "anonymous");
          return new Promise(function(c) {
            b.addEventListener("load", function() {
              c();
            }, false);
            b.addEventListener("error", function() {
              c();
            }, false);
            document.body.appendChild(b);
          });
        }
        function Wb() {
          return Z2(this, function b() {
            return O2(b, function(c) {
              switch (c.g) {
                case 1:
                  return c.m = 2, N2(c, WebAssembly.instantiate(Sb), 4);
                case 4:
                  c.g = 3;
                  c.m = 0;
                  break;
                case 2:
                  return c.m = 0, c.j = null, c.return(false);
                case 3:
                  return c.return(true);
              }
            });
          });
        }
        function Xb(a) {
          this.g = a;
          this.listeners = {};
          this.j = {};
          this.F = {};
          this.m = {};
          this.s = {};
          this.G = this.o = this.R = true;
          this.C = Promise.resolve();
          this.P = "";
          this.B = {};
          this.locateFile = a && a.locateFile || Tb;
          if ("object" === typeof window)
            var b = window.location.pathname.toString().substring(0, window.location.pathname.toString().lastIndexOf("/")) + "/";
          else if ("undefined" !== typeof location)
            b = location.pathname.toString().substring(0, location.pathname.toString().lastIndexOf("/")) + "/";
          else
            throw Error("solutions can only be loaded on a web page or in a web worker");
          this.S = b;
          if (a.options) {
            b = K2(Object.keys(a.options));
            for (var c = b.next(); !c.done; c = b.next()) {
              c = c.value;
              var d = a.options[c].default;
              void 0 !== d && (this.j[c] = "function" === typeof d ? d() : d);
            }
          }
        }
        v = Xb.prototype;
        v.close = function() {
          this.i && this.i.delete();
          return Promise.resolve();
        };
        function Yb(a, b) {
          return void 0 === a.g.files ? [] : "function" === typeof a.g.files ? a.g.files(b) : a.g.files;
        }
        function Zb(a) {
          return Z2(a, function c() {
            var d = this, e, g, f, h, k3, l, n, u, w, r, y;
            return O2(c, function(m) {
              switch (m.g) {
                case 1:
                  e = d;
                  if (!d.R)
                    return m.return();
                  g = Yb(d, d.j);
                  return N2(m, Wb(), 2);
                case 2:
                  f = m.h;
                  if ("object" === typeof window)
                    return Ub("createMediapipeSolutionsWasm", { locateFile: d.locateFile }), Ub("createMediapipeSolutionsPackedAssets", { locateFile: d.locateFile }), l = g.filter(function(t2) {
                      return void 0 !== t2.data;
                    }), n = g.filter(function(t2) {
                      return void 0 === t2.data;
                    }), u = Promise.all(l.map(function(t2) {
                      var x = $b(e, t2.url);
                      if (void 0 !== t2.path) {
                        var z2 = t2.path;
                        x = x.then(function(E2) {
                          e.overrideFile(z2, E2);
                          return Promise.resolve(E2);
                        });
                      }
                      return x;
                    })), w = Promise.all(n.map(function(t2) {
                      return void 0 === t2.simd || t2.simd && f || !t2.simd && !f ? Vb(e.locateFile(t2.url, e.S)) : Promise.resolve();
                    })).then(function() {
                      return Z2(e, function x() {
                        var z2, E2, F2 = this;
                        return O2(x, function(I2) {
                          if (1 == I2.g)
                            return z2 = window.createMediapipeSolutionsWasm, E2 = window.createMediapipeSolutionsPackedAssets, N2(I2, z2(E2), 2);
                          F2.h = I2.h;
                          I2.g = 0;
                        });
                      });
                    }), r = function() {
                      return Z2(e, function x() {
                        var z2 = this;
                        return O2(x, function(E2) {
                          z2.g.graph && z2.g.graph.url ? E2 = N2(E2, $b(z2, z2.g.graph.url), 0) : (E2.g = 0, E2 = void 0);
                          return E2;
                        });
                      });
                    }(), N2(m, Promise.all([w, u, r]), 7);
                  if ("function" !== typeof importScripts)
                    throw Error("solutions can only be loaded on a web page or in a web worker");
                  h = g.filter(function(t2) {
                    return void 0 === t2.simd || t2.simd && f || !t2.simd && !f;
                  }).map(function(t2) {
                    return e.locateFile(t2.url, e.S);
                  });
                  importScripts.apply(null, L2(h));
                  return N2(m, createMediapipeSolutionsWasm(Module), 6);
                case 6:
                  d.h = m.h;
                  d.l = new OffscreenCanvas(1, 1);
                  d.h.canvas = d.l;
                  k3 = d.h.GL.createContext(
                    d.l,
                    { antialias: false, alpha: false, ba: "undefined" !== typeof WebGL2RenderingContext ? 2 : 1 }
                  );
                  d.h.GL.makeContextCurrent(k3);
                  m.g = 4;
                  break;
                case 7:
                  d.l = document.createElement("canvas");
                  y = d.l.getContext("webgl2", {});
                  if (!y && (y = d.l.getContext("webgl", {}), !y))
                    return alert("Failed to create WebGL canvas context when passing video frame."), m.return();
                  d.D = y;
                  d.h.canvas = d.l;
                  d.h.createContext(d.l, true, true, {});
                case 4:
                  d.i = new d.h.SolutionWasm(), d.R = false, m.g = 0;
              }
            });
          });
        }
        function ac(a) {
          return Z2(a, function c() {
            var d = this, e, g, f, h, k3, l, n, u;
            return O2(c, function(w) {
              if (1 == w.g) {
                if (d.g.graph && d.g.graph.url && d.P === d.g.graph.url)
                  return w.return();
                d.o = true;
                if (!d.g.graph || !d.g.graph.url) {
                  w.g = 2;
                  return;
                }
                d.P = d.g.graph.url;
                return N2(w, $b(d, d.g.graph.url), 3);
              }
              2 != w.g && (e = w.h, d.i.loadGraph(e));
              g = K2(Object.keys(d.B));
              for (f = g.next(); !f.done; f = g.next())
                h = f.value, d.i.overrideFile(h, d.B[h]);
              d.B = {};
              if (d.g.listeners)
                for (k3 = K2(d.g.listeners), l = k3.next(); !l.done; l = k3.next())
                  n = l.value, bc(d, n);
              u = d.j;
              d.j = {};
              d.setOptions(u);
              w.g = 0;
            });
          });
        }
        v.reset = function() {
          return Z2(this, function b() {
            var c = this;
            return O2(b, function(d) {
              c.i && (c.i.reset(), c.m = {}, c.s = {});
              d.g = 0;
            });
          });
        };
        v.setOptions = function(a, b) {
          var c = this;
          if (b = b || this.g.options) {
            for (var d = [], e = [], g = {}, f = K2(Object.keys(a)), h = f.next(); !h.done; g = { K: g.K, L: g.L }, h = f.next()) {
              var k3 = h.value;
              k3 in this.j && this.j[k3] === a[k3] || (this.j[k3] = a[k3], h = b[k3], void 0 !== h && (h.onChange && (g.K = h.onChange, g.L = a[k3], d.push(function(l) {
                return function() {
                  return Z2(c, function u() {
                    var w, r = this;
                    return O2(u, function(y) {
                      if (1 == y.g)
                        return N2(y, l.K(l.L), 2);
                      w = y.h;
                      true === w && (r.o = true);
                      y.g = 0;
                    });
                  });
                };
              }(g))), h.graphOptionXref && (k3 = { valueNumber: 1 === h.type ? a[k3] : 0, valueBoolean: 0 === h.type ? a[k3] : false, valueString: 2 === h.type ? a[k3] : "" }, h = Object.assign(Object.assign(Object.assign({}, { calculatorName: "", calculatorIndex: 0 }), h.graphOptionXref), k3), e.push(h))));
            }
            if (0 !== d.length || 0 !== e.length)
              this.o = true, this.A = (void 0 === this.A ? [] : this.A).concat(e), this.u = (void 0 === this.u ? [] : this.u).concat(d);
          }
        };
        function cc(a) {
          return Z2(a, function c() {
            var d = this, e, g, f, h, k3, l, n;
            return O2(c, function(u) {
              switch (u.g) {
                case 1:
                  if (!d.o)
                    return u.return();
                  if (!d.u) {
                    u.g = 2;
                    break;
                  }
                  e = K2(d.u);
                  g = e.next();
                case 3:
                  if (g.done) {
                    u.g = 5;
                    break;
                  }
                  f = g.value;
                  return N2(u, f(), 4);
                case 4:
                  g = e.next();
                  u.g = 3;
                  break;
                case 5:
                  d.u = void 0;
                case 2:
                  if (d.A) {
                    h = new d.h.GraphOptionChangeRequestList();
                    k3 = K2(d.A);
                    for (l = k3.next(); !l.done; l = k3.next())
                      n = l.value, h.push_back(n);
                    d.i.changeOptions(h);
                    h.delete();
                    d.A = void 0;
                  }
                  d.o = false;
                  u.g = 0;
              }
            });
          });
        }
        v.initialize = function() {
          return Z2(this, function b() {
            var c = this;
            return O2(b, function(d) {
              return 1 == d.g ? N2(d, Zb(c), 2) : 3 != d.g ? N2(d, ac(c), 3) : N2(d, cc(c), 0);
            });
          });
        };
        function $b(a, b) {
          return Z2(a, function d() {
            var e = this, g, f;
            return O2(d, function(h) {
              if (b in e.F)
                return h.return(e.F[b]);
              g = e.locateFile(b, "");
              f = fetch(g).then(function(k3) {
                return k3.arrayBuffer();
              });
              e.F[b] = f;
              return h.return(f);
            });
          });
        }
        v.overrideFile = function(a, b) {
          this.i ? this.i.overrideFile(a, b) : this.B[a] = b;
        };
        v.clearOverriddenFiles = function() {
          this.B = {};
          this.i && this.i.clearOverriddenFiles();
        };
        v.send = function(a, b) {
          return Z2(this, function d() {
            var e = this, g, f, h, k3, l, n, u, w, r;
            return O2(d, function(y) {
              switch (y.g) {
                case 1:
                  if (!e.g.inputs)
                    return y.return();
                  g = 1e3 * (void 0 === b || null === b ? performance.now() : b);
                  return N2(y, e.C, 2);
                case 2:
                  return N2(y, e.initialize(), 3);
                case 3:
                  f = new e.h.PacketDataList();
                  h = K2(Object.keys(a));
                  for (k3 = h.next(); !k3.done; k3 = h.next())
                    if (l = k3.value, n = e.g.inputs[l]) {
                      a: {
                        var m = e;
                        var t2 = a[l];
                        switch (n.type) {
                          case "video":
                            var x = m.m[n.stream];
                            x || (x = new Ob(m.h, m.D), m.m[n.stream] = x);
                            m = x;
                            0 === m.l && (m.l = m.h.createTexture());
                            if ("undefined" !== typeof HTMLVideoElement && t2 instanceof HTMLVideoElement) {
                              var z2 = t2.videoWidth;
                              x = t2.videoHeight;
                            } else
                              "undefined" !== typeof HTMLImageElement && t2 instanceof HTMLImageElement ? (z2 = t2.naturalWidth, x = t2.naturalHeight) : (z2 = t2.width, x = t2.height);
                            x = { glName: m.l, width: z2, height: x };
                            z2 = m.g;
                            z2.canvas.width = x.width;
                            z2.canvas.height = x.height;
                            z2.activeTexture(z2.TEXTURE0);
                            m.h.bindTexture2d(m.l);
                            z2.texImage2D(z2.TEXTURE_2D, 0, z2.RGBA, z2.RGBA, z2.UNSIGNED_BYTE, t2);
                            m.h.bindTexture2d(0);
                            m = x;
                            break a;
                          case "detections":
                            x = m.m[n.stream];
                            x || (x = new Rb(m.h), m.m[n.stream] = x);
                            m = x;
                            m.data || (m.data = new m.g.DetectionListData());
                            m.data.reset(t2.length);
                            for (x = 0; x < t2.length; ++x) {
                              z2 = t2[x];
                              var E2 = m.data, F2 = E2.setBoundingBox, I2 = x;
                              var H2 = z2.T;
                              var p2 = new Fb();
                              X2(p2, 1, H2.Z);
                              X2(p2, 2, H2.$);
                              X2(p2, 3, H2.height);
                              X2(p2, 4, H2.width);
                              X2(p2, 5, H2.rotation);
                              X2(p2, 6, H2.X);
                              var A = H2 = new Ya();
                              U2(A, 1, W2(p2, 1));
                              U2(A, 2, W2(p2, 2));
                              U2(A, 3, W2(p2, 3));
                              U2(A, 4, W2(p2, 4));
                              U2(A, 5, W2(p2, 5));
                              var C2 = W2(p2, 6);
                              if (null != C2 && null != C2) {
                                Ra(A.g, 48);
                                var q2 = A.g, B2 = C2;
                                C2 = 0 > B2;
                                B2 = Math.abs(B2);
                                var D2 = B2 >>> 0;
                                B2 = Math.floor((B2 - D2) / 4294967296);
                                B2 >>>= 0;
                                C2 && (B2 = ~B2 >>> 0, D2 = (~D2 >>> 0) + 1, 4294967295 < D2 && (D2 = 0, B2++, 4294967295 < B2 && (B2 = 0)));
                                Q2 = D2;
                                R2 = B2;
                                C2 = Q2;
                                for (D2 = R2; 0 < D2 || 127 < C2; )
                                  q2.push(C2 & 127 | 128), C2 = (C2 >>> 7 | D2 << 25) >>> 0, D2 >>>= 7;
                                q2.push(C2);
                              }
                              rb(p2, A);
                              H2 = $a(H2);
                              F2.call(E2, I2, H2);
                              if (z2.O)
                                for (E2 = 0; E2 < z2.O.length; ++E2)
                                  p2 = z2.O[E2], A = p2.visibility ? true : false, F2 = m.data, I2 = F2.addNormalizedLandmark, H2 = x, p2 = Object.assign(Object.assign({}, p2), { visibility: A ? p2.visibility : 0 }), A = new Ab(), X2(A, 1, p2.x), X2(A, 2, p2.y), X2(A, 3, p2.z), p2.visibility && X2(A, 4, p2.visibility), q2 = p2 = new Ya(), U2(q2, 1, W2(A, 1)), U2(q2, 2, W2(A, 2)), U2(q2, 3, W2(A, 3)), U2(q2, 4, W2(A, 4)), U2(q2, 5, W2(A, 5)), rb(A, q2), p2 = $a(p2), I2.call(F2, H2, p2);
                              if (z2.M)
                                for (E2 = 0; E2 < z2.M.length; ++E2) {
                                  F2 = m.data;
                                  I2 = F2.addClassification;
                                  H2 = x;
                                  p2 = z2.M[E2];
                                  A = new wb();
                                  X2(A, 2, p2.Y);
                                  p2.index && X2(A, 1, p2.index);
                                  p2.label && X2(A, 3, p2.label);
                                  p2.displayName && X2(A, 4, p2.displayName);
                                  q2 = p2 = new Ya();
                                  D2 = W2(A, 1);
                                  if (null != D2 && null != D2)
                                    if (Ra(q2.g, 8), C2 = q2.g, 0 <= D2)
                                      Ra(C2, D2);
                                    else {
                                      for (B2 = 0; 9 > B2; B2++)
                                        C2.push(D2 & 127 | 128), D2 >>= 7;
                                      C2.push(1);
                                    }
                                  U2(q2, 2, W2(A, 2));
                                  C2 = W2(A, 3);
                                  null != C2 && (C2 = Ca(C2), Ra(q2.g, 26), Ra(q2.g, C2.length), Za(q2, q2.g.end()), Za(q2, C2));
                                  C2 = W2(A, 4);
                                  null != C2 && (C2 = Ca(C2), Ra(q2.g, 34), Ra(q2.g, C2.length), Za(q2, q2.g.end()), Za(q2, C2));
                                  rb(A, q2);
                                  p2 = $a(p2);
                                  I2.call(F2, H2, p2);
                                }
                            }
                            m = m.data;
                            break a;
                          default:
                            m = {};
                        }
                      }
                      u = m;
                      w = n.stream;
                      switch (n.type) {
                        case "video":
                          f.pushTexture2d(Object.assign(Object.assign({}, u), { stream: w, timestamp: g }));
                          break;
                        case "detections":
                          r = u;
                          r.stream = w;
                          r.timestamp = g;
                          f.pushDetectionList(r);
                          break;
                        default:
                          throw Error("Unknown input config type: '" + n.type + "'");
                      }
                    }
                  e.i.send(f);
                  return N2(y, e.C, 4);
                case 4:
                  f.delete(), y.g = 0;
              }
            });
          });
        };
        function dc(a, b, c) {
          return Z2(a, function e() {
            var g, f, h, k3, l, n, u = this, w, r, y, m, t2, x, z2, E2;
            return O2(e, function(F2) {
              switch (F2.g) {
                case 1:
                  if (!c)
                    return F2.return(b);
                  g = {};
                  f = 0;
                  h = K2(Object.keys(c));
                  for (k3 = h.next(); !k3.done; k3 = h.next())
                    l = k3.value, n = c[l], "string" !== typeof n && "texture" === n.type && void 0 !== b[n.stream] && ++f;
                  1 < f && (u.G = false);
                  w = K2(Object.keys(c));
                  k3 = w.next();
                case 2:
                  if (k3.done) {
                    F2.g = 4;
                    break;
                  }
                  r = k3.value;
                  y = c[r];
                  if ("string" === typeof y)
                    return z2 = g, E2 = r, N2(F2, ec(u, r, b[y]), 14);
                  m = b[y.stream];
                  if ("detection_list" === y.type) {
                    if (m) {
                      var I2 = m.getRectList();
                      for (var H2 = m.getLandmarksList(), p2 = m.getClassificationsList(), A = [], C2 = 0; C2 < I2.size(); ++C2) {
                        var q2 = I2.get(C2);
                        a: {
                          var B2 = new Fb();
                          for (q2 = new Sa(q2); S2(q2); )
                            switch (q2.i) {
                              case 13:
                                var D2 = T(q2);
                                X2(B2, 1, D2);
                                break;
                              case 21:
                                D2 = T(q2);
                                X2(B2, 2, D2);
                                break;
                              case 29:
                                D2 = T(q2);
                                X2(B2, 3, D2);
                                break;
                              case 37:
                                D2 = T(q2);
                                X2(B2, 4, D2);
                                break;
                              case 45:
                                D2 = T(q2);
                                X2(B2, 5, D2);
                                break;
                              case 48:
                                D2 = Oa(q2.g);
                                X2(B2, 6, D2);
                                break;
                              default:
                                if (!sb(B2, q2))
                                  break a;
                            }
                        }
                        B2 = { Z: Y2(B2, 1), $: Y2(B2, 2), height: Y2(B2, 3), width: Y2(B2, 4), rotation: Y2(B2, 5, 0), X: lb(B2, 6, 0) };
                        q2 = nb(Eb(H2.get(C2)), Ab).map(Nb);
                        var la = p2.get(C2);
                        a:
                          for (D2 = new yb(), la = new Sa(la); S2(la); )
                            switch (la.i) {
                              case 10:
                                D2.addClassification(Ua(la, new wb(), xb));
                                break;
                              default:
                                if (!sb(D2, la))
                                  break a;
                            }
                        B2 = { T: B2, O: q2, M: Mb(D2) };
                        A.push(B2);
                      }
                      I2 = A;
                    } else
                      I2 = [];
                    g[r] = I2;
                    F2.g = 7;
                    break;
                  }
                  if ("proto_list" === y.type) {
                    if (m) {
                      I2 = Array(m.size());
                      for (H2 = 0; H2 < m.size(); H2++)
                        I2[H2] = m.get(H2);
                      m.delete();
                    } else
                      I2 = [];
                    g[r] = I2;
                    F2.g = 7;
                    break;
                  }
                  if (void 0 === m) {
                    F2.g = 3;
                    break;
                  }
                  if ("float_list" === y.type) {
                    g[r] = m;
                    F2.g = 7;
                    break;
                  }
                  if ("proto" === y.type) {
                    g[r] = m;
                    F2.g = 7;
                    break;
                  }
                  if ("texture" !== y.type)
                    throw Error("Unknown output config type: '" + y.type + "'");
                  t2 = u.s[r];
                  t2 || (t2 = new Ob(u.h, u.D), u.s[r] = t2);
                  return N2(F2, Pb(t2, m, u.G), 13);
                case 13:
                  x = F2.h, g[r] = x;
                case 7:
                  y.transform && g[r] && (g[r] = y.transform(g[r]));
                  F2.g = 3;
                  break;
                case 14:
                  z2[E2] = F2.h;
                case 3:
                  k3 = w.next();
                  F2.g = 2;
                  break;
                case 4:
                  return F2.return(g);
              }
            });
          });
        }
        function ec(a, b, c) {
          return Z2(a, function e() {
            var g = this, f;
            return O2(e, function(h) {
              return "number" === typeof c || c instanceof Uint8Array || c instanceof g.h.Uint8BlobList ? h.return(c) : c instanceof g.h.Texture2dDataOut ? (f = g.s[b], f || (f = new Ob(g.h, g.D), g.s[b] = f), h.return(Pb(f, c, g.G))) : h.return(void 0);
            });
          });
        }
        function bc(a, b) {
          for (var c = b.name || "$", d = [].concat(L2(b.wants)), e = new a.h.StringList(), g = K2(b.wants), f = g.next(); !f.done; f = g.next())
            e.push_back(f.value);
          g = a.h.PacketListener.implement({ onResults: function(h) {
            for (var k3 = {}, l = 0; l < b.wants.length; ++l)
              k3[d[l]] = h.get(l);
            var n = a.listeners[c];
            n && (a.C = dc(a, k3, b.outs).then(function(u) {
              u = n(u);
              for (var w = 0; w < b.wants.length; ++w) {
                var r = k3[d[w]];
                "object" === typeof r && r.hasOwnProperty && r.hasOwnProperty("delete") && r.delete();
              }
              u && (a.C = u);
            }));
          } });
          a.i.attachMultiListener(e, g);
          e.delete();
        }
        v.onResults = function(a, b) {
          this.listeners[b || "$"] = a;
        };
        P2("Solution", Xb);
        P2("OptionType", { BOOL: 0, NUMBER: 1, aa: 2, 0: "BOOL", 1: "NUMBER", 2: "STRING" });
        function fc(a) {
          a = Kb(a);
          var b = a.getMesh();
          if (!b)
            return a;
          var c = new Float32Array(b.getVertexBufferList());
          b.getVertexBufferList = function() {
            return c;
          };
          var d = new Uint32Array(b.getIndexBufferList());
          b.getIndexBufferList = function() {
            return d;
          };
          return a;
        }
        ;
        var gc = { files: [{ url: "face_mesh_solution_packed_assets_loader.js" }, { simd: true, url: "face_mesh_solution_simd_wasm_bin.js" }, { simd: false, url: "face_mesh_solution_wasm_bin.js" }], graph: { url: "face_mesh.binarypb" }, listeners: [{ wants: ["multi_face_geometry", "image_transformed", "multi_face_landmarks"], outs: { image: "image_transformed", multiFaceGeometry: { type: "proto_list", stream: "multi_face_geometry", transform: function(a) {
          return a.map(fc);
        } }, multiFaceLandmarks: { type: "proto_list", stream: "multi_face_landmarks", transform: function(a) {
          return a.map(function(b) {
            return nb(
              Eb(b),
              Ab
            ).map(Nb);
          });
        } } } }], inputs: { image: { type: "video", stream: "input_frames_gpu" } }, options: { useCpuInference: { type: 0, graphOptionXref: { calculatorType: "InferenceCalculator", fieldName: "use_cpu_inference" }, default: "iPad Simulator;iPhone Simulator;iPod Simulator;iPad;iPhone;iPod".split(";").includes(navigator.platform) || navigator.userAgent.includes("Mac") && "ontouchend" in document }, enableFaceGeometry: { type: 0, graphOptionXref: {
          calculatorName: "EnableFaceGeometryConstant",
          calculatorType: "ConstantSidePacketCalculator",
          fieldName: "bool_value"
        } }, selfieMode: { type: 0, graphOptionXref: { calculatorType: "GlScalerCalculator", calculatorIndex: 1, fieldName: "flip_horizontal" } }, maxNumFaces: { type: 1, graphOptionXref: { calculatorType: "ConstantSidePacketCalculator", calculatorName: "ConstantSidePacketCalculatorNumFaces", fieldName: "int_value" } }, refineLandmarks: { type: 0, graphOptionXref: { calculatorType: "ConstantSidePacketCalculator", calculatorName: "ConstantSidePacketCalculatorRefineLandmarks", fieldName: "bool_value" } }, minDetectionConfidence: {
          type: 1,
          graphOptionXref: { calculatorType: "TensorsToDetectionsCalculator", calculatorName: "facelandmarkfrontgpu__facedetectionshortrangegpu__facedetectionshortrangecommon__TensorsToDetectionsCalculator", fieldName: "min_score_thresh" }
        }, minTrackingConfidence: { type: 1, graphOptionXref: { calculatorType: "ThresholdingCalculator", calculatorName: "facelandmarkfrontgpu__facelandmarkgpu__ThresholdingCalculator", fieldName: "threshold" } }, cameraNear: { type: 1, graphOptionXref: {
          calculatorType: "FaceGeometryEnvGeneratorCalculator",
          fieldName: "near"
        } }, cameraFar: { type: 1, graphOptionXref: { calculatorType: "FaceGeometryEnvGeneratorCalculator", fieldName: "far" } }, cameraVerticalFovDegrees: { type: 1, graphOptionXref: { calculatorType: "FaceGeometryEnvGeneratorCalculator", fieldName: "vertical_fov_degrees" } } } };
        var hc = [[61, 146], [146, 91], [91, 181], [181, 84], [84, 17], [17, 314], [314, 405], [405, 321], [321, 375], [375, 291], [61, 185], [185, 40], [40, 39], [39, 37], [37, 0], [0, 267], [267, 269], [269, 270], [270, 409], [409, 291], [78, 95], [95, 88], [88, 178], [178, 87], [87, 14], [14, 317], [317, 402], [402, 318], [318, 324], [324, 308], [78, 191], [191, 80], [80, 81], [81, 82], [82, 13], [13, 312], [312, 311], [311, 310], [310, 415], [415, 308]], ic = [[263, 249], [249, 390], [390, 373], [373, 374], [374, 380], [380, 381], [381, 382], [382, 362], [263, 466], [466, 388], [388, 387], [387, 386], [
          386,
          385
        ], [385, 384], [384, 398], [398, 362]], jc = [[276, 283], [283, 282], [282, 295], [295, 285], [300, 293], [293, 334], [334, 296], [296, 336]], kc = [[33, 7], [7, 163], [163, 144], [144, 145], [145, 153], [153, 154], [154, 155], [155, 133], [33, 246], [246, 161], [161, 160], [160, 159], [159, 158], [158, 157], [157, 173], [173, 133]], lc = [[46, 53], [53, 52], [52, 65], [65, 55], [70, 63], [63, 105], [105, 66], [66, 107]], mc = [
          [10, 338],
          [338, 297],
          [297, 332],
          [332, 284],
          [284, 251],
          [251, 389],
          [389, 356],
          [356, 454],
          [454, 323],
          [323, 361],
          [361, 288],
          [288, 397],
          [397, 365],
          [365, 379],
          [379, 378],
          [378, 400],
          [400, 377],
          [377, 152],
          [152, 148],
          [148, 176],
          [176, 149],
          [149, 150],
          [150, 136],
          [136, 172],
          [172, 58],
          [58, 132],
          [132, 93],
          [93, 234],
          [234, 127],
          [127, 162],
          [162, 21],
          [21, 54],
          [54, 103],
          [103, 67],
          [67, 109],
          [109, 10]
        ], nc = [].concat(L2(hc), L2(ic), L2(jc), L2(kc), L2(lc), L2(mc));
        function oc(a) {
          a = a || {};
          a = Object.assign(Object.assign({}, gc), a);
          this.g = new Xb(a);
        }
        v = oc.prototype;
        v.close = function() {
          this.g.close();
          return Promise.resolve();
        };
        v.onResults = function(a) {
          this.g.onResults(a);
        };
        v.initialize = function() {
          return Z2(this, function b() {
            var c = this;
            return O2(b, function(d) {
              return N2(d, c.g.initialize(), 0);
            });
          });
        };
        v.reset = function() {
          this.g.reset();
        };
        v.send = function(a) {
          return Z2(this, function c() {
            var d = this;
            return O2(c, function(e) {
              return N2(e, d.g.send(a), 0);
            });
          });
        };
        v.setOptions = function(a) {
          this.g.setOptions(a);
        };
        P2("FACE_GEOMETRY", { Layout: { COLUMN_MAJOR: 0, ROW_MAJOR: 1, 0: "COLUMN_MAJOR", 1: "ROW_MAJOR" }, PrimitiveType: { TRIANGLE: 0, 0: "TRIANGLE" }, VertexType: { VERTEX_PT: 0, 0: "VERTEX_PT" }, DEFAULT_CAMERA_PARAMS: { verticalFovDegrees: 63, near: 1, far: 1e4 } });
        P2("FaceMesh", oc);
        P2("FACEMESH_LIPS", hc);
        P2("FACEMESH_LEFT_EYE", ic);
        P2("FACEMESH_LEFT_EYEBROW", jc);
        P2("FACEMESH_LEFT_IRIS", [[474, 475], [475, 476], [476, 477], [477, 474]]);
        P2("FACEMESH_RIGHT_EYE", kc);
        P2("FACEMESH_RIGHT_EYEBROW", lc);
        P2("FACEMESH_RIGHT_IRIS", [[469, 470], [470, 471], [471, 472], [472, 469]]);
        P2("FACEMESH_FACE_OVAL", mc);
        P2("FACEMESH_CONTOURS", nc);
        P2("FACEMESH_TESSELATION", [
          [127, 34],
          [34, 139],
          [139, 127],
          [11, 0],
          [0, 37],
          [37, 11],
          [232, 231],
          [231, 120],
          [120, 232],
          [72, 37],
          [37, 39],
          [39, 72],
          [128, 121],
          [121, 47],
          [47, 128],
          [232, 121],
          [121, 128],
          [128, 232],
          [104, 69],
          [69, 67],
          [67, 104],
          [175, 171],
          [171, 148],
          [148, 175],
          [118, 50],
          [50, 101],
          [101, 118],
          [73, 39],
          [39, 40],
          [40, 73],
          [9, 151],
          [151, 108],
          [108, 9],
          [48, 115],
          [115, 131],
          [131, 48],
          [194, 204],
          [204, 211],
          [211, 194],
          [74, 40],
          [40, 185],
          [185, 74],
          [80, 42],
          [42, 183],
          [183, 80],
          [40, 92],
          [92, 186],
          [186, 40],
          [230, 229],
          [229, 118],
          [118, 230],
          [202, 212],
          [
            212,
            214
          ],
          [214, 202],
          [83, 18],
          [18, 17],
          [17, 83],
          [76, 61],
          [61, 146],
          [146, 76],
          [160, 29],
          [29, 30],
          [30, 160],
          [56, 157],
          [157, 173],
          [173, 56],
          [106, 204],
          [204, 194],
          [194, 106],
          [135, 214],
          [214, 192],
          [192, 135],
          [203, 165],
          [165, 98],
          [98, 203],
          [21, 71],
          [71, 68],
          [68, 21],
          [51, 45],
          [45, 4],
          [4, 51],
          [144, 24],
          [24, 23],
          [23, 144],
          [77, 146],
          [146, 91],
          [91, 77],
          [205, 50],
          [50, 187],
          [187, 205],
          [201, 200],
          [200, 18],
          [18, 201],
          [91, 106],
          [106, 182],
          [182, 91],
          [90, 91],
          [91, 181],
          [181, 90],
          [85, 84],
          [84, 17],
          [17, 85],
          [206, 203],
          [203, 36],
          [36, 206],
          [148, 171],
          [171, 140],
          [140, 148],
          [
            92,
            40
          ],
          [40, 39],
          [39, 92],
          [193, 189],
          [189, 244],
          [244, 193],
          [159, 158],
          [158, 28],
          [28, 159],
          [247, 246],
          [246, 161],
          [161, 247],
          [236, 3],
          [3, 196],
          [196, 236],
          [54, 68],
          [68, 104],
          [104, 54],
          [193, 168],
          [168, 8],
          [8, 193],
          [117, 228],
          [228, 31],
          [31, 117],
          [189, 193],
          [193, 55],
          [55, 189],
          [98, 97],
          [97, 99],
          [99, 98],
          [126, 47],
          [47, 100],
          [100, 126],
          [166, 79],
          [79, 218],
          [218, 166],
          [155, 154],
          [154, 26],
          [26, 155],
          [209, 49],
          [49, 131],
          [131, 209],
          [135, 136],
          [136, 150],
          [150, 135],
          [47, 126],
          [126, 217],
          [217, 47],
          [223, 52],
          [52, 53],
          [53, 223],
          [45, 51],
          [51, 134],
          [134, 45],
          [211, 170],
          [
            170,
            140
          ],
          [140, 211],
          [67, 69],
          [69, 108],
          [108, 67],
          [43, 106],
          [106, 91],
          [91, 43],
          [230, 119],
          [119, 120],
          [120, 230],
          [226, 130],
          [130, 247],
          [247, 226],
          [63, 53],
          [53, 52],
          [52, 63],
          [238, 20],
          [20, 242],
          [242, 238],
          [46, 70],
          [70, 156],
          [156, 46],
          [78, 62],
          [62, 96],
          [96, 78],
          [46, 53],
          [53, 63],
          [63, 46],
          [143, 34],
          [34, 227],
          [227, 143],
          [123, 117],
          [117, 111],
          [111, 123],
          [44, 125],
          [125, 19],
          [19, 44],
          [236, 134],
          [134, 51],
          [51, 236],
          [216, 206],
          [206, 205],
          [205, 216],
          [154, 153],
          [153, 22],
          [22, 154],
          [39, 37],
          [37, 167],
          [167, 39],
          [200, 201],
          [201, 208],
          [208, 200],
          [36, 142],
          [142, 100],
          [
            100,
            36
          ],
          [57, 212],
          [212, 202],
          [202, 57],
          [20, 60],
          [60, 99],
          [99, 20],
          [28, 158],
          [158, 157],
          [157, 28],
          [35, 226],
          [226, 113],
          [113, 35],
          [160, 159],
          [159, 27],
          [27, 160],
          [204, 202],
          [202, 210],
          [210, 204],
          [113, 225],
          [225, 46],
          [46, 113],
          [43, 202],
          [202, 204],
          [204, 43],
          [62, 76],
          [76, 77],
          [77, 62],
          [137, 123],
          [123, 116],
          [116, 137],
          [41, 38],
          [38, 72],
          [72, 41],
          [203, 129],
          [129, 142],
          [142, 203],
          [64, 98],
          [98, 240],
          [240, 64],
          [49, 102],
          [102, 64],
          [64, 49],
          [41, 73],
          [73, 74],
          [74, 41],
          [212, 216],
          [216, 207],
          [207, 212],
          [42, 74],
          [74, 184],
          [184, 42],
          [169, 170],
          [170, 211],
          [211, 169],
          [
            170,
            149
          ],
          [149, 176],
          [176, 170],
          [105, 66],
          [66, 69],
          [69, 105],
          [122, 6],
          [6, 168],
          [168, 122],
          [123, 147],
          [147, 187],
          [187, 123],
          [96, 77],
          [77, 90],
          [90, 96],
          [65, 55],
          [55, 107],
          [107, 65],
          [89, 90],
          [90, 180],
          [180, 89],
          [101, 100],
          [100, 120],
          [120, 101],
          [63, 105],
          [105, 104],
          [104, 63],
          [93, 137],
          [137, 227],
          [227, 93],
          [15, 86],
          [86, 85],
          [85, 15],
          [129, 102],
          [102, 49],
          [49, 129],
          [14, 87],
          [87, 86],
          [86, 14],
          [55, 8],
          [8, 9],
          [9, 55],
          [100, 47],
          [47, 121],
          [121, 100],
          [145, 23],
          [23, 22],
          [22, 145],
          [88, 89],
          [89, 179],
          [179, 88],
          [6, 122],
          [122, 196],
          [196, 6],
          [88, 95],
          [95, 96],
          [96, 88],
          [138, 172],
          [172, 136],
          [136, 138],
          [215, 58],
          [58, 172],
          [172, 215],
          [115, 48],
          [48, 219],
          [219, 115],
          [42, 80],
          [80, 81],
          [81, 42],
          [195, 3],
          [3, 51],
          [51, 195],
          [43, 146],
          [146, 61],
          [61, 43],
          [171, 175],
          [175, 199],
          [199, 171],
          [81, 82],
          [82, 38],
          [38, 81],
          [53, 46],
          [46, 225],
          [225, 53],
          [144, 163],
          [163, 110],
          [110, 144],
          [52, 65],
          [65, 66],
          [66, 52],
          [229, 228],
          [228, 117],
          [117, 229],
          [34, 127],
          [127, 234],
          [234, 34],
          [107, 108],
          [108, 69],
          [69, 107],
          [109, 108],
          [108, 151],
          [151, 109],
          [48, 64],
          [64, 235],
          [235, 48],
          [62, 78],
          [78, 191],
          [191, 62],
          [129, 209],
          [209, 126],
          [126, 129],
          [111, 35],
          [35, 143],
          [
            143,
            111
          ],
          [117, 123],
          [123, 50],
          [50, 117],
          [222, 65],
          [65, 52],
          [52, 222],
          [19, 125],
          [125, 141],
          [141, 19],
          [221, 55],
          [55, 65],
          [65, 221],
          [3, 195],
          [195, 197],
          [197, 3],
          [25, 7],
          [7, 33],
          [33, 25],
          [220, 237],
          [237, 44],
          [44, 220],
          [70, 71],
          [71, 139],
          [139, 70],
          [122, 193],
          [193, 245],
          [245, 122],
          [247, 130],
          [130, 33],
          [33, 247],
          [71, 21],
          [21, 162],
          [162, 71],
          [170, 169],
          [169, 150],
          [150, 170],
          [188, 174],
          [174, 196],
          [196, 188],
          [216, 186],
          [186, 92],
          [92, 216],
          [2, 97],
          [97, 167],
          [167, 2],
          [141, 125],
          [125, 241],
          [241, 141],
          [164, 167],
          [167, 37],
          [37, 164],
          [72, 38],
          [38, 12],
          [12, 72],
          [38, 82],
          [82, 13],
          [13, 38],
          [63, 68],
          [68, 71],
          [71, 63],
          [226, 35],
          [35, 111],
          [111, 226],
          [101, 50],
          [50, 205],
          [205, 101],
          [206, 92],
          [92, 165],
          [165, 206],
          [209, 198],
          [198, 217],
          [217, 209],
          [165, 167],
          [167, 97],
          [97, 165],
          [220, 115],
          [115, 218],
          [218, 220],
          [133, 112],
          [112, 243],
          [243, 133],
          [239, 238],
          [238, 241],
          [241, 239],
          [214, 135],
          [135, 169],
          [169, 214],
          [190, 173],
          [173, 133],
          [133, 190],
          [171, 208],
          [208, 32],
          [32, 171],
          [125, 44],
          [44, 237],
          [237, 125],
          [86, 87],
          [87, 178],
          [178, 86],
          [85, 86],
          [86, 179],
          [179, 85],
          [84, 85],
          [85, 180],
          [180, 84],
          [83, 84],
          [84, 181],
          [181, 83],
          [201, 83],
          [83, 182],
          [182, 201],
          [137, 93],
          [93, 132],
          [132, 137],
          [76, 62],
          [62, 183],
          [183, 76],
          [61, 76],
          [76, 184],
          [184, 61],
          [57, 61],
          [61, 185],
          [185, 57],
          [212, 57],
          [57, 186],
          [186, 212],
          [214, 207],
          [207, 187],
          [187, 214],
          [34, 143],
          [143, 156],
          [156, 34],
          [79, 239],
          [239, 237],
          [237, 79],
          [123, 137],
          [137, 177],
          [177, 123],
          [44, 1],
          [1, 4],
          [4, 44],
          [201, 194],
          [194, 32],
          [32, 201],
          [64, 102],
          [102, 129],
          [129, 64],
          [213, 215],
          [215, 138],
          [138, 213],
          [59, 166],
          [166, 219],
          [219, 59],
          [242, 99],
          [99, 97],
          [97, 242],
          [2, 94],
          [94, 141],
          [141, 2],
          [75, 59],
          [59, 235],
          [235, 75],
          [24, 110],
          [110, 228],
          [
            228,
            24
          ],
          [25, 130],
          [130, 226],
          [226, 25],
          [23, 24],
          [24, 229],
          [229, 23],
          [22, 23],
          [23, 230],
          [230, 22],
          [26, 22],
          [22, 231],
          [231, 26],
          [112, 26],
          [26, 232],
          [232, 112],
          [189, 190],
          [190, 243],
          [243, 189],
          [221, 56],
          [56, 190],
          [190, 221],
          [28, 56],
          [56, 221],
          [221, 28],
          [27, 28],
          [28, 222],
          [222, 27],
          [29, 27],
          [27, 223],
          [223, 29],
          [30, 29],
          [29, 224],
          [224, 30],
          [247, 30],
          [30, 225],
          [225, 247],
          [238, 79],
          [79, 20],
          [20, 238],
          [166, 59],
          [59, 75],
          [75, 166],
          [60, 75],
          [75, 240],
          [240, 60],
          [147, 177],
          [177, 215],
          [215, 147],
          [20, 79],
          [79, 166],
          [166, 20],
          [187, 147],
          [147, 213],
          [213, 187],
          [112, 233],
          [233, 244],
          [244, 112],
          [233, 128],
          [128, 245],
          [245, 233],
          [128, 114],
          [114, 188],
          [188, 128],
          [114, 217],
          [217, 174],
          [174, 114],
          [131, 115],
          [115, 220],
          [220, 131],
          [217, 198],
          [198, 236],
          [236, 217],
          [198, 131],
          [131, 134],
          [134, 198],
          [177, 132],
          [132, 58],
          [58, 177],
          [143, 35],
          [35, 124],
          [124, 143],
          [110, 163],
          [163, 7],
          [7, 110],
          [228, 110],
          [110, 25],
          [25, 228],
          [356, 389],
          [389, 368],
          [368, 356],
          [11, 302],
          [302, 267],
          [267, 11],
          [452, 350],
          [350, 349],
          [349, 452],
          [302, 303],
          [303, 269],
          [269, 302],
          [357, 343],
          [343, 277],
          [277, 357],
          [452, 453],
          [453, 357],
          [357, 452],
          [333, 332],
          [
            332,
            297
          ],
          [297, 333],
          [175, 152],
          [152, 377],
          [377, 175],
          [347, 348],
          [348, 330],
          [330, 347],
          [303, 304],
          [304, 270],
          [270, 303],
          [9, 336],
          [336, 337],
          [337, 9],
          [278, 279],
          [279, 360],
          [360, 278],
          [418, 262],
          [262, 431],
          [431, 418],
          [304, 408],
          [408, 409],
          [409, 304],
          [310, 415],
          [415, 407],
          [407, 310],
          [270, 409],
          [409, 410],
          [410, 270],
          [450, 348],
          [348, 347],
          [347, 450],
          [422, 430],
          [430, 434],
          [434, 422],
          [313, 314],
          [314, 17],
          [17, 313],
          [306, 307],
          [307, 375],
          [375, 306],
          [387, 388],
          [388, 260],
          [260, 387],
          [286, 414],
          [414, 398],
          [398, 286],
          [335, 406],
          [406, 418],
          [418, 335],
          [364, 367],
          [
            367,
            416
          ],
          [416, 364],
          [423, 358],
          [358, 327],
          [327, 423],
          [251, 284],
          [284, 298],
          [298, 251],
          [281, 5],
          [5, 4],
          [4, 281],
          [373, 374],
          [374, 253],
          [253, 373],
          [307, 320],
          [320, 321],
          [321, 307],
          [425, 427],
          [427, 411],
          [411, 425],
          [421, 313],
          [313, 18],
          [18, 421],
          [321, 405],
          [405, 406],
          [406, 321],
          [320, 404],
          [404, 405],
          [405, 320],
          [315, 16],
          [16, 17],
          [17, 315],
          [426, 425],
          [425, 266],
          [266, 426],
          [377, 400],
          [400, 369],
          [369, 377],
          [322, 391],
          [391, 269],
          [269, 322],
          [417, 465],
          [465, 464],
          [464, 417],
          [386, 257],
          [257, 258],
          [258, 386],
          [466, 260],
          [260, 388],
          [388, 466],
          [456, 399],
          [399, 419],
          [419, 456],
          [284, 332],
          [332, 333],
          [333, 284],
          [417, 285],
          [285, 8],
          [8, 417],
          [346, 340],
          [340, 261],
          [261, 346],
          [413, 441],
          [441, 285],
          [285, 413],
          [327, 460],
          [460, 328],
          [328, 327],
          [355, 371],
          [371, 329],
          [329, 355],
          [392, 439],
          [439, 438],
          [438, 392],
          [382, 341],
          [341, 256],
          [256, 382],
          [429, 420],
          [420, 360],
          [360, 429],
          [364, 394],
          [394, 379],
          [379, 364],
          [277, 343],
          [343, 437],
          [437, 277],
          [443, 444],
          [444, 283],
          [283, 443],
          [275, 440],
          [440, 363],
          [363, 275],
          [431, 262],
          [262, 369],
          [369, 431],
          [297, 338],
          [338, 337],
          [337, 297],
          [273, 375],
          [375, 321],
          [321, 273],
          [450, 451],
          [
            451,
            349
          ],
          [349, 450],
          [446, 342],
          [342, 467],
          [467, 446],
          [293, 334],
          [334, 282],
          [282, 293],
          [458, 461],
          [461, 462],
          [462, 458],
          [276, 353],
          [353, 383],
          [383, 276],
          [308, 324],
          [324, 325],
          [325, 308],
          [276, 300],
          [300, 293],
          [293, 276],
          [372, 345],
          [345, 447],
          [447, 372],
          [352, 345],
          [345, 340],
          [340, 352],
          [274, 1],
          [1, 19],
          [19, 274],
          [456, 248],
          [248, 281],
          [281, 456],
          [436, 427],
          [427, 425],
          [425, 436],
          [381, 256],
          [256, 252],
          [252, 381],
          [269, 391],
          [391, 393],
          [393, 269],
          [200, 199],
          [199, 428],
          [428, 200],
          [266, 330],
          [330, 329],
          [329, 266],
          [287, 273],
          [273, 422],
          [422, 287],
          [250, 462],
          [
            462,
            328
          ],
          [328, 250],
          [258, 286],
          [286, 384],
          [384, 258],
          [265, 353],
          [353, 342],
          [342, 265],
          [387, 259],
          [259, 257],
          [257, 387],
          [424, 431],
          [431, 430],
          [430, 424],
          [342, 353],
          [353, 276],
          [276, 342],
          [273, 335],
          [335, 424],
          [424, 273],
          [292, 325],
          [325, 307],
          [307, 292],
          [366, 447],
          [447, 345],
          [345, 366],
          [271, 303],
          [303, 302],
          [302, 271],
          [423, 266],
          [266, 371],
          [371, 423],
          [294, 455],
          [455, 460],
          [460, 294],
          [279, 278],
          [278, 294],
          [294, 279],
          [271, 272],
          [272, 304],
          [304, 271],
          [432, 434],
          [434, 427],
          [427, 432],
          [272, 407],
          [407, 408],
          [408, 272],
          [394, 430],
          [430, 431],
          [431, 394],
          [395, 369],
          [369, 400],
          [400, 395],
          [334, 333],
          [333, 299],
          [299, 334],
          [351, 417],
          [417, 168],
          [168, 351],
          [352, 280],
          [280, 411],
          [411, 352],
          [325, 319],
          [319, 320],
          [320, 325],
          [295, 296],
          [296, 336],
          [336, 295],
          [319, 403],
          [403, 404],
          [404, 319],
          [330, 348],
          [348, 349],
          [349, 330],
          [293, 298],
          [298, 333],
          [333, 293],
          [323, 454],
          [454, 447],
          [447, 323],
          [15, 16],
          [16, 315],
          [315, 15],
          [358, 429],
          [429, 279],
          [279, 358],
          [14, 15],
          [15, 316],
          [316, 14],
          [285, 336],
          [336, 9],
          [9, 285],
          [329, 349],
          [349, 350],
          [350, 329],
          [374, 380],
          [380, 252],
          [252, 374],
          [318, 402],
          [402, 403],
          [403, 318],
          [6, 197],
          [
            197,
            419
          ],
          [419, 6],
          [318, 319],
          [319, 325],
          [325, 318],
          [367, 364],
          [364, 365],
          [365, 367],
          [435, 367],
          [367, 397],
          [397, 435],
          [344, 438],
          [438, 439],
          [439, 344],
          [272, 271],
          [271, 311],
          [311, 272],
          [195, 5],
          [5, 281],
          [281, 195],
          [273, 287],
          [287, 291],
          [291, 273],
          [396, 428],
          [428, 199],
          [199, 396],
          [311, 271],
          [271, 268],
          [268, 311],
          [283, 444],
          [444, 445],
          [445, 283],
          [373, 254],
          [254, 339],
          [339, 373],
          [282, 334],
          [334, 296],
          [296, 282],
          [449, 347],
          [347, 346],
          [346, 449],
          [264, 447],
          [447, 454],
          [454, 264],
          [336, 296],
          [296, 299],
          [299, 336],
          [338, 10],
          [10, 151],
          [151, 338],
          [278, 439],
          [
            439,
            455
          ],
          [455, 278],
          [292, 407],
          [407, 415],
          [415, 292],
          [358, 371],
          [371, 355],
          [355, 358],
          [340, 345],
          [345, 372],
          [372, 340],
          [346, 347],
          [347, 280],
          [280, 346],
          [442, 443],
          [443, 282],
          [282, 442],
          [19, 94],
          [94, 370],
          [370, 19],
          [441, 442],
          [442, 295],
          [295, 441],
          [248, 419],
          [419, 197],
          [197, 248],
          [263, 255],
          [255, 359],
          [359, 263],
          [440, 275],
          [275, 274],
          [274, 440],
          [300, 383],
          [383, 368],
          [368, 300],
          [351, 412],
          [412, 465],
          [465, 351],
          [263, 467],
          [467, 466],
          [466, 263],
          [301, 368],
          [368, 389],
          [389, 301],
          [395, 378],
          [378, 379],
          [379, 395],
          [412, 351],
          [351, 419],
          [419, 412],
          [436, 426],
          [426, 322],
          [322, 436],
          [2, 164],
          [164, 393],
          [393, 2],
          [370, 462],
          [462, 461],
          [461, 370],
          [164, 0],
          [0, 267],
          [267, 164],
          [302, 11],
          [11, 12],
          [12, 302],
          [268, 12],
          [12, 13],
          [13, 268],
          [293, 300],
          [300, 301],
          [301, 293],
          [446, 261],
          [261, 340],
          [340, 446],
          [330, 266],
          [266, 425],
          [425, 330],
          [426, 423],
          [423, 391],
          [391, 426],
          [429, 355],
          [355, 437],
          [437, 429],
          [391, 327],
          [327, 326],
          [326, 391],
          [440, 457],
          [457, 438],
          [438, 440],
          [341, 382],
          [382, 362],
          [362, 341],
          [459, 457],
          [457, 461],
          [461, 459],
          [434, 430],
          [430, 394],
          [394, 434],
          [414, 463],
          [463, 362],
          [362, 414],
          [396, 369],
          [369, 262],
          [262, 396],
          [354, 461],
          [461, 457],
          [457, 354],
          [316, 403],
          [403, 402],
          [402, 316],
          [315, 404],
          [404, 403],
          [403, 315],
          [314, 405],
          [405, 404],
          [404, 314],
          [313, 406],
          [406, 405],
          [405, 313],
          [421, 418],
          [418, 406],
          [406, 421],
          [366, 401],
          [401, 361],
          [361, 366],
          [306, 408],
          [408, 407],
          [407, 306],
          [291, 409],
          [409, 408],
          [408, 291],
          [287, 410],
          [410, 409],
          [409, 287],
          [432, 436],
          [436, 410],
          [410, 432],
          [434, 416],
          [416, 411],
          [411, 434],
          [264, 368],
          [368, 383],
          [383, 264],
          [309, 438],
          [438, 457],
          [457, 309],
          [352, 376],
          [376, 401],
          [401, 352],
          [274, 275],
          [275, 4],
          [4, 274],
          [421, 428],
          [
            428,
            262
          ],
          [262, 421],
          [294, 327],
          [327, 358],
          [358, 294],
          [433, 416],
          [416, 367],
          [367, 433],
          [289, 455],
          [455, 439],
          [439, 289],
          [462, 370],
          [370, 326],
          [326, 462],
          [2, 326],
          [326, 370],
          [370, 2],
          [305, 460],
          [460, 455],
          [455, 305],
          [254, 449],
          [449, 448],
          [448, 254],
          [255, 261],
          [261, 446],
          [446, 255],
          [253, 450],
          [450, 449],
          [449, 253],
          [252, 451],
          [451, 450],
          [450, 252],
          [256, 452],
          [452, 451],
          [451, 256],
          [341, 453],
          [453, 452],
          [452, 341],
          [413, 464],
          [464, 463],
          [463, 413],
          [441, 413],
          [413, 414],
          [414, 441],
          [258, 442],
          [442, 441],
          [441, 258],
          [257, 443],
          [443, 442],
          [442, 257],
          [259, 444],
          [444, 443],
          [443, 259],
          [260, 445],
          [445, 444],
          [444, 260],
          [467, 342],
          [342, 445],
          [445, 467],
          [459, 458],
          [458, 250],
          [250, 459],
          [289, 392],
          [392, 290],
          [290, 289],
          [290, 328],
          [328, 460],
          [460, 290],
          [376, 433],
          [433, 435],
          [435, 376],
          [250, 290],
          [290, 392],
          [392, 250],
          [411, 416],
          [416, 433],
          [433, 411],
          [341, 463],
          [463, 464],
          [464, 341],
          [453, 464],
          [464, 465],
          [465, 453],
          [357, 465],
          [465, 412],
          [412, 357],
          [343, 412],
          [412, 399],
          [399, 343],
          [360, 363],
          [363, 440],
          [440, 360],
          [437, 399],
          [399, 456],
          [456, 437],
          [420, 456],
          [456, 363],
          [363, 420],
          [401, 435],
          [435, 288],
          [288, 401],
          [
            372,
            383
          ],
          [383, 353],
          [353, 372],
          [339, 255],
          [255, 249],
          [249, 339],
          [448, 261],
          [261, 255],
          [255, 448],
          [133, 243],
          [243, 190],
          [190, 133],
          [133, 155],
          [155, 112],
          [112, 133],
          [33, 246],
          [246, 247],
          [247, 33],
          [33, 130],
          [130, 25],
          [25, 33],
          [398, 384],
          [384, 286],
          [286, 398],
          [362, 398],
          [398, 414],
          [414, 362],
          [362, 463],
          [463, 341],
          [341, 362],
          [263, 359],
          [359, 467],
          [467, 263],
          [263, 249],
          [249, 255],
          [255, 263],
          [466, 467],
          [467, 260],
          [260, 466],
          [75, 60],
          [60, 166],
          [166, 75],
          [238, 239],
          [239, 79],
          [79, 238],
          [162, 127],
          [127, 139],
          [139, 162],
          [72, 11],
          [11, 37],
          [37, 72],
          [121, 232],
          [
            232,
            120
          ],
          [120, 121],
          [73, 72],
          [72, 39],
          [39, 73],
          [114, 128],
          [128, 47],
          [47, 114],
          [233, 232],
          [232, 128],
          [128, 233],
          [103, 104],
          [104, 67],
          [67, 103],
          [152, 175],
          [175, 148],
          [148, 152],
          [119, 118],
          [118, 101],
          [101, 119],
          [74, 73],
          [73, 40],
          [40, 74],
          [107, 9],
          [9, 108],
          [108, 107],
          [49, 48],
          [48, 131],
          [131, 49],
          [32, 194],
          [194, 211],
          [211, 32],
          [184, 74],
          [74, 185],
          [185, 184],
          [191, 80],
          [80, 183],
          [183, 191],
          [185, 40],
          [40, 186],
          [186, 185],
          [119, 230],
          [230, 118],
          [118, 119],
          [210, 202],
          [202, 214],
          [214, 210],
          [84, 83],
          [83, 17],
          [17, 84],
          [77, 76],
          [76, 146],
          [146, 77],
          [161, 160],
          [160, 30],
          [30, 161],
          [190, 56],
          [56, 173],
          [173, 190],
          [182, 106],
          [106, 194],
          [194, 182],
          [138, 135],
          [135, 192],
          [192, 138],
          [129, 203],
          [203, 98],
          [98, 129],
          [54, 21],
          [21, 68],
          [68, 54],
          [5, 51],
          [51, 4],
          [4, 5],
          [145, 144],
          [144, 23],
          [23, 145],
          [90, 77],
          [77, 91],
          [91, 90],
          [207, 205],
          [205, 187],
          [187, 207],
          [83, 201],
          [201, 18],
          [18, 83],
          [181, 91],
          [91, 182],
          [182, 181],
          [180, 90],
          [90, 181],
          [181, 180],
          [16, 85],
          [85, 17],
          [17, 16],
          [205, 206],
          [206, 36],
          [36, 205],
          [176, 148],
          [148, 140],
          [140, 176],
          [165, 92],
          [92, 39],
          [39, 165],
          [245, 193],
          [193, 244],
          [244, 245],
          [27, 159],
          [159, 28],
          [28, 27],
          [
            30,
            247
          ],
          [247, 161],
          [161, 30],
          [174, 236],
          [236, 196],
          [196, 174],
          [103, 54],
          [54, 104],
          [104, 103],
          [55, 193],
          [193, 8],
          [8, 55],
          [111, 117],
          [117, 31],
          [31, 111],
          [221, 189],
          [189, 55],
          [55, 221],
          [240, 98],
          [98, 99],
          [99, 240],
          [142, 126],
          [126, 100],
          [100, 142],
          [219, 166],
          [166, 218],
          [218, 219],
          [112, 155],
          [155, 26],
          [26, 112],
          [198, 209],
          [209, 131],
          [131, 198],
          [169, 135],
          [135, 150],
          [150, 169],
          [114, 47],
          [47, 217],
          [217, 114],
          [224, 223],
          [223, 53],
          [53, 224],
          [220, 45],
          [45, 134],
          [134, 220],
          [32, 211],
          [211, 140],
          [140, 32],
          [109, 67],
          [67, 108],
          [108, 109],
          [146, 43],
          [43, 91],
          [91, 146],
          [231, 230],
          [230, 120],
          [120, 231],
          [113, 226],
          [226, 247],
          [247, 113],
          [105, 63],
          [63, 52],
          [52, 105],
          [241, 238],
          [238, 242],
          [242, 241],
          [124, 46],
          [46, 156],
          [156, 124],
          [95, 78],
          [78, 96],
          [96, 95],
          [70, 46],
          [46, 63],
          [63, 70],
          [116, 143],
          [143, 227],
          [227, 116],
          [116, 123],
          [123, 111],
          [111, 116],
          [1, 44],
          [44, 19],
          [19, 1],
          [3, 236],
          [236, 51],
          [51, 3],
          [207, 216],
          [216, 205],
          [205, 207],
          [26, 154],
          [154, 22],
          [22, 26],
          [165, 39],
          [39, 167],
          [167, 165],
          [199, 200],
          [200, 208],
          [208, 199],
          [101, 36],
          [36, 100],
          [100, 101],
          [43, 57],
          [57, 202],
          [202, 43],
          [242, 20],
          [20, 99],
          [99, 242],
          [56, 28],
          [
            28,
            157
          ],
          [157, 56],
          [124, 35],
          [35, 113],
          [113, 124],
          [29, 160],
          [160, 27],
          [27, 29],
          [211, 204],
          [204, 210],
          [210, 211],
          [124, 113],
          [113, 46],
          [46, 124],
          [106, 43],
          [43, 204],
          [204, 106],
          [96, 62],
          [62, 77],
          [77, 96],
          [227, 137],
          [137, 116],
          [116, 227],
          [73, 41],
          [41, 72],
          [72, 73],
          [36, 203],
          [203, 142],
          [142, 36],
          [235, 64],
          [64, 240],
          [240, 235],
          [48, 49],
          [49, 64],
          [64, 48],
          [42, 41],
          [41, 74],
          [74, 42],
          [214, 212],
          [212, 207],
          [207, 214],
          [183, 42],
          [42, 184],
          [184, 183],
          [210, 169],
          [169, 211],
          [211, 210],
          [140, 170],
          [170, 176],
          [176, 140],
          [104, 105],
          [105, 69],
          [69, 104],
          [193, 122],
          [122, 168],
          [168, 193],
          [50, 123],
          [123, 187],
          [187, 50],
          [89, 96],
          [96, 90],
          [90, 89],
          [66, 65],
          [65, 107],
          [107, 66],
          [179, 89],
          [89, 180],
          [180, 179],
          [119, 101],
          [101, 120],
          [120, 119],
          [68, 63],
          [63, 104],
          [104, 68],
          [234, 93],
          [93, 227],
          [227, 234],
          [16, 15],
          [15, 85],
          [85, 16],
          [209, 129],
          [129, 49],
          [49, 209],
          [15, 14],
          [14, 86],
          [86, 15],
          [107, 55],
          [55, 9],
          [9, 107],
          [120, 100],
          [100, 121],
          [121, 120],
          [153, 145],
          [145, 22],
          [22, 153],
          [178, 88],
          [88, 179],
          [179, 178],
          [197, 6],
          [6, 196],
          [196, 197],
          [89, 88],
          [88, 96],
          [96, 89],
          [135, 138],
          [138, 136],
          [136, 135],
          [138, 215],
          [215, 172],
          [172, 138],
          [
            218,
            115
          ],
          [115, 219],
          [219, 218],
          [41, 42],
          [42, 81],
          [81, 41],
          [5, 195],
          [195, 51],
          [51, 5],
          [57, 43],
          [43, 61],
          [61, 57],
          [208, 171],
          [171, 199],
          [199, 208],
          [41, 81],
          [81, 38],
          [38, 41],
          [224, 53],
          [53, 225],
          [225, 224],
          [24, 144],
          [144, 110],
          [110, 24],
          [105, 52],
          [52, 66],
          [66, 105],
          [118, 229],
          [229, 117],
          [117, 118],
          [227, 34],
          [34, 234],
          [234, 227],
          [66, 107],
          [107, 69],
          [69, 66],
          [10, 109],
          [109, 151],
          [151, 10],
          [219, 48],
          [48, 235],
          [235, 219],
          [183, 62],
          [62, 191],
          [191, 183],
          [142, 129],
          [129, 126],
          [126, 142],
          [116, 111],
          [111, 143],
          [143, 116],
          [118, 117],
          [117, 50],
          [50, 118],
          [223, 222],
          [
            222,
            52
          ],
          [52, 223],
          [94, 19],
          [19, 141],
          [141, 94],
          [222, 221],
          [221, 65],
          [65, 222],
          [196, 3],
          [3, 197],
          [197, 196],
          [45, 220],
          [220, 44],
          [44, 45],
          [156, 70],
          [70, 139],
          [139, 156],
          [188, 122],
          [122, 245],
          [245, 188],
          [139, 71],
          [71, 162],
          [162, 139],
          [149, 170],
          [170, 150],
          [150, 149],
          [122, 188],
          [188, 196],
          [196, 122],
          [206, 216],
          [216, 92],
          [92, 206],
          [164, 2],
          [2, 167],
          [167, 164],
          [242, 141],
          [141, 241],
          [241, 242],
          [0, 164],
          [164, 37],
          [37, 0],
          [11, 72],
          [72, 12],
          [12, 11],
          [12, 38],
          [38, 13],
          [13, 12],
          [70, 63],
          [63, 71],
          [71, 70],
          [31, 226],
          [226, 111],
          [111, 31],
          [36, 101],
          [101, 205],
          [205, 36],
          [203, 206],
          [206, 165],
          [165, 203],
          [126, 209],
          [209, 217],
          [217, 126],
          [98, 165],
          [165, 97],
          [97, 98],
          [237, 220],
          [220, 218],
          [218, 237],
          [237, 239],
          [239, 241],
          [241, 237],
          [210, 214],
          [214, 169],
          [169, 210],
          [140, 171],
          [171, 32],
          [32, 140],
          [241, 125],
          [125, 237],
          [237, 241],
          [179, 86],
          [86, 178],
          [178, 179],
          [180, 85],
          [85, 179],
          [179, 180],
          [181, 84],
          [84, 180],
          [180, 181],
          [182, 83],
          [83, 181],
          [181, 182],
          [194, 201],
          [201, 182],
          [182, 194],
          [177, 137],
          [137, 132],
          [132, 177],
          [184, 76],
          [76, 183],
          [183, 184],
          [185, 61],
          [61, 184],
          [184, 185],
          [186, 57],
          [57, 185],
          [185, 186],
          [216, 212],
          [
            212,
            186
          ],
          [186, 216],
          [192, 214],
          [214, 187],
          [187, 192],
          [139, 34],
          [34, 156],
          [156, 139],
          [218, 79],
          [79, 237],
          [237, 218],
          [147, 123],
          [123, 177],
          [177, 147],
          [45, 44],
          [44, 4],
          [4, 45],
          [208, 201],
          [201, 32],
          [32, 208],
          [98, 64],
          [64, 129],
          [129, 98],
          [192, 213],
          [213, 138],
          [138, 192],
          [235, 59],
          [59, 219],
          [219, 235],
          [141, 242],
          [242, 97],
          [97, 141],
          [97, 2],
          [2, 141],
          [141, 97],
          [240, 75],
          [75, 235],
          [235, 240],
          [229, 24],
          [24, 228],
          [228, 229],
          [31, 25],
          [25, 226],
          [226, 31],
          [230, 23],
          [23, 229],
          [229, 230],
          [231, 22],
          [22, 230],
          [230, 231],
          [232, 26],
          [26, 231],
          [231, 232],
          [233, 112],
          [112, 232],
          [232, 233],
          [244, 189],
          [189, 243],
          [243, 244],
          [189, 221],
          [221, 190],
          [190, 189],
          [222, 28],
          [28, 221],
          [221, 222],
          [223, 27],
          [27, 222],
          [222, 223],
          [224, 29],
          [29, 223],
          [223, 224],
          [225, 30],
          [30, 224],
          [224, 225],
          [113, 247],
          [247, 225],
          [225, 113],
          [99, 60],
          [60, 240],
          [240, 99],
          [213, 147],
          [147, 215],
          [215, 213],
          [60, 20],
          [20, 166],
          [166, 60],
          [192, 187],
          [187, 213],
          [213, 192],
          [243, 112],
          [112, 244],
          [244, 243],
          [244, 233],
          [233, 245],
          [245, 244],
          [245, 128],
          [128, 188],
          [188, 245],
          [188, 114],
          [114, 174],
          [174, 188],
          [134, 131],
          [131, 220],
          [220, 134],
          [174, 217],
          [217, 236],
          [236, 174],
          [236, 198],
          [198, 134],
          [134, 236],
          [215, 177],
          [177, 58],
          [58, 215],
          [156, 143],
          [143, 124],
          [124, 156],
          [25, 110],
          [110, 7],
          [7, 25],
          [31, 228],
          [228, 25],
          [25, 31],
          [264, 356],
          [356, 368],
          [368, 264],
          [0, 11],
          [11, 267],
          [267, 0],
          [451, 452],
          [452, 349],
          [349, 451],
          [267, 302],
          [302, 269],
          [269, 267],
          [350, 357],
          [357, 277],
          [277, 350],
          [350, 452],
          [452, 357],
          [357, 350],
          [299, 333],
          [333, 297],
          [297, 299],
          [396, 175],
          [175, 377],
          [377, 396],
          [280, 347],
          [347, 330],
          [330, 280],
          [269, 303],
          [303, 270],
          [270, 269],
          [151, 9],
          [9, 337],
          [337, 151],
          [344, 278],
          [278, 360],
          [360, 344],
          [424, 418],
          [
            418,
            431
          ],
          [431, 424],
          [270, 304],
          [304, 409],
          [409, 270],
          [272, 310],
          [310, 407],
          [407, 272],
          [322, 270],
          [270, 410],
          [410, 322],
          [449, 450],
          [450, 347],
          [347, 449],
          [432, 422],
          [422, 434],
          [434, 432],
          [18, 313],
          [313, 17],
          [17, 18],
          [291, 306],
          [306, 375],
          [375, 291],
          [259, 387],
          [387, 260],
          [260, 259],
          [424, 335],
          [335, 418],
          [418, 424],
          [434, 364],
          [364, 416],
          [416, 434],
          [391, 423],
          [423, 327],
          [327, 391],
          [301, 251],
          [251, 298],
          [298, 301],
          [275, 281],
          [281, 4],
          [4, 275],
          [254, 373],
          [373, 253],
          [253, 254],
          [375, 307],
          [307, 321],
          [321, 375],
          [280, 425],
          [425, 411],
          [411, 280],
          [200, 421],
          [
            421,
            18
          ],
          [18, 200],
          [335, 321],
          [321, 406],
          [406, 335],
          [321, 320],
          [320, 405],
          [405, 321],
          [314, 315],
          [315, 17],
          [17, 314],
          [423, 426],
          [426, 266],
          [266, 423],
          [396, 377],
          [377, 369],
          [369, 396],
          [270, 322],
          [322, 269],
          [269, 270],
          [413, 417],
          [417, 464],
          [464, 413],
          [385, 386],
          [386, 258],
          [258, 385],
          [248, 456],
          [456, 419],
          [419, 248],
          [298, 284],
          [284, 333],
          [333, 298],
          [168, 417],
          [417, 8],
          [8, 168],
          [448, 346],
          [346, 261],
          [261, 448],
          [417, 413],
          [413, 285],
          [285, 417],
          [326, 327],
          [327, 328],
          [328, 326],
          [277, 355],
          [355, 329],
          [329, 277],
          [309, 392],
          [392, 438],
          [438, 309],
          [381, 382],
          [
            382,
            256
          ],
          [256, 381],
          [279, 429],
          [429, 360],
          [360, 279],
          [365, 364],
          [364, 379],
          [379, 365],
          [355, 277],
          [277, 437],
          [437, 355],
          [282, 443],
          [443, 283],
          [283, 282],
          [281, 275],
          [275, 363],
          [363, 281],
          [395, 431],
          [431, 369],
          [369, 395],
          [299, 297],
          [297, 337],
          [337, 299],
          [335, 273],
          [273, 321],
          [321, 335],
          [348, 450],
          [450, 349],
          [349, 348],
          [359, 446],
          [446, 467],
          [467, 359],
          [283, 293],
          [293, 282],
          [282, 283],
          [250, 458],
          [458, 462],
          [462, 250],
          [300, 276],
          [276, 383],
          [383, 300],
          [292, 308],
          [308, 325],
          [325, 292],
          [283, 276],
          [276, 293],
          [293, 283],
          [264, 372],
          [372, 447],
          [447, 264],
          [346, 352],
          [352, 340],
          [340, 346],
          [354, 274],
          [274, 19],
          [19, 354],
          [363, 456],
          [456, 281],
          [281, 363],
          [426, 436],
          [436, 425],
          [425, 426],
          [380, 381],
          [381, 252],
          [252, 380],
          [267, 269],
          [269, 393],
          [393, 267],
          [421, 200],
          [200, 428],
          [428, 421],
          [371, 266],
          [266, 329],
          [329, 371],
          [432, 287],
          [287, 422],
          [422, 432],
          [290, 250],
          [250, 328],
          [328, 290],
          [385, 258],
          [258, 384],
          [384, 385],
          [446, 265],
          [265, 342],
          [342, 446],
          [386, 387],
          [387, 257],
          [257, 386],
          [422, 424],
          [424, 430],
          [430, 422],
          [445, 342],
          [342, 276],
          [276, 445],
          [422, 273],
          [273, 424],
          [424, 422],
          [306, 292],
          [292, 307],
          [307, 306],
          [
            352,
            366
          ],
          [366, 345],
          [345, 352],
          [268, 271],
          [271, 302],
          [302, 268],
          [358, 423],
          [423, 371],
          [371, 358],
          [327, 294],
          [294, 460],
          [460, 327],
          [331, 279],
          [279, 294],
          [294, 331],
          [303, 271],
          [271, 304],
          [304, 303],
          [436, 432],
          [432, 427],
          [427, 436],
          [304, 272],
          [272, 408],
          [408, 304],
          [395, 394],
          [394, 431],
          [431, 395],
          [378, 395],
          [395, 400],
          [400, 378],
          [296, 334],
          [334, 299],
          [299, 296],
          [6, 351],
          [351, 168],
          [168, 6],
          [376, 352],
          [352, 411],
          [411, 376],
          [307, 325],
          [325, 320],
          [320, 307],
          [285, 295],
          [295, 336],
          [336, 285],
          [320, 319],
          [319, 404],
          [404, 320],
          [329, 330],
          [330, 349],
          [349, 329],
          [334, 293],
          [293, 333],
          [333, 334],
          [366, 323],
          [323, 447],
          [447, 366],
          [316, 15],
          [15, 315],
          [315, 316],
          [331, 358],
          [358, 279],
          [279, 331],
          [317, 14],
          [14, 316],
          [316, 317],
          [8, 285],
          [285, 9],
          [9, 8],
          [277, 329],
          [329, 350],
          [350, 277],
          [253, 374],
          [374, 252],
          [252, 253],
          [319, 318],
          [318, 403],
          [403, 319],
          [351, 6],
          [6, 419],
          [419, 351],
          [324, 318],
          [318, 325],
          [325, 324],
          [397, 367],
          [367, 365],
          [365, 397],
          [288, 435],
          [435, 397],
          [397, 288],
          [278, 344],
          [344, 439],
          [439, 278],
          [310, 272],
          [272, 311],
          [311, 310],
          [248, 195],
          [195, 281],
          [281, 248],
          [375, 273],
          [273, 291],
          [291, 375],
          [175, 396],
          [396, 199],
          [199, 175],
          [312, 311],
          [311, 268],
          [268, 312],
          [276, 283],
          [283, 445],
          [445, 276],
          [390, 373],
          [373, 339],
          [339, 390],
          [295, 282],
          [282, 296],
          [296, 295],
          [448, 449],
          [449, 346],
          [346, 448],
          [356, 264],
          [264, 454],
          [454, 356],
          [337, 336],
          [336, 299],
          [299, 337],
          [337, 338],
          [338, 151],
          [151, 337],
          [294, 278],
          [278, 455],
          [455, 294],
          [308, 292],
          [292, 415],
          [415, 308],
          [429, 358],
          [358, 355],
          [355, 429],
          [265, 340],
          [340, 372],
          [372, 265],
          [352, 346],
          [346, 280],
          [280, 352],
          [295, 442],
          [442, 282],
          [282, 295],
          [354, 19],
          [19, 370],
          [370, 354],
          [285, 441],
          [441, 295],
          [295, 285],
          [
            195,
            248
          ],
          [248, 197],
          [197, 195],
          [457, 440],
          [440, 274],
          [274, 457],
          [301, 300],
          [300, 368],
          [368, 301],
          [417, 351],
          [351, 465],
          [465, 417],
          [251, 301],
          [301, 389],
          [389, 251],
          [394, 395],
          [395, 379],
          [379, 394],
          [399, 412],
          [412, 419],
          [419, 399],
          [410, 436],
          [436, 322],
          [322, 410],
          [326, 2],
          [2, 393],
          [393, 326],
          [354, 370],
          [370, 461],
          [461, 354],
          [393, 164],
          [164, 267],
          [267, 393],
          [268, 302],
          [302, 12],
          [12, 268],
          [312, 268],
          [268, 13],
          [13, 312],
          [298, 293],
          [293, 301],
          [301, 298],
          [265, 446],
          [446, 340],
          [340, 265],
          [280, 330],
          [330, 425],
          [425, 280],
          [322, 426],
          [426, 391],
          [391, 322],
          [
            420,
            429
          ],
          [429, 437],
          [437, 420],
          [393, 391],
          [391, 326],
          [326, 393],
          [344, 440],
          [440, 438],
          [438, 344],
          [458, 459],
          [459, 461],
          [461, 458],
          [364, 434],
          [434, 394],
          [394, 364],
          [428, 396],
          [396, 262],
          [262, 428],
          [274, 354],
          [354, 457],
          [457, 274],
          [317, 316],
          [316, 402],
          [402, 317],
          [316, 315],
          [315, 403],
          [403, 316],
          [315, 314],
          [314, 404],
          [404, 315],
          [314, 313],
          [313, 405],
          [405, 314],
          [313, 421],
          [421, 406],
          [406, 313],
          [323, 366],
          [366, 361],
          [361, 323],
          [292, 306],
          [306, 407],
          [407, 292],
          [306, 291],
          [291, 408],
          [408, 306],
          [291, 287],
          [287, 409],
          [409, 291],
          [287, 432],
          [432, 410],
          [410, 287],
          [427, 434],
          [434, 411],
          [411, 427],
          [372, 264],
          [264, 383],
          [383, 372],
          [459, 309],
          [309, 457],
          [457, 459],
          [366, 352],
          [352, 401],
          [401, 366],
          [1, 274],
          [274, 4],
          [4, 1],
          [418, 421],
          [421, 262],
          [262, 418],
          [331, 294],
          [294, 358],
          [358, 331],
          [435, 433],
          [433, 367],
          [367, 435],
          [392, 289],
          [289, 439],
          [439, 392],
          [328, 462],
          [462, 326],
          [326, 328],
          [94, 2],
          [2, 370],
          [370, 94],
          [289, 305],
          [305, 455],
          [455, 289],
          [339, 254],
          [254, 448],
          [448, 339],
          [359, 255],
          [255, 446],
          [446, 359],
          [254, 253],
          [253, 449],
          [449, 254],
          [253, 252],
          [252, 450],
          [450, 253],
          [252, 256],
          [256, 451],
          [451, 252],
          [
            256,
            341
          ],
          [341, 452],
          [452, 256],
          [414, 413],
          [413, 463],
          [463, 414],
          [286, 441],
          [441, 414],
          [414, 286],
          [286, 258],
          [258, 441],
          [441, 286],
          [258, 257],
          [257, 442],
          [442, 258],
          [257, 259],
          [259, 443],
          [443, 257],
          [259, 260],
          [260, 444],
          [444, 259],
          [260, 467],
          [467, 445],
          [445, 260],
          [309, 459],
          [459, 250],
          [250, 309],
          [305, 289],
          [289, 290],
          [290, 305],
          [305, 290],
          [290, 460],
          [460, 305],
          [401, 376],
          [376, 435],
          [435, 401],
          [309, 250],
          [250, 392],
          [392, 309],
          [376, 411],
          [411, 433],
          [433, 376],
          [453, 341],
          [341, 464],
          [464, 453],
          [357, 453],
          [453, 465],
          [465, 357],
          [343, 357],
          [357, 412],
          [412, 343],
          [437, 343],
          [343, 399],
          [399, 437],
          [344, 360],
          [360, 440],
          [440, 344],
          [420, 437],
          [437, 456],
          [456, 420],
          [360, 420],
          [420, 363],
          [363, 360],
          [361, 401],
          [401, 288],
          [288, 361],
          [265, 372],
          [372, 353],
          [353, 265],
          [390, 339],
          [339, 249],
          [249, 390],
          [339, 448],
          [448, 255],
          [255, 339]
        ]);
        P2("matrixDataToMatrix", function(a) {
          for (var b = a.getCols(), c = a.getRows(), d = a.getPackedDataList(), e = [], g = 0; g < c; g++)
            e.push(Array(b));
          for (g = 0; g < c; g++)
            for (var f = 0; f < b; f++) {
              var h = 1 === a.getLayout() ? g * b + f : f * c + g;
              e[g][f] = d[h];
            }
          return e;
        });
        P2("VERSION", "0.4.1633559619");
      }).call(exports);
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/flags.js
  var ENV3;
  var init_flags2 = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/flags.js"() {
      init_dist();
      ENV3 = env();
      ENV3.registerFlag("KEEP_INTERMEDIATE_TENSORS", () => false, (debugValue) => {
        if (debugValue) {
          console.warn("Keep intermediate tensors is ON. This will print the values of all intermediate tensors during model inference. Not all models support this mode. For details, check e2e/benchmarks/ model_config.js. This significantly impacts performance.");
        }
      });
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/data/compiled_api.js
  var DataType, SaverDef;
  var init_compiled_api = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/data/compiled_api.js"() {
      (function(DataType2) {
        DataType2[DataType2["DT_INVALID"] = 0] = "DT_INVALID";
        DataType2[DataType2["DT_FLOAT"] = 1] = "DT_FLOAT";
        DataType2[DataType2["DT_DOUBLE"] = 2] = "DT_DOUBLE";
        DataType2[DataType2["DT_INT32"] = 3] = "DT_INT32";
        DataType2[DataType2["DT_UINT8"] = 4] = "DT_UINT8";
        DataType2[DataType2["DT_INT16"] = 5] = "DT_INT16";
        DataType2[DataType2["DT_INT8"] = 6] = "DT_INT8";
        DataType2[DataType2["DT_STRING"] = 7] = "DT_STRING";
        DataType2[DataType2["DT_COMPLEX64"] = 8] = "DT_COMPLEX64";
        DataType2[DataType2["DT_INT64"] = 9] = "DT_INT64";
        DataType2[DataType2["DT_BOOL"] = 10] = "DT_BOOL";
        DataType2[DataType2["DT_QINT8"] = 11] = "DT_QINT8";
        DataType2[DataType2["DT_QUINT8"] = 12] = "DT_QUINT8";
        DataType2[DataType2["DT_QINT32"] = 13] = "DT_QINT32";
        DataType2[DataType2["DT_BFLOAT16"] = 14] = "DT_BFLOAT16";
        DataType2[DataType2["DT_QINT16"] = 15] = "DT_QINT16";
        DataType2[DataType2["DT_QUINT16"] = 16] = "DT_QUINT16";
        DataType2[DataType2["DT_UINT16"] = 17] = "DT_UINT16";
        DataType2[DataType2["DT_COMPLEX128"] = 18] = "DT_COMPLEX128";
        DataType2[DataType2["DT_HALF"] = 19] = "DT_HALF";
        DataType2[DataType2["DT_RESOURCE"] = 20] = "DT_RESOURCE";
        DataType2[DataType2["DT_VARIANT"] = 21] = "DT_VARIANT";
        DataType2[DataType2["DT_UINT32"] = 22] = "DT_UINT32";
        DataType2[DataType2["DT_UINT64"] = 23] = "DT_UINT64";
        DataType2[DataType2["DT_FLOAT_REF"] = 101] = "DT_FLOAT_REF";
        DataType2[DataType2["DT_DOUBLE_REF"] = 102] = "DT_DOUBLE_REF";
        DataType2[DataType2["DT_INT32_REF"] = 103] = "DT_INT32_REF";
        DataType2[DataType2["DT_UINT8_REF"] = 104] = "DT_UINT8_REF";
        DataType2[DataType2["DT_INT16_REF"] = 105] = "DT_INT16_REF";
        DataType2[DataType2["DT_INT8_REF"] = 106] = "DT_INT8_REF";
        DataType2[DataType2["DT_STRING_REF"] = 107] = "DT_STRING_REF";
        DataType2[DataType2["DT_COMPLEX64_REF"] = 108] = "DT_COMPLEX64_REF";
        DataType2[DataType2["DT_INT64_REF"] = 109] = "DT_INT64_REF";
        DataType2[DataType2["DT_BOOL_REF"] = 110] = "DT_BOOL_REF";
        DataType2[DataType2["DT_QINT8_REF"] = 111] = "DT_QINT8_REF";
        DataType2[DataType2["DT_QUINT8_REF"] = 112] = "DT_QUINT8_REF";
        DataType2[DataType2["DT_QINT32_REF"] = 113] = "DT_QINT32_REF";
        DataType2[DataType2["DT_BFLOAT16_REF"] = 114] = "DT_BFLOAT16_REF";
        DataType2[DataType2["DT_QINT16_REF"] = 115] = "DT_QINT16_REF";
        DataType2[DataType2["DT_QUINT16_REF"] = 116] = "DT_QUINT16_REF";
        DataType2[DataType2["DT_UINT16_REF"] = 117] = "DT_UINT16_REF";
        DataType2[DataType2["DT_COMPLEX128_REF"] = 118] = "DT_COMPLEX128_REF";
        DataType2[DataType2["DT_HALF_REF"] = 119] = "DT_HALF_REF";
        DataType2[DataType2["DT_RESOURCE_REF"] = 120] = "DT_RESOURCE_REF";
        DataType2[DataType2["DT_VARIANT_REF"] = 121] = "DT_VARIANT_REF";
        DataType2[DataType2["DT_UINT32_REF"] = 122] = "DT_UINT32_REF";
        DataType2[DataType2["DT_UINT64_REF"] = 123] = "DT_UINT64_REF";
      })(DataType || (DataType = {}));
      (function(SaverDef2) {
        let CheckpointFormatVersion;
        (function(CheckpointFormatVersion2) {
          CheckpointFormatVersion2[CheckpointFormatVersion2["LEGACY"] = 0] = "LEGACY";
          CheckpointFormatVersion2[CheckpointFormatVersion2["V1"] = 1] = "V1";
          CheckpointFormatVersion2[CheckpointFormatVersion2["V2"] = 2] = "V2";
        })(CheckpointFormatVersion = SaverDef2.CheckpointFormatVersion || (SaverDef2.CheckpointFormatVersion = {}));
      })(SaverDef || (SaverDef = {}));
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/custom_op/register.js
  function getRegisteredOp(name) {
    return CUSTOM_OPS[name];
  }
  var CUSTOM_OPS;
  var init_register = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/custom_op/register.js"() {
      CUSTOM_OPS = {};
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/utils.js
  function getParamValue(paramName, node, tensorMap, context, resourceManager) {
    const inputParam = node.inputParams[paramName];
    if (inputParam && inputParam.inputIndexStart !== void 0) {
      const start = inputParam.inputIndexStart;
      const end = inputParam.inputIndexEnd === 0 ? void 0 : inputParam.inputIndexEnd === void 0 ? start + 1 : inputParam.inputIndexEnd;
      if (inputParam.type === "tensor") {
        return getTensor(node.inputNames[inputParam.inputIndexStart], tensorMap, context, resourceManager);
      }
      if (inputParam.type === "tensors") {
        const inputs = node.inputNames.slice(start, end);
        return inputs.map((name) => getTensor(name, tensorMap, context, resourceManager));
      }
      const tensor2 = getTensor(node.inputNames.slice(start)[0], tensorMap, context, resourceManager);
      const data = tensor2.dataSync();
      return inputParam.type === "number" ? data[0] : util_exports.toNestedArray(tensor2.shape, data);
    }
    const attrParam = node.attrParams[paramName];
    return attrParam && attrParam.value;
  }
  function getTensor(name, tensorsMap, context, resourceManager) {
    const [nodeName, index] = parseNodeName(name);
    if (resourceManager != null) {
      const tensor2 = resourceManager.getHashTableHandleByName(nodeName);
      if (tensor2 != null) {
        return tensor2;
      }
    }
    const contextId = context.currentContextIds.find((contextId2) => {
      return !!tensorsMap[getNodeNameWithContextId(nodeName, contextId2)];
    });
    return contextId !== void 0 ? tensorsMap[getNodeNameWithContextId(nodeName, contextId)][index] : void 0;
  }
  function getTensorsForCurrentContenxt(name, tensorsMap, context) {
    return tensorsMap[getNodeNameWithContextId(name, context.currentContextId)];
  }
  function getNodeNameAndIndex(inputName, context) {
    const [nodeName, index, outputName] = parseNodeName(inputName);
    return [
      getNodeNameWithContextId(nodeName, context && context.currentContextId),
      index,
      outputName
    ];
  }
  function getNodeNameWithContextId(name, contextId) {
    return !!contextId ? `${name}-${contextId}` : name;
  }
  function parseNodeName(name) {
    const parts = name.split(":");
    if (parts.length === 1) {
      return [name, 0, void 0];
    }
    const nodeName = parts[0];
    const outputName = parts.length === 3 ? parts[1] : void 0;
    const index = Number(parts[parts.length - 1]);
    return [nodeName, index, outputName];
  }
  function getPadding(node, tensorMap, context) {
    let pad2 = getParamValue("pad", node, tensorMap, context);
    if (pad2 === "explicit") {
      pad2 = getParamValue("explicitPaddings", node, tensorMap, context);
      const explicitPadding = [[0, 0], [0, 0], [0, 0], [0, 0]];
      for (let i = 0; i < 4; i++) {
        explicitPadding[i][0] = pad2[i * 2];
        explicitPadding[i][1] = pad2[i * 2 + 1];
      }
      return explicitPadding;
    }
    return pad2;
  }
  function cloneTensor(tensor2) {
    return tensor2.kept ? tensor2 : clone(tensor2);
  }
  var init_utils = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/utils.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/arithmetic.js
  var arithmetic_exports = {};
  __export(arithmetic_exports, {
    json: () => json
  });
  var json;
  var init_arithmetic = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/arithmetic.js"() {
      json = [
        {
          "tfOpName": "Add",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "AddV2",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "AddN",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "end": 0,
              "name": "tensors",
              "type": "tensors"
            }
          ]
        },
        {
          "tfOpName": "BiasAdd",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Sub",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "RealDiv",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Div",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "DivNoNan",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "FloorDiv",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Mul",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Maximum",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Minimum",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Pow",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "SquaredDifference",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Mod",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "FloorMod",
          "category": "arithmetic",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/basic_math.js
  var basic_math_exports = {};
  __export(basic_math_exports, {
    json: () => json2
  });
  var json2;
  var init_basic_math = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/basic_math.js"() {
      json2 = [
        {
          "tfOpName": "Abs",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Acos",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Asin",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Atan",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Atan2",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "y",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Ceil",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "ClipByValue",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "clipValueMin",
              "type": "number"
            },
            {
              "start": 2,
              "name": "clipValueMax",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Complex",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "real",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "imag",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "ComplexAbs",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Cos",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Cosh",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Elu",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Exp",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Floor",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Log",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Imag",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "Tout",
              "name": "outputType",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Neg",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Real",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "Tout",
              "name": "outputType",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Prelu",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "alpha",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Relu",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Relu6",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Selu",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Sigmoid",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Sin",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Sinh",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Sqrt",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Rsqrt",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Square",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Tan",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Tanh",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Sign",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Round",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Expm1",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Log1p",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Reciprocal",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Softplus",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Asinh",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Acosh",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Atanh",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Erf",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Prod",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axes",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "keep_dims",
              "name": "keepDims",
              "type": "bool",
              "notSupported": true
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "LeakyRelu",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "alpha",
              "name": "alpha",
              "type": "number",
              "defaultValue": 0.2
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "IsNan",
          "category": "basic_math",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/control.js
  var control_exports = {};
  __export(control_exports, {
    json: () => json3
  });
  var json3;
  var init_control = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/control.js"() {
      json3 = [
        {
          "tfOpName": "EmptyTensorList",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "elementShape",
              "type": "shape"
            },
            {
              "start": 1,
              "name": "maxNumElements",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "LoopCond",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "pred",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "Switch",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "data",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "pred",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "Merge",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "end": 0,
              "name": "tensors",
              "type": "tensors"
            }
          ]
        },
        {
          "tfOpName": "Enter",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensor",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "frame_name",
              "name": "frameName",
              "type": "string"
            },
            {
              "tfName": "is_constant",
              "name": "isConstant",
              "type": "bool"
            }
          ]
        },
        {
          "tfOpName": "Exit",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensor",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "NextIteration",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensor",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "TensorArrayV3",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "size",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "dtype",
              "name": "dtype",
              "type": "dtype"
            },
            {
              "tfName": "element_shape",
              "name": "elementShape",
              "type": "shape"
            },
            {
              "tfName": "dynamic_size",
              "name": "dynamicSize",
              "type": "bool"
            },
            {
              "tfName": "clear_after_read",
              "name": "clearAfterRead",
              "type": "bool"
            },
            {
              "tfName": "identical_element_shapes",
              "name": "identicalElementShapes",
              "type": "bool"
            },
            {
              "tfName": "tensor_array_name",
              "name": "name",
              "type": "string"
            }
          ]
        },
        {
          "tfOpName": "TensorArrayWriteV3",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorArrayId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "index",
              "type": "number"
            },
            {
              "start": 2,
              "name": "tensor",
              "type": "tensor"
            },
            {
              "start": 3,
              "name": "flowIn",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "TensorArrayReadV3",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorArrayId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "index",
              "type": "number"
            },
            {
              "start": 2,
              "name": "flowIn",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "dtype",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "TensorArrayGatherV3",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorArrayId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "indices",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "flowIn",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "dtype",
              "name": "dtype",
              "type": "dtype"
            },
            {
              "tfName": "element_shape",
              "name": "elementShape",
              "type": "shape"
            }
          ]
        },
        {
          "tfOpName": "TensorArrayScatterV3",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorArrayId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "indices",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "tensor",
              "type": "tensor"
            },
            {
              "start": 3,
              "name": "flowIn",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorArrayConcatV3",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorArrayId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "flowIn",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "dtype",
              "name": "dtype",
              "type": "dtype"
            },
            {
              "tfName": "element_shape_except0",
              "name": "elementShapeExcept0",
              "type": "shape",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "TensorArraySplitV3",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorArrayId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "tensor",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "lengths",
              "type": "number[]"
            },
            {
              "start": 3,
              "name": "flowIn",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorArraySizeV3",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorArrayId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "flowIn",
              "type": "number"
            }
          ]
        },
        {
          "tfOpName": "TensorArrayCloseV3",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorArrayId",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "StatelessIf",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "cond",
              "type": "tensor"
            },
            {
              "start": 1,
              "end": 0,
              "name": "args",
              "type": "tensors"
            }
          ],
          "attrs": [
            {
              "tfName": "then_branch",
              "name": "thenBranch",
              "type": "func"
            },
            {
              "tfName": "else_branch",
              "name": "elseBranch",
              "type": "func"
            }
          ]
        },
        {
          "tfOpName": "If",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "cond",
              "type": "tensor"
            },
            {
              "start": 1,
              "end": 0,
              "name": "args",
              "type": "tensors"
            }
          ],
          "attrs": [
            {
              "tfName": "then_branch",
              "name": "thenBranch",
              "type": "func"
            },
            {
              "tfName": "else_branch",
              "name": "elseBranch",
              "type": "func"
            }
          ]
        },
        {
          "tfOpName": "StatelessWhile",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "end": 0,
              "name": "args",
              "type": "tensors"
            }
          ],
          "attrs": [
            {
              "tfName": "cond",
              "name": "cond",
              "type": "func"
            },
            {
              "tfName": "body",
              "name": "body",
              "type": "func"
            }
          ]
        },
        {
          "tfOpName": "While",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "end": 0,
              "name": "args",
              "type": "tensors"
            }
          ],
          "attrs": [
            {
              "tfName": "cond",
              "name": "cond",
              "type": "func"
            },
            {
              "tfName": "body",
              "name": "body",
              "type": "func"
            }
          ]
        },
        {
          "tfOpName": "TensorListScatter",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensor",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "indices",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "elementShape",
              "type": "shape"
            }
          ],
          "attrs": [
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListScatterV2",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensor",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "indices",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "elementShape",
              "type": "shape"
            },
            {
              "start": 3,
              "name": "numElements",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListGather",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorListId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "indices",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "elementShape",
              "type": "shape"
            }
          ],
          "attrs": [
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListGetItem",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorListId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "index",
              "type": "number"
            },
            {
              "start": 2,
              "name": "elementShape",
              "type": "shape"
            }
          ],
          "attrs": [
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListSetItem",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorListId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "index",
              "type": "number"
            },
            {
              "start": 2,
              "name": "tensor",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListReserve",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "elementShape",
              "type": "shape"
            },
            {
              "start": 1,
              "name": "numElements",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListFromTensor",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensor",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "elementShape",
              "type": "shape"
            }
          ],
          "attrs": [
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListStack",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorListId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "elementShape",
              "type": "shape"
            }
          ],
          "attrs": [
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            },
            {
              "tfName": "num_elements",
              "name": "numElements",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListSplit",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensor",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "elementShape",
              "type": "shape"
            },
            {
              "start": 2,
              "name": "lengths",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListConcat",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorListId",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "element_shape",
              "name": "elementShape",
              "type": "shape"
            },
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListConcatV2",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorListId",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "element_shape",
              "name": "elementShape",
              "type": "shape"
            },
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListPopBack",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorListId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "elementShape",
              "type": "shape"
            }
          ],
          "attrs": [
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListPushBack",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorListId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "tensor",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "element_dtype",
              "name": "elementDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TensorListLength",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorListId",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "TensorListResize",
          "category": "control",
          "inputs": [
            {
              "start": 0,
              "name": "tensorListId",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "size",
              "type": "number"
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/convolution.js
  var convolution_exports = {};
  __export(convolution_exports, {
    json: () => json4
  });
  var json4;
  var init_convolution = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/convolution.js"() {
      json4 = [
        {
          "tfOpName": "AvgPool",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "notSupported": true
            },
            {
              "tfName": "ksize",
              "name": "kernelSize",
              "type": "number[]"
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "MaxPool",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "notSupported": true
            },
            {
              "tfName": "ksize",
              "name": "kernelSize",
              "type": "number[]"
            },
            {
              "tfName": "explicit_paddings",
              "name": "explicitPaddings",
              "type": "number[]",
              "defaultValue": [],
              "notSupported": true
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "MaxPoolWithArgmax",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "ksize",
              "name": "kernelSize",
              "type": "number[]"
            },
            {
              "tfName": "include_batch_in_index",
              "name": "includeBatchInIndex",
              "type": "bool"
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "AvgPool3D",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "notSupported": true
            },
            {
              "tfName": "ksize",
              "name": "kernelSize",
              "type": "number[]"
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "MaxPool3D",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "notSupported": true
            },
            {
              "tfName": "ksize",
              "name": "kernelSize",
              "type": "number[]"
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Conv1D",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "filter",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "stride",
              "name": "stride",
              "type": "number"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "defaultValue": "NWC"
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "dilation",
              "name": "dilation",
              "type": "number",
              "defaultValue": 1
            }
          ]
        },
        {
          "tfOpName": "Conv2D",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "filter",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "useCudnnOnGpu",
              "name": "useCudnnOnGpu",
              "type": "bool"
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "defaultValue": "NHWC"
            },
            {
              "tfName": "explicit_paddings",
              "name": "explicitPaddings",
              "type": "number[]",
              "defaultValue": []
            },
            {
              "tfName": "dilations",
              "name": "dilations",
              "type": "number[]"
            }
          ]
        },
        {
          "tfOpName": "_FusedConv2D",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "filter",
              "type": "tensor"
            },
            {
              "start": 2,
              "end": 0,
              "name": "args",
              "type": "tensors"
            }
          ],
          "attrs": [
            {
              "tfName": "num_args",
              "name": "numArgs",
              "type": "number"
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "explicit_paddings",
              "name": "explicitPaddings",
              "type": "number[]",
              "defaultValue": []
            },
            {
              "tfName": "use_cudnn_on_gpu",
              "name": "useCudnnOnGpu",
              "type": "bool",
              "defaultValue": true
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "defaultValue": "NHWC"
            },
            {
              "tfName": "dilations",
              "name": "dilations",
              "type": "number[]",
              "defaultValue": [
                1,
                1,
                1,
                1
              ]
            },
            {
              "tfName": "fused_ops",
              "name": "fusedOps",
              "type": "string[]",
              "defaultValue": []
            },
            {
              "tfName": "epsilon",
              "name": "epsilon",
              "type": "number",
              "defaultValue": 1e-4
            },
            {
              "tfName": "leakyrelu_alpha",
              "name": "leakyreluAlpha",
              "type": "number",
              "defaultValue": 0.2
            }
          ]
        },
        {
          "tfOpName": "Conv2DBackpropInput",
          "category": "convolution",
          "inputs": [
            {
              "start": 2,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "filter",
              "type": "tensor"
            },
            {
              "start": 0,
              "name": "outputShape",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "notSupported": true
            },
            {
              "tfName": "explicit_paddings",
              "name": "explicitPaddings",
              "type": "number[]",
              "defaultValue": []
            },
            {
              "tfName": "dilations",
              "name": "dilations",
              "type": "number[]",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "DepthwiseConv2d",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "input",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "filter",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "defaultValue": "NHWC"
            },
            {
              "tfName": "explicit_paddings",
              "name": "explicitPaddings",
              "type": "number[]",
              "defaultValue": []
            },
            {
              "tfName": "dilations",
              "name": "dilations",
              "type": "number[]"
            }
          ]
        },
        {
          "tfOpName": "DepthwiseConv2dNative",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "input",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "filter",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "defaultValue": "NHWC"
            },
            {
              "tfName": "explicit_paddings",
              "name": "explicitPaddings",
              "type": "number[]",
              "defaultValue": []
            },
            {
              "tfName": "dilations",
              "name": "dilations",
              "type": "number[]"
            }
          ]
        },
        {
          "tfOpName": "FusedDepthwiseConv2dNative",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "filter",
              "type": "tensor"
            },
            {
              "start": 2,
              "end": 0,
              "name": "args",
              "type": "tensors"
            }
          ],
          "attrs": [
            {
              "tfName": "num_args",
              "name": "numArgs",
              "type": "number"
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "defaultValue": "NHWC"
            },
            {
              "tfName": "dilations",
              "name": "dilations",
              "type": "number[]",
              "defaultValue": [
                1,
                1,
                1,
                1
              ]
            },
            {
              "tfName": "fused_ops",
              "name": "fusedOps",
              "type": "string[]",
              "defaultValue": []
            },
            {
              "tfName": "explicit_paddings",
              "name": "explicitPaddings",
              "type": "number[]",
              "defaultValue": []
            }
          ]
        },
        {
          "tfOpName": "Conv3D",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "filter",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "defaultValue": "NHWC"
            },
            {
              "tfName": "dilations",
              "name": "dilations",
              "type": "number[]"
            }
          ]
        },
        {
          "tfOpName": "Dilation2D",
          "category": "convolution",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "filter",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "strides",
              "name": "strides",
              "type": "number[]"
            },
            {
              "tfName": "rates",
              "name": "dilations",
              "type": "number[]"
            },
            {
              "tfName": "padding",
              "name": "pad",
              "type": "string"
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/creation.js
  var creation_exports = {};
  __export(creation_exports, {
    json: () => json5
  });
  var json5;
  var init_creation = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/creation.js"() {
      json5 = [
        {
          "tfOpName": "Fill",
          "category": "creation",
          "inputs": [
            {
              "start": 0,
              "name": "shape",
              "type": "number[]"
            },
            {
              "start": 1,
              "name": "value",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "LinSpace",
          "category": "creation",
          "inputs": [
            {
              "start": 0,
              "name": "start",
              "type": "number"
            },
            {
              "start": 1,
              "name": "stop",
              "type": "number"
            },
            {
              "start": 2,
              "name": "num",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "OneHot",
          "category": "creation",
          "inputs": [
            {
              "start": 0,
              "name": "indices",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "depth",
              "type": "number"
            },
            {
              "start": 2,
              "name": "onValue",
              "type": "number",
              "defaultValue": 1
            },
            {
              "start": 3,
              "name": "offValue",
              "type": "number",
              "defaultValue": 0
            }
          ],
          "attrs": [
            {
              "tfName": "axis",
              "name": "axis",
              "type": "number",
              "notSupported": true
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "Ones",
          "category": "creation",
          "inputs": [
            {
              "start": 0,
              "name": "shape",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "OnesLike",
          "category": "creation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "dtype",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "RandomStandardNormal",
          "category": "creation",
          "inputs": [
            {
              "start": 0,
              "name": "shape",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "seed",
              "name": "seed",
              "type": "number",
              "defaultValue": 0
            },
            {
              "tfName": "seed2",
              "name": "seed2",
              "type": "number",
              "defaultValue": 0,
              "notSupported": true
            },
            {
              "tfName": "dtype",
              "name": "dtype",
              "type": "dtype"
            },
            {
              "tfName": "T",
              "name": "T",
              "type": "number",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "RandomUniform",
          "category": "creation",
          "inputs": [
            {
              "start": 0,
              "name": "shape",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "minval",
              "name": "minval",
              "type": "number",
              "defaultValue": 0
            },
            {
              "tfName": "maxval",
              "name": "maxval",
              "type": "number",
              "defaultValue": 1
            },
            {
              "tfName": "dtype",
              "name": "dtype",
              "type": "dtype"
            },
            {
              "tfName": "seed",
              "name": "seed",
              "type": "number",
              "defaultValue": 0
            },
            {
              "tfName": "seed2",
              "name": "seed2",
              "type": "number",
              "defaultValue": 0,
              "notSupported": true
            },
            {
              "tfName": "T",
              "name": "T",
              "type": "number",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Range",
          "category": "creation",
          "inputs": [
            {
              "start": 0,
              "name": "start",
              "type": "number"
            },
            {
              "start": 1,
              "name": "stop",
              "type": "number"
            },
            {
              "start": 2,
              "name": "step",
              "type": "number",
              "defaultValue": 0
            }
          ],
          "attrs": [
            {
              "tfName": "Tidx",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "TruncatedNormal",
          "category": "creation",
          "inputs": [
            {
              "start": 0,
              "name": "shape",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "means",
              "name": "mean",
              "type": "number",
              "defaultValue": 0
            },
            {
              "tfName": "stddev",
              "name": "stdDev",
              "type": "number",
              "defaultValue": 1
            },
            {
              "tfName": "seed",
              "name": "seed",
              "type": "number"
            },
            {
              "tfName": "seed2",
              "name": "seed2",
              "type": "number",
              "defaultValue": 0,
              "notSupported": true
            },
            {
              "tfName": "dtype",
              "name": "dtype",
              "type": "dtype"
            },
            {
              "tfName": "T",
              "name": "T",
              "type": "number",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Zeros",
          "category": "creation",
          "inputs": [
            {
              "start": 0,
              "name": "shape",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "ZerosLike",
          "category": "creation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "Multinomial",
          "category": "creation",
          "inputs": [
            {
              "start": 0,
              "name": "logits",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "numSamples",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "seed",
              "name": "seed",
              "type": "number"
            },
            {
              "tfName": "seed2",
              "name": "seed2",
              "type": "number"
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype"
            },
            {
              "tfName": "output_dtype",
              "name": "output_dtype",
              "type": "dtype"
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/dynamic.js
  var dynamic_exports = {};
  __export(dynamic_exports, {
    json: () => json6
  });
  var json6;
  var init_dynamic = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/dynamic.js"() {
      json6 = [
        {
          "tfOpName": "NonMaxSuppressionV2",
          "category": "dynamic",
          "inputs": [
            {
              "start": 0,
              "name": "boxes",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "scores",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "maxOutputSize",
              "type": "number"
            },
            {
              "start": 3,
              "name": "iouThreshold",
              "type": "number"
            }
          ]
        },
        {
          "tfOpName": "NonMaxSuppressionV3",
          "category": "dynamic",
          "inputs": [
            {
              "start": 0,
              "name": "boxes",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "scores",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "maxOutputSize",
              "type": "number"
            },
            {
              "start": 3,
              "name": "iouThreshold",
              "type": "number"
            },
            {
              "start": 4,
              "name": "scoreThreshold",
              "type": "number"
            }
          ]
        },
        {
          "tfOpName": "NonMaxSuppressionV4",
          "category": "dynamic",
          "inputs": [
            {
              "start": 0,
              "name": "boxes",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "scores",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "maxOutputSize",
              "type": "number"
            },
            {
              "start": 3,
              "name": "iouThreshold",
              "type": "number"
            },
            {
              "start": 4,
              "name": "scoreThreshold",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "T_threshold",
              "name": "threshold",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "pad_to_max_output_size",
              "name": "padToMaxOutputSize",
              "type": "bool"
            }
          ]
        },
        {
          "tfOpName": "NonMaxSuppressionV5",
          "category": "dynamic",
          "inputs": [
            {
              "start": 0,
              "name": "boxes",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "scores",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "maxOutputSize",
              "type": "number"
            },
            {
              "start": 3,
              "name": "iouThreshold",
              "type": "number"
            },
            {
              "start": 4,
              "name": "scoreThreshold",
              "type": "number"
            },
            {
              "start": 5,
              "name": "softNmsSigma",
              "type": "number"
            }
          ]
        },
        {
          "tfOpName": "Where",
          "category": "dynamic",
          "inputs": [
            {
              "start": 0,
              "name": "condition",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "ListDiff",
          "category": "dynamic",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "y",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/evaluation.js
  var evaluation_exports = {};
  __export(evaluation_exports, {
    json: () => json7
  });
  var json7;
  var init_evaluation = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/evaluation.js"() {
      json7 = [
        {
          "tfOpName": "LowerBound",
          "category": "evaluation",
          "inputs": [
            {
              "start": 0,
              "name": "sortedSequence",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "values",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "TopKV2",
          "category": "evaluation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "k",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "sorted",
              "name": "sorted",
              "type": "bool"
            }
          ]
        },
        {
          "tfOpName": "UpperBound",
          "category": "evaluation",
          "inputs": [
            {
              "start": 0,
              "name": "sortedSequence",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "values",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "Unique",
          "category": "evaluation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "UniqueV2",
          "category": "evaluation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number"
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/graph.js
  var graph_exports = {};
  __export(graph_exports, {
    json: () => json8
  });
  var json8;
  var init_graph = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/graph.js"() {
      json8 = [
        {
          "tfOpName": "PlaceholderWithDefault",
          "category": "graph",
          "inputs": [
            {
              "start": 0,
              "name": "default",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "shape",
              "name": "shape",
              "type": "shape"
            },
            {
              "tfName": "dtype",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "Placeholder",
          "category": "graph",
          "attrs": [
            {
              "tfName": "shape",
              "name": "shape",
              "type": "shape"
            },
            {
              "tfName": "dtype",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "Const",
          "category": "graph"
        },
        {
          "tfOpName": "Identity",
          "category": "graph",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "IdentityN",
          "category": "graph",
          "inputs": [
            {
              "start": 0,
              "end": 0,
              "name": "x",
              "type": "tensors"
            }
          ]
        },
        {
          "tfOpName": "Snapshot",
          "category": "graph",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "Rank",
          "category": "graph",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "Size",
          "category": "graph",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "Shape",
          "category": "graph",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "ShapeN",
          "category": "graph",
          "inputs": [
            {
              "start": 0,
              "end": 0,
              "name": "x",
              "type": "tensors"
            }
          ]
        },
        {
          "tfOpName": "Print",
          "category": "graph",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "data",
              "type": "tensors"
            }
          ],
          "attrs": [
            {
              "tfName": "message",
              "name": "message",
              "type": "string"
            },
            {
              "tfName": "first_n",
              "name": "firstN",
              "type": "number",
              "notSupported": true
            },
            {
              "tfName": "summarize",
              "name": "summarize",
              "type": "number",
              "defaultValue": 3
            }
          ]
        },
        {
          "tfOpName": "NoOp",
          "category": "graph",
          "inputs": []
        },
        {
          "tfOpName": "StopGradient",
          "category": "graph",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "FakeQuantWithMinMaxVars",
          "category": "graph",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "min",
              "name": "min",
              "type": "number"
            },
            {
              "tfName": "max",
              "name": "max",
              "type": "number"
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/hash_table.js
  var hash_table_exports = {};
  __export(hash_table_exports, {
    json: () => json9
  });
  var json9;
  var init_hash_table = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/hash_table.js"() {
      json9 = [
        {
          "tfOpName": "HashTable",
          "category": "hash_table",
          "inputs": [],
          "attrs": [
            {
              "tfName": "shared_name",
              "name": "sharedName",
              "type": "string"
            },
            {
              "tfName": "use_node_name_sharing",
              "name": "useNodeNameSharing",
              "type": "bool"
            },
            {
              "tfName": "key_dtype",
              "name": "keyDType",
              "type": "dtype"
            },
            {
              "tfName": "value_dtype",
              "name": "valueDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "HashTableV2",
          "category": "hash_table",
          "inputs": [],
          "attrs": [
            {
              "tfName": "shared_name",
              "name": "sharedName",
              "type": "string"
            },
            {
              "tfName": "use_node_name_sharing",
              "name": "useNodeNameSharing",
              "type": "bool"
            },
            {
              "tfName": "key_dtype",
              "name": "keyDType",
              "type": "dtype"
            },
            {
              "tfName": "value_dtype",
              "name": "valueDType",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "LookupTableImport",
          "category": "hash_table",
          "inputs": [
            {
              "start": 0,
              "name": "tableHandle",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "keys",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "values",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "Tin",
              "name": "tIn",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "Tout",
              "name": "tOut",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "LookupTableImportV2",
          "category": "hash_table",
          "inputs": [
            {
              "start": 0,
              "name": "tableHandle",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "keys",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "values",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "Tin",
              "name": "tIn",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "Tout",
              "name": "tOut",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "LookupTableFind",
          "category": "hash_table",
          "inputs": [
            {
              "start": 0,
              "name": "tableHandle",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "keys",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "defaultValue",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "Tin",
              "name": "tIn",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "Tout",
              "name": "tOut",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "LookupTableFindV2",
          "category": "hash_table",
          "inputs": [
            {
              "start": 0,
              "name": "tableHandle",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "keys",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "defaultValue",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "Tin",
              "name": "tIn",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "Tout",
              "name": "tOut",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "LookupTableSize",
          "category": "hash_table",
          "inputs": [
            {
              "start": 0,
              "name": "tableHandle",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "LookupTableSizeV2",
          "category": "hash_table",
          "inputs": [
            {
              "start": 0,
              "name": "tableHandle",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "InitializeTable",
          "category": "hash_table",
          "inputs": [
            {
              "start": 0,
              "name": "tableHandle",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "keys",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "values",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "InitializeTableV2",
          "category": "hash_table",
          "inputs": [
            {
              "start": 0,
              "name": "tableHandle",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "keys",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "values",
              "type": "tensor"
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/image.js
  var image_exports = {};
  __export(image_exports, {
    json: () => json10
  });
  var json10;
  var init_image = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/image.js"() {
      json10 = [
        {
          "tfOpName": "ResizeBilinear",
          "category": "image",
          "inputs": [
            {
              "start": 0,
              "name": "images",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "size",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "align_corners",
              "name": "alignCorners",
              "type": "bool"
            },
            {
              "tfName": "half_pixel_centers",
              "name": "halfPixelCenters",
              "type": "bool"
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "ResizeNearestNeighbor",
          "category": "image",
          "inputs": [
            {
              "start": 0,
              "name": "images",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "size",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "align_corners",
              "name": "alignCorners",
              "type": "bool"
            },
            {
              "tfName": "half_pixel_centers",
              "name": "halfPixelCenters",
              "type": "bool"
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "CropAndResize",
          "category": "image",
          "inputs": [
            {
              "start": 0,
              "name": "image",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "boxes",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "boxInd",
              "type": "tensor"
            },
            {
              "start": 3,
              "name": "cropSize",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "method",
              "name": "method",
              "type": "string"
            },
            {
              "tfName": "extrapolation_value",
              "name": "extrapolationValue",
              "type": "number"
            }
          ]
        },
        {
          "tfOpName": "ImageProjectiveTransformV3",
          "category": "image",
          "inputs": [
            {
              "start": 0,
              "name": "images",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "transforms",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "outputShape",
              "type": "number[]"
            },
            {
              "start": 3,
              "name": "fillValue",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "interpolation",
              "name": "interpolation",
              "type": "string"
            },
            {
              "tfName": "fill_mode",
              "name": "fillMode",
              "type": "string"
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/logical.js
  var logical_exports = {};
  __export(logical_exports, {
    json: () => json11
  });
  var json11;
  var init_logical = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/logical.js"() {
      json11 = [
        {
          "tfOpName": "Equal",
          "category": "logical",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "NotEqual",
          "category": "logical",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Greater",
          "category": "logical",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "GreaterEqual",
          "category": "logical",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Less",
          "category": "logical",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "LessEqual",
          "category": "logical",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "LogicalAnd",
          "category": "logical",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "LogicalNot",
          "category": "logical",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "LogicalOr",
          "category": "logical",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Select",
          "category": "logical",
          "inputs": [
            {
              "start": 0,
              "name": "condition",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "SelectV2",
          "category": "logical",
          "inputs": [
            {
              "start": 0,
              "name": "condition",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/matrices.js
  var matrices_exports = {};
  __export(matrices_exports, {
    json: () => json12
  });
  var json12;
  var init_matrices = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/matrices.js"() {
      json12 = [
        {
          "tfOpName": "_FusedMatMul",
          "category": "matrices",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            },
            {
              "start": 2,
              "end": 0,
              "name": "args",
              "type": "tensors"
            }
          ],
          "attrs": [
            {
              "tfName": "num_args",
              "name": "numArgs",
              "type": "number"
            },
            {
              "tfName": "fused_ops",
              "name": "fusedOps",
              "type": "string[]",
              "defaultValue": []
            },
            {
              "tfName": "epsilon",
              "name": "epsilon",
              "type": "number",
              "defaultValue": 1e-4
            },
            {
              "tfName": "transpose_a",
              "name": "transposeA",
              "type": "bool",
              "defaultValue": false
            },
            {
              "tfName": "transpose_b",
              "name": "transposeB",
              "type": "bool",
              "defaultValue": false
            },
            {
              "tfName": "leakyrelu_alpha",
              "name": "leakyreluAlpha",
              "type": "number",
              "defaultValue": 0.2
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "MatMul",
          "category": "matrices",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "transpose_a",
              "name": "transposeA",
              "type": "bool",
              "defaultValue": false
            },
            {
              "tfName": "transpose_b",
              "name": "transposeB",
              "type": "bool",
              "defaultValue": false
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "BatchMatMul",
          "category": "matrices",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "adj_x",
              "name": "transposeA",
              "type": "bool",
              "defaultValue": false
            },
            {
              "tfName": "adj_y",
              "name": "transposeB",
              "type": "bool",
              "defaultValue": false
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "BatchMatMulV2",
          "category": "matrices",
          "inputs": [
            {
              "start": 0,
              "name": "a",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "b",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "adj_x",
              "name": "transposeA",
              "type": "bool",
              "defaultValue": false
            },
            {
              "tfName": "adj_y",
              "name": "transposeB",
              "type": "bool",
              "defaultValue": false
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Transpose",
          "category": "matrices",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "perm",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Einsum",
          "category": "matrices",
          "inputs": [
            {
              "start": 0,
              "end": 0,
              "name": "tensors",
              "type": "tensors"
            }
          ],
          "attrs": [
            {
              "tfName": "equation",
              "name": "equation",
              "type": "string"
            },
            {
              "tfName": "N",
              "name": "n",
              "type": "number",
              "defaultValue": 2
            },
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/normalization.js
  var normalization_exports = {};
  __export(normalization_exports, {
    json: () => json13
  });
  var json13;
  var init_normalization = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/normalization.js"() {
      json13 = [
        {
          "tfOpName": "EuclideanNorm",
          "category": "normalization",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "keep_dims",
              "name": "keepDims",
              "type": "bool",
              "defaultValue": false
            }
          ]
        },
        {
          "tfOpName": "FusedBatchNorm",
          "category": "normalization",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "scale",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "offset",
              "type": "tensor"
            },
            {
              "start": 3,
              "name": "mean",
              "type": "tensor"
            },
            {
              "start": 4,
              "name": "variance",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "epsilon",
              "name": "epsilon",
              "type": "number",
              "defaultValue": 1e-3
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "FusedBatchNormV2",
          "category": "normalization",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "scale",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "offset",
              "type": "tensor"
            },
            {
              "start": 3,
              "name": "mean",
              "type": "tensor"
            },
            {
              "start": 4,
              "name": "variance",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "epsilon",
              "name": "epsilon",
              "type": "number",
              "defaultValue": 1e-3
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "FusedBatchNormV3",
          "category": "normalization",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "scale",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "offset",
              "type": "tensor"
            },
            {
              "start": 3,
              "name": "mean",
              "type": "tensor"
            },
            {
              "start": 4,
              "name": "variance",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "epsilon",
              "name": "epsilon",
              "type": "number",
              "defaultValue": 1e-3
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "LRN",
          "category": "normalization",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "depth_radius",
              "name": "radius",
              "type": "number",
              "defaultValue": 5
            },
            {
              "tfName": "bias",
              "name": "bias",
              "type": "number",
              "defaultValue": 1
            },
            {
              "tfName": "alpha",
              "name": "alpha",
              "type": "number",
              "defaultValue": 1
            },
            {
              "tfName": "beta",
              "name": "beta",
              "type": "number",
              "defaultValue": 0.5
            }
          ]
        },
        {
          "tfOpName": "Softmax",
          "category": "normalization",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "LogSoftmax",
          "category": "normalization",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "SparseToDense",
          "category": "normalization",
          "inputs": [
            {
              "start": 0,
              "name": "sparseIndices",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "outputShape",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "sparseValues",
              "type": "tensor"
            },
            {
              "start": 3,
              "name": "defaultValue",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "validate_indices",
              "name": "validateIndices",
              "type": "bool",
              "defaultValue": true,
              "notSupported": true
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/reduction.js
  var reduction_exports = {};
  __export(reduction_exports, {
    json: () => json14
  });
  var json14;
  var init_reduction = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/reduction.js"() {
      json14 = [
        {
          "tfOpName": "Bincount",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "size",
              "type": "number"
            },
            {
              "start": 2,
              "name": "weights",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "DenseBincount",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "size",
              "type": "number"
            },
            {
              "start": 2,
              "name": "weights",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "binary_output",
              "name": "binaryOutput",
              "type": "bool"
            }
          ]
        },
        {
          "tfOpName": "Max",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "keep_dims",
              "name": "keepDims",
              "type": "bool"
            }
          ]
        },
        {
          "tfOpName": "Mean",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "keep_dims",
              "name": "keepDims",
              "type": "bool"
            }
          ]
        },
        {
          "tfOpName": "Min",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "keep_dims",
              "name": "keepDims",
              "type": "bool"
            }
          ]
        },
        {
          "tfOpName": "Sum",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "keep_dims",
              "name": "keepDims",
              "type": "bool"
            }
          ]
        },
        {
          "tfOpName": "All",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "keep_dims",
              "name": "keepDims",
              "type": "bool"
            }
          ]
        },
        {
          "tfOpName": "Any",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "keep_dims",
              "name": "keepDims",
              "type": "bool"
            }
          ]
        },
        {
          "tfOpName": "ArgMax",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number"
            }
          ]
        },
        {
          "tfOpName": "ArgMin",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number"
            }
          ]
        },
        {
          "tfOpName": "Prod",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "keep_dims",
              "name": "keepDims",
              "type": "bool"
            }
          ]
        },
        {
          "tfOpName": "Cumprod",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "exclusive",
              "name": "exclusive",
              "type": "bool"
            },
            {
              "tfName": "reverse",
              "name": "reverse",
              "type": "bool"
            }
          ]
        },
        {
          "tfOpName": "Cumsum",
          "category": "reduction",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "exclusive",
              "name": "exclusive",
              "type": "bool"
            },
            {
              "tfName": "reverse",
              "name": "reverse",
              "type": "bool"
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/slice_join.js
  var slice_join_exports = {};
  __export(slice_join_exports, {
    json: () => json15
  });
  var json15;
  var init_slice_join = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/slice_join.js"() {
      json15 = [
        {
          "tfOpName": "ConcatV2",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "end": -1,
              "name": "tensors",
              "type": "tensors"
            },
            {
              "start": -1,
              "name": "axis",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "N",
              "name": "n",
              "type": "number",
              "defaultValue": 2
            }
          ]
        },
        {
          "tfOpName": "Concat",
          "category": "slice_join",
          "inputs": [
            {
              "start": 1,
              "end": 0,
              "name": "tensors",
              "type": "tensors"
            },
            {
              "start": 0,
              "name": "axis",
              "type": "number"
            }
          ],
          "attrs": [
            {
              "tfName": "N",
              "name": "n",
              "type": "number",
              "defaultValue": 2
            }
          ]
        },
        {
          "tfOpName": "GatherV2",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "indices",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "axis",
              "type": "number",
              "defaultValue": 0
            }
          ],
          "attrs": [
            {
              "tfName": "batch_dims",
              "name": "batchDims",
              "type": "number",
              "defaultValue": 0
            }
          ]
        },
        {
          "tfOpName": "Gather",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "indices",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "validate_indices",
              "name": "validateIndices",
              "type": "bool",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Reverse",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "dims",
              "type": "bool[]"
            }
          ]
        },
        {
          "tfOpName": "ReverseV2",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number[]"
            }
          ]
        },
        {
          "tfOpName": "Slice",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "begin",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "size",
              "type": "number[]"
            }
          ]
        },
        {
          "tfOpName": "StridedSlice",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "begin",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "end",
              "type": "number[]"
            },
            {
              "start": 3,
              "name": "strides",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "begin_mask",
              "name": "beginMask",
              "type": "number",
              "defaultValue": 0
            },
            {
              "tfName": "end_mask",
              "name": "endMask",
              "type": "number",
              "defaultValue": 0
            },
            {
              "tfName": "new_axis_mask",
              "name": "newAxisMask",
              "type": "number",
              "defaultValue": 0
            },
            {
              "tfName": "ellipsis_mask",
              "name": "ellipsisMask",
              "type": "number",
              "defaultValue": 0
            },
            {
              "tfName": "shrink_axis_mask",
              "name": "shrinkAxisMask",
              "type": "number",
              "defaultValue": 0
            }
          ]
        },
        {
          "tfOpName": "Pack",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "end": 0,
              "name": "tensors",
              "type": "tensors"
            }
          ],
          "attrs": [
            {
              "tfName": "axis",
              "name": "axis",
              "type": "number",
              "defaultValue": 0
            }
          ]
        },
        {
          "tfOpName": "Unpack",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "tensor",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "axis",
              "name": "axis",
              "type": "number",
              "defaultValue": 0
            },
            {
              "tfName": "num",
              "name": "num",
              "type": "number",
              "defaultValue": 0,
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "Tile",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "reps",
              "type": "number[]"
            }
          ]
        },
        {
          "tfOpName": "Split",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "axis",
              "type": "number",
              "defaultValue": 0
            },
            {
              "start": 1,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "num_split",
              "name": "numOrSizeSplits",
              "type": "number",
              "defaultValue": 1
            }
          ]
        },
        {
          "tfOpName": "SplitV",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "numOrSizeSplits",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "axis",
              "type": "number",
              "defaultValue": 0
            }
          ]
        },
        {
          "tfOpName": "ScatterNd",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "indices",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "values",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "shape",
              "type": "number[]"
            }
          ]
        },
        {
          "tfOpName": "GatherNd",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "indices",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "SparseToDense",
          "category": "slice_join",
          "inputs": [
            {
              "start": 0,
              "name": "sparseIndices",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "outputShape",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "sparseValues",
              "type": "tensor"
            },
            {
              "start": 3,
              "name": "defaultValue",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "validate_indices",
              "name": "validateIndices",
              "type": "bool",
              "defaultValue": false,
              "notSupported": true
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/sparse.js
  var sparse_exports = {};
  __export(sparse_exports, {
    json: () => json16
  });
  var json16;
  var init_sparse = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/sparse.js"() {
      json16 = [
        {
          "tfOpName": "SparseFillEmptyRows",
          "category": "sparse",
          "inputs": [
            {
              "start": 0,
              "name": "indices",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "values",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "denseShape",
              "type": "tensor"
            },
            {
              "start": 3,
              "name": "defaultValue",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "SparseReshape",
          "category": "sparse",
          "inputs": [
            {
              "start": 0,
              "name": "inputIndices",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "inputShape",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "newShape",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "T",
              "name": "dtype",
              "type": "dtype",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "SparseSegmentMean",
          "category": "sparse",
          "inputs": [
            {
              "start": 0,
              "name": "data",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "indices",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "segmentIds",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "SparseSegmentSum",
          "category": "sparse",
          "inputs": [
            {
              "start": 0,
              "name": "data",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "indices",
              "type": "tensor"
            },
            {
              "start": 2,
              "name": "segmentIds",
              "type": "tensor"
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/spectral.js
  var spectral_exports = {};
  __export(spectral_exports, {
    json: () => json17
  });
  var json17;
  var init_spectral = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/spectral.js"() {
      json17 = [
        {
          "tfOpName": "FFT",
          "category": "spectral",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "IFFT",
          "category": "spectral",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ]
        },
        {
          "tfOpName": "RFFT",
          "category": "spectral",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "fft_length",
              "type": "number",
              "notSupported": true
            }
          ]
        },
        {
          "tfOpName": "IRFFT",
          "category": "spectral",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "fft_length",
              "type": "number",
              "notSupported": true
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/string.js
  var string_exports = {};
  __export(string_exports, {
    json: () => json18
  });
  var json18;
  var init_string = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/string.js"() {
      json18 = [
        {
          "tfOpName": "StringNGrams",
          "category": "string",
          "inputs": [
            {
              "start": 0,
              "name": "data",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "dataSplits",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "separator",
              "name": "separator",
              "type": "string"
            },
            {
              "tfName": "ngram_widths",
              "name": "nGramWidths",
              "type": "number[]"
            },
            {
              "tfName": "left_pad",
              "name": "leftPad",
              "type": "string"
            },
            {
              "tfName": "right_pad",
              "name": "rightPad",
              "type": "string"
            },
            {
              "tfName": "pad_width",
              "name": "padWidth",
              "type": "number"
            },
            {
              "tfName": "preserve_short_sequences",
              "name": "preserveShortSequences",
              "type": "bool"
            }
          ],
          "outputs": [
            "ngrams",
            "ngrams_splits"
          ]
        },
        {
          "tfOpName": "StringSplit",
          "category": "string",
          "inputs": [
            {
              "start": 0,
              "name": "input",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "delimiter",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "skip_empty",
              "name": "skipEmpty",
              "type": "bool"
            }
          ],
          "outputs": [
            "indices",
            "values",
            "shape"
          ]
        },
        {
          "tfOpName": "StringToHashBucketFast",
          "category": "string",
          "inputs": [
            {
              "start": 0,
              "name": "input",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "num_buckets",
              "name": "numBuckets",
              "type": "number"
            }
          ]
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/transformation.js
  var transformation_exports = {};
  __export(transformation_exports, {
    json: () => json19
  });
  var json19;
  var init_transformation = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/transformation.js"() {
      json19 = [
        {
          "tfOpName": "Cast",
          "category": "transformation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "SrcT",
              "name": "sdtype",
              "type": "dtype",
              "notSupported": true
            },
            {
              "tfName": "DstT",
              "name": "dtype",
              "type": "dtype"
            }
          ]
        },
        {
          "tfOpName": "ExpandDims",
          "category": "transformation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "axis",
              "type": "number"
            }
          ]
        },
        {
          "tfOpName": "MirrorPad",
          "category": "transformation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "padding",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "mode",
              "name": "mode",
              "type": "string"
            }
          ]
        },
        {
          "tfOpName": "Pad",
          "category": "transformation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "padding",
              "type": "number[]"
            }
          ],
          "attrs": [
            {
              "tfName": "constant_value",
              "name": "constantValue",
              "type": "number",
              "defaultValue": 0
            }
          ]
        },
        {
          "tfOpName": "PadV2",
          "category": "transformation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "padding",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "constantValue",
              "type": "number",
              "defaultValue": 0
            }
          ]
        },
        {
          "tfOpName": "Reshape",
          "category": "transformation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "shape",
              "type": "number[]"
            }
          ]
        },
        {
          "tfOpName": "Squeeze",
          "category": "transformation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "axis",
              "tfDeprecatedName": "squeeze_dims",
              "name": "axis",
              "type": "number[]"
            }
          ]
        },
        {
          "tfOpName": "SpaceToBatchND",
          "category": "transformation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "blockShape",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "paddings",
              "type": "number[]"
            }
          ]
        },
        {
          "tfOpName": "BatchToSpaceND",
          "category": "transformation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "blockShape",
              "type": "number[]"
            },
            {
              "start": 2,
              "name": "crops",
              "type": "number[]"
            }
          ]
        },
        {
          "tfOpName": "DepthToSpace",
          "category": "transformation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            }
          ],
          "attrs": [
            {
              "tfName": "block_size",
              "name": "blockSize",
              "type": "number"
            },
            {
              "tfName": "data_format",
              "name": "dataFormat",
              "type": "string"
            }
          ]
        },
        {
          "tfOpName": "BroadcastTo",
          "category": "transformation",
          "inputs": [
            {
              "start": 0,
              "name": "x",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "shape",
              "type": "number[]"
            }
          ],
          "attrs": []
        },
        {
          "tfOpName": "BroadcastArgs",
          "category": "transformation",
          "inputs": [
            {
              "start": 0,
              "name": "s0",
              "type": "tensor"
            },
            {
              "start": 1,
              "name": "s1",
              "type": "tensor"
            }
          ],
          "attrs": []
        }
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/operation_mapper.js
  function decodeBase64(text) {
    const global2 = env().global;
    if (typeof global2.atob !== "undefined") {
      return global2.atob(text);
    } else if (typeof Buffer !== "undefined") {
      return new Buffer(text, "base64").toString();
    } else {
      throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()");
    }
  }
  function parseStringParam(s, keepCase) {
    const value = Array.isArray(s) ? String.fromCharCode.apply(null, s) : decodeBase64(s);
    return keepCase ? value : value.toLowerCase();
  }
  function getStringParam(attrs, name, def, keepCase = false) {
    const param = attrs[name];
    if (param != null) {
      return parseStringParam(param.s, keepCase);
    }
    return def;
  }
  function getBoolParam(attrs, name, def) {
    const param = attrs[name];
    return param ? param.b : def;
  }
  function getNumberParam(attrs, name, def) {
    const param = attrs[name] || {};
    const value = param["i"] != null ? param["i"] : param["f"] != null ? param["f"] : def;
    return typeof value === "number" ? value : parseInt(value, 10);
  }
  function parseDtypeParam(value) {
    if (typeof value === "string") {
      value = DataType[value];
    }
    switch (value) {
      case DataType.DT_FLOAT:
      case DataType.DT_HALF:
        return "float32";
      case DataType.DT_INT32:
      case DataType.DT_INT64:
      case DataType.DT_INT8:
      case DataType.DT_UINT8:
        return "int32";
      case DataType.DT_BOOL:
        return "bool";
      case DataType.DT_DOUBLE:
        return "float32";
      case DataType.DT_STRING:
        return "string";
      default:
        return null;
    }
  }
  function getFuncParam(attrs, name, def) {
    const param = attrs[name];
    if (param && param.func) {
      return param.func.name;
    }
    return def;
  }
  function getDtypeParam(attrs, name, def) {
    const param = attrs[name];
    if (param && param.type) {
      return parseDtypeParam(param.type);
    }
    return def;
  }
  function getDtypeArrayParam(attrs, name, def) {
    const param = attrs[name];
    if (param && param.list && param.list.type) {
      return param.list.type.map((v) => parseDtypeParam(v));
    }
    return def;
  }
  function parseTensorShapeParam(shape) {
    if (shape.unknownRank) {
      return void 0;
    }
    if (shape.dim != null) {
      return shape.dim.map((dim) => typeof dim.size === "number" ? dim.size : parseInt(dim.size, 10));
    }
    return [];
  }
  function getTensorShapeParam(attrs, name, def) {
    const param = attrs[name];
    if (param && param.shape) {
      return parseTensorShapeParam(param.shape);
    }
    return def;
  }
  function getNumericArrayParam(attrs, name, def) {
    const param = attrs[name];
    if (param) {
      return ((param.list.f && param.list.f.length ? param.list.f : param.list.i) || []).map((v) => typeof v === "number" ? v : parseInt(v, 10));
    }
    return def;
  }
  function getStringArrayParam(attrs, name, def, keepCase = false) {
    const param = attrs[name];
    if (param && param.list && param.list.s) {
      return param.list.s.map((v) => {
        return parseStringParam(v, keepCase);
      });
    }
    return def;
  }
  function getTensorShapeArrayParam(attrs, name, def) {
    const param = attrs[name];
    if (param && param.list && param.list.shape) {
      return param.list.shape.map((v) => {
        return parseTensorShapeParam(v);
      });
    }
    return def;
  }
  function getBoolArrayParam(attrs, name, def) {
    const param = attrs[name];
    if (param && param.list && param.list.b) {
      return param.list.b;
    }
    return def;
  }
  var OperationMapper;
  var init_operation_mapper = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/operation_mapper.js"() {
      init_dist();
      init_compiled_api();
      init_register();
      init_utils();
      init_arithmetic();
      init_basic_math();
      init_control();
      init_convolution();
      init_creation();
      init_dynamic();
      init_evaluation();
      init_graph();
      init_hash_table();
      init_image();
      init_logical();
      init_matrices();
      init_normalization();
      init_reduction();
      init_slice_join();
      init_sparse();
      init_spectral();
      init_string();
      init_transformation();
      OperationMapper = class {
        // Loads the op mapping from the JSON file.
        constructor() {
          const ops = [
            arithmetic_exports,
            basic_math_exports,
            control_exports,
            convolution_exports,
            creation_exports,
            dynamic_exports,
            evaluation_exports,
            graph_exports,
            hash_table_exports,
            image_exports,
            logical_exports,
            matrices_exports,
            normalization_exports,
            reduction_exports,
            slice_join_exports,
            sparse_exports,
            spectral_exports,
            string_exports,
            transformation_exports
          ];
          const mappersJson = [].concat(...ops.map((op2) => op2.json));
          this.opMappers = mappersJson.reduce((map, mapper) => {
            map[mapper.tfOpName] = mapper;
            return map;
          }, {});
        }
        // Singleton instance for the mapper
        static get Instance() {
          return this._instance || (this._instance = new this());
        }
        // Converts the model inference graph from Tensorflow GraphDef to local
        // representation for TensorFlow.js API
        transformGraph(graph, signature = {}) {
          const tfNodes = graph.node;
          const placeholders = [];
          const weights = [];
          const initNodes = [];
          const nodes = tfNodes.reduce((map, node) => {
            map[node.name] = this.mapNode(node);
            if (node.op.startsWith("Placeholder")) {
              placeholders.push(map[node.name]);
            } else if (node.op === "Const") {
              weights.push(map[node.name]);
            } else if (node.input == null || node.input.length === 0) {
              initNodes.push(map[node.name]);
            }
            return map;
          }, {});
          let inputs = [];
          const outputs = [];
          let inputNodeNameToKey = {};
          let outputNodeNameToKey = {};
          if (signature != null) {
            inputNodeNameToKey = this.mapSignatureEntries(signature.inputs);
            outputNodeNameToKey = this.mapSignatureEntries(signature.outputs);
          }
          const allNodes = Object.keys(nodes);
          allNodes.forEach((key) => {
            const node = nodes[key];
            node.inputNames.forEach((name, index) => {
              const [nodeName, , outputName] = getNodeNameAndIndex(name);
              const inputNode = nodes[nodeName];
              if (inputNode.outputs != null) {
                const outputIndex = inputNode.outputs.indexOf(outputName);
                if (outputIndex !== -1) {
                  const inputName = `${nodeName}:${outputIndex}`;
                  node.inputNames[index] = inputName;
                }
              }
              node.inputs.push(inputNode);
              inputNode.children.push(node);
            });
          });
          if (Object.keys(outputNodeNameToKey).length === 0) {
            allNodes.forEach((key) => {
              const node = nodes[key];
              if (node.children.length === 0) {
                outputs.push(node);
              }
            });
          } else {
            Object.keys(outputNodeNameToKey).forEach((name) => {
              const [nodeName] = getNodeNameAndIndex(name);
              const node = nodes[nodeName];
              if (node != null) {
                node.signatureKey = outputNodeNameToKey[name];
                outputs.push(node);
              }
            });
          }
          if (Object.keys(inputNodeNameToKey).length > 0) {
            Object.keys(inputNodeNameToKey).forEach((name) => {
              const [nodeName] = getNodeNameAndIndex(name);
              const node = nodes[nodeName];
              if (node) {
                node.signatureKey = inputNodeNameToKey[name];
                inputs.push(node);
              }
            });
          } else {
            inputs = placeholders;
          }
          let functions = {};
          if (graph.library != null && graph.library.function != null) {
            functions = graph.library.function.reduce((functions2, func) => {
              functions2[func.signature.name] = this.mapFunction(func);
              return functions2;
            }, {});
          }
          const result = { nodes, inputs, outputs, weights, placeholders, signature, functions };
          if (initNodes.length > 0) {
            result.initNodes = initNodes;
          }
          return result;
        }
        mapSignatureEntries(entries) {
          return Object.keys(entries || {}).reduce((prev, curr) => {
            prev[entries[curr].name] = curr;
            return prev;
          }, {});
        }
        mapNode(node) {
          const mapper = getRegisteredOp(node.op) || this.opMappers[node.op] || {};
          if (node.attr == null) {
            node.attr = {};
          }
          const newNode = {
            name: node.name,
            op: node.op,
            category: mapper.category,
            inputNames: (node.input || []).map((input) => input.startsWith("^") ? input.slice(1) : input),
            inputs: [],
            children: [],
            inputParams: {},
            attrParams: {},
            rawAttrs: node.attr,
            outputs: mapper.outputs
          };
          if (mapper.inputs != null) {
            newNode.inputParams = mapper.inputs.reduce((map, param) => {
              map[param.name] = {
                type: param.type,
                inputIndexStart: param.start,
                inputIndexEnd: param.end
              };
              return map;
            }, {});
          }
          if (mapper.attrs != null) {
            newNode.attrParams = mapper.attrs.reduce((map, param) => {
              const type = param.type;
              let value = void 0;
              switch (param.type) {
                case "string":
                  value = getStringParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getStringParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "string[]":
                  value = getStringArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getStringArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "number":
                  value = getNumberParam(node.attr, param.tfName, param.defaultValue || 0);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getNumberParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "number[]":
                  value = getNumericArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getNumericArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "bool":
                  value = getBoolParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getBoolParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "bool[]":
                  value = getBoolArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getBoolArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "shape":
                  value = getTensorShapeParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getTensorShapeParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "shape[]":
                  value = getTensorShapeArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getTensorShapeArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "dtype":
                  value = getDtypeParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getDtypeParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "dtype[]":
                  value = getDtypeArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getDtypeArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "func":
                  value = getFuncParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getFuncParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "tensor":
                case "tensors":
                  break;
                default:
                  throw new Error(`Unsupported param type: ${param.type} for op: ${node.op}`);
              }
              map[param.name] = { value, type };
              return map;
            }, {});
          }
          return newNode;
        }
        // map the TFunctionDef to TFJS graph object
        mapFunction(functionDef) {
          const tfNodes = functionDef.nodeDef;
          const placeholders = [];
          const weights = [];
          let nodes = {};
          if (tfNodes != null) {
            nodes = tfNodes.reduce((map, node) => {
              map[node.name] = this.mapNode(node);
              if (node.op === "Const") {
                weights.push(map[node.name]);
              }
              return map;
            }, {});
          }
          const inputs = [];
          const outputs = [];
          functionDef.signature.inputArg.forEach((arg) => {
            const [nodeName] = getNodeNameAndIndex(arg.name);
            const node = {
              name: nodeName,
              op: "Placeholder",
              inputs: [],
              inputNames: [],
              category: "graph",
              inputParams: {},
              attrParams: { dtype: { value: parseDtypeParam(arg.type), type: "dtype" } },
              children: []
            };
            node.signatureKey = arg.name;
            inputs.push(node);
            nodes[nodeName] = node;
          });
          const allNodes = Object.keys(nodes);
          allNodes.forEach((key) => {
            const node = nodes[key];
            node.inputNames.forEach((name, index) => {
              const [nodeName, , outputName] = getNodeNameAndIndex(name);
              const inputNode = nodes[nodeName];
              if (inputNode.outputs != null) {
                const outputIndex = inputNode.outputs.indexOf(outputName);
                if (outputIndex !== -1) {
                  const inputName = `${nodeName}:${outputIndex}`;
                  node.inputNames[index] = inputName;
                }
              }
              node.inputs.push(inputNode);
              inputNode.children.push(node);
            });
          });
          const returnNodeMap = functionDef.ret;
          functionDef.signature.outputArg.forEach((output) => {
            const [nodeName, index] = getNodeNameAndIndex(returnNodeMap[output.name]);
            const node = nodes[nodeName];
            if (node != null) {
              node.defaultOutput = index;
              outputs.push(node);
            }
          });
          const signature = this.mapArgsToSignature(functionDef);
          return { nodes, inputs, outputs, weights, placeholders, signature };
        }
        mapArgsToSignature(functionDef) {
          return {
            methodName: functionDef.signature.name,
            inputs: functionDef.signature.inputArg.reduce((map, arg) => {
              map[arg.name] = this.mapArgToTensorInfo(arg);
              return map;
            }, {}),
            outputs: functionDef.signature.outputArg.reduce((map, arg) => {
              map[arg.name] = this.mapArgToTensorInfo(arg, functionDef.ret);
              return map;
            }, {})
          };
        }
        mapArgToTensorInfo(arg, nameMap) {
          let name = arg.name;
          if (nameMap != null) {
            name = nameMap[name];
          }
          return { name, dtype: arg.type };
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/custom_op/node_value_impl.js
  var NodeValueImpl;
  var init_node_value_impl = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/custom_op/node_value_impl.js"() {
      init_utils();
      init_operation_mapper();
      NodeValueImpl = class {
        constructor(node, tensorMap, context) {
          this.node = node;
          this.tensorMap = tensorMap;
          this.context = context;
          this.inputs = [];
          this.attrs = {};
          this.inputs = node.inputNames.map((name) => this.getInput(name));
          if (node.rawAttrs != null) {
            this.attrs = Object.keys(node.rawAttrs).reduce((attrs, key) => {
              attrs[key] = this.getAttr(key);
              return attrs;
            }, {});
          }
        }
        /**
         * Return the value of the attribute or input param.
         * @param name String: name of attribute or input param.
         */
        getInput(name) {
          return getTensor(name, this.tensorMap, this.context);
        }
        /**
         * Return the value of the attribute or input param.
         * @param name String: name of attribute or input param.
         */
        getAttr(name, defaultValue) {
          const value = this.node.rawAttrs[name];
          if (value.tensor != null) {
            return getTensor(name, this.tensorMap, this.context);
          }
          if (value.i != null || value.f != null) {
            return getNumberParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.s != null) {
            return getStringParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.b != null) {
            return getBoolParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.shape != null) {
            return getTensorShapeParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.type != null) {
            return getDtypeParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.list != null) {
            if (value.list.i != null || value.list.f != null) {
              return getNumericArrayParam(this.node.rawAttrs, name, defaultValue);
            }
            if (value.list.s != null) {
              return getStringArrayParam(this.node.rawAttrs, name, defaultValue);
            }
            if (value.list.shape != null) {
              return getTensorShapeArrayParam(this.node.rawAttrs, name, defaultValue);
            }
            if (value.list.b != null) {
              return getBoolArrayParam(this.node.rawAttrs, name, defaultValue);
            }
            if (value.list.type != null) {
              return getDtypeArrayParam(this.node.rawAttrs, name, defaultValue);
            }
          }
          return defaultValue;
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-core/dist/ops/ops_for_converter.js
  var ops_for_converter_exports = {};
  __export(ops_for_converter_exports, {
    OP_SCOPE_SUFFIX: () => OP_SCOPE_SUFFIX,
    abs: () => abs,
    acos: () => acos,
    acosh: () => acosh,
    add: () => add2,
    addN: () => addN,
    all: () => all,
    any: () => any,
    argMax: () => argMax,
    argMin: () => argMin,
    asin: () => asin,
    asinh: () => asinh,
    atan: () => atan,
    atan2: () => atan2,
    atanh: () => atanh,
    avgPool: () => avgPool,
    avgPool3d: () => avgPool3d,
    basicLSTMCell: () => basicLSTMCell,
    batchNorm: () => batchNorm,
    batchNorm2d: () => batchNorm2d,
    batchNorm3d: () => batchNorm3d,
    batchNorm4d: () => batchNorm4d,
    batchToSpaceND: () => batchToSpaceND,
    bincount: () => bincount,
    booleanMaskAsync: () => booleanMaskAsync,
    broadcastArgs: () => broadcastArgs,
    broadcastTo: () => broadcastTo,
    buffer: () => buffer,
    cast: () => cast,
    ceil: () => ceil,
    clipByValue: () => clipByValue,
    clone: () => clone,
    complex: () => complex,
    concat: () => concat,
    concat1d: () => concat1d,
    concat2d: () => concat2d,
    concat3d: () => concat3d,
    concat4d: () => concat4d,
    conv1d: () => conv1d,
    conv2d: () => conv2d,
    conv2dTranspose: () => conv2dTranspose,
    conv3d: () => conv3d,
    conv3dTranspose: () => conv3dTranspose,
    cos: () => cos,
    cosh: () => cosh,
    cosineWindow: () => cosineWindow,
    cumprod: () => cumprod,
    cumsum: () => cumsum,
    denseBincount: () => denseBincount,
    depthToSpace: () => depthToSpace,
    depthwiseConv2d: () => depthwiseConv2d,
    diag: () => diag,
    dilation2d: () => dilation2d,
    div: () => div,
    divNoNan: () => divNoNan,
    dot: () => dot,
    dropout: () => dropout,
    einsum: () => einsum,
    elu: () => elu,
    enclosingPowerOfTwo: () => enclosingPowerOfTwo,
    equal: () => equal,
    erf: () => erf,
    euclideanNorm: () => euclideanNorm,
    exp: () => exp,
    expandDims: () => expandDims,
    expm1: () => expm1,
    eye: () => eye,
    fft: () => fft,
    fill: () => fill,
    floor: () => floor,
    floorDiv: () => floorDiv,
    fused: () => fused_ops_exports,
    gather: () => gather,
    gatherND: () => gatherND,
    greater: () => greater,
    greaterEqual: () => greaterEqual,
    ifft: () => ifft,
    imag: () => imag,
    image: () => image,
    inTopKAsync: () => inTopKAsync,
    irfft: () => irfft,
    isFinite: () => isFinite2,
    isInf: () => isInf,
    isNaN: () => isNaN2,
    leakyRelu: () => leakyRelu,
    less: () => less,
    lessEqual: () => lessEqual,
    linalg: () => linalg,
    linspace: () => linspace,
    localResponseNormalization: () => localResponseNormalization,
    log: () => log2,
    log1p: () => log1p,
    logSigmoid: () => logSigmoid,
    logSoftmax: () => logSoftmax,
    logSumExp: () => logSumExp,
    logicalAnd: () => logicalAnd,
    logicalNot: () => logicalNot,
    logicalOr: () => logicalOr,
    logicalXor: () => logicalXor,
    losses: () => losses,
    lowerBound: () => lowerBound,
    matMul: () => matMul,
    max: () => max,
    maxPool: () => maxPool,
    maxPool3d: () => maxPool3d,
    maxPoolWithArgmax: () => maxPoolWithArgmax,
    maximum: () => maximum,
    mean: () => mean,
    meshgrid: () => meshgrid,
    min: () => min,
    minimum: () => minimum,
    mirrorPad: () => mirrorPad,
    mod: () => mod,
    moments: () => moments,
    movingAverage: () => movingAverage,
    mul: () => mul,
    multiRNNCell: () => multiRNNCell,
    multinomial: () => multinomial,
    neg: () => neg,
    norm: () => norm,
    notEqual: () => notEqual,
    oneHot: () => oneHot,
    ones: () => ones2,
    onesLike: () => onesLike,
    op: () => op,
    outerProduct: () => outerProduct,
    pad: () => pad,
    pad1d: () => pad1d,
    pad2d: () => pad2d,
    pad3d: () => pad3d,
    pad4d: () => pad4d,
    pool: () => pool,
    pow: () => pow,
    prelu: () => prelu,
    print: () => print,
    prod: () => prod,
    raggedGather: () => raggedGather,
    raggedRange: () => raggedRange,
    raggedTensorToTensor: () => raggedTensorToTensor,
    rand: () => rand,
    randomGamma: () => randomGamma,
    randomNormal: () => randomNormal,
    randomStandardNormal: () => randomStandardNormal,
    randomUniform: () => randomUniform,
    range: () => range,
    real: () => real,
    reciprocal: () => reciprocal,
    relu: () => relu,
    relu6: () => relu6,
    reshape: () => reshape,
    reverse: () => reverse,
    reverse1d: () => reverse1d,
    reverse2d: () => reverse2d,
    reverse3d: () => reverse3d,
    reverse4d: () => reverse4d,
    rfft: () => rfft,
    round: () => round2,
    rsqrt: () => rsqrt,
    scalar: () => scalar,
    scatterND: () => scatterND,
    searchSorted: () => searchSorted,
    selu: () => selu,
    separableConv2d: () => separableConv2d,
    setdiff1dAsync: () => setdiff1dAsync,
    sigmoid: () => sigmoid,
    sign: () => sign,
    signal: () => signal,
    sin: () => sin,
    sinh: () => sinh,
    slice: () => slice,
    slice1d: () => slice1d,
    slice2d: () => slice2d,
    slice3d: () => slice3d,
    slice4d: () => slice4d,
    softmax: () => softmax,
    softplus: () => softplus,
    spaceToBatchND: () => spaceToBatchND,
    sparse: () => sparse,
    sparseToDense: () => sparseToDense,
    spectral: () => spectral,
    split: () => split,
    sqrt: () => sqrt,
    square: () => square,
    squaredDifference: () => squaredDifference,
    squeeze: () => squeeze,
    stack: () => stack,
    step: () => step,
    stridedSlice: () => stridedSlice,
    string: () => string,
    sub: () => sub,
    sum: () => sum2,
    tan: () => tan,
    tanh: () => tanh2,
    tensor: () => tensor,
    tensor1d: () => tensor1d,
    tensor2d: () => tensor2d,
    tensor3d: () => tensor3d,
    tensor4d: () => tensor4d,
    tensor5d: () => tensor5d,
    tensor6d: () => tensor6d,
    tile: () => tile,
    topk: () => topk,
    transpose: () => transpose,
    truncatedNormal: () => truncatedNormal,
    unique: () => unique,
    unsortedSegmentSum: () => unsortedSegmentSum,
    unstack: () => unstack,
    upperBound: () => upperBound,
    variable: () => variable,
    where: () => where,
    whereAsync: () => whereAsync,
    zeros: () => zeros,
    zerosLike: () => zerosLike
  });
  var init_ops_for_converter = __esm({
    "node_modules/@tensorflow/tfjs-core/dist/ops/ops_for_converter.js"() {
      init_ops();
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/arithmetic_executor.js
  var executeOp;
  var init_arithmetic_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/arithmetic_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "BiasAdd":
          case "AddV2":
          case "Add": {
            return [ops.add(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "AddN": {
            return [ops.addN(getParamValue("tensors", node, tensorMap, context))];
          }
          case "FloorMod":
          case "Mod":
            return [ops.mod(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          case "Mul":
            return [ops.mul(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          case "RealDiv":
          case "Div": {
            return [ops.div(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "DivNoNan": {
            return [ops.divNoNan(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "FloorDiv": {
            return [ops.floorDiv(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "Sub": {
            return [ops.sub(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "Minimum": {
            return [ops.minimum(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "Maximum": {
            return [ops.maximum(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "Pow": {
            return [ops.pow(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "SquaredDifference": {
            return [ops.squaredDifference(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/basic_math_executor.js
  var executeOp2;
  var init_basic_math_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/basic_math_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp2 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "Abs":
          case "ComplexAbs":
            return [ops.abs(getParamValue("x", node, tensorMap, context))];
          case "Acos":
            return [ops.acos(getParamValue("x", node, tensorMap, context))];
          case "Acosh":
            return [ops.acosh(getParamValue("x", node, tensorMap, context))];
          case "Asin":
            return [ops.asin(getParamValue("x", node, tensorMap, context))];
          case "Asinh":
            return [ops.asinh(getParamValue("x", node, tensorMap, context))];
          case "Atan":
            return [ops.atan(getParamValue("x", node, tensorMap, context))];
          case "Atan2":
            return [ops.atan2(getParamValue("x", node, tensorMap, context), getParamValue("y", node, tensorMap, context))];
          case "Atanh":
            return [ops.atanh(getParamValue("x", node, tensorMap, context))];
          case "Ceil":
            return [ops.ceil(getParamValue("x", node, tensorMap, context))];
          case "Complex":
            return [ops.complex(getParamValue("real", node, tensorMap, context), getParamValue("imag", node, tensorMap, context))];
          case "Cos":
            return [ops.cos(getParamValue("x", node, tensorMap, context))];
          case "Cosh":
            return [ops.cosh(getParamValue("x", node, tensorMap, context))];
          case "Elu":
            return [ops.elu(getParamValue("x", node, tensorMap, context))];
          case "Erf":
            return [ops.erf(getParamValue("x", node, tensorMap, context))];
          case "Exp":
            return [ops.exp(getParamValue("x", node, tensorMap, context))];
          case "Expm1": {
            return [ops.expm1(getParamValue("x", node, tensorMap, context))];
          }
          case "Floor":
            return [ops.floor(getParamValue("x", node, tensorMap, context))];
          case "Log":
            return [ops.log(getParamValue("x", node, tensorMap, context))];
          case "Log1p": {
            return [ops.log1p(getParamValue("x", node, tensorMap, context))];
          }
          case "Imag":
            return [ops.imag(getParamValue("x", node, tensorMap, context))];
          case "Neg":
            return [ops.neg(getParamValue("x", node, tensorMap, context))];
          case "Reciprocal": {
            return [ops.reciprocal(getParamValue("x", node, tensorMap, context))];
          }
          case "Real":
            return [ops.real(getParamValue("x", node, tensorMap, context))];
          case "Relu":
            return [ops.relu(getParamValue("x", node, tensorMap, context))];
          case "Round": {
            return [ops.round(getParamValue("x", node, tensorMap, context))];
          }
          case "Selu":
            return [ops.selu(getParamValue("x", node, tensorMap, context))];
          case "Sigmoid":
            return [ops.sigmoid(getParamValue("x", node, tensorMap, context))];
          case "Sin":
            return [ops.sin(getParamValue("x", node, tensorMap, context))];
          case "Sign": {
            return [ops.sign(getParamValue("x", node, tensorMap, context))];
          }
          case "Sinh": {
            return [ops.sinh(getParamValue("x", node, tensorMap, context))];
          }
          case "Softplus": {
            return [ops.softplus(getParamValue("x", node, tensorMap, context))];
          }
          case "Sqrt": {
            return [ops.sqrt(getParamValue("x", node, tensorMap, context))];
          }
          case "Square": {
            return [ops.square(getParamValue("x", node, tensorMap, context))];
          }
          case "Tanh": {
            return [ops.tanh(getParamValue("x", node, tensorMap, context))];
          }
          case "Tan":
            return [ops.tan(getParamValue("x", node, tensorMap, context))];
          case "ClipByValue":
            return [ops.clipByValue(getParamValue("x", node, tensorMap, context), getParamValue("clipValueMin", node, tensorMap, context), getParamValue("clipValueMax", node, tensorMap, context))];
          case "Relu6":
            return [ops.relu6(getParamValue("x", node, tensorMap, context))];
          case "Rsqrt":
            return [ops.rsqrt(getTensor(node.inputNames[0], tensorMap, context))];
          case "Prod":
            return [ops.prod(getParamValue("x", node, tensorMap, context), getParamValue("axes", node, tensorMap, context))];
          case "LeakyRelu":
            return [ops.leakyRelu(getParamValue("x", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context))];
          case "Prelu":
            return [ops.prelu(getParamValue("x", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context))];
          case "IsNan":
            return [ops.isNaN(getTensor(node.inputNames[0], tensorMap, context))];
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_utils.js
  function assertShapesMatchAllowUndefinedSize(shapeA, shapeB, errorMessagePrefix = "") {
    if (typeof shapeA === "number" || typeof shapeB === "number") {
      return;
    }
    util_exports.assert(shapeA.length === shapeB.length, () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);
    for (let i = 0; i < shapeA.length; i++) {
      const dim0 = shapeA[i];
      const dim1 = shapeB[i];
      util_exports.assert(dim0 < 0 || dim1 < 0 || dim0 === dim1, () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);
    }
  }
  function fullDefinedShape(elementShape) {
    if (typeof elementShape === "number" || elementShape.some((dim) => dim < 0)) {
      return false;
    }
    return true;
  }
  function inferElementShape(listElementShape, tensors, elementShape) {
    let partialShape = mergeElementShape(listElementShape, elementShape);
    const notfullDefinedShape = !fullDefinedShape(partialShape);
    if (notfullDefinedShape && tensors.length === 0) {
      throw new Error(`Tried to calculate elements of an empty list with non-fully-defined elementShape: ${partialShape}`);
    }
    if (notfullDefinedShape) {
      tensors.forEach((tensor2) => {
        partialShape = mergeElementShape(tensor2.shape, partialShape);
      });
    }
    if (!fullDefinedShape(partialShape)) {
      throw new Error(`Non-fully-defined elementShape: ${partialShape}`);
    }
    return partialShape;
  }
  function mergeElementShape(elementShapeA, elementShapeB) {
    if (typeof elementShapeA === "number") {
      return elementShapeB;
    }
    if (typeof elementShapeB === "number") {
      return elementShapeA;
    }
    if (elementShapeA.length !== elementShapeB.length) {
      throw new Error(`Incompatible ranks during merge: ${elementShapeA} vs. ${elementShapeB}`);
    }
    const result = [];
    for (let i = 0; i < elementShapeA.length; ++i) {
      const dim0 = elementShapeA[i];
      const dim1 = elementShapeB[i];
      if (dim0 >= 0 && dim1 >= 0 && dim0 !== dim1) {
        throw new Error(`Incompatible shape during merge: ${elementShapeA} vs. ${elementShapeB}`);
      }
      result[i] = dim0 >= 0 ? dim0 : dim1;
    }
    return result;
  }
  var init_tensor_utils = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_utils.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_array.js
  var TensorArray;
  var init_tensor_array = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_array.js"() {
      init_dist();
      init_tensor_utils();
      TensorArray = class {
        constructor(name, dtype, maxSize, elementShape, identicalElementShapes, dynamicSize, clearAfterRead) {
          this.name = name;
          this.dtype = dtype;
          this.maxSize = maxSize;
          this.elementShape = elementShape;
          this.identicalElementShapes = identicalElementShapes;
          this.dynamicSize = dynamicSize;
          this.clearAfterRead = clearAfterRead;
          this.tensors = [];
          this.closed_ = false;
          this.idTensor = scalar(0);
          keep(this.idTensor);
        }
        get id() {
          return this.idTensor.id;
        }
        get closed() {
          return this.closed_;
        }
        /**
         * Dispose the tensors and idTensor and mark the TensoryArray as closed.
         */
        clearAndClose(keepIds) {
          this.tensors.forEach((tensor2) => {
            if (keepIds == null || !keepIds.has(tensor2.tensor.id)) {
              tensor2.tensor.dispose();
            }
          });
          this.tensors = [];
          this.closed_ = true;
          this.idTensor.dispose();
        }
        size() {
          return this.tensors.length;
        }
        /**
         * Read the value at location index in the TensorArray.
         * @param index Number the index to read from.
         */
        read(index) {
          if (this.closed_) {
            throw new Error(`TensorArray ${this.name} has already been closed.`);
          }
          if (index < 0 || index >= this.size()) {
            throw new Error(`Tried to read from index ${index}, but array size is: ${this.size()}`);
          }
          const tensorWithState = this.tensors[index];
          if (tensorWithState.cleared) {
            throw new Error(`TensorArray ${this.name}: Could not read index ${index} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);
          }
          if (this.clearAfterRead) {
            tensorWithState.cleared = true;
          }
          tensorWithState.read = true;
          return tensorWithState.tensor;
        }
        /**
         * Helper method to read multiple tensors from the specified indices.
         */
        readMany(indices) {
          return indices.map((index) => this.read(index));
        }
        /**
         * Write value into the index of the TensorArray.
         * @param index number the index to write to.
         * @param tensor
         */
        write(index, tensor2) {
          if (this.closed_) {
            throw new Error(`TensorArray ${this.name} has already been closed.`);
          }
          if (index < 0 || !this.dynamicSize && index >= this.maxSize) {
            throw new Error(`Tried to write to index ${index}, but array is not resizeable and size is: ${this.maxSize}`);
          }
          const t2 = this.tensors[index] || {};
          if (tensor2.dtype !== this.dtype) {
            throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index},
          because the value dtype is ${tensor2.dtype}, but TensorArray dtype is ${this.dtype}.`);
          }
          if (this.size() === 0 && (this.elementShape == null || this.elementShape.length === 0)) {
            this.elementShape = tensor2.shape;
          }
          assertShapesMatchAllowUndefinedSize(this.elementShape, tensor2.shape, `TensorArray ${this.name}: Could not write to TensorArray index ${index}.`);
          if (t2.read) {
            throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index}, because it has already been read.`);
          }
          if (t2.written) {
            throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index}, because it has already been written.`);
          }
          t2.tensor = tensor2;
          keep(tensor2);
          t2.written = true;
          this.tensors[index] = t2;
        }
        /**
         * Helper method to write multiple tensors to the specified indices.
         */
        writeMany(indices, tensors) {
          if (indices.length !== tensors.length) {
            throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${indices.length} is not the same as tensors size: ${tensors.length}.`);
          }
          indices.forEach((i, index) => this.write(i, tensors[index]));
        }
        /**
         * Return selected values in the TensorArray as a packed Tensor. All of
         * selected values must have been written and their shapes must all match.
         * @param [indices] number[] Optional. Taking values in [0, max_value). If the
         *    TensorArray is not dynamic, max_value=size(). If not specified returns
         *    all tensors in the original order.
         * @param [dtype]
         */
        gather(indices, dtype) {
          if (!!dtype && dtype !== this.dtype) {
            throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${dtype}`);
          }
          if (!indices) {
            indices = [];
            for (let i = 0; i < this.size(); i++) {
              indices.push(i);
            }
          } else {
            indices = indices.slice(0, this.size());
          }
          if (indices.length === 0) {
            return tensor([], [0].concat(this.elementShape));
          }
          const tensors = this.readMany(indices);
          assertShapesMatchAllowUndefinedSize(this.elementShape, tensors[0].shape, "TensorArray shape mismatch: ");
          return stack(tensors, 0);
        }
        /**
         * Return the values in the TensorArray as a concatenated Tensor.
         */
        concat(dtype) {
          if (!!dtype && dtype !== this.dtype) {
            throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${dtype}`);
          }
          if (this.size() === 0) {
            return tensor([], [0].concat(this.elementShape));
          }
          const indices = [];
          for (let i = 0; i < this.size(); i++) {
            indices.push(i);
          }
          const tensors = this.readMany(indices);
          assertShapesMatchAllowUndefinedSize(this.elementShape, tensors[0].shape, `TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${tensors[0].shape})`);
          return concat(tensors, 0);
        }
        /**
         * Scatter the values of a Tensor in specific indices of a TensorArray.
         * @param indices nummber[] values in [0, max_value). If the
         *    TensorArray is not dynamic, max_value=size().
         * @param tensor Tensor input tensor.
         */
        scatter(indices, tensor2) {
          if (tensor2.dtype !== this.dtype) {
            throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${tensor2.dtype}`);
          }
          if (indices.length !== tensor2.shape[0]) {
            throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${indices.length} vs. ${tensor2.shape[0]}`);
          }
          const maxIndex = Math.max(...indices);
          if (!this.dynamicSize && maxIndex >= this.maxSize) {
            throw new Error(`Max index must be < array size (${maxIndex}  vs. ${this.maxSize})`);
          }
          this.writeMany(indices, unstack(tensor2, 0));
        }
        /**
         * Split the values of a Tensor into the TensorArray.
         * @param length number[] with the lengths to use when splitting value along
         *    its first dimension.
         * @param tensor Tensor, the tensor to split.
         */
        split(length, tensor2) {
          if (tensor2.dtype !== this.dtype) {
            throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${tensor2.dtype}`);
          }
          let totalLength = 0;
          const cumulativeLengths = length.map((len) => {
            totalLength += len;
            return totalLength;
          });
          if (totalLength !== tensor2.shape[0]) {
            throw new Error(`Expected sum of lengths to be equal to
          tensor.shape[0], but sum of lengths is
        ${totalLength}, and tensor's shape is: ${tensor2.shape}`);
          }
          if (!this.dynamicSize && length.length !== this.maxSize) {
            throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${length.length}), and the TensorArray is not marked as dynamically resizeable`);
          }
          const elementPerRow = totalLength === 0 ? 0 : tensor2.size / totalLength;
          const tensors = [];
          tidy(() => {
            tensor2 = reshape(tensor2, [1, totalLength, elementPerRow]);
            for (let i = 0; i < length.length; ++i) {
              const previousLength = i === 0 ? 0 : cumulativeLengths[i - 1];
              const indices2 = [0, previousLength, 0];
              const sizes = [1, length[i], elementPerRow];
              tensors[i] = reshape(slice(tensor2, indices2, sizes), this.elementShape);
            }
            return tensors;
          });
          const indices = [];
          for (let i = 0; i < length.length; i++) {
            indices[i] = i;
          }
          this.writeMany(indices, tensors);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_list.js
  function fromTensor(tensor2, elementShape, elementDtype) {
    const dtype = tensor2.dtype;
    if (tensor2.shape.length < 1) {
      throw new Error(`Tensor must be at least a vector, but saw shape: ${tensor2.shape}`);
    }
    if (tensor2.dtype !== elementDtype) {
      throw new Error(`Invalid data types; op elements ${tensor2.dtype}, but list elements ${elementDtype}`);
    }
    const tensorElementShape = tensor2.shape.slice(1);
    assertShapesMatchAllowUndefinedSize(tensorElementShape, elementShape, "TensorList shape mismatch: ");
    const tensorList = unstack(tensor2);
    return new TensorList(tensorList, elementShape, dtype);
  }
  function reserve(elementShape, elementDtype, numElements, maxNumElements) {
    return new TensorList([], elementShape, elementDtype, maxNumElements);
  }
  function scatter(tensor2, indices, elementShape, numElements) {
    if (indices.length !== tensor2.shape[0]) {
      throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${indices.length} vs. ${tensor2.shape[0]}`);
    }
    const maxIndex = Math.max(...indices);
    if (numElements != null && numElements !== -1 && maxIndex >= numElements) {
      throw new Error(`Max index must be < array size (${maxIndex}  vs. ${numElements})`);
    }
    const list = new TensorList([], elementShape, tensor2.dtype, numElements);
    const tensors = unstack(tensor2, 0);
    indices.forEach((value, index) => {
      list.setItem(value, tensors[index]);
    });
    return list;
  }
  function split2(tensor2, length, elementShape) {
    let totalLength = 0;
    const cumulativeLengths = length.map((len) => {
      totalLength += len;
      return totalLength;
    });
    if (totalLength !== tensor2.shape[0]) {
      throw new Error(`Expected sum of lengths to be equal to
          tensor.shape[0], but sum of lengths is
        ${totalLength}, and tensor's shape is: ${tensor2.shape}`);
    }
    const shapeWithoutFirstDim = tensor2.shape.slice(1);
    const outputElementShape = mergeElementShape(shapeWithoutFirstDim, elementShape);
    const elementPerRow = totalLength === 0 ? 0 : tensor2.size / totalLength;
    const tensors = tidy(() => {
      const tensors2 = [];
      tensor2 = reshape(tensor2, [1, totalLength, elementPerRow]);
      for (let i = 0; i < length.length; ++i) {
        const previousLength = i === 0 ? 0 : cumulativeLengths[i - 1];
        const indices = [0, previousLength, 0];
        const sizes = [1, length[i], elementPerRow];
        tensors2[i] = reshape(slice(tensor2, indices, sizes), outputElementShape);
      }
      tensor2.dispose();
      return tensors2;
    });
    const list = new TensorList([], elementShape, tensor2.dtype, length.length);
    for (let i = 0; i < tensors.length; i++) {
      list.setItem(i, tensors[i]);
    }
    return list;
  }
  var TensorList;
  var init_tensor_list = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_list.js"() {
      init_dist();
      init_tensor_utils();
      TensorList = class {
        /**
         *
         * @param tensors list of tensors
         * @param elementShape shape of each tensor, this can be a single number (any
         * shape is allowed) or partial shape (dim = -1).
         * @param elementDtype data type of each tensor
         * @param maxNumElements The maximum allowed size of `tensors`. Defaults to -1
         *   meaning that the size of `tensors` is unbounded.
         */
        constructor(tensors, elementShape, elementDtype, maxNumElements = -1) {
          this.tensors = tensors;
          this.elementShape = elementShape;
          this.elementDtype = elementDtype;
          if (tensors != null) {
            tensors.forEach((tensor2) => {
              if (elementDtype !== tensor2.dtype) {
                throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${tensor2.dtype}`);
              }
              assertShapesMatchAllowUndefinedSize(elementShape, tensor2.shape, "TensorList shape mismatch: ");
              keep(tensor2);
            });
          }
          this.idTensor = scalar(0);
          this.maxNumElements = maxNumElements;
          keep(this.idTensor);
        }
        get id() {
          return this.idTensor.id;
        }
        /**
         * Get a new TensorList containing a copy of the underlying tensor container.
         */
        copy() {
          return new TensorList([...this.tensors], this.elementShape, this.elementDtype);
        }
        /**
         * Dispose the tensors and idTensor and clear the tensor list.
         */
        clearAndClose(keepIds) {
          this.tensors.forEach((tensor2) => {
            if (keepIds == null || !keepIds.has(tensor2.id)) {
              tensor2.dispose();
            }
          });
          this.tensors.length = 0;
          this.idTensor.dispose();
        }
        /**
         * The size of the tensors in the tensor list.
         */
        size() {
          return this.tensors.length;
        }
        /**
         * Return a tensor that stacks a list of rank-R tf.Tensors into one rank-(R+1)
         * tf.Tensor.
         * @param elementShape shape of each tensor
         * @param elementDtype data type of each tensor
         * @param numElements the number of elements to stack
         */
        stack(elementShape, elementDtype, numElements = -1) {
          if (elementDtype !== this.elementDtype) {
            throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);
          }
          if (numElements !== -1 && this.tensors.length !== numElements) {
            throw new Error(`Operation expected a list with ${numElements} elements but got a list with ${this.tensors.length} elements.`);
          }
          assertShapesMatchAllowUndefinedSize(elementShape, this.elementShape, "TensorList shape mismatch: ");
          const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          return tidy(() => {
            const reshapedTensors = this.tensors.map((tensor2) => reshape(tensor2, outputElementShape));
            return stack(reshapedTensors, 0);
          });
        }
        /**
         * Pop a tensor from the end of the list.
         * @param elementShape shape of the tensor
         * @param elementDtype data type of the tensor
         */
        popBack(elementShape, elementDtype) {
          if (elementDtype !== this.elementDtype) {
            throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);
          }
          if (this.size() === 0) {
            throw new Error("Trying to pop from an empty list.");
          }
          const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          const tensor2 = this.tensors.pop();
          tensor2.kept = false;
          assertShapesMatchAllowUndefinedSize(tensor2.shape, elementShape, "TensorList shape mismatch: ");
          return reshape(tensor2, outputElementShape);
        }
        /**
         * Push a tensor to the end of the list.
         * @param tensor Tensor to be pushed.
         */
        pushBack(tensor2) {
          if (tensor2.dtype !== this.elementDtype) {
            throw new Error(`Invalid data types; op elements ${tensor2.dtype}, but list elements ${this.elementDtype}`);
          }
          assertShapesMatchAllowUndefinedSize(tensor2.shape, this.elementShape, "TensorList shape mismatch: ");
          if (this.maxNumElements === this.size()) {
            throw new Error(`Trying to push element into a full list.`);
          }
          keep(tensor2);
          this.tensors.push(tensor2);
        }
        /**
         * Update the size of the list.
         * @param size the new size of the list.
         */
        resize(size) {
          if (size < 0) {
            throw new Error(`TensorListResize expects size to be non-negative. Got: ${size}`);
          }
          if (this.maxNumElements !== -1 && size > this.maxNumElements) {
            throw new Error(`TensorListResize input size ${size} is greater maxNumElement ${this.maxNumElements}.`);
          }
          const destTensorList = new TensorList([], this.elementShape, this.elementDtype, this.maxNumElements);
          destTensorList.tensors.length = size;
          for (let i = 0; i < Math.min(this.tensors.length, size); ++i) {
            destTensorList.tensors[i] = this.tensors[i];
          }
          return destTensorList;
        }
        /**
         * Retrieve the element at the provided index
         * @param elementShape shape of the tensor
         * @param elementDtype dtype of the tensor
         * @param elementIndex index of the tensor
         */
        getItem(elementIndex, elementShape, elementDtype) {
          if (elementDtype !== this.elementDtype) {
            throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);
          }
          if (elementIndex < 0 || elementIndex > this.tensors.length) {
            throw new Error(`Trying to access element ${elementIndex} in a list with ${this.tensors.length} elements.`);
          }
          if (this.tensors[elementIndex] == null) {
            throw new Error(`element at index ${elementIndex} is null.`);
          }
          assertShapesMatchAllowUndefinedSize(this.tensors[elementIndex].shape, elementShape, "TensorList shape mismatch: ");
          const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          return reshape(this.tensors[elementIndex], outputElementShape);
        }
        /**
         * Set the tensor at the index
         * @param elementIndex index of the tensor
         * @param tensor the tensor to be inserted into the list
         */
        setItem(elementIndex, tensor2) {
          if (tensor2.dtype !== this.elementDtype) {
            throw new Error(`Invalid data types; op elements ${tensor2.dtype}, but list elements ${this.elementDtype}`);
          }
          if (elementIndex < 0 || this.maxNumElements !== -1 && elementIndex >= this.maxNumElements) {
            throw new Error(`Trying to set element ${elementIndex} in a list with max ${this.maxNumElements} elements.`);
          }
          assertShapesMatchAllowUndefinedSize(this.elementShape, tensor2.shape, "TensorList shape mismatch: ");
          keep(tensor2);
          if (this.tensors[elementIndex] != null) {
            this.tensors[elementIndex].kept = false;
          }
          this.tensors[elementIndex] = tensor2;
        }
        /**
         * Return selected values in the TensorList as a stacked Tensor. All of
         * selected values must have been written and their shapes must all match.
         * @param indices indices of tensors to gather
         * @param elementDtype output tensor dtype
         * @param elementShape output tensor element shape
         */
        gather(indices, elementDtype, elementShape) {
          if (elementDtype !== this.elementDtype) {
            throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);
          }
          assertShapesMatchAllowUndefinedSize(this.elementShape, elementShape, "TensorList shape mismatch: ");
          indices = indices.slice(0, this.size());
          const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          if (indices.length === 0) {
            return tensor([], [0].concat(outputElementShape));
          }
          return tidy(() => {
            const tensors = indices.map((i) => reshape(this.tensors[i], outputElementShape));
            return stack(tensors, 0);
          });
        }
        /**
         * Return the values in the TensorList as a concatenated Tensor.
         * @param elementDtype output tensor dtype
         * @param elementShape output tensor element shape
         */
        concat(elementDtype, elementShape) {
          if (!!elementDtype && elementDtype !== this.elementDtype) {
            throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${elementDtype}`);
          }
          assertShapesMatchAllowUndefinedSize(this.elementShape, elementShape, "TensorList shape mismatch: ");
          const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          if (this.size() === 0) {
            return tensor([], [0].concat(outputElementShape));
          }
          return tidy(() => {
            const tensors = this.tensors.map((t2) => reshape(t2, outputElementShape));
            return concat(tensors, 0);
          });
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/control_executor.js
  var executeOp3;
  var init_control_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/control_executor.js"() {
      init_dist();
      init_tensor_array();
      init_tensor_list();
      init_utils();
      executeOp3 = (node, tensorMap, context) => __async(void 0, null, function* () {
        switch (node.op) {
          case "If":
          case "StatelessIf": {
            const thenFunc = getParamValue("thenBranch", node, tensorMap, context);
            const elseFunc = getParamValue("elseBranch", node, tensorMap, context);
            const cond = getParamValue("cond", node, tensorMap, context);
            const args = getParamValue("args", node, tensorMap, context);
            const condValue = yield cond.data();
            if (condValue[0]) {
              return context.functionMap[thenFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap);
            } else {
              return context.functionMap[elseFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap);
            }
          }
          case "While":
          case "StatelessWhile": {
            const bodyFunc = getParamValue("body", node, tensorMap, context);
            const condFunc = getParamValue("cond", node, tensorMap, context);
            const args = getParamValue("args", node, tensorMap, context);
            const condResult = yield context.functionMap[condFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap);
            const argIds = args.map((tensor2) => tensor2.id);
            let condValue = yield condResult[0].data();
            condResult.forEach((tensor2) => {
              if (!tensor2.kept && argIds.indexOf(tensor2.id) === -1) {
                tensor2.dispose();
              }
            });
            let result = args;
            while (condValue[0]) {
              const origResult = result;
              result = yield context.functionMap[bodyFunc].executeFunctionAsync(result, context.tensorArrayMap, context.tensorListMap);
              const resultIds = result.map((tensor2) => tensor2.id);
              origResult.forEach((tensor2) => {
                if (!tensor2.kept && argIds.indexOf(tensor2.id) === -1 && resultIds.indexOf(tensor2.id) === -1) {
                  tensor2.dispose();
                }
              });
              const condResult2 = yield context.functionMap[condFunc].executeFunctionAsync(result, context.tensorArrayMap, context.tensorListMap);
              condValue = yield condResult2[0].data();
              condResult2.forEach((tensor2) => {
                if (!tensor2.kept && argIds.indexOf(tensor2.id) === -1 && resultIds.indexOf(tensor2.id) === -1) {
                  tensor2.dispose();
                }
              });
            }
            return result;
          }
          case "LoopCond": {
            const pred = getParamValue("pred", node, tensorMap, context);
            return [cloneTensor(pred)];
          }
          case "Switch": {
            const pred = getParamValue("pred", node, tensorMap, context);
            let data = getParamValue("data", node, tensorMap, context);
            if (!data.kept) {
              data = cloneTensor(data);
            }
            return (yield pred.data())[0] ? [void 0, data] : [data, void 0];
          }
          case "Merge": {
            const inputName = node.inputNames.find((name) => getTensor(name, tensorMap, context) !== void 0);
            if (inputName) {
              const data = getTensor(inputName, tensorMap, context);
              return [cloneTensor(data)];
            }
            return void 0;
          }
          case "Enter": {
            const frameId = getParamValue("frameName", node, tensorMap, context);
            const data = getParamValue("tensor", node, tensorMap, context);
            context.enterFrame(frameId);
            return [cloneTensor(data)];
          }
          case "Exit": {
            const data = getParamValue("tensor", node, tensorMap, context);
            context.exitFrame();
            return [cloneTensor(data)];
          }
          case "NextIteration": {
            const data = getParamValue("tensor", node, tensorMap, context);
            context.nextIteration();
            return [cloneTensor(data)];
          }
          case "TensorArrayV3": {
            const size = getParamValue("size", node, tensorMap, context);
            const dtype = getParamValue("dtype", node, tensorMap, context);
            const elementShape = getParamValue("elementShape", node, tensorMap, context);
            const dynamicSize = getParamValue("dynamicSize", node, tensorMap, context);
            const clearAfterRead = getParamValue("clearAfterRead", node, tensorMap, context);
            const identicalElementShapes = getParamValue("identicalElementShapes", node, tensorMap, context);
            const name = getParamValue("name", node, tensorMap, context);
            const tensorArray = new TensorArray(name, dtype, size, elementShape, identicalElementShapes, dynamicSize, clearAfterRead);
            context.addTensorArray(tensorArray);
            return [tensorArray.idTensor, scalar(1)];
          }
          case "TensorArrayWriteV3": {
            const id = getParamValue("tensorArrayId", node, tensorMap, context);
            const index = getParamValue("index", node, tensorMap, context);
            const writeTensor = getParamValue("tensor", node, tensorMap, context);
            const writeTensorArray = context.getTensorArray(id.id);
            writeTensorArray.write(index, writeTensor);
            return [writeTensorArray.idTensor];
          }
          case "TensorArrayReadV3": {
            const readId = getParamValue("tensorArrayId", node, tensorMap, context);
            const readIndex = getParamValue("index", node, tensorMap, context);
            const readTensorArray = context.getTensorArray(readId.id);
            return [readTensorArray.read(readIndex)];
          }
          case "TensorArrayGatherV3": {
            const gatherId = getParamValue("tensorArrayId", node, tensorMap, context);
            const gatherIndices = getParamValue("indices", node, tensorMap, context);
            const gatherDtype = getParamValue("dtype", node, tensorMap, context);
            const gatherTensorArray = context.getTensorArray(gatherId.id);
            return [gatherTensorArray.gather(gatherIndices, gatherDtype)];
          }
          case "TensorArrayScatterV3": {
            const scatterId = getParamValue("tensorArrayId", node, tensorMap, context);
            const scatterIndices = getParamValue("indices", node, tensorMap, context);
            const scatterTensor = getParamValue("tensor", node, tensorMap, context);
            const scatterTensorArray = context.getTensorArray(scatterId.id);
            scatterTensorArray.scatter(scatterIndices, scatterTensor);
            return [scatterTensorArray.idTensor];
          }
          case "TensorArrayConcatV3": {
            const concatId = getParamValue("tensorArrayId", node, tensorMap, context);
            const concatTensorArray = context.getTensorArray(concatId.id);
            const concatDtype = getParamValue("dtype", node, tensorMap, context);
            return [concatTensorArray.concat(concatDtype)];
          }
          case "TensorArraySplitV3": {
            const splitId = getParamValue("tensorArrayId", node, tensorMap, context);
            const splitTensor = getParamValue("tensor", node, tensorMap, context);
            const lengths = getParamValue("lengths", node, tensorMap, context);
            const splitTensorArray = context.getTensorArray(splitId.id);
            splitTensorArray.split(lengths, splitTensor);
            return [splitTensorArray.idTensor];
          }
          case "TensorArraySizeV3": {
            const sizeId = getParamValue("tensorArrayId", node, tensorMap, context);
            const sizeTensorArray = context.getTensorArray(sizeId.id);
            return [scalar(sizeTensorArray.size(), "int32")];
          }
          case "TensorArrayCloseV3": {
            const closeId = getParamValue("tensorArrayId", node, tensorMap, context);
            const closeTensorArray = context.getTensorArray(closeId.id);
            closeTensorArray.clearAndClose();
            return [closeTensorArray.idTensor];
          }
          case "TensorListSetItem": {
            const idTensor = getParamValue("tensorListId", node, tensorMap, context);
            const index = getParamValue("index", node, tensorMap, context);
            const writeTensor = getParamValue("tensor", node, tensorMap, context);
            const tensorList = context.getTensorList(idTensor.id);
            tensorList.setItem(index, writeTensor);
            return [tensorList.idTensor];
          }
          case "TensorListGetItem": {
            const idTensor = getParamValue("tensorListId", node, tensorMap, context);
            const readIndex = getParamValue("index", node, tensorMap, context);
            const elementShape = getParamValue("elementShape", node, tensorMap, context);
            const elementDType = getParamValue("elementDType", node, tensorMap, context);
            const tensorList = context.getTensorList(idTensor.id);
            return [tensorList.getItem(readIndex, elementShape, elementDType)];
          }
          case "TensorListScatterV2":
          case "TensorListScatter": {
            const scatterIndices = getParamValue("indices", node, tensorMap, context);
            const scatterTensor = getParamValue("tensor", node, tensorMap, context);
            const elementShape = getParamValue("elementShape", node, tensorMap, context);
            const numElements = getParamValue("numElements", node, tensorMap, context);
            const tensorList = scatter(scatterTensor, scatterIndices, elementShape, numElements);
            context.addTensorList(tensorList);
            return [tensorList.idTensor];
          }
          case "TensorListReserve":
          case "EmptyTensorList": {
            const elementShape = getParamValue("elementShape", node, tensorMap, context);
            const elementDtype = getParamValue("elementDType", node, tensorMap, context);
            let numElementsParam;
            if (node.op === "TensorListReserve") {
              numElementsParam = "numElements";
            } else {
              numElementsParam = "maxNumElements";
            }
            const numElements = getParamValue(numElementsParam, node, tensorMap, context);
            const maxNumElements = node.op === "TensorListReserve" ? -1 : numElements;
            const tensorList = reserve(elementShape, elementDtype, numElements, maxNumElements);
            context.addTensorList(tensorList);
            return [tensorList.idTensor];
          }
          case "TensorListGather": {
            const gatherId = getParamValue("tensorListId", node, tensorMap, context);
            const gatherIndices = getParamValue("indices", node, tensorMap, context);
            const elementShape = getParamValue("elementShape", node, tensorMap, context);
            const elementDtype = getParamValue("elementDType", node, tensorMap, context);
            const tensorList = context.getTensorList(gatherId.id);
            return [tensorList.gather(gatherIndices, elementDtype, elementShape)];
          }
          case "TensorListStack": {
            const idTensor = getParamValue("tensorListId", node, tensorMap, context);
            const elementShape = getParamValue("elementShape", node, tensorMap, context);
            const elementDtype = getParamValue("elementDType", node, tensorMap, context);
            const numElements = getParamValue("numElements", node, tensorMap, context);
            const tensorList = context.getTensorList(idTensor.id);
            return [tensorList.stack(elementShape, elementDtype, numElements)];
          }
          case "TensorListFromTensor": {
            const tensor2 = getParamValue("tensor", node, tensorMap, context);
            const elementShape = getParamValue("elementShape", node, tensorMap, context);
            const elementDtype = getParamValue("elementDType", node, tensorMap, context);
            const tensorList = fromTensor(tensor2, elementShape, elementDtype);
            context.addTensorList(tensorList);
            return [tensorList.idTensor];
          }
          case "TensorListConcat":
          case "TensorListConcatV2": {
            const concatId = getParamValue("tensorListId", node, tensorMap, context);
            const tensorList = context.getTensorList(concatId.id);
            const concatDtype = getParamValue("dtype", node, tensorMap, context);
            const elementShape = getParamValue("elementShape", node, tensorMap, context);
            return [tensorList.concat(concatDtype, elementShape)];
          }
          case "TensorListPushBack": {
            const idTensor = getParamValue("tensorListId", node, tensorMap, context);
            const writeTensor = getParamValue("tensor", node, tensorMap, context);
            const tensorList = context.getTensorList(idTensor.id);
            tensorList.pushBack(writeTensor);
            return [tensorList.idTensor];
          }
          case "TensorListPopBack": {
            const idTensor = getParamValue("tensorListId", node, tensorMap, context);
            const elementShape = getParamValue("elementShape", node, tensorMap, context);
            const elementDType = getParamValue("elementDType", node, tensorMap, context);
            const tensorList = context.getTensorList(idTensor.id);
            return [tensorList.popBack(elementShape, elementDType)];
          }
          case "TensorListSplit": {
            const splitTensor = getParamValue("tensor", node, tensorMap, context);
            const elementShape = getParamValue("elementShape", node, tensorMap, context);
            const lengths = getParamValue("lengths", node, tensorMap, context);
            const tensorList = split2(splitTensor, lengths, elementShape);
            context.addTensorList(tensorList);
            return [tensorList.idTensor];
          }
          case "TensorListLength": {
            const idTensor = getParamValue("tensorListId", node, tensorMap, context);
            const tensorList = context.getTensorList(idTensor.id);
            return [scalar(tensorList.size(), "int32")];
          }
          case "TensorListResize": {
            const idTensor = getParamValue("tensorListId", node, tensorMap, context);
            const size = getParamValue("size", node, tensorMap, context);
            const srcTensorList = context.getTensorList(idTensor.id);
            const destTensorList = srcTensorList.resize(size);
            context.addTensorList(destTensorList);
            return [destTensorList.idTensor];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      });
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/convolution_executor.js
  function fusedConvAndDepthWiseParams(node, tensorMap, context) {
    const [extraOp, activationFunc] = getParamValue("fusedOps", node, tensorMap, context);
    const isBiasAdd = extraOp === "biasadd";
    const noBiasAdd = !isBiasAdd;
    const isPrelu = activationFunc === "prelu";
    const isBatchNorm = extraOp === "fusedbatchnorm";
    const numArgs = getParamValue("numArgs", node, tensorMap, context);
    if (isBiasAdd) {
      if (isPrelu && numArgs !== 2) {
        throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
      }
      if (!isPrelu && isBiasAdd && numArgs !== 1) {
        throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.");
      }
    }
    if (isBatchNorm) {
      throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported");
    }
    const stride = getParamValue("strides", node, tensorMap, context);
    const pad2 = getPadding(node, tensorMap, context);
    const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
    const dilations = getParamValue("dilations", node, tensorMap, context);
    let [biasArg, preluArg] = getParamValue("args", node, tensorMap, context);
    if (noBiasAdd) {
      preluArg = biasArg;
      biasArg = void 0;
    }
    const leakyreluAlpha = getParamValue("leakyreluAlpha", node, tensorMap, context);
    return {
      stride,
      pad: pad2,
      dataFormat,
      dilations,
      biasArg,
      preluArg,
      activationFunc,
      leakyreluAlpha
    };
  }
  var executeOp4;
  var init_convolution_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/convolution_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp4 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "Conv1D": {
            const stride = getParamValue("stride", node, tensorMap, context);
            const pad2 = getParamValue("pad", node, tensorMap, context);
            const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
            const dilation = getParamValue("dilation", node, tensorMap, context);
            return [ops.conv1d(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), stride, pad2, dataFormat, dilation)];
          }
          case "Conv2D": {
            const stride = getParamValue("strides", node, tensorMap, context);
            const pad2 = getPadding(node, tensorMap, context);
            const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
            const dilations = getParamValue("dilations", node, tensorMap, context);
            return [ops.conv2d(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2]], pad2, dataFormat, [dilations[1], dilations[2]])];
          }
          case "_FusedConv2D": {
            const { stride, pad: pad2, dataFormat, dilations, biasArg, preluArg, activationFunc, leakyreluAlpha } = fusedConvAndDepthWiseParams(node, tensorMap, context);
            return [ops.fused.conv2d({
              x: getParamValue("x", node, tensorMap, context),
              filter: getParamValue("filter", node, tensorMap, context),
              strides: [stride[1], stride[2]],
              pad: pad2,
              dataFormat,
              dilations: [dilations[1], dilations[2]],
              bias: biasArg,
              activation: activationFunc,
              preluActivationWeights: preluArg,
              leakyreluAlpha
            })];
          }
          case "FusedDepthwiseConv2dNative": {
            const { stride, pad: pad2, dataFormat, dilations, biasArg, preluArg, activationFunc, leakyreluAlpha } = fusedConvAndDepthWiseParams(node, tensorMap, context);
            return [ops.fused.depthwiseConv2d({
              x: getParamValue("x", node, tensorMap, context),
              filter: getParamValue("filter", node, tensorMap, context),
              strides: [stride[1], stride[2]],
              pad: pad2,
              dataFormat,
              dilations: [dilations[1], dilations[2]],
              bias: biasArg,
              activation: activationFunc,
              preluActivationWeights: preluArg,
              leakyreluAlpha
            })];
          }
          case "Conv2DBackpropInput":
          case "Conv2dTranspose": {
            const shape = getParamValue("outputShape", node, tensorMap, context);
            const stride = getParamValue("strides", node, tensorMap, context);
            const pad2 = getPadding(node, tensorMap, context);
            return [ops.conv2dTranspose(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), shape, [stride[1], stride[2]], pad2)];
          }
          case "DepthwiseConv2dNative":
          case "DepthwiseConv2d": {
            const stride = getParamValue("strides", node, tensorMap, context);
            const pad2 = getPadding(node, tensorMap, context);
            const dilations = getParamValue("dilations", node, tensorMap, context);
            const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
            return [ops.depthwiseConv2d(getParamValue("input", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2]], pad2, dataFormat, [dilations[1], dilations[2]])];
          }
          case "Conv3D": {
            const stride = getParamValue("strides", node, tensorMap, context);
            const pad2 = getParamValue("pad", node, tensorMap, context);
            const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
            const dilations = getParamValue("dilations", node, tensorMap, context);
            return [ops.conv3d(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2], stride[3]], pad2, dataFormat, [dilations[1], dilations[2], dilations[3]])];
          }
          case "AvgPool": {
            const stride = getParamValue("strides", node, tensorMap, context);
            const pad2 = getParamValue("pad", node, tensorMap, context);
            const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
            return [ops.avgPool(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad2)];
          }
          case "MaxPool": {
            const stride = getParamValue("strides", node, tensorMap, context);
            const pad2 = getParamValue("pad", node, tensorMap, context);
            const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
            return [ops.maxPool(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad2)];
          }
          case "MaxPoolWithArgmax": {
            const stride = getParamValue("strides", node, tensorMap, context);
            const pad2 = getParamValue("pad", node, tensorMap, context);
            const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
            const includeBatchInIndex = getParamValue("includeBatchInIndex", node, tensorMap, context);
            const { result, indexes } = ops.maxPoolWithArgmax(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad2, includeBatchInIndex);
            return [result, indexes];
          }
          case "AvgPool3D": {
            const stride = getParamValue("strides", node, tensorMap, context);
            const pad2 = getParamValue("pad", node, tensorMap, context);
            const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
            return [ops.avgPool3d(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2], kernelSize[3]], [stride[1], stride[2], stride[3]], pad2)];
          }
          case "MaxPool3D": {
            const stride = getParamValue("strides", node, tensorMap, context);
            const pad2 = getParamValue("pad", node, tensorMap, context);
            const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
            return [ops.maxPool3d(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2], kernelSize[3]], [stride[1], stride[2], stride[3]], pad2)];
          }
          case "Dilation2D": {
            const strides = getParamValue("strides", node, tensorMap, context);
            const pad2 = getParamValue("pad", node, tensorMap, context);
            const dilations = getParamValue("dilations", node, tensorMap, context);
            const strideHeight = strides[1];
            const strideWidth = strides[2];
            const dilationHeight = dilations[1];
            const dilationWidth = dilations[2];
            return [ops.dilation2d(
              getParamValue("x", node, tensorMap, context),
              getParamValue("filter", node, tensorMap, context),
              [strideHeight, strideWidth],
              pad2,
              [dilationHeight, dilationWidth],
              "NHWC"
              /* dataFormat */
            )];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/creation_executor.js
  var executeOp5;
  var init_creation_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/creation_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp5 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "Fill": {
            const shape = getParamValue("shape", node, tensorMap, context);
            const dtype = getParamValue("dtype", node, tensorMap, context);
            const value = getParamValue("value", node, tensorMap, context);
            return [ops.fill(shape, value, dtype)];
          }
          case "LinSpace": {
            const start = getParamValue("start", node, tensorMap, context);
            const stop = getParamValue("stop", node, tensorMap, context);
            const num = getParamValue("num", node, tensorMap, context);
            return [ops.linspace(start, stop, num)];
          }
          case "Multinomial": {
            const logits = getParamValue("logits", node, tensorMap, context);
            const numSamples = getParamValue("numSamples", node, tensorMap, context);
            const seed = getParamValue("seed", node, tensorMap, context);
            return [ops.multinomial(logits, numSamples, seed)];
          }
          case "OneHot": {
            const indices = getParamValue("indices", node, tensorMap, context);
            const depth = getParamValue("depth", node, tensorMap, context);
            const onValue = getParamValue("onValue", node, tensorMap, context);
            const offValue = getParamValue("offValue", node, tensorMap, context);
            const dtype = getParamValue("dtype", node, tensorMap, context);
            return [ops.oneHot(indices, depth, onValue, offValue, dtype)];
          }
          case "Ones": {
            return [ops.ones(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
          }
          case "OnesLike": {
            return [ops.onesLike(getParamValue("x", node, tensorMap, context))];
          }
          case "RandomStandardNormal": {
            return [ops.randomStandardNormal(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context), getParamValue("seed", node, tensorMap, context))];
          }
          case "RandomUniform": {
            return [ops.randomUniform(
              // tslint:disable-next-line:no-any
              getParamValue("shape", node, tensorMap, context),
              getParamValue("minval", node, tensorMap, context),
              getParamValue("maxval", node, tensorMap, context),
              getParamValue("dtype", node, tensorMap, context)
            )];
          }
          case "Range": {
            const start = getParamValue("start", node, tensorMap, context);
            const stop = getParamValue("stop", node, tensorMap, context);
            const step3 = getParamValue("step", node, tensorMap, context);
            return [ops.range(start, stop, step3, getParamValue("dtype", node, tensorMap, context))];
          }
          case "TruncatedNormal": {
            const shape = getParamValue("shape", node, tensorMap, context);
            const mean3 = getParamValue("mean", node, tensorMap, context);
            const stdDev = getParamValue("stdDev", node, tensorMap, context);
            const seed = getParamValue("seed", node, tensorMap, context);
            return [ops.truncatedNormal(shape, mean3, stdDev, getParamValue("dtype", node, tensorMap, context), seed)];
          }
          case "Zeros": {
            return [ops.zeros(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
          }
          case "ZerosLike": {
            return [ops.zerosLike(getParamValue("x", node, tensorMap, context))];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/dynamic_executor.js
  function nmsParams(node, tensorMap, context) {
    const boxes = getParamValue("boxes", node, tensorMap, context);
    const scores = getParamValue("scores", node, tensorMap, context);
    const maxOutputSize = getParamValue("maxOutputSize", node, tensorMap, context);
    const iouThreshold = getParamValue("iouThreshold", node, tensorMap, context);
    const scoreThreshold = getParamValue("scoreThreshold", node, tensorMap, context);
    const softNmsSigma = getParamValue("softNmsSigma", node, tensorMap, context);
    return {
      boxes,
      scores,
      maxOutputSize,
      iouThreshold,
      scoreThreshold,
      softNmsSigma
    };
  }
  var executeOp6;
  var init_dynamic_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/dynamic_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp6 = (_0, _1, _2, _3, ..._4) => __async(void 0, [_0, _1, _2, _3, ..._4], function* (node, tensorMap, context, resourceManager, ops = ops_for_converter_exports) {
        switch (node.op) {
          case "NonMaxSuppressionV5": {
            const { boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma } = nmsParams(node, tensorMap, context);
            const result = yield ops.image.nonMaxSuppressionWithScoreAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
            return [result.selectedIndices, result.selectedScores];
          }
          case "NonMaxSuppressionV4": {
            const { boxes, scores, maxOutputSize, iouThreshold, scoreThreshold } = nmsParams(node, tensorMap, context);
            const padToMaxOutputSize = getParamValue("padToMaxOutputSize", node, tensorMap, context);
            const result = yield ops.image.nonMaxSuppressionPaddedAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);
            return [result.selectedIndices, result.validOutputs];
          }
          case "NonMaxSuppressionV3":
          case "NonMaxSuppressionV2": {
            const { boxes, scores, maxOutputSize, iouThreshold, scoreThreshold } = nmsParams(node, tensorMap, context);
            return [yield ops.image.nonMaxSuppressionAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold)];
          }
          case "Where": {
            const condition = ops.cast(getParamValue("condition", node, tensorMap, context), "bool");
            const result = [yield ops.whereAsync(condition)];
            condition.dispose();
            return result;
          }
          case "ListDiff": {
            return ops.setdiff1dAsync(getParamValue("x", node, tensorMap, context), getParamValue("y", node, tensorMap, context));
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      });
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/evaluation_executor.js
  var executeOp7;
  var init_evaluation_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/evaluation_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp7 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "LowerBound": {
            const sortedSequence = getParamValue("sortedSequence", node, tensorMap, context);
            const values = getParamValue("values", node, tensorMap, context);
            return [ops.lowerBound(sortedSequence, values)];
          }
          case "TopKV2": {
            const x = getParamValue("x", node, tensorMap, context);
            const k3 = getParamValue("k", node, tensorMap, context);
            const sorted = getParamValue("sorted", node, tensorMap, context);
            const result = ops.topk(x, k3, sorted);
            return [result.values, result.indices];
          }
          case "UpperBound": {
            const sortedSequence = getParamValue("sortedSequence", node, tensorMap, context);
            const values = getParamValue("values", node, tensorMap, context);
            return [ops.upperBound(sortedSequence, values)];
          }
          case "Unique": {
            const x = getParamValue("x", node, tensorMap, context);
            const result = ops.unique(x);
            return [result.values, result.indices];
          }
          case "UniqueV2": {
            const x = getParamValue("x", node, tensorMap, context);
            const axis = getParamValue("axis", node, tensorMap, context);
            const result = ops.unique(x, axis);
            return [result.values, result.indices];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/graph_executor.js
  var executeOp8;
  var init_graph_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/graph_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp8 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "Const": {
            return tensorMap[node.name];
          }
          case "PlaceholderWithDefault":
            const def = getParamValue("default", node, tensorMap, context);
            return [getTensor(node.name, tensorMap, context) || def];
          case "Placeholder":
            return [getTensor(node.name, tensorMap, context)];
          case "Identity":
          case "StopGradient":
          case "FakeQuantWithMinMaxVars": {
            const data2 = getParamValue("x", node, tensorMap, context);
            return [cloneTensor(data2)];
          }
          case "IdentityN":
            return getParamValue("x", node, tensorMap, context).map((t2) => cloneTensor(t2));
          case "Snapshot":
            const snapshot = getParamValue("x", node, tensorMap, context);
            return [cloneTensor(snapshot)];
          case "Shape":
            return [ops.tensor1d(getParamValue("x", node, tensorMap, context).shape, "int32")];
          case "ShapeN":
            return getParamValue("x", node, tensorMap, context).map((t2) => ops.tensor1d(t2.shape));
          case "Size":
            return [ops.scalar(getParamValue("x", node, tensorMap, context).size, "int32")];
          case "Rank":
            return [ops.scalar(getParamValue("x", node, tensorMap, context).rank, "int32")];
          case "NoOp":
            return [ops.scalar(1)];
          case "Print":
            const input = getParamValue("x", node, tensorMap, context);
            const data = getParamValue("data", node, tensorMap, context);
            const message = getParamValue("message", node, tensorMap, context);
            const summarize = getParamValue("summarize", node, tensorMap, context);
            console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance.");
            console.log(message);
            for (let i = 0; i < data.length; i++) {
              console.log(Array.prototype.slice.call(data[i].dataSync()).slice(0, summarize));
            }
            return [input];
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/executor/hash_table.js
  var HashTable;
  var init_hash_table2 = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/executor/hash_table.js"() {
      init_dist();
      init_ops_for_converter();
      HashTable = class {
        /**
         * Constructor of HashTable. Creates a hash table.
         *
         * @param keyDType `dtype` of the table keys.
         * @param valueDType `dtype` of the table values.
         */
        constructor(keyDType, valueDType) {
          this.keyDType = keyDType;
          this.valueDType = valueDType;
          this.handle = scalar(0);
          this.tensorMap = /* @__PURE__ */ new Map();
          keep(this.handle);
        }
        get id() {
          return this.handle.id;
        }
        /**
         * Dispose the tensors and handle and clear the hashtable.
         */
        clearAndClose() {
          this.tensorMap.forEach((value) => value.dispose());
          this.tensorMap.clear();
          this.handle.dispose();
        }
        /**
         * The number of items in the hash table.
         */
        size() {
          return this.tensorMap.size;
        }
        /**
         * The number of items in the hash table as a rank-0 tensor.
         */
        tensorSize() {
          return scalar(this.size(), "int32");
        }
        /**
         * Replaces the contents of the table with the specified keys and values.
         * @param keys Keys to store in the hashtable.
         * @param values Values to store in the hashtable.
         */
        import(keys, values) {
          return __async(this, null, function* () {
            this.checkKeyAndValueTensor(keys, values);
            const $keys = yield keys.data();
            this.tensorMap.forEach((value) => value.dispose());
            this.tensorMap.clear();
            return tidy(() => {
              const $values = unstack(values);
              const keysLength = $keys.length;
              const valuesLength = $values.length;
              util_exports.assert(keysLength === valuesLength, () => `The number of elements doesn't match, keys has ${keysLength} elements, the values has ${valuesLength} elements.`);
              for (let i = 0; i < keysLength; i++) {
                const key = $keys[i];
                const value = $values[i];
                keep(value);
                this.tensorMap.set(key, value);
              }
              return this.handle;
            });
          });
        }
        /**
         * Looks up keys in a hash table, outputs the corresponding values.
         *
         * Performs batch lookups, for every element in the key tensor, `find`
         * stacks the corresponding value into the return tensor.
         *
         * If an element is not present in the table, the given `defaultValue` is
         * used.
         *
         * @param keys Keys to look up. Must have the same type as the keys of the
         *     table.
         * @param defaultValue The scalar `defaultValue` is the value output for keys
         *     not present in the table. It must also be of the same type as the
         *     table values.
         */
        find(keys, defaultValue) {
          return __async(this, null, function* () {
            this.checkKeyAndValueTensor(keys, defaultValue);
            const $keys = yield keys.data();
            return tidy(() => {
              const result = [];
              for (let i = 0; i < $keys.length; i++) {
                const key = $keys[i];
                const value = this.findWithDefault(key, defaultValue);
                result.push(value);
              }
              return stack(result);
            });
          });
        }
        // tslint:disable-next-line: no-any
        findWithDefault(key, defaultValue) {
          const result = this.tensorMap.get(key);
          return result != null ? result : defaultValue;
        }
        checkKeyAndValueTensor(key, value) {
          if (key.dtype !== this.keyDType) {
            throw new Error(`Expect key dtype ${this.keyDType}, but got ${key.dtype}`);
          }
          if (value.dtype !== this.valueDType) {
            throw new Error(`Expect value dtype ${this.valueDType}, but got ${value.dtype}`);
          }
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/hash_table_executor.js
  var executeOp9;
  var init_hash_table_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/hash_table_executor.js"() {
      init_hash_table2();
      init_utils();
      executeOp9 = (node, tensorMap, context, resourceManager) => __async(void 0, null, function* () {
        switch (node.op) {
          case "HashTable":
          case "HashTableV2": {
            const existingTableHandle = resourceManager.getHashTableHandleByName(node.name);
            if (existingTableHandle != null) {
              return [existingTableHandle];
            } else {
              const keyDType = getParamValue("keyDType", node, tensorMap, context);
              const valueDType = getParamValue("valueDType", node, tensorMap, context);
              const hashTable = new HashTable(keyDType, valueDType);
              resourceManager.addHashTable(node.name, hashTable);
              return [hashTable.handle];
            }
          }
          case "InitializeTable":
          case "InitializeTableV2":
          case "LookupTableImport":
          case "LookupTableImportV2": {
            const handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
            const keys = getParamValue("keys", node, tensorMap, context);
            const values = getParamValue("values", node, tensorMap, context);
            const hashTable = resourceManager.getHashTableById(handle.id);
            return [yield hashTable.import(keys, values)];
          }
          case "LookupTableFind":
          case "LookupTableFindV2": {
            const handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
            const keys = getParamValue("keys", node, tensorMap, context);
            const defaultValue = getParamValue("defaultValue", node, tensorMap, context);
            const hashTable = resourceManager.getHashTableById(handle.id);
            return [yield hashTable.find(keys, defaultValue)];
          }
          case "LookupTableSize":
          case "LookupTableSizeV2": {
            const handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
            const hashTable = resourceManager.getHashTableById(handle.id);
            return [hashTable.tensorSize()];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      });
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/image_executor.js
  var executeOp10;
  var init_image_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/image_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp10 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "ResizeBilinear": {
            const images = getParamValue("images", node, tensorMap, context);
            const size = getParamValue("size", node, tensorMap, context);
            const alignCorners = getParamValue("alignCorners", node, tensorMap, context);
            const halfPixelCenters = getParamValue("halfPixelCenters", node, tensorMap, context);
            return [ops.image.resizeBilinear(images, [size[0], size[1]], alignCorners, halfPixelCenters)];
          }
          case "ResizeNearestNeighbor": {
            const images = getParamValue("images", node, tensorMap, context);
            const size = getParamValue("size", node, tensorMap, context);
            const alignCorners = getParamValue("alignCorners", node, tensorMap, context);
            const halfPixelCenters = getParamValue("halfPixelCenters", node, tensorMap, context);
            return [ops.image.resizeNearestNeighbor(images, [size[0], size[1]], alignCorners, halfPixelCenters)];
          }
          case "CropAndResize": {
            const image2 = getParamValue("image", node, tensorMap, context);
            const boxes = getParamValue("boxes", node, tensorMap, context);
            const boxInd = getParamValue("boxInd", node, tensorMap, context);
            const cropSize = getParamValue("cropSize", node, tensorMap, context);
            const method = getParamValue("method", node, tensorMap, context);
            const extrapolationValue = getParamValue("extrapolationValue", node, tensorMap, context);
            return [ops.image.cropAndResize(image2, boxes, boxInd, cropSize, method, extrapolationValue)];
          }
          case "ImageProjectiveTransformV3": {
            const images = getParamValue("images", node, tensorMap, context);
            const transforms = getParamValue("transforms", node, tensorMap, context);
            const outputShape = getParamValue("outputShape", node, tensorMap, context);
            const fillValue = getParamValue("fillValue", node, tensorMap, context);
            const interpolation = getParamValue("interpolation", node, tensorMap, context);
            const fillMode = getParamValue("fillMode", node, tensorMap, context);
            return [ops.image.transform(images, transforms, interpolation.toLowerCase(), fillMode.toLowerCase(), fillValue, outputShape)];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/logical_executor.js
  var executeOp11;
  var init_logical_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/logical_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp11 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "Equal": {
            return [ops.equal(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "NotEqual": {
            return [ops.notEqual(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "Greater": {
            return [ops.greater(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "GreaterEqual": {
            return [ops.greaterEqual(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "Less": {
            return [ops.less(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "LessEqual": {
            return [ops.lessEqual(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "LogicalAnd": {
            return [ops.logicalAnd(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "LogicalNot": {
            return [ops.logicalNot(getParamValue("a", node, tensorMap, context))];
          }
          case "LogicalOr": {
            return [ops.logicalOr(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          case "Select":
          case "SelectV2": {
            return [ops.where(getParamValue("condition", node, tensorMap, context), getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/matrices_executor.js
  var executeOp12;
  var init_matrices_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/matrices_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp12 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "BatchMatMul":
          case "BatchMatMulV2":
          case "MatMul":
            return [ops.matMul(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context), getParamValue("transposeA", node, tensorMap, context), getParamValue("transposeB", node, tensorMap, context))];
          case "Einsum":
            return [ops.einsum(getParamValue("equation", node, tensorMap, context), ...getParamValue("tensors", node, tensorMap, context))];
          case "Transpose":
            return [ops.transpose(getParamValue("x", node, tensorMap, context), getParamValue("perm", node, tensorMap, context))];
          case "_FusedMatMul":
            const [extraOp, activationFunc] = getParamValue("fusedOps", node, tensorMap, context);
            const isBiasAdd = extraOp === "biasadd";
            const isPrelu = activationFunc === "prelu";
            const numArgs = getParamValue("numArgs", node, tensorMap, context);
            const leakyreluAlpha = getParamValue("leakyreluAlpha", node, tensorMap, context);
            if (isBiasAdd) {
              if (isPrelu && numArgs !== 2) {
                throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
              }
              if (!isPrelu && numArgs !== 1) {
                throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.");
              }
            }
            const [biasArg, preluArg] = getParamValue("args", node, tensorMap, context);
            return [ops.fused.matMul({
              a: getParamValue("a", node, tensorMap, context),
              b: getParamValue("b", node, tensorMap, context),
              transposeA: getParamValue("transposeA", node, tensorMap, context),
              transposeB: getParamValue("transposeB", node, tensorMap, context),
              bias: biasArg,
              activation: activationFunc,
              preluActivationWeights: preluArg,
              leakyreluAlpha
            })];
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/normalization_executor.js
  var executeOp13;
  var init_normalization_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/normalization_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp13 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "EuclideanNorm":
            return [ops.euclideanNorm(getParamValue("x", node, tensorMap, context), getParamValue("axis", node, tensorMap, context), getParamValue("keepDims", node, tensorMap, context))];
          case "FusedBatchNorm":
          case "FusedBatchNormV2": {
            return [ops.batchNorm(getParamValue("x", node, tensorMap, context), getParamValue("mean", node, tensorMap, context), getParamValue("variance", node, tensorMap, context), getParamValue("offset", node, tensorMap, context), getParamValue("scale", node, tensorMap, context), getParamValue("epsilon", node, tensorMap, context))];
          }
          case "FusedBatchNormV3": {
            return [ops.batchNorm(getParamValue("x", node, tensorMap, context), getParamValue("mean", node, tensorMap, context), getParamValue("variance", node, tensorMap, context), getParamValue("offset", node, tensorMap, context), getParamValue("scale", node, tensorMap, context), getParamValue("epsilon", node, tensorMap, context))];
          }
          case "LRN": {
            return [ops.localResponseNormalization(getParamValue("x", node, tensorMap, context), getParamValue("radius", node, tensorMap, context), getParamValue("bias", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context), getParamValue("beta", node, tensorMap, context))];
          }
          case "Softmax": {
            return [ops.softmax(getParamValue("x", node, tensorMap, context))];
          }
          case "LogSoftmax": {
            return [ops.logSoftmax(getParamValue("x", node, tensorMap, context))];
          }
          case "SparseToDense": {
            return [ops.sparseToDense(getParamValue("sparseIndices", node, tensorMap, context), getParamValue("outputShape", node, tensorMap, context), getParamValue("sparseValues", node, tensorMap, context), getParamValue("defaultValue", node, tensorMap, context))];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/ragged_executor.js
  var executeOp14;
  var init_ragged_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/ragged_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp14 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "RaggedGather": {
            const { outputNestedSplits, outputDenseValues } = ops.raggedGather(getParamValue("paramsNestedSplits", node, tensorMap, context), getParamValue("paramsDenseValues", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("outputRaggedRank", node, tensorMap, context));
            return outputNestedSplits.concat(outputDenseValues);
          }
          case "RaggedRange": {
            const { rtNestedSplits, rtDenseValues } = ops.raggedRange(getParamValue("starts", node, tensorMap, context), getParamValue("limits", node, tensorMap, context), getParamValue("splits", node, tensorMap, context));
            return [rtNestedSplits, rtDenseValues];
          }
          case "RaggedTensorToTensor": {
            return [ops.raggedTensorToTensor(getParamValue("shape", node, tensorMap, context), getParamValue("values", node, tensorMap, context), getParamValue("defaultValue", node, tensorMap, context), getParamValue("rowPartitionTensors", node, tensorMap, context), getParamValue("rowPartitionTypes", node, tensorMap, context))];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/reduction_executor.js
  var executeOp15;
  var init_reduction_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/reduction_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp15 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "Max": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const keepDims = getParamValue("keepDims", node, tensorMap, context);
            return [ops.max(getParamValue("x", node, tensorMap, context), axis, keepDims)];
          }
          case "Mean": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const keepDims = getParamValue("keepDims", node, tensorMap, context);
            return [ops.mean(getParamValue("x", node, tensorMap, context), axis, keepDims)];
          }
          case "Min": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const keepDims = getParamValue("keepDims", node, tensorMap, context);
            return [ops.min(getParamValue("x", node, tensorMap, context), axis, keepDims)];
          }
          case "Sum": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const keepDims = getParamValue("keepDims", node, tensorMap, context);
            return [ops.sum(getParamValue("x", node, tensorMap, context), axis, keepDims)];
          }
          case "All": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const keepDims = getParamValue("keepDims", node, tensorMap, context);
            return [ops.all(getParamValue("x", node, tensorMap, context), axis, keepDims)];
          }
          case "Any": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const keepDims = getParamValue("keepDims", node, tensorMap, context);
            return [ops.any(getParamValue("x", node, tensorMap, context), axis, keepDims)];
          }
          case "ArgMax": {
            const axis = getParamValue("axis", node, tensorMap, context);
            return [ops.argMax(getParamValue("x", node, tensorMap, context), axis)];
          }
          case "ArgMin": {
            const axis = getParamValue("axis", node, tensorMap, context);
            return [ops.argMin(getParamValue("x", node, tensorMap, context), axis)];
          }
          case "Prod": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const keepDims = getParamValue("keepDims", node, tensorMap, context);
            return [ops.prod(getParamValue("x", node, tensorMap, context), axis, keepDims)];
          }
          case "Cumprod": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const exclusive = getParamValue("exclusive", node, tensorMap, context);
            const reverse3 = getParamValue("reverse", node, tensorMap, context);
            return [ops.cumprod(getParamValue("x", node, tensorMap, context), axis, exclusive, reverse3)];
          }
          case "Cumsum": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const exclusive = getParamValue("exclusive", node, tensorMap, context);
            const reverse3 = getParamValue("reverse", node, tensorMap, context);
            return [ops.cumsum(getParamValue("x", node, tensorMap, context), axis, exclusive, reverse3)];
          }
          case "Bincount":
            const x = getParamValue("x", node, tensorMap, context);
            const weights = getParamValue("weights", node, tensorMap, context);
            const size = getParamValue("size", node, tensorMap, context);
            return [ops.bincount(x, weights, size)];
          case "DenseBincount": {
            const x2 = getParamValue("x", node, tensorMap, context);
            const weights2 = getParamValue("weights", node, tensorMap, context);
            const size2 = getParamValue("size", node, tensorMap, context);
            const binaryOutput = getParamValue("binaryOutput", node, tensorMap, context);
            return [ops.denseBincount(x2, weights2, size2, binaryOutput)];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/slice_join_executor.js
  var executeOp16;
  var init_slice_join_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/slice_join_executor.js"() {
      init_dist();
      init_ops_for_converter();
      init_utils();
      executeOp16 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "ConcatV2":
          case "Concat": {
            const n = getParamValue("n", node, tensorMap, context);
            const axis = getParamValue("axis", node, tensorMap, context);
            let inputs = getParamValue("tensors", node, tensorMap, context);
            inputs = inputs.slice(0, n);
            return [ops.concat(inputs, axis)];
          }
          case "Gather": {
            const input = getParamValue("x", node, tensorMap, context);
            const indices = getParamValue("indices", node, tensorMap, context);
            return [ops.gather(input, ops.cast(indices, "int32"), 0)];
          }
          case "GatherV2": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const batchDims = getParamValue("batchDims", node, tensorMap, context);
            const input = getParamValue("x", node, tensorMap, context);
            const indices = getParamValue("indices", node, tensorMap, context);
            return [ops.gather(input, ops.cast(indices, "int32"), axis, batchDims)];
          }
          case "Reverse": {
            const dims = getParamValue("dims", node, tensorMap, context);
            const axis = [];
            for (let i = 0; i < dims.length; i++) {
              if (dims[i]) {
                axis.push(i);
              }
            }
            const input = getParamValue("x", node, tensorMap, context);
            return [ops.reverse(input, axis)];
          }
          case "ReverseV2": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const input = getParamValue("x", node, tensorMap, context);
            return [ops.reverse(input, axis)];
          }
          case "Slice": {
            const begin = getParamValue("begin", node, tensorMap, context);
            const size = getParamValue("size", node, tensorMap, context);
            return [ops.slice(getParamValue("x", node, tensorMap, context), begin, size)];
          }
          case "StridedSlice": {
            const begin = getParamValue("begin", node, tensorMap, context);
            const end = getParamValue("end", node, tensorMap, context);
            const strides = getParamValue("strides", node, tensorMap, context);
            const beginMask = getParamValue("beginMask", node, tensorMap, context);
            const endMask = getParamValue("endMask", node, tensorMap, context);
            const ellipsisMask = getParamValue("ellipsisMask", node, tensorMap, context);
            const newAxisMask = getParamValue("newAxisMask", node, tensorMap, context);
            const shrinkAxisMask = getParamValue("shrinkAxisMask", node, tensorMap, context);
            const tensor2 = getParamValue("x", node, tensorMap, context);
            return [ops.stridedSlice(tensor2, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask)];
          }
          case "Pack": {
            return tidy(() => {
              const axis = getParamValue("axis", node, tensorMap, context);
              const tensors = getParamValue("tensors", node, tensorMap, context);
              const shape = tensors[0].shape;
              const squeezedShape = ops.squeeze(tensors[0]).shape;
              const mapped = tensors.map((tensor2) => {
                const sameShape = util_exports.arraysEqual(tensor2.shape, shape);
                if (!sameShape && !util_exports.arraysEqual(ops.squeeze(tensor2).shape, squeezedShape)) {
                  throw new Error("the input tensors shape does not match");
                }
                return sameShape ? tensor2 : ops.reshape(tensor2, shape);
              });
              return [ops.stack(mapped, axis)];
            });
          }
          case "Unpack": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const tensor2 = getParamValue("tensor", node, tensorMap, context);
            return ops.unstack(tensor2, axis);
          }
          case "Tile": {
            const reps = getParamValue("reps", node, tensorMap, context);
            return [ops.tile(getParamValue("x", node, tensorMap, context), reps)];
          }
          case "Split":
          case "SplitV": {
            const axis = getParamValue("axis", node, tensorMap, context);
            const numOrSizeSplits = getParamValue("numOrSizeSplits", node, tensorMap, context);
            const tensor2 = getParamValue("x", node, tensorMap, context);
            return ops.split(tensor2, numOrSizeSplits, axis);
          }
          case "ScatterNd": {
            const indices = getParamValue("indices", node, tensorMap, context);
            const values = getParamValue("values", node, tensorMap, context);
            const shape = getParamValue("shape", node, tensorMap, context);
            return [ops.scatterND(indices, values, shape)];
          }
          case "GatherNd": {
            const x = getParamValue("x", node, tensorMap, context);
            const indices = getParamValue("indices", node, tensorMap, context);
            return [ops.gatherND(x, indices)];
          }
          case "SparseToDense": {
            const indices = getParamValue("sparseIndices", node, tensorMap, context);
            const shape = getParamValue("outputShape", node, tensorMap, context);
            const sparseValues = getParamValue("sparseValues", node, tensorMap, context);
            const defaultValue = getParamValue("defaultValue", node, tensorMap, context);
            return [ops.sparseToDense(indices, sparseValues, shape, sparseValues.dtype === defaultValue.dtype ? defaultValue : ops.cast(defaultValue, sparseValues.dtype))];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/sparse_executor.js
  var executeOp17;
  var init_sparse_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/sparse_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp17 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "SparseFillEmptyRows": {
            const { outputIndices, outputValues, emptyRowIndicator, reverseIndexMap } = ops.sparse.sparseFillEmptyRows(getParamValue("indices", node, tensorMap, context), getParamValue("values", node, tensorMap, context), getParamValue("denseShape", node, tensorMap, context), getParamValue("defaultValue", node, tensorMap, context));
            return [
              outputIndices,
              outputValues,
              emptyRowIndicator,
              reverseIndexMap
            ];
          }
          case "SparseReshape": {
            const { outputIndices, outputShape } = ops.sparse.sparseReshape(getParamValue("inputIndices", node, tensorMap, context), getParamValue("inputShape", node, tensorMap, context), getParamValue("newShape", node, tensorMap, context));
            return [outputIndices, outputShape];
          }
          case "SparseSegmentMean": {
            const outputData = ops.sparse.sparseSegmentMean(getParamValue("data", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("segmentIds", node, tensorMap, context));
            return [outputData];
          }
          case "SparseSegmentSum": {
            const outputData = ops.sparse.sparseSegmentSum(getParamValue("data", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("segmentIds", node, tensorMap, context));
            return [outputData];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/spectral_executor.js
  var executeOp18;
  var init_spectral_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/spectral_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp18 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "FFT": {
            return [ops.fft(getParamValue("x", node, tensorMap, context))];
          }
          case "IFFT": {
            return [ops.ifft(getParamValue("x", node, tensorMap, context))];
          }
          case "RFFT": {
            return [ops.rfft(getParamValue("x", node, tensorMap, context))];
          }
          case "IRFFT": {
            return [ops.irfft(getParamValue("x", node, tensorMap, context))];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/string_executor.js
  var executeOp19;
  var init_string_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/string_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp19 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "StringNGrams": {
            const { nGrams, nGramsSplits } = ops.string.stringNGrams(getParamValue("data", node, tensorMap, context), getParamValue("dataSplits", node, tensorMap, context), getParamValue("separator", node, tensorMap, context), getParamValue("nGramWidths", node, tensorMap, context), getParamValue("leftPad", node, tensorMap, context), getParamValue("rightPad", node, tensorMap, context), getParamValue("padWidth", node, tensorMap, context), getParamValue("preserveShortSequences", node, tensorMap, context));
            return [nGrams, nGramsSplits];
          }
          case "StringSplit": {
            const { indices, values, shape } = ops.string.stringSplit(getParamValue("input", node, tensorMap, context), getParamValue("delimiter", node, tensorMap, context), getParamValue("skipEmpty", node, tensorMap, context));
            return [indices, values, shape];
          }
          case "StringToHashBucketFast": {
            const output = ops.string.stringToHashBucketFast(getParamValue("input", node, tensorMap, context), getParamValue("numBuckets", node, tensorMap, context));
            return [output];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/executors/transformation_executor.js
  var executeOp20;
  var init_transformation_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/transformation_executor.js"() {
      init_ops_for_converter();
      init_utils();
      executeOp20 = (node, tensorMap, context, ops = ops_for_converter_exports) => {
        switch (node.op) {
          case "Cast": {
            return [ops.cast(getParamValue("x", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
          }
          case "ExpandDims": {
            const axis = getParamValue("axis", node, tensorMap, context);
            return [ops.expandDims(getParamValue("x", node, tensorMap, context), axis)];
          }
          case "Squeeze": {
            const axis = getParamValue("axis", node, tensorMap, context);
            return [ops.squeeze(getParamValue("x", node, tensorMap, context), axis)];
          }
          case "Reshape": {
            return [ops.reshape(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
          }
          case "MirrorPad": {
            return [ops.mirrorPad(getParamValue("x", node, tensorMap, context), getParamValue("padding", node, tensorMap, context), getParamValue("mode", node, tensorMap, context))];
          }
          case "PadV2":
          case "Pad": {
            return [ops.pad(getParamValue("x", node, tensorMap, context), getParamValue("padding", node, tensorMap, context), getParamValue("constantValue", node, tensorMap, context))];
          }
          case "SpaceToBatchND": {
            const blockShape = getParamValue("blockShape", node, tensorMap, context);
            const paddings = getParamValue("paddings", node, tensorMap, context);
            return [ops.spaceToBatchND(getParamValue("x", node, tensorMap, context), blockShape, paddings)];
          }
          case "BatchToSpaceND": {
            const blockShape = getParamValue("blockShape", node, tensorMap, context);
            const crops = getParamValue("crops", node, tensorMap, context);
            return [ops.batchToSpaceND(getParamValue("x", node, tensorMap, context), blockShape, crops)];
          }
          case "DepthToSpace": {
            const blockSize = getParamValue("blockSize", node, tensorMap, context);
            const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
            return [ops.depthToSpace(getParamValue("x", node, tensorMap, context), blockSize, dataFormat)];
          }
          case "BroadcastTo": {
            return [ops.broadcastTo(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
          }
          case "BroadcastArgs": {
            return [ops.broadcastArgs(getParamValue("s0", node, tensorMap, context), getParamValue("s1", node, tensorMap, context))];
          }
          default:
            throw TypeError(`Node type ${node.op} is not implemented`);
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/operations/operation_executor.js
  function executeOp21(node, tensorMap, context, resourceManager, tidy2 = tidy) {
    const value = ((node2, tensorMap2, context2) => {
      switch (node2.category) {
        case "arithmetic":
          return tidy2(() => executeOp(node2, tensorMap2, context2));
        case "basic_math":
          return tidy2(() => executeOp2(node2, tensorMap2, context2));
        case "control":
          return executeOp3(node2, tensorMap2, context2);
        case "convolution":
          return tidy2(() => executeOp4(node2, tensorMap2, context2));
        case "creation":
          return tidy2(() => executeOp5(node2, tensorMap2, context2));
        case "dynamic":
          return executeOp6(node2, tensorMap2, context2);
        case "evaluation":
          return tidy2(() => executeOp7(node2, tensorMap2, context2));
        case "image":
          return tidy2(() => executeOp10(node2, tensorMap2, context2));
        case "graph":
          return tidy2(() => executeOp8(node2, tensorMap2, context2));
        case "logical":
          return tidy2(() => executeOp11(node2, tensorMap2, context2));
        case "matrices":
          return tidy2(() => executeOp12(node2, tensorMap2, context2));
        case "normalization":
          return tidy2(() => executeOp13(node2, tensorMap2, context2));
        case "ragged":
          return tidy2(() => executeOp14(node2, tensorMap2, context2));
        case "reduction":
          return tidy2(() => executeOp15(node2, tensorMap2, context2));
        case "slice_join":
          return tidy2(() => executeOp16(node2, tensorMap2, context2));
        case "sparse":
          return tidy2(() => executeOp17(node2, tensorMap2, context2));
        case "spectral":
          return tidy2(() => executeOp18(node2, tensorMap2, context2));
        case "string":
          return tidy2(() => executeOp19(node2, tensorMap2, context2));
        case "transformation":
          return tidy2(() => executeOp20(node2, tensorMap2, context2));
        case "hash_table":
          return executeOp9(node2, tensorMap2, context2, resourceManager);
        case "custom":
          const opMapper = getRegisteredOp(node2.op);
          if (opMapper && opMapper.customExecutor) {
            return opMapper.customExecutor(new NodeValueImpl(node2, tensorMap2, context2));
          } else {
            throw TypeError(`Custom op ${node2.op} is not registered.`);
          }
        default:
          throw TypeError(`Unknown op '${node2.op}'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()`);
      }
    })(node, tensorMap, context);
    if (util_exports.isPromise(value)) {
      return value.then((data) => [].concat(data));
    }
    return [].concat(value);
  }
  var init_operation_executor = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/operations/operation_executor.js"() {
      init_dist();
      init_node_value_impl();
      init_register();
      init_arithmetic_executor();
      init_basic_math_executor();
      init_control_executor();
      init_convolution_executor();
      init_creation_executor();
      init_dynamic_executor();
      init_evaluation_executor();
      init_graph_executor();
      init_hash_table_executor();
      init_image_executor();
      init_logical_executor();
      init_matrices_executor();
      init_normalization_executor();
      init_ragged_executor();
      init_reduction_executor();
      init_slice_join_executor();
      init_sparse_executor();
      init_spectral_executor();
      init_string_executor();
      init_transformation_executor();
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/executor/execution_context.js
  var ExecutionContext;
  var init_execution_context = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/executor/execution_context.js"() {
      ExecutionContext = class {
        constructor(weightMap = {}, tensorArrayMap = {}, tensorListMap = {}, functionMap = {}) {
          this.weightMap = weightMap;
          this.tensorArrayMap = tensorArrayMap;
          this.tensorListMap = tensorListMap;
          this.functionMap = functionMap;
          this.rootContext = { id: 0, frameName: "", iterationId: 0 };
          this.contexts = [this.rootContext];
          this.lastId = 0;
          this.generateCurrentContextIds();
        }
        newFrame(id, frameName) {
          return { id, frameName, iterationId: 0 };
        }
        /**
         * Set the current context
         * @param contexts: ExecutionContextInfo[] the current path of execution
         * frames
         */
        set currentContext(contexts) {
          if (this.contexts !== contexts) {
            this.contexts = contexts;
            this.generateCurrentContextIds();
          }
        }
        get currentContext() {
          return this.contexts;
        }
        /**
         * Returns the current context in string format.
         */
        get currentContextId() {
          return this._currentContextIds[0];
        }
        /**
         * Returns the current context and all parent contexts in string format.
         * This allow access to the nodes in the current and parent frames.
         */
        get currentContextIds() {
          return this._currentContextIds;
        }
        generateCurrentContextIds() {
          const names = [];
          for (let i = 0; i < this.contexts.length - 1; i++) {
            const contexts = this.contexts.slice(0, this.contexts.length - i);
            names.push(this.contextIdforContexts(contexts));
          }
          names.push("");
          this._currentContextIds = names;
        }
        contextIdforContexts(contexts) {
          return contexts ? contexts.map((context) => context.id === 0 && context.iterationId === 0 ? "" : `${context.frameName}-${context.iterationId}`).join("/") : "";
        }
        /**
         * Enter a new frame, a new context is pushed on the current context list.
         * @param frameId new frame id
         */
        enterFrame(frameId) {
          if (this.contexts) {
            this.lastId++;
            this.contexts = this.contexts.slice();
            this.contexts.push(this.newFrame(this.lastId, frameId));
            this._currentContextIds.unshift(this.contextIdforContexts(this.contexts));
          }
        }
        /**
         * Exit the current frame, the last context is removed from the current
         * context list.
         */
        exitFrame() {
          if (this.contexts && this.contexts.length > 1) {
            this.contexts = this.contexts.slice();
            this.contexts.splice(-1);
            this.currentContextIds.shift();
          } else {
            throw new Error("Cannot exit frame, the context is empty");
          }
        }
        /**
         * Enter the next iteration of a loop, the iteration id of last context is
         * increased.
         */
        nextIteration() {
          if (this.contexts && this.contexts.length > 0) {
            this.contexts = this.contexts.slice();
            this.lastId++;
            const context = Object.assign({}, this.contexts[this.contexts.length - 1]);
            context.iterationId += 1;
            context.id = this.lastId;
            this.contexts.splice(-1, 1, context);
            this._currentContextIds.splice(0, 1, this.contextIdforContexts(this.contexts));
          } else {
            throw new Error("Cannot increase frame iteration, the context is empty");
          }
        }
        getWeight(name) {
          return this.weightMap[name];
        }
        addTensorArray(tensorArray) {
          this.tensorArrayMap[tensorArray.id] = tensorArray;
        }
        getTensorArray(id) {
          return this.tensorArrayMap[id];
        }
        addTensorList(tensorList) {
          this.tensorListMap[tensorList.id] = tensorList;
        }
        getTensorList(id) {
          return this.tensorListMap[id];
        }
        dispose(keepIds) {
          for (const key in this.tensorArrayMap) {
            this.tensorArrayMap[key].clearAndClose(keepIds);
          }
          for (const key in this.tensorListMap) {
            this.tensorListMap[key].clearAndClose(keepIds);
          }
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/executor/model_analysis.js
  function getExecutionSubgraph(inputs, outputs, weightMap, initNodes) {
    const usedNodes = /* @__PURE__ */ new Set();
    const missingInputs = [];
    let dynamicNode = null;
    let syncInputs = null;
    const seen = /* @__PURE__ */ new Set();
    const inputNodeNames = Object.keys(inputs).map((name) => parseNodeName(name)[0]);
    let initNodeNames = [];
    if (initNodes != null) {
      initNodeNames = initNodes.map((node) => parseNodeName(node.name)[0]);
    }
    const frontier = [...outputs];
    while (frontier.length > 0) {
      const node = frontier.pop();
      if (isControlFlow(node) || isDynamicShape(node) || isHashTable(node)) {
        if (dynamicNode == null) {
          dynamicNode = node;
          syncInputs = dynamicNode.children.map((child) => child.name).filter((name) => usedNodes.has(name));
        }
      }
      usedNodes.add(node.name);
      if (weightMap[node.name] != null) {
        continue;
      }
      if (inputNodeNames.indexOf(node.name) !== -1) {
        continue;
      }
      if (initNodeNames.indexOf(node.name) !== -1) {
        continue;
      }
      if (node.inputs.length === 0) {
        missingInputs.push(node.name);
        continue;
      }
      node.inputs.forEach((input) => {
        if (seen.has(input.name)) {
          return;
        }
        seen.add(input.name);
        frontier.push(input);
      });
    }
    return { inputs, outputs, usedNodes, missingInputs, dynamicNode, syncInputs };
  }
  function getNodesInTopologicalOrder(graph, weightMap, executionInfo) {
    const { usedNodes, inputs } = executionInfo;
    const frontier = [];
    const inputNodes = Object.keys(inputs).map((name) => parseNodeName(name)[0]).map((name) => graph.nodes[name]);
    const initNodes = graph.initNodes;
    inputNodes.forEach((input) => {
      if (usedNodes.has(input.name)) {
        frontier.push(input);
      }
    });
    graph.weights.forEach((weight) => {
      if (usedNodes.has(weight.name)) {
        frontier.push(weight);
      }
    });
    if (initNodes != null) {
      initNodes.forEach((node) => {
        if (usedNodes.has(node.name)) {
          frontier.push(node);
        }
      });
    }
    const seen = /* @__PURE__ */ new Set();
    const orderedNodes = [];
    while (frontier.length > 0) {
      const node = frontier.pop();
      seen.add(node.name);
      if (!weightMap[node.name]) {
        orderedNodes.push(node);
      }
      node.children.forEach((child) => {
        if (!seen.has(child.name) && usedNodes.has(child.name) && child.inputs.every((input) => seen.has(input.name))) {
          frontier.push(child);
        }
      });
    }
    return orderedNodes;
  }
  function isControlFlow(node) {
    return CONTROL_FLOW_OPS.indexOf(node.op) >= 0;
  }
  function isDynamicShape(node) {
    return DYNAMIC_SHAPE_OPS.indexOf(node.op) >= 0;
  }
  function isHashTable(node) {
    return HASH_TABLE_OPS.indexOf(node.op) >= 0;
  }
  var CONTROL_FLOW_OPS, DYNAMIC_SHAPE_OPS, HASH_TABLE_OPS;
  var init_model_analysis = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/executor/model_analysis.js"() {
      init_utils();
      CONTROL_FLOW_OPS = [
        "Switch",
        "Merge",
        "Enter",
        "Exit",
        "NextIteration",
        "StatelessIf",
        "StatelessWhile",
        "if",
        "While"
      ];
      DYNAMIC_SHAPE_OPS = [
        "NonMaxSuppressionV2",
        "NonMaxSuppressionV3",
        "NonMaxSuppressionV5",
        "Where"
      ];
      HASH_TABLE_OPS = [
        "HashTable",
        "HashTableV2",
        "LookupTableImport",
        "LookupTableImportV2",
        "LookupTableFind",
        "LookupTableFindV2",
        "LookupTableSize",
        "LookupTableSizeV2"
      ];
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/executor/graph_executor.js
  var GraphExecutor;
  var init_graph_executor2 = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/executor/graph_executor.js"() {
      init_dist();
      init_utils();
      init_operation_executor();
      init_execution_context();
      init_model_analysis();
      GraphExecutor = class {
        /**
         *
         * @param graph Graph the model or function graph to be executed.
         * @param parent When building function exector you need to set the parent
         * executor. Since the weights and function executor maps are set at parant
         * level, that function executor can access the function maps and weight maps
         * through the parent.
         */
        constructor(graph, parent) {
          this.graph = graph;
          this.parent = parent;
          this.compiledMap = /* @__PURE__ */ new Map();
          this._weightMap = {};
          this.SEPERATOR = ",";
          this._functions = {};
          this._functionExecutorMap = {};
          this.keepIntermediateTensors = false;
          this._outputs = graph.outputs;
          this._inputs = graph.inputs;
          this._initNodes = graph.initNodes;
          this._signature = graph.signature;
          this._functions = graph.functions;
          if (graph.functions != null) {
            Object.keys(graph.functions).forEach((name) => {
              this._functionExecutorMap[name] = new GraphExecutor(graph.functions[name], this);
            });
          }
        }
        get weightIds() {
          return this.parent ? this.parent.weightIds : this._weightIds;
        }
        get functionExecutorMap() {
          return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;
        }
        get weightMap() {
          return this.parent ? this.parent.weightMap : this._weightMap;
        }
        set weightMap(weightMap) {
          const weightIds = Object.keys(weightMap).map((key) => weightMap[key].map((tensor2) => tensor2.id));
          this._weightIds = [].concat(...weightIds);
          this._weightMap = weightMap;
        }
        /**
         * Set `ResourceManager` shared by executors of a model.
         * @param resourceManager: `ResourceManager` of the `GraphModel`.
         */
        set resourceManager(resourceManager) {
          this._resourceManager = resourceManager;
        }
        get inputs() {
          return this._inputs.map((node) => {
            return {
              name: node.name,
              shape: node.attrParams["shape"] ? node.attrParams["shape"].value : void 0,
              dtype: node.attrParams["dtype"] ? node.attrParams["dtype"].value : void 0
            };
          });
        }
        get outputs() {
          return this._outputs.map((node) => {
            return {
              name: node.name,
              shape: node.attrParams["shape"] ? node.attrParams["shape"].value : void 0,
              dtype: node.attrParams["dtype"] ? node.attrParams["dtype"].value : void 0
            };
          });
        }
        get inputNodes() {
          return this._inputs.map((node) => node.signatureKey || node.name);
        }
        get outputNodes() {
          return this._outputs.map((node) => {
            const name = node.signatureKey || node.name;
            return node.defaultOutput ? `${name}:${node.defaultOutput}` : name;
          });
        }
        get functions() {
          return Object.keys(this._functions).reduce((map, key) => {
            map[key] = this._functions[key].signature;
            return map;
          }, {});
        }
        getCompilationKey(inputs, outputs) {
          const sortedInputs = inputs.map((node) => node.name).sort();
          const sortedOutputs = outputs.map((node) => node.name).sort();
          return sortedInputs.join(this.SEPERATOR) + "--" + sortedOutputs.join(this.SEPERATOR);
        }
        /**
         * Compiles the inference graph and returns the minimal set of nodes that are
         * required for execution, in the correct execution order.
         */
        compile(inputs, outputs) {
          const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);
          const { missingInputs, dynamicNode, syncInputs } = executionInfo;
          if (dynamicNode != null) {
            throw new Error(`This execution contains the node '${dynamicNode.name}', which has the dynamic op '${dynamicNode.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${syncInputs}]`);
          }
          if (missingInputs.length > 0) {
            const outNames = outputs.map((n) => n.name);
            const inNames = Object.keys(inputs);
            throw new Error(`Cannot compute the outputs [${outNames}] from the provided inputs [${inNames}]. Missing the following inputs: [${missingInputs}]`);
          }
          return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);
        }
        cloneAndKeepTensor(tensor2) {
          if (tensor2 == null) {
            return null;
          }
          const clone2 = tensor2.clone();
          keep(clone2);
          return clone2;
        }
        cloneTensorList(tensors) {
          if (!tensors) {
            return null;
          }
          const clonedTensor = tensors.map((tensor2) => {
            return this.cloneAndKeepTensor(tensor2);
          });
          return clonedTensor;
        }
        cloneTensorMap(tensorsMap) {
          return Object.fromEntries(Object.entries(tensorsMap).map(([name, tensorsList]) => {
            return [name, this.cloneTensorList(tensorsList)];
          }));
        }
        /**
         * Executes the inference for given input tensors.
         * @param inputs Tensor map for the model inputs, keyed by the input node
         * names.
         * @param outputs Optional. output node name from the Tensorflow model, if
         * no outputs are specified, the default outputs of the model would be used.
         * You can inspect intermediate nodes of the model by adding them to the
         * outputs array.
         */
        execute(inputs, outputs) {
          this.disposeIntermediateTensors();
          inputs = this.mapInputs(inputs);
          const names = Object.keys(inputs).sort();
          this.checkInputs(inputs);
          this.checkInputShapeAndType(inputs);
          outputs = this.mapOutputs(outputs);
          this.checkOutputs(outputs);
          const inputNodes = names.map((name) => this.graph.nodes[parseNodeName(name)[0]]);
          const outputNodeNames = outputs.map((name) => parseNodeName(name)[0]);
          let outputNodes = outputNodeNames.map((name) => this.graph.nodes[name]);
          if (outputNodes.length === 0) {
            outputNodes = this._outputs;
          }
          const compilationKey = this.getCompilationKey(inputNodes, outputNodes);
          let orderedNodes = this.compiledMap.get(compilationKey);
          if (orderedNodes == null) {
            orderedNodes = this.compile(inputs, outputNodes);
            this.compiledMap.set(compilationKey, orderedNodes);
          }
          try {
            this.keepIntermediateTensors = env().getBool("KEEP_INTERMEDIATE_TENSORS");
          } catch (e) {
            this.keepIntermediateTensors = false;
            console.warn(e.message);
          }
          const tensorArrayMap = {};
          const tensorListMap = {};
          return tidy(() => {
            const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);
            const tensorsMap = Object.assign({}, this.weightMap);
            if (this.keepIntermediateTensors) {
              this.clonedTensorsMap = this.cloneTensorMap(this.weightMap);
            }
            Object.keys(inputs).forEach((name) => {
              const [nodeName, index] = parseNodeName(name);
              const tensors = [];
              tensors[index] = inputs[name];
              tensorsMap[nodeName] = tensors;
              if (this.keepIntermediateTensors) {
                this.clonedTensorsMap[nodeName] = this.cloneTensorList(tensors);
              }
            });
            const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);
            const intermediateTensorConsumerCount = {};
            for (let i = 0; i < orderedNodes.length; i++) {
              const node = orderedNodes[i];
              if (!tensorsMap[node.name]) {
                const tensors = executeOp21(node, tensorsMap, context, this._resourceManager);
                if (util_exports.isPromise(tensors)) {
                  throw new Error(`The execution of the op '${node.op}' returned a promise. Please use model.executeAsync() instead.`);
                }
                tensorsMap[node.name] = tensors;
                if (this.keepIntermediateTensors) {
                  this.clonedTensorsMap[node.name] = this.cloneTensorList(tensors);
                }
                this.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount);
              }
            }
            if (this.parent == null) {
              context.dispose(tensorsToKeep);
            }
            return outputs.map((name) => getTensor(name, tensorsMap, context));
          });
        }
        getFrozenTensorIds(tensorMap) {
          const ids = [].concat.apply([], Object.keys(tensorMap).map((key) => tensorMap[key]).map((tensors) => tensors.map((tensor2) => tensor2.id)));
          return new Set(ids);
        }
        checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {
          if (node.category === "control" || outputNames.indexOf(nodeName) !== -1) {
            return;
          }
          tensorMap[nodeName].forEach((tensor2) => {
            if (tensor2 != null) {
              intermediateTensorConsumerCount[tensor2.id] = (intermediateTensorConsumerCount[tensor2.id] || 0) + node.children.length;
            }
          });
          node.inputs.forEach((input) => {
            if (input.category !== "control") {
              const tensors = getTensorsForCurrentContenxt(input.name, tensorMap, context);
              if (tensors != null) {
                tensors.forEach((tensor2) => {
                  if (tensor2 && !tensor2.kept && !tensorsToKeep.has(tensor2.id)) {
                    const count = intermediateTensorConsumerCount[tensor2.id];
                    if (count === 1) {
                      tensor2.dispose();
                      delete intermediateTensorConsumerCount[tensor2.id];
                    } else if (count != null) {
                      intermediateTensorConsumerCount[tensor2.id]--;
                    }
                  }
                });
              }
            }
          });
        }
        /**
         * Executes the inference for given input tensors in Async fashion.
         * @param inputs Tensor map for the model inputs, keyed by the input node
         * names.
         * @param outputs output node name from the Tensorflow model, if no outputs
         * are specified, the default outputs of the model would be used. You can
         * inspect intermediate nodes of the model by adding them to the outputs
         * array.
         */
        executeAsync(inputs, outputs) {
          return __async(this, null, function* () {
            return this._executeAsync(inputs, outputs);
          });
        }
        disposeIntermediateTensors() {
          if (!this.clonedTensorsMap) {
            return;
          }
          Object.values(this.clonedTensorsMap).forEach((tensorsList) => {
            for (const tensor2 of tensorsList) {
              if (tensor2 && !tensor2.isDisposed) {
                tensor2.dispose();
              }
            }
          });
          this.clonedTensorsMap = null;
        }
        getIntermediateTensors() {
          return this.clonedTensorsMap;
        }
        /**
         * Executes the inference for given input tensors in Async fashion.
         * @param inputs Tensor map for the model inputs, keyed by the input node
         * names.
         * @param outputs Optional. output node name from the Tensorflow model,
         * if no outputs are specified, the default outputs of the model would be
         * used. You can inspect intermediate nodes of the model by adding them to
         * the outputs array.
         * @param isFunctionExecution Optional. Flag for executing a function.
         * @param tensorArrayMap Optional, global TensorArray map by id. Used for
         * function execution.
         * @param tensorArrayMap Optinal global TensorList map by id. Used for
         * function execution.
         */
        _executeAsync(_0, _1) {
          return __async(this, arguments, function* (inputs, outputs, isFunctionExecution = false, tensorArrayMap = {}, tensorListMap = {}) {
            this.disposeIntermediateTensors();
            if (!isFunctionExecution) {
              inputs = this.mapInputs(inputs);
              this.checkInputs(inputs);
              this.checkInputShapeAndType(inputs);
              outputs = this.mapOutputs(outputs);
              this.checkOutputs(outputs);
            }
            try {
              this.keepIntermediateTensors = env().getBool("KEEP_INTERMEDIATE_TENSORS");
            } catch (e) {
              this.keepIntermediateTensors = false;
              console.warn(e.message);
            }
            const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);
            if (this.keepIntermediateTensors) {
              this.clonedTensorsMap = this.cloneTensorMap(this.weightMap);
            }
            const tensorsMap = yield this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);
            const results = outputs.map((name) => getTensor(name, tensorsMap, context));
            const outputIds = results.map((t2) => t2.id);
            const inputIds = Object.keys(inputs).map((name) => inputs[name].id);
            const keepIds = /* @__PURE__ */ new Set([...outputIds, ...inputIds, ...this.weightIds]);
            Object.values(tensorsMap).forEach((tensorsList) => {
              tensorsList.forEach((tensor2) => {
                if (tensor2 && !tensor2.isDisposed && !keepIds.has(tensor2.id)) {
                  tensor2.dispose();
                }
              });
            });
            if (this.parent == null) {
              context.dispose(keepIds);
            }
            return results;
          });
        }
        executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {
          return __async(this, null, function* () {
            const mappedInputs = inputs.reduce((map, tensor2, index) => {
              map[this.inputs[index].name] = tensor2;
              return map;
            }, {});
            return this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);
          });
        }
        /**
         * When there are control flow nodes in the graph, the graph execution use
         * ExecutionContext to keep track of the frames and loop iterators.
         * @param inputs placeholder tensors for the graph.
         * @param context the execution context object for current execution.
         * @param outputNames Optional. output node name from the Tensorflow model,
         * if no outputs are specified, the default outputs of the model would be
         * used. You can inspect intermediate nodes of the model by adding them to
         * the outputs array.
         * @param isFunctionExecution Flag for executing a function.
         */
        executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {
          return __async(this, null, function* () {
            const names = Object.keys(inputs);
            const inputNodes = names.map((name) => this.graph.nodes[parseNodeName(name)[0]]);
            const outputNodeNames = outputNames.map((name) => parseNodeName(name)[0]);
            let outputNodes = outputNodeNames.map((name) => this.graph.nodes[name]);
            if (outputNodes.length === 0) {
              outputNodes = this._outputs;
            }
            const { usedNodes, missingInputs, dynamicNode, syncInputs } = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes);
            const stack2 = [
              ...inputNodes,
              ...this.graph.weights,
              ...this._initNodes || []
            ].map((node) => {
              return { node, contexts: context.currentContext };
            });
            const tensorsMap = Object.assign({}, this.weightMap);
            Object.keys(inputs).forEach((name) => {
              const [nodeName, index] = parseNodeName(name);
              const tensors = [];
              tensors[index] = inputs[name];
              tensorsMap[nodeName] = tensors;
            });
            const intermediateTensorConsumerCount = {};
            const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);
            const added = {};
            while (stack2.length > 0) {
              const promises = this.processStack(inputNodes, stack2, context, tensorsMap, added, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount, usedNodes);
              yield Promise.all(promises);
            }
            if (dynamicNode == null && !isFunctionExecution) {
              console.warn(`This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.`);
            }
            const missingOutputs = outputNodes.filter((node) => !isControlFlow(node) && !getTensor(node.name, tensorsMap, context)).map((node) => node.name);
            if (missingOutputs.length > 0) {
              let alternativeMsg = "";
              if (dynamicNode != null) {
                alternativeMsg = `Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${syncInputs}]`;
              }
              throw new Error(`Cannot compute the outputs [${missingOutputs}] from the provided inputs [${names}]. Consider providing the following inputs: [${missingInputs}]. ${alternativeMsg}`);
            }
            return tensorsMap;
          });
        }
        processStack(inputNodes, stack2, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {
          const promises = [];
          while (stack2.length > 0) {
            const item = stack2.pop();
            context.currentContext = item.contexts;
            let nodeName = "";
            if (item.node.op === "Enter" && getParamValue("isConstant", item.node, tensorMap, context)) {
              [nodeName] = getNodeNameAndIndex(item.node.name, context);
            }
            if (tensorMap[item.node.name] == null) {
              const tensors = executeOp21(item.node, tensorMap, context, this._resourceManager);
              if (!nodeName) {
                [nodeName] = getNodeNameAndIndex(item.node.name, context);
              }
              const currentContext = context.currentContext;
              if (util_exports.isPromise(tensors)) {
                promises.push(tensors.then((t2) => {
                  tensorMap[nodeName] = t2;
                  if (this.keepIntermediateTensors) {
                    this.clonedTensorsMap[nodeName] = this.cloneTensorList(t2);
                  }
                  context.currentContext = currentContext;
                  this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);
                  this.processChildNodes(item.node, stack2, context, tensorMap, added, usedNodes);
                  return t2;
                }));
              } else {
                tensorMap[nodeName] = tensors;
                if (this.keepIntermediateTensors) {
                  this.clonedTensorsMap[nodeName] = this.cloneTensorList(tensors);
                }
                this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);
                this.processChildNodes(item.node, stack2, context, tensorMap, added, usedNodes);
              }
            } else {
              this.processChildNodes(item.node, stack2, context, tensorMap, added, usedNodes);
            }
          }
          return promises;
        }
        processChildNodes(node, stack2, context, tensorMap, added, usedNodes) {
          node.children.forEach((childNode) => {
            const [nodeName] = getNodeNameAndIndex(childNode.name, context);
            if (added[nodeName] || !usedNodes.has(childNode.name)) {
              return;
            }
            if (childNode.op === "Merge") {
              if (childNode.inputNames.some((name) => {
                return !!getTensor(name, tensorMap, context);
              })) {
                added[nodeName] = true;
                stack2.push({ contexts: context.currentContext, node: childNode });
              }
            } else if (childNode.inputNames.every((name) => {
              return !!getTensor(name, tensorMap, context);
            })) {
              added[nodeName] = true;
              stack2.push({ contexts: context.currentContext, node: childNode });
            }
          });
        }
        /**
         * Releases the memory used by the weight tensors.
         */
        dispose() {
          Object.keys(this.weightMap).forEach((key) => this.weightMap[key].forEach((tensor2) => tensor2.dispose()));
        }
        checkInputShapeAndType(inputs) {
          Object.keys(inputs).forEach((name) => {
            const input = inputs[name];
            const [nodeName] = parseNodeName(name);
            const node = this.graph.nodes[nodeName];
            if (node.attrParams["shape"] && node.attrParams["shape"].value) {
              const shape = node.attrParams["shape"].value;
              const match = shape.length === input.shape.length && input.shape.every((dim, index) => shape[index] === -1 || shape[index] === dim);
              util_exports.assert(match, () => `The shape of dict['${node.name}'] provided in model.execute(dict) must be [${shape}], but was [${input.shape}]`);
            }
            if (node.attrParams["dtype"] && node.attrParams["dtype"].value) {
              util_exports.assert(input.dtype === node.attrParams["dtype"].value, () => `The dtype of dict['${node.name}'] provided in model.execute(dict) must be ${node.attrParams["dtype"].value}, but was ${input.dtype}`);
            }
          });
        }
        mapInputs(inputs) {
          var _a, _b;
          const result = {};
          for (const inputName in inputs) {
            const tensor2 = (_b = (_a = this._signature) === null || _a === void 0 ? void 0 : _a.inputs) === null || _b === void 0 ? void 0 : _b[inputName];
            if (tensor2 != null) {
              result[tensor2.name] = inputs[inputName];
            } else {
              result[inputName] = inputs[inputName];
            }
          }
          return result;
        }
        checkInputs(inputs) {
          const notInGraph = Object.keys(inputs).filter((name) => {
            const [nodeName] = parseNodeName(name);
            return this.graph.nodes[nodeName] == null;
          });
          if (notInGraph.length > 0) {
            throw new Error(`The dict provided in model.execute(dict) has keys: [${notInGraph}] that are not part of graph`);
          }
        }
        mapOutputs(outputs) {
          return outputs.map((name) => {
            var _a, _b;
            const tensor2 = (_b = (_a = this._signature) === null || _a === void 0 ? void 0 : _a.outputs) === null || _b === void 0 ? void 0 : _b[name];
            if (tensor2 != null) {
              return tensor2.name;
            }
            return name;
          }, {});
        }
        checkOutputs(outputs) {
          outputs.forEach((name) => {
            const [normalizedName] = parseNodeName(name);
            if (!this.graph.nodes[normalizedName]) {
              throw new Error(`The output '${name}' is not found in the graph`);
            }
          });
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/executor/resource_manager.js
  var ResourceManager;
  var init_resource_manager = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/executor/resource_manager.js"() {
      ResourceManager = class {
        constructor(hashTableNameToHandle = {}, hashTableMap = {}) {
          this.hashTableNameToHandle = hashTableNameToHandle;
          this.hashTableMap = hashTableMap;
        }
        /**
         * Register a `HashTable` in the resource manager.
         *
         * The `HashTable` can be retrieved by `resourceManager.getHashTableById`,
         * where id is the table handle tensor's id.
         *
         * @param name Op node name that creates the `HashTable`.
         * @param hashTable The `HashTable` to be added to resource manager.
         */
        addHashTable(name, hashTable) {
          this.hashTableNameToHandle[name] = hashTable.handle;
          this.hashTableMap[hashTable.id] = hashTable;
        }
        /**
         * Get the table handle by node name.
         * @param name Op node name that creates the `HashTable`. This name is also
         *     used in the inputs list of lookup and import `HashTable` ops.
         */
        getHashTableHandleByName(name) {
          return this.hashTableNameToHandle[name];
        }
        /**
         * Get the actual `HashTable` by its handle tensor's id.
         * @param id The id of the handle tensor.
         */
        getHashTableById(id) {
          return this.hashTableMap[id];
        }
        /**
         * Dispose `ResourceManager`, including its hashTables and tensors in them.
         */
        dispose() {
          for (const key in this.hashTableMap) {
            this.hashTableMap[key].clearAndClose();
            delete this.hashTableMap[key];
          }
          for (const name in this.hashTableNameToHandle) {
            this.hashTableNameToHandle[name].dispose();
            delete this.hashTableNameToHandle[name];
          }
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/executor/graph_model.js
  function loadGraphModel(_0) {
    return __async(this, arguments, function* (modelUrl, options = {}, tfio = io_exports) {
      if (modelUrl == null) {
        throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");
      }
      if (options == null) {
        options = {};
      }
      if (options.fromTFHub && typeof modelUrl === "string") {
        modelUrl = getTFHubUrl(modelUrl);
      }
      const model = new GraphModel(modelUrl, options, tfio);
      yield model.load();
      return model;
    });
  }
  function getTFHubUrl(modelUrl) {
    if (!modelUrl.endsWith("/")) {
      modelUrl = modelUrl + "/";
    }
    return `${modelUrl}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`;
  }
  var TFHUB_SEARCH_PARAM, DEFAULT_MODEL_NAME, GraphModel;
  var init_graph_model = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/executor/graph_model.js"() {
      init_dist();
      init_operation_mapper();
      init_graph_executor2();
      init_resource_manager();
      TFHUB_SEARCH_PARAM = "?tfjs-format=file";
      DEFAULT_MODEL_NAME = "model.json";
      GraphModel = class {
        /**
         * @param modelUrl url for the model, or an `io.IOHandler`.
         * @param weightManifestUrl url for the weight file generated by
         * scripts/convert.py script.
         * @param requestOption options for Request, which allows to send credentials
         * and custom headers.
         * @param onProgress Optional, progress callback function, fired periodically
         * before the load is completed.
         */
        constructor(modelUrl, loadOptions = {}, tfio = io_exports) {
          this.modelUrl = modelUrl;
          this.loadOptions = loadOptions;
          this.version = "n/a";
          this.io = tfio;
          if (loadOptions == null) {
            this.loadOptions = {};
          }
          this.resourceManager = new ResourceManager();
        }
        // Returns the version information for the tensorflow model GraphDef.
        get modelVersion() {
          return this.version;
        }
        get inputNodes() {
          return this.executor.inputNodes;
        }
        get outputNodes() {
          return this.executor.outputNodes;
        }
        get inputs() {
          return this.executor.inputs;
        }
        get outputs() {
          return this.executor.outputs;
        }
        get weights() {
          return this.executor.weightMap;
        }
        get metadata() {
          return this.artifacts.userDefinedMetadata;
        }
        get modelSignature() {
          return this.signature;
        }
        get modelStructuredOutputKeys() {
          return this.structuredOutputKeys;
        }
        findIOHandler() {
          const path = this.modelUrl;
          if (path.load != null) {
            this.handler = path;
          } else if (this.loadOptions.requestInit != null) {
            this.handler = this.io.browserHTTPRequest(path, this.loadOptions);
          } else {
            const handlers = this.io.getLoadHandlers(path, this.loadOptions);
            if (handlers.length === 0) {
              handlers.push(this.io.browserHTTPRequest(path, this.loadOptions));
            } else if (handlers.length > 1) {
              throw new Error(`Found more than one (${handlers.length}) load handlers for URL '${[path]}'`);
            }
            this.handler = handlers[0];
          }
        }
        /**
         * Loads the model and weight files, construct the in memory weight map and
         * compile the inference graph.
         */
        load() {
          this.findIOHandler();
          if (this.handler.load == null) {
            throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
          }
          const loadResult = this.handler.load();
          if (util_exports.isPromise(loadResult)) {
            return loadResult.then((artifacts) => this.loadSync(artifacts));
          }
          return this.loadSync(loadResult);
        }
        /**
         * Synchronously construct the in memory weight map and
         * compile the inference graph.
         *
         * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
         */
        loadSync(artifacts) {
          this.artifacts = artifacts;
          const graph = this.artifacts.modelTopology;
          let signature = this.artifacts.signature;
          if (this.artifacts.userDefinedMetadata != null) {
            const metadata = this.artifacts.userDefinedMetadata;
            if (metadata.signature != null) {
              signature = metadata.signature;
            }
            if (metadata.structuredOutputKeys != null) {
              this.structuredOutputKeys = metadata.structuredOutputKeys;
            }
          }
          this.signature = signature;
          this.version = `${graph.versions.producer}.${graph.versions.minConsumer}`;
          const weightMap = this.io.decodeWeights(this.artifacts.weightData, this.artifacts.weightSpecs);
          this.executor = new GraphExecutor(OperationMapper.Instance.transformGraph(graph, this.signature));
          this.executor.weightMap = this.convertTensorMapToTensorsMap(weightMap);
          this.executor.resourceManager = this.resourceManager;
          if (artifacts.modelInitializer != null && artifacts.modelInitializer.node != null) {
            const initializer = OperationMapper.Instance.transformGraph(artifacts.modelInitializer);
            this.initializer = new GraphExecutor(initializer);
            this.initializer.weightMap = this.executor.weightMap;
            this.initializer.resourceManager = this.resourceManager;
            this.initializerSignature = artifacts.initializerSignature;
          }
          return true;
        }
        /**
         * Save the configuration and/or weights of the GraphModel.
         *
         * An `IOHandler` is an object that has a `save` method of the proper
         * signature defined. The `save` method manages the storing or
         * transmission of serialized data ("artifacts") that represent the
         * model's topology and weights onto or via a specific medium, such as
         * file downloads, local storage, IndexedDB in the web browser and HTTP
         * requests to a server. TensorFlow.js provides `IOHandler`
         * implementations for a number of frequently used saving mediums, such as
         * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`
         * for more details.
         *
         * This method also allows you to refer to certain types of `IOHandler`s
         * as URL-like string shortcuts, such as 'localstorage://' and
         * 'indexeddb://'.
         *
         * Example 1: Save `model`'s topology and weights to browser [local
         * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);
         * then load it back.
         *
         * ```js
         * const modelUrl =
         *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';
         * const model = await tf.loadGraphModel(modelUrl);
         * const zeros = tf.zeros([1, 224, 224, 3]);
         * model.predict(zeros).print();
         *
         * const saveResults = await model.save('localstorage://my-model-1');
         *
         * const loadedModel = await tf.loadGraphModel('localstorage://my-model-1');
         * console.log('Prediction from loaded model:');
         * model.predict(zeros).print();
         * ```
         *
         * @param handlerOrURL An instance of `IOHandler` or a URL-like,
         * scheme-based string shortcut for `IOHandler`.
         * @param config Options for saving the model.
         * @returns A `Promise` of `SaveResult`, which summarizes the result of
         * the saving, such as byte sizes of the saved artifacts for the model's
         *   topology and weight values.
         *
         * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
         */
        save(handlerOrURL, config) {
          return __async(this, null, function* () {
            if (typeof handlerOrURL === "string") {
              const handlers = this.io.getSaveHandlers(handlerOrURL);
              if (handlers.length === 0) {
                throw new Error(`Cannot find any save handlers for URL '${handlerOrURL}'`);
              } else if (handlers.length > 1) {
                throw new Error(`Found more than one (${handlers.length}) save handlers for URL '${handlerOrURL}'`);
              }
              handlerOrURL = handlers[0];
            }
            if (handlerOrURL.save == null) {
              throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
            }
            return handlerOrURL.save(this.artifacts);
          });
        }
        addStructuredOutputNames(outputTensors) {
          if (this.structuredOutputKeys) {
            const outputTensorsArray = outputTensors instanceof Tensor ? [outputTensors] : outputTensors;
            const outputTensorMap = {};
            outputTensorsArray.forEach((outputTensor, i) => outputTensorMap[this.structuredOutputKeys[i]] = outputTensor);
            return outputTensorMap;
          }
          return outputTensors;
        }
        /**
         * Execute the inference for the input tensors.
         *
         * @param input The input tensors, when there is single input for the model,
         * inputs param should be a `tf.Tensor`. For models with mutliple inputs,
         * inputs params should be in either `tf.Tensor`[] if the input order is
         * fixed, or otherwise NamedTensorMap format.
         *
         * For model with multiple inputs, we recommend you use NamedTensorMap as the
         * input type, if you use `tf.Tensor`[], the order of the array needs to
         * follow the
         * order of inputNodes array. @see {@link GraphModel.inputNodes}
         *
         * You can also feed any intermediate nodes using the NamedTensorMap as the
         * input type. For example, given the graph
         *    InputNode => Intermediate => OutputNode,
         * you can execute the subgraph Intermediate => OutputNode by calling
         *    model.execute('IntermediateNode' : tf.tensor(...));
         *
         * This is useful for models that uses tf.dynamic_rnn, where the intermediate
         * state needs to be fed manually.
         *
         * For batch inference execution, the tensors for each input need to be
         * concatenated together. For example with mobilenet, the required input shape
         * is [1, 244, 244, 3], which represents the [batch, height, width, channel].
         * If we are provide a batched data of 100 images, the input tensor should be
         * in the shape of [100, 244, 244, 3].
         *
         * @param config Prediction configuration for specifying the batch size.
         * Currently the batch size option is ignored for graph model.
         *
         * @returns Inference result tensors. If the model is converted and it
         * originally had structured_outputs in tensorflow, then a NamedTensorMap
         * will be returned matching the structured_outputs. If no structured_outputs
         * are present, the output will be single `tf.Tensor` if the model has single
         * output node, otherwise Tensor[].
         *
         * @doc {heading: 'Models', subheading: 'Classes'}
         */
        predict(inputs, config) {
          const outputTensors = this.execute(inputs, this.outputNodes);
          return this.addStructuredOutputNames(outputTensors);
        }
        /**
         * Execute the inference for the input tensors in async fashion, use this
         * method when your model contains control flow ops.
         *
         * @param input The input tensors, when there is single input for the model,
         * inputs param should be a `tf.Tensor`. For models with mutliple inputs,
         * inputs params should be in either `tf.Tensor`[] if the input order is
         * fixed, or otherwise NamedTensorMap format.
         *
         * For model with multiple inputs, we recommend you use NamedTensorMap as the
         * input type, if you use `tf.Tensor`[], the order of the array needs to
         * follow the
         * order of inputNodes array. @see {@link GraphModel.inputNodes}
         *
         * You can also feed any intermediate nodes using the NamedTensorMap as the
         * input type. For example, given the graph
         *    InputNode => Intermediate => OutputNode,
         * you can execute the subgraph Intermediate => OutputNode by calling
         *    model.execute('IntermediateNode' : tf.tensor(...));
         *
         * This is useful for models that uses tf.dynamic_rnn, where the intermediate
         * state needs to be fed manually.
         *
         * For batch inference execution, the tensors for each input need to be
         * concatenated together. For example with mobilenet, the required input shape
         * is [1, 244, 244, 3], which represents the [batch, height, width, channel].
         * If we are provide a batched data of 100 images, the input tensor should be
         * in the shape of [100, 244, 244, 3].
         *
         * @param config Prediction configuration for specifying the batch size.
         * Currently the batch size option is ignored for graph model.
         *
         * @returns A Promise of inference result tensors. If the model is converted
         * and it originally had structured_outputs in tensorflow, then a
         * NamedTensorMap will be returned matching the structured_outputs. If no
         * structured_outputs are present, the output will be single `tf.Tensor` if
         * the model has single output node, otherwise Tensor[].
         *
         * @doc {heading: 'Models', subheading: 'Classes'}
         */
        predictAsync(inputs, config) {
          return __async(this, null, function* () {
            const outputTensors = yield this.executeAsync(inputs, this.outputNodes);
            return this.addStructuredOutputNames(outputTensors);
          });
        }
        normalizeInputs(inputs) {
          var _a;
          if (!(inputs instanceof Tensor) && !Array.isArray(inputs)) {
            const signatureInputs = (_a = this.signature) === null || _a === void 0 ? void 0 : _a.inputs;
            if (signatureInputs != null) {
              for (const input in signatureInputs) {
                const tensor2 = signatureInputs[input];
                if (tensor2.resourceId != null) {
                  inputs[input] = this.resourceIdToCapturedInput[tensor2.resourceId];
                }
              }
            }
            return inputs;
          }
          inputs = Array.isArray(inputs) ? inputs : [inputs];
          const numCapturedInputs = Object.keys(this.resourceIdToCapturedInput).length;
          if (inputs.length + numCapturedInputs !== this.inputNodes.length) {
            throw new Error(`Input tensor count mismatch, the graph model has ${this.inputNodes.length - numCapturedInputs} non-resource placeholders, while there are ${inputs.length} input tensors provided.`);
          }
          let inputIndex = 0;
          return this.inputNodes.reduce((map, inputName) => {
            var _a2, _b, _c;
            const resourceId = (_c = (_b = (_a2 = this.signature) === null || _a2 === void 0 ? void 0 : _a2.inputs) === null || _b === void 0 ? void 0 : _b[inputName]) === null || _c === void 0 ? void 0 : _c.resourceId;
            if (resourceId != null) {
              map[inputName] = this.resourceIdToCapturedInput[resourceId];
            } else {
              map[inputName] = inputs[inputIndex++];
            }
            return map;
          }, {});
        }
        normalizeOutputs(outputs) {
          outputs = outputs || this.outputNodes;
          return !Array.isArray(outputs) ? [outputs] : outputs;
        }
        executeInitializerGraph() {
          if (this.initializer == null) {
            return [];
          }
          if (this.initializerSignature == null) {
            return this.initializer.execute({}, []);
          } else {
            return this.initializer.execute({}, Object.keys(this.initializerSignature.outputs));
          }
        }
        executeInitializerGraphAsync() {
          return __async(this, null, function* () {
            if (this.initializer == null) {
              return [];
            }
            if (this.initializerSignature == null) {
              return this.initializer.executeAsync({}, []);
            } else {
              return this.initializer.executeAsync({}, Object.keys(this.initializerSignature.outputs));
            }
          });
        }
        setResourceIdToCapturedInput(outputs) {
          this.resourceIdToCapturedInput = {};
          if (this.initializerSignature) {
            const signatureOutputs = this.initializerSignature.outputs;
            const outputNames = Object.keys(signatureOutputs);
            for (let i = 0; i < outputNames.length; i++) {
              const outputName = outputNames[i];
              const tensorInfo = signatureOutputs[outputName];
              this.resourceIdToCapturedInput[tensorInfo.resourceId] = outputs[i];
            }
          }
        }
        /**
         * Executes inference for the model for given input tensors.
         * @param inputs tensor, tensor array or tensor map of the inputs for the
         * model, keyed by the input node names.
         * @param outputs output node name from the TensorFlow model, if no
         * outputs are specified, the default outputs of the model would be used.
         * You can inspect intermediate nodes of the model by adding them to the
         * outputs array.
         *
         * @returns A single tensor if provided with a single output or no outputs
         * are provided and there is only one default output, otherwise return a
         * tensor array. The order of the tensor array is the same as the outputs
         * if provided, otherwise the order of outputNodes attribute of the model.
         *
         * @doc {heading: 'Models', subheading: 'Classes'}
         */
        execute(inputs, outputs) {
          if (this.resourceIdToCapturedInput == null) {
            this.setResourceIdToCapturedInput(this.executeInitializerGraph());
          }
          inputs = this.normalizeInputs(inputs);
          outputs = this.normalizeOutputs(outputs);
          const result = this.executor.execute(inputs, outputs);
          return result.length > 1 ? result : result[0];
        }
        /**
         * Executes inference for the model for given input tensors in async
         * fashion, use this method when your model contains control flow ops.
         * @param inputs tensor, tensor array or tensor map of the inputs for the
         * model, keyed by the input node names.
         * @param outputs output node name from the TensorFlow model, if no outputs
         * are specified, the default outputs of the model would be used. You can
         * inspect intermediate nodes of the model by adding them to the outputs
         * array.
         *
         * @returns A Promise of single tensor if provided with a single output or
         * no outputs are provided and there is only one default output, otherwise
         * return a tensor map.
         *
         * @doc {heading: 'Models', subheading: 'Classes'}
         */
        executeAsync(inputs, outputs) {
          return __async(this, null, function* () {
            if (this.resourceIdToCapturedInput == null) {
              this.setResourceIdToCapturedInput(yield this.executeInitializerGraphAsync());
            }
            inputs = this.normalizeInputs(inputs);
            outputs = this.normalizeOutputs(outputs);
            const result = yield this.executor.executeAsync(inputs, outputs);
            return result.length > 1 ? result : result[0];
          });
        }
        /**
         * Get intermediate tensors for model debugging mode (flag
         * KEEP_INTERMEDIATE_TENSORS is true).
         *
         * @doc {heading: 'Models', subheading: 'Classes'}
         */
        getIntermediateTensors() {
          return this.executor.getIntermediateTensors();
        }
        /**
         * Dispose intermediate tensors for model debugging mode (flag
         * KEEP_INTERMEDIATE_TENSORS is true).
         *
         * @doc {heading: 'Models', subheading: 'Classes'}
         */
        disposeIntermediateTensors() {
          this.executor.disposeIntermediateTensors();
        }
        convertTensorMapToTensorsMap(map) {
          return Object.keys(map).reduce((newMap, key) => {
            newMap[key] = [map[key]];
            return newMap;
          }, {});
        }
        /**
         * Releases the memory used by the weight tensors and resourceManager.
         *
         * @doc {heading: 'Models', subheading: 'Classes'}
         */
        dispose() {
          this.executor.dispose();
          if (this.initializer) {
            this.initializer.dispose();
            if (this.resourceIdToCapturedInput) {
              dispose(this.resourceIdToCapturedInput);
            }
          }
          this.resourceManager.dispose();
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/version.js
  var init_version = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/version.js"() {
    }
  });

  // node_modules/@tensorflow/tfjs-converter/dist/index.js
  var init_dist2 = __esm({
    "node_modules/@tensorflow/tfjs-converter/dist/index.js"() {
      init_flags2();
      init_graph_model();
      init_register();
      init_version();
    }
  });

  // node_modules/@tensorflow-models/face-landmarks-detection/dist/face-landmarks-detection.esm.js
  function S(t2, e, n, r) {
    return new (n || (n = Promise))(function(i, o) {
      function a(t3) {
        try {
          s(r.next(t3));
        } catch (t4) {
          o(t4);
        }
      }
      function u(t3) {
        try {
          s(r.throw(t3));
        } catch (t4) {
          o(t4);
        }
      }
      function s(t3) {
        var e2;
        t3.done ? i(t3.value) : (e2 = t3.value, e2 instanceof n ? e2 : new n(function(t4) {
          t4(e2);
        })).then(a, u);
      }
      s((r = r.apply(t2, e || [])).next());
    });
  }
  function F(t2, e) {
    var n, r, i, o, a = { label: 0, sent: function() {
      if (1 & i[0])
        throw i[1];
      return i[1];
    }, trys: [], ops: [] };
    return o = { next: u(0), throw: u(1), return: u(2) }, "function" == typeof Symbol && (o[Symbol.iterator] = function() {
      return this;
    }), o;
    function u(o2) {
      return function(u2) {
        return function(o3) {
          if (n)
            throw new TypeError("Generator is already executing.");
          for (; a; )
            try {
              if (n = 1, r && (i = 2 & o3[0] ? r.return : o3[0] ? r.throw || ((i = r.return) && i.call(r), 0) : r.next) && !(i = i.call(r, o3[1])).done)
                return i;
              switch (r = 0, i && (o3 = [2 & o3[0], i.value]), o3[0]) {
                case 0:
                case 1:
                  i = o3;
                  break;
                case 4:
                  return a.label++, { value: o3[1], done: false };
                case 5:
                  a.label++, r = o3[1], o3 = [0];
                  continue;
                case 7:
                  o3 = a.ops.pop(), a.trys.pop();
                  continue;
                default:
                  if (!(i = a.trys, (i = i.length > 0 && i[i.length - 1]) || 6 !== o3[0] && 2 !== o3[0])) {
                    a = 0;
                    continue;
                  }
                  if (3 === o3[0] && (!i || o3[1] > i[0] && o3[1] < i[3])) {
                    a.label = o3[1];
                    break;
                  }
                  if (6 === o3[0] && a.label < i[1]) {
                    a.label = i[1], i = o3;
                    break;
                  }
                  if (i && a.label < i[2]) {
                    a.label = i[2], a.ops.push(o3);
                    break;
                  }
                  i[2] && a.ops.pop(), a.trys.pop();
                  continue;
              }
              o3 = e.call(t2, a);
            } catch (t3) {
              o3 = [6, t3], r = 0;
            } finally {
              n = i = 0;
            }
          if (5 & o3[0])
            throw o3[1];
          return { value: o3[0] ? o3[1] : void 0, done: true };
        }([o2, u2]);
      };
    }
  }
  function C(t2) {
    var e = t2.map(function(t3) {
      return t3[0];
    });
    return e.push(t2[t2.length - 1][1]), e;
  }
  function R(t2) {
    for (var e = { locationData: { relativeKeypoints: [] } }, n = Number.MAX_SAFE_INTEGER, r = Number.MIN_SAFE_INTEGER, i = Number.MAX_SAFE_INTEGER, o = Number.MIN_SAFE_INTEGER, a = 0; a < t2.length; ++a) {
      var u = t2[a];
      n = Math.min(n, u.x), r = Math.max(r, u.x), i = Math.min(i, u.y), o = Math.max(o, u.y), e.locationData.relativeKeypoints.push({ x: u.x, y: u.y });
    }
    return e.locationData.relativeBoundingBox = { xMin: n, yMin: i, xMax: r, yMax: o, width: r - n, height: o - i }, e;
  }
  function B(t2) {
    return S(this, void 0, void 0, function() {
      var e, n;
      return F(this, function(r) {
        switch (r.label) {
          case 0:
            return e = function(t3) {
              if (null == t3)
                return E({}, I);
              var e2 = E({}, t3);
              return e2.runtime = "mediapipe", null == e2.maxFaces && (e2.maxFaces = I.maxFaces), null == e2.refineLandmarks && (e2.refineLandmarks = I.refineLandmarks), e2;
            }(t2), [4, (n = new L(e)).initialize()];
          case 1:
            return r.sent(), [2, n];
        }
      });
    });
  }
  function U(t2, e, n, r) {
    return new (n || (n = Promise))(function(i, o) {
      function a(t3) {
        try {
          s(r.next(t3));
        } catch (t4) {
          o(t4);
        }
      }
      function u(t3) {
        try {
          s(r.throw(t3));
        } catch (t4) {
          o(t4);
        }
      }
      function s(t3) {
        var e2;
        t3.done ? i(t3.value) : (e2 = t3.value, e2 instanceof n ? e2 : new n(function(t4) {
          t4(e2);
        })).then(a, u);
      }
      s((r = r.apply(t2, e || [])).next());
    });
  }
  function N(t2, e) {
    var n, r, i, o, a = { label: 0, sent: function() {
      if (1 & i[0])
        throw i[1];
      return i[1];
    }, trys: [], ops: [] };
    return o = { next: u(0), throw: u(1), return: u(2) }, "function" == typeof Symbol && (o[Symbol.iterator] = function() {
      return this;
    }), o;
    function u(o2) {
      return function(u2) {
        return function(o3) {
          if (n)
            throw new TypeError("Generator is already executing.");
          for (; a; )
            try {
              if (n = 1, r && (i = 2 & o3[0] ? r.return : o3[0] ? r.throw || ((i = r.return) && i.call(r), 0) : r.next) && !(i = i.call(r, o3[1])).done)
                return i;
              switch (r = 0, i && (o3 = [2 & o3[0], i.value]), o3[0]) {
                case 0:
                case 1:
                  i = o3;
                  break;
                case 4:
                  return a.label++, { value: o3[1], done: false };
                case 5:
                  a.label++, r = o3[1], o3 = [0];
                  continue;
                case 7:
                  o3 = a.ops.pop(), a.trys.pop();
                  continue;
                default:
                  if (!((i = (i = a.trys).length > 0 && i[i.length - 1]) || 6 !== o3[0] && 2 !== o3[0])) {
                    a = 0;
                    continue;
                  }
                  if (3 === o3[0] && (!i || o3[1] > i[0] && o3[1] < i[3])) {
                    a.label = o3[1];
                    break;
                  }
                  if (6 === o3[0] && a.label < i[1]) {
                    a.label = i[1], i = o3;
                    break;
                  }
                  if (i && a.label < i[2]) {
                    a.label = i[2], a.ops.push(o3);
                    break;
                  }
                  i[2] && a.ops.pop(), a.trys.pop();
                  continue;
              }
              o3 = e.call(t2, a);
            } catch (t3) {
              o3 = [6, t3], r = 0;
            } finally {
              n = i = 0;
            }
          if (5 & o3[0])
            throw o3[1];
          return { value: o3[0] ? o3[1] : void 0, done: true };
        }([o2, u2]);
      };
    }
  }
  function W(t2) {
    return U(this, void 0, void 0, function() {
      var e, n;
      return N(this, function(r) {
        switch (r.label) {
          case 0:
            return e = function(t3) {
              if (null == t3)
                return z({}, H);
              var e2 = z({}, t3);
              return e2.runtime = "mediapipe", null == e2.modelType && (e2.modelType = H.modelType), null == e2.maxFaces && (e2.maxFaces = H.maxFaces), e2;
            }(t2), [4, (n = new K(e)).initialize()];
          case 1:
            return r.sent(), [2, n];
        }
      });
    });
  }
  function G(t2) {
    return t2 instanceof Tensor ? { height: t2.shape[0], width: t2.shape[1] } : { height: t2.height, width: t2.width };
  }
  function X(t2) {
    return t2 instanceof Tensor ? t2 : browser_exports.fromPixels(t2);
  }
  function Y(t2, e) {
    util_exports.assert(0 !== t2.width, function() {
      return e + " width cannot be 0.";
    }), util_exports.assert(0 !== t2.height, function() {
      return e + " height cannot be 0.";
    });
  }
  function J(t2, e, n) {
    var r = e.outputTensorSize, i = e.keepAspectRatio, o = e.borderMode, h = e.outputTensorFloatRange, f = G(t2), g = function(t3, e2) {
      return e2 ? { xCenter: e2.xCenter * t3.width, yCenter: e2.yCenter * t3.height, width: e2.width * t3.width, height: e2.height * t3.height, rotation: e2.rotation } : { xCenter: 0.5 * t3.width, yCenter: 0.5 * t3.height, width: t3.width, height: t3.height, rotation: 0 };
    }(f, n), v = function(t3, e2, n2) {
      if (void 0 === n2 && (n2 = false), !n2)
        return { top: 0, left: 0, right: 0, bottom: 0 };
      var r2 = e2.height, i2 = e2.width;
      Y(e2, "targetSize"), Y(t3, "roi");
      var o2, a, u = r2 / i2, s = t3.height / t3.width, c = 0, h2 = 0;
      return u > s ? (o2 = t3.width, a = t3.width * u, h2 = (1 - s / u) / 2) : (o2 = t3.height / u, a = t3.height, c = (1 - u / s) / 2), t3.width = o2, t3.height = a, { top: h2, left: c, right: c, bottom: h2 };
    }(g, r, i), m = function(t3, e2, n2, r2) {
      var i2 = t3.width, o2 = t3.height, a = r2 ? -1 : 1, u = Math.cos(t3.rotation), s = Math.sin(t3.rotation), c = t3.xCenter, h2 = t3.yCenter, l = 1 / e2, f2 = 1 / n2, d = new Array(16);
      return d[0] = i2 * u * a * l, d[1] = -o2 * s * l, d[2] = 0, d[3] = (-0.5 * i2 * u * a + 0.5 * o2 * s + c) * l, d[4] = i2 * s * a * f2, d[5] = o2 * u * f2, d[6] = 0, d[7] = (-0.5 * o2 * u - 0.5 * i2 * s * a + h2) * f2, d[8] = 0, d[9] = 0, d[10] = i2 * l, d[11] = 0, d[12] = 0, d[13] = 0, d[14] = 0, d[15] = 1, function(t4) {
        if (16 !== t4.length)
          throw new Error("Array length must be 16 but got " + t4.length);
        return [[t4[0], t4[1], t4[2], t4[3]], [t4[4], t4[5], t4[6], t4[7]], [t4[8], t4[9], t4[10], t4[11]], [t4[12], t4[13], t4[14], t4[15]]];
      }(d);
    }(g, f.width, f.height, false), y = tidy(function() {
      var e2 = X(t2), n2 = tensor2d(function(t3, e3, n3) {
        return Y(n3, "inputResolution"), [1 / n3.width * t3[0][0] * e3.width, 1 / n3.height * t3[0][1] * e3.width, t3[0][3] * e3.width, 1 / n3.width * t3[1][0] * e3.height, 1 / n3.height * t3[1][1] * e3.height, t3[1][3] * e3.height, 0, 0];
      }(m, f, r), [1, 8]), i2 = "zero" === o ? "constant" : "nearest", g2 = image.transform(expandDims(cast(e2, "float32")), n2, "bilinear", i2, 0, [r.height, r.width]);
      return null != h ? function(t3, e3) {
        var n3 = function(t4, e4, n4, r2) {
          var i3 = (r2 - n4) / 255;
          return { scale: i3, offset: n4 - 0 * i3 };
        }(0, 0, e3[0], e3[1]);
        return tidy(function() {
          return add2(mul(t3, n3.scale), n3.offset);
        });
      }(g2, h) : g2;
    });
    return { imageTensor: y, padding: v, transformationMatrix: m };
  }
  function q(t2) {
    null == t2.reduceBoxesInLowestLayer && (t2.reduceBoxesInLowestLayer = false), null == t2.interpolatedScaleAspectRatio && (t2.interpolatedScaleAspectRatio = 1), null == t2.fixedAnchorSize && (t2.fixedAnchorSize = false);
    for (var e = [], n = 0; n < t2.numLayers; ) {
      for (var r = [], i = [], o = [], a = [], u = n; u < t2.strides.length && t2.strides[u] === t2.strides[n]; ) {
        var s = $(t2.minScale, t2.maxScale, u, t2.strides.length);
        if (0 === u && t2.reduceBoxesInLowestLayer)
          o.push(1), o.push(2), o.push(0.5), a.push(0.1), a.push(s), a.push(s);
        else {
          for (var c = 0; c < t2.aspectRatios.length; ++c)
            o.push(t2.aspectRatios[c]), a.push(s);
          if (t2.interpolatedScaleAspectRatio > 0) {
            var h = u === t2.strides.length - 1 ? 1 : $(t2.minScale, t2.maxScale, u + 1, t2.strides.length);
            a.push(Math.sqrt(s * h)), o.push(t2.interpolatedScaleAspectRatio);
          }
        }
        u++;
      }
      for (var l = 0; l < o.length; ++l) {
        var f = Math.sqrt(o[l]);
        r.push(a[l] / f), i.push(a[l] * f);
      }
      var d = 0, p2 = 0;
      if (t2.featureMapHeight.length > 0)
        d = t2.featureMapHeight[n], p2 = t2.featureMapWidth[n];
      else {
        var g = t2.strides[n];
        d = Math.ceil(t2.inputSizeHeight / g), p2 = Math.ceil(t2.inputSizeWidth / g);
      }
      for (var v = 0; v < d; ++v)
        for (var m = 0; m < p2; ++m)
          for (var y = 0; y < r.length; ++y) {
            var w = { xCenter: (m + t2.anchorOffsetX) / p2, yCenter: (v + t2.anchorOffsetY) / d, width: 0, height: 0 };
            t2.fixedAnchorSize ? (w.width = 1, w.height = 1) : (w.width = i[y], w.height = r[y]), e.push(w);
          }
      n = u;
    }
    return e;
  }
  function $(t2, e, n, r) {
    return 1 === r ? 0.5 * (t2 + e) : t2 + (e - t2) * n / (r - 1);
  }
  function Z(t2, e) {
    var n = e[0], r = e[1];
    return [n * t2[0] + r * t2[1] + t2[3], n * t2[4] + r * t2[5] + t2[7]];
  }
  function Q(t2, e, n, r) {
    return U(this, void 0, void 0, function() {
      var r2, s, c, h, l;
      return N(this, function(f) {
        switch (f.label) {
          case 0:
            return t2.sort(function(t3, e2) {
              return Math.max.apply(Math, e2.score) - Math.max.apply(Math, t3.score);
            }), r2 = tensor2d(t2.map(function(t3) {
              return [t3.locationData.relativeBoundingBox.yMin, t3.locationData.relativeBoundingBox.xMin, t3.locationData.relativeBoundingBox.yMax, t3.locationData.relativeBoundingBox.xMax];
            })), s = tensor1d(t2.map(function(t3) {
              return t3.score[0];
            })), [4, image.nonMaxSuppressionAsync(r2, s, e, n)];
          case 1:
            return [4, (c = f.sent()).array()];
          case 2:
            return h = f.sent(), l = t2.filter(function(t3, e2) {
              return h.indexOf(e2) > -1;
            }), dispose([r2, s, c]), [2, l];
        }
      });
    });
  }
  function tt(t2, e, n) {
    return U(this, void 0, void 0, function() {
      var r, i, a, u, c;
      return N(this, function(l) {
        switch (l.label) {
          case 0:
            return r = t2[0], i = t2[1], a = function(t3, e2, n2) {
              return tidy(function() {
                var r2, i2, o, a6;
                n2.reverseOutputOrder ? (i2 = squeeze(slice(t3, [0, n2.boxCoordOffset + 0], [-1, 1])), r2 = squeeze(slice(t3, [0, n2.boxCoordOffset + 1], [-1, 1])), a6 = squeeze(slice(t3, [0, n2.boxCoordOffset + 2], [-1, 1])), o = squeeze(slice(t3, [0, n2.boxCoordOffset + 3], [-1, 1]))) : (r2 = squeeze(slice(t3, [0, n2.boxCoordOffset + 0], [-1, 1])), i2 = squeeze(slice(t3, [0, n2.boxCoordOffset + 1], [-1, 1])), o = squeeze(slice(t3, [0, n2.boxCoordOffset + 2], [-1, 1])), a6 = squeeze(slice(t3, [0, n2.boxCoordOffset + 3], [-1, 1]))), i2 = add2(mul(div(i2, n2.xScale), e2.w), e2.x), r2 = add2(mul(div(r2, n2.yScale), e2.h), e2.y), n2.applyExponentialOnBoxSize ? (o = mul(exp(div(o, n2.hScale)), e2.h), a6 = mul(exp(div(a6, n2.wScale)), e2.w)) : (o = mul(div(o, n2.hScale), e2.h), a6 = mul(div(a6, n2.wScale), e2.h));
                var u2 = sub(r2, div(o, 2)), s = sub(i2, div(a6, 2)), c2 = add2(r2, div(o, 2)), l2 = add2(i2, div(a6, 2)), b = concat([reshape(u2, [n2.numBoxes, 1]), reshape(s, [n2.numBoxes, 1]), reshape(c2, [n2.numBoxes, 1]), reshape(l2, [n2.numBoxes, 1])], 1);
                if (n2.numKeypoints)
                  for (var x = 0; x < n2.numKeypoints; ++x) {
                    var M = n2.keypointCoordOffset + x * n2.numValuesPerKeypoint, A = void 0, T = void 0;
                    n2.reverseOutputOrder ? (A = squeeze(slice(t3, [0, M], [-1, 1])), T = squeeze(slice(t3, [0, M + 1], [-1, 1]))) : (T = squeeze(slice(t3, [0, M], [-1, 1])), A = squeeze(slice(t3, [0, M + 1], [-1, 1])));
                    var E2 = add2(mul(div(A, n2.xScale), e2.w), e2.x), S2 = add2(mul(div(T, n2.yScale), e2.h), e2.y);
                    b = concat([b, reshape(E2, [n2.numBoxes, 1]), reshape(S2, [n2.numBoxes, 1])], 1);
                  }
                return b;
              });
            }(i, e, n), u = tidy(function() {
              var t3 = r;
              return n.sigmoidScore ? (null != n.scoreClippingThresh && (t3 = clipByValue(r, -n.scoreClippingThresh, n.scoreClippingThresh)), t3 = sigmoid(t3)) : t3;
            }), [4, et(a, u, n)];
          case 1:
            return c = l.sent(), dispose([a, u]), [2, c];
        }
      });
    });
  }
  function et(t2, e, n) {
    return U(this, void 0, void 0, function() {
      var r, i, o, a, u, s, c, h, l, f, d, p2;
      return N(this, function(g) {
        switch (g.label) {
          case 0:
            return r = [], [4, t2.data()];
          case 1:
            return i = g.sent(), [4, e.data()];
          case 2:
            for (o = g.sent(), a = 0; a < n.numBoxes; ++a)
              if (!(null != n.minScoreThresh && o[a] < n.minScoreThresh || (u = a * n.numCoords, s = nt(i[u + 0], i[u + 1], i[u + 2], i[u + 3], o[a], n.flipVertically, a), (c = s.locationData.relativeBoundingBox).width < 0 || c.height < 0))) {
                if (n.numKeypoints > 0)
                  for ((h = s.locationData).relativeKeypoints = [], l = n.numKeypoints * n.numValuesPerKeypoint, f = 0; f < l; f += n.numValuesPerKeypoint)
                    d = u + n.keypointCoordOffset + f, p2 = { x: i[d + 0], y: n.flipVertically ? 1 - i[d + 1] : i[d + 1] }, h.relativeKeypoints.push(p2);
                r.push(s);
              }
            return [2, r];
        }
      });
    });
  }
  function nt(t2, e, n, r, i, o, a) {
    return { score: [i], ind: a, locationData: { relativeBoundingBox: { xMin: e, yMin: o ? 1 - n : t2, xMax: r, yMax: o ? 1 - t2 : n, width: r - e, height: n - t2 } } };
  }
  function ft(t2) {
    return U(this, void 0, void 0, function() {
      var e, n, r;
      return N(this, function(i) {
        switch (i.label) {
          case 0:
            return e = function(t3) {
              if (null == t3)
                return z({}, at);
              var e2 = z({}, t3);
              return null == e2.modelType && (e2.modelType = at.modelType), null == e2.maxFaces && (e2.maxFaces = at.maxFaces), null == e2.detectorModelUrl && ("full" === e2.modelType ? e2.detectorModelUrl = "https://tfhub.dev/mediapipe/tfjs-model/face_detection/full/1" : e2.detectorModelUrl = "https://tfhub.dev/mediapipe/tfjs-model/face_detection/short/1"), e2;
            }(t2), n = "string" == typeof e.detectorModelUrl && e.detectorModelUrl.indexOf("https://tfhub.dev") > -1, [4, loadGraphModel(e.detectorModelUrl, { fromTFHub: n })];
          case 1:
            return r = i.sent(), [2, new lt(e.modelType, r, e.maxFaces)];
        }
      });
    });
  }
  function dt(t2, e) {
    return U(this, void 0, void 0, function() {
      var n, r;
      return N(this, function(i) {
        if (t2 === rt.MediaPipeFaceDetector) {
          if (r = void 0, null != (n = e)) {
            if ("tfjs" === n.runtime)
              return [2, ft(n)];
            if ("mediapipe" === n.runtime)
              return [2, W(n)];
            r = n.runtime;
          }
          throw new Error("Expect modelConfig.runtime to be either 'tfjs' or 'mediapipe', but got " + r);
        }
        throw new Error(t2 + " is not a supported model name.");
      });
    });
  }
  function pt(t2) {
    return t2.width * t2.height;
  }
  function gt(t2) {
    var e = t2.xCenter - t2.width / 2, n = e + t2.width, r = t2.yCenter - t2.height / 2;
    return { xMin: e, xMax: n, yMin: r, yMax: r + t2.height, width: t2.width, height: t2.height };
  }
  function vt(t2, e) {
    var n = gt(t2), r = gt(e);
    if (!function(t3, e2) {
      return !(t3.xMax < e2.xMin || e2.xMax < t3.xMin || t3.yMax < e2.yMin || e2.yMax < t3.yMin);
    }(n, r))
      return 0;
    var i = pt(function(t3, e2) {
      var n2 = Math.max(t3.xMin, e2.xMin), r2 = Math.min(t3.xMax, e2.xMax), i2 = Math.max(t3.yMin, e2.yMin), o2 = Math.min(t3.yMax, e2.yMax);
      return { xMin: n2, xMax: r2, yMin: i2, yMax: o2, width: Math.max(r2 - n2, 0), height: Math.max(o2 - i2, 0) };
    }(n, r)), o = pt(n) + pt(r) - i;
    return o > 0 ? i / o : 0;
  }
  function mt(t2, e, n, r) {
    var i = t2.width, o = t2.height, a = r ? -1 : 1, u = Math.cos(t2.rotation), s = Math.sin(t2.rotation), c = t2.xCenter, h = t2.yCenter, l = 1 / e, f = 1 / n, d = new Array(16);
    return d[0] = i * u * a * l, d[1] = -o * s * l, d[2] = 0, d[3] = (-0.5 * i * u * a + 0.5 * o * s + c) * l, d[4] = i * s * a * f, d[5] = o * u * f, d[6] = 0, d[7] = (-0.5 * o * u - 0.5 * i * s * a + h) * f, d[8] = 0, d[9] = 0, d[10] = i * l, d[11] = 0, d[12] = 0, d[13] = 0, d[14] = 0, d[15] = 1, function(t3) {
      if (16 !== t3.length)
        throw new Error("Array length must be 16 but got " + t3.length);
      return [[t3[0], t3[1], t3[2], t3[3]], [t3[4], t3[5], t3[6], t3[7]], [t3[8], t3[9], t3[10], t3[11]], [t3[12], t3[13], t3[14], t3[15]]];
    }(d);
  }
  function yt(t2) {
    return t2 instanceof Tensor ? { height: t2.shape[0], width: t2.shape[1] } : { height: t2.height, width: t2.width };
  }
  function wt(t2) {
    return t2 - 2 * Math.PI * Math.floor((t2 + Math.PI) / (2 * Math.PI));
  }
  function bt(t2) {
    return t2 instanceof Tensor ? t2 : browser_exports.fromPixels(t2);
  }
  function xt(t2, n) {
    util_exports.assert(0 !== t2.width, function() {
      return n + " width cannot be 0.";
    }), util_exports.assert(0 !== t2.height, function() {
      return n + " height cannot be 0.";
    });
  }
  function Mt(t2, n) {
    var r = function(t3, e, n2, r2) {
      var i = e - t3, o = r2 - n2;
      if (0 === i)
        throw new Error("Original min and max are both " + t3 + ", range cannot be 0.");
      var a = o / i;
      return { scale: a, offset: n2 - t3 * a };
    }(0, 255, n[0], n[1]);
    return tidy(function() {
      return add2(mul(t2, r.scale), r.offset);
    });
  }
  function At(t2, n, r) {
    var i = n.outputTensorSize, o = n.keepAspectRatio, a = n.borderMode, u = n.outputTensorFloatRange, s = yt(t2), c = function(t3, e) {
      return e ? { xCenter: e.xCenter * t3.width, yCenter: e.yCenter * t3.height, width: e.width * t3.width, height: e.height * t3.height, rotation: e.rotation } : { xCenter: 0.5 * t3.width, yCenter: 0.5 * t3.height, width: t3.width, height: t3.height, rotation: 0 };
    }(s, r), h = function(t3, e, n2) {
      if (void 0 === n2 && (n2 = false), !n2)
        return { top: 0, left: 0, right: 0, bottom: 0 };
      var r2 = e.height, i2 = e.width;
      xt(e, "targetSize"), xt(t3, "roi");
      var o2, a6, u2 = r2 / i2, s2 = t3.height / t3.width, c2 = 0, h2 = 0;
      return u2 > s2 ? (o2 = t3.width, a6 = t3.width * u2, h2 = (1 - s2 / u2) / 2) : (o2 = t3.height / u2, a6 = t3.height, c2 = (1 - u2 / s2) / 2), t3.width = o2, t3.height = a6, { top: h2, left: c2, right: c2, bottom: h2 };
    }(c, i, o), l = mt(c, s.width, s.height, false), f = tidy(function() {
      var n2 = bt(t2), r2 = tensor2d(function(t3, e, n3) {
        return xt(n3, "inputResolution"), [1 / n3.width * t3[0][0] * e.width, 1 / n3.height * t3[0][1] * e.width, t3[0][3] * e.width, 1 / n3.width * t3[1][0] * e.height, 1 / n3.height * t3[1][1] * e.height, t3[1][3] * e.height, 0, 0];
      }(l, s, i), [1, 8]), o2 = "zero" === a ? "constant" : "nearest", c2 = image.transform(expandDims(cast(n2, "float32")), r2, "bilinear", o2, 0, [i.height, i.width]);
      return null != u ? Mt(c2, u) : c2;
    });
    return { imageTensor: f, padding: h, transformationMatrix: l };
  }
  function Tt(t2) {
    return { xCenter: t2.xMin + t2.width / 2, yCenter: t2.yMin + t2.height / 2, width: t2.width, height: t2.height };
  }
  function Et(t2) {
    var e = t2.relativeKeypoints;
    if (e.length <= 1)
      throw new Error("2 or more keypoints required to calculate a rect.");
    var n = Number.MAX_VALUE, r = Number.MAX_VALUE, i = Number.MIN_VALUE, o = Number.MIN_VALUE;
    return e.forEach(function(t3) {
      n = Math.min(n, t3.x), i = Math.max(i, t3.x), r = Math.min(r, t3.y), o = Math.max(o, t3.y);
    }), { xCenter: (n + i) / 2, yCenter: (r + o) / 2, width: i - n, height: o - r };
  }
  function St(t2, e, n, r, i) {
    var o = "rect" === n ? function(t3, e2, n2) {
      var r2, i2 = t3.locationData;
      if ("boundingbox" === e2)
        r2 = Tt(i2.boundingBox);
      else {
        r2 = Et(i2);
        var o2 = n2.width, a = n2.height;
        r2.xCenter = Math.round(r2.xCenter * o2), r2.yCenter = Math.round(r2.yCenter * a), r2.width = Math.round(r2.width * o2), r2.height = Math.round(r2.height * a);
      }
      return r2;
    }(t2, e, r) : function(t3, e2) {
      var n2 = t3.locationData;
      return "boundingbox" === e2 ? Tt(n2.relativeBoundingBox) : Et(n2);
    }(t2, e);
    return i && (o.rotation = function(t3, e2, n2) {
      var r2, i2 = t3.locationData, o2 = n2.rotationVectorStartKeypointIndex, a = n2.rotationVectorEndKeypointIndex;
      r2 = n2.rotationVectorTargetAngle ? n2.rotationVectorTargetAngle : Math.PI * n2.rotationVectorTargetAngleDegree / 180;
      var u = i2.relativeKeypoints[o2].x * e2.width, s = i2.relativeKeypoints[o2].y * e2.height, c = i2.relativeKeypoints[a].x * e2.width, h = i2.relativeKeypoints[a].y * e2.height;
      return wt(r2 - Math.atan2(-(h - s), c - u));
    }(t2, r, i)), o;
  }
  function Ft(t2, e, n) {
    for (var r = 0; r < e.length; ++r) {
      var i = e[r], o = n[t2[r]];
      o.x = i.x, o.y = i.y;
    }
  }
  function Ct(t2, e, n, r) {
    if ("string" == typeof e) {
      if ("copy" === e)
        for (var i = 0; i < n.length; ++i)
          r[t2[i]].z = n[i].z;
    } else {
      var o = function(t3, e2) {
        for (var n2 = 0, r2 = 0; r2 < e2.length; ++r2)
          n2 += t3[e2[r2]].z;
        return n2 / e2.length;
      }(r, e);
      for (i = 0; i < t2.length; ++i)
        r[t2[i]].z = o;
    }
  }
  function Ot(t2, e) {
    for (var n = function(t3) {
      var e2 = [].concat.apply([], t3.map(function(t4) {
        return t4.indexesMapping;
      }));
      if (0 === e2.length)
        throw new Error("There should be at least one landmark in indexes mapping");
      var n2 = e2[0], r2 = e2[0], i2 = new Set(e2);
      i2.forEach(function(t4) {
        n2 = Math.min(n2, t4), r2 = Math.max(r2, t4);
      });
      var o2 = i2.size;
      if (0 !== n2)
        throw new Error("Indexes are expected to start with 0 instead of " + n2);
      if (r2 + 1 !== o2)
        throw new Error("Indexes should have no gaps but " + (r2 - o2 + 1) + " indexes are missing");
      return o2;
    }(e), r = new Array(n).fill(null).map(Object), i = 0; i < t2.length; ++i) {
      var o = t2[i], a = e[i];
      if (o.length !== a.indexesMapping.length)
        throw new Error("There are " + o.length + " refinement landmarks while mapping has " + a.indexesMapping.length);
      Ft(a.indexesMapping, o, r), Ct(a.indexesMapping, a.zRefinement, o, r);
    }
    return r;
  }
  function _t(t2, e) {
    return t2.map(function(t3) {
      var n = E(E({}, t3), { x: t3.x * e.width, y: t3.y * e.height });
      return null != t3.z && (n.z = t3.z * e.width), n;
    });
  }
  function jt(t2, e) {
    return "none" === t2 ? e : function(t3) {
      return 1 / (1 + Math.exp(-t3));
    }(e);
  }
  function kt(t2, e, n, r) {
    return S(this, void 0, void 0, function() {
      var i, o, a, u, s, c, h, l;
      return F(this, function(f) {
        switch (f.label) {
          case 0:
            return n = n || e.flipHorizontally || false, r = r || e.flipVertically || false, i = t2.size, o = i / e.numLandmarks, [4, t2.data()];
          case 1:
            for (a = f.sent(), u = [], s = 0; s < e.numLandmarks; ++s)
              c = s * o, (l = { x: 0, y: 0 }).x = n ? e.inputImageWidth - a[c] : a[c], o > 1 && (l.y = r ? e.inputImageHeight - a[c + 1] : a[c + 1]), o > 2 && (l.z = a[c + 2]), o > 3 && (l.score = jt(e.visibilityActivation, a[c + 3])), u.push(l);
            for (h = 0; h < u.length; ++h)
              (l = u[h]).x = l.x / e.inputImageWidth, l.y = l.y / e.inputImageHeight, l.z = l.z / e.inputImageWidth / (e.normalizeZ || 1);
            return [2, u];
        }
      });
    });
  }
  function Rt(t2, e, n) {
    var r = t2.width, i = t2.height, o = t2.rotation;
    if (null == n.rotation && null == n.rotationDegree || (o = function(t3, e2) {
      null != e2.rotation ? t3 += e2.rotation : null != e2.rotationDegree && (t3 += Math.PI * e2.rotationDegree / 180);
      return wt(t3);
    }(o, n)), 0 === o)
      t2.xCenter = t2.xCenter + r * n.shiftX, t2.yCenter = t2.yCenter + i * n.shiftY;
    else {
      var a = (e.width * r * n.shiftX * Math.cos(o) - e.height * i * n.shiftY * Math.sin(o)) / e.width, u = (e.width * r * n.shiftX * Math.sin(o) + e.height * i * n.shiftY * Math.cos(o)) / e.height;
      t2.xCenter = t2.xCenter + a, t2.yCenter = t2.yCenter + u;
    }
    if (n.squareLong) {
      var s = Math.max(r * e.width, i * e.height);
      r = s / e.width, i = s / e.height;
    } else if (n.squareShort) {
      var c = Math.min(r * e.width, i * e.height);
      r = c / e.width, i = c / e.height;
    }
    return t2.width = r * n.scaleX, t2.height = i * n.scaleY, t2;
  }
  function qt(t2) {
    return S(this, void 0, void 0, function() {
      var e, n, r, i;
      return F(this, function(o) {
        switch (o.label) {
          case 0:
            return e = function(t3) {
              if (null == t3)
                return E({}, It);
              var e2 = E({}, t3);
              return e2.runtime = "tfjs", null == e2.maxFaces && (e2.maxFaces = It.maxFaces), null == e2.refineLandmarks && (e2.refineLandmarks = It.refineLandmarks), null == e2.landmarkModelUrl && (e2.landmarkModelUrl = e2.refineLandmarks ? "https://tfhub.dev/mediapipe/tfjs-model/face_landmarks_detection/attention_mesh/1" : "https://tfhub.dev/mediapipe/tfjs-model/face_landmarks_detection/face_mesh/1"), e2;
            }(t2), n = "string" == typeof e.landmarkModelUrl && e.landmarkModelUrl.indexOf("https://tfhub.dev") > -1, [4, loadGraphModel(e.landmarkModelUrl, { fromTFHub: n })];
          case 1:
            return r = o.sent(), [4, dt(rt.MediaPipeFaceDetector, { modelType: "short", maxFaces: e.maxFaces, detectorModelUrl: e.detectorModelUrl, runtime: e.runtime })];
          case 2:
            return i = o.sent(), [2, new Jt(i, r, e.maxFaces, e.refineLandmarks)];
        }
      });
    });
  }
  function $t(t2, e) {
    return S(this, void 0, void 0, function() {
      var n, r;
      return F(this, function(i) {
        if (t2 === Yt.MediaPipeFaceMesh) {
          if (r = void 0, null != (n = e)) {
            if ("tfjs" === n.runtime)
              return [2, qt(n)];
            if ("mediapipe" === n.runtime)
              return [2, B(n)];
            r = n.runtime;
          }
          throw new Error("Expect modelConfig.runtime to be either 'tfjs' or 'mediapipe', but got " + r);
        }
        throw new Error(t2 + " is not a supported model name.");
      });
    });
  }
  var t, E, O, _, j, k, I, L, D, P, z, V, H, K, rt, it, ot, at, ut, st, ct, ht, lt, It, Lt, Bt, Dt, Pt, zt, Ut, Nt, Vt, Ht, Kt, Wt, Gt, Xt, Yt, Jt, Zt;
  var init_face_landmarks_detection_esm = __esm({
    "node_modules/@tensorflow-models/face-landmarks-detection/dist/face-landmarks-detection.esm.js"() {
      t = __toESM(require_face_mesh());
      init_dist();
      init_dist();
      init_dist2();
      init_dist2();
      E = function() {
        return E = Object.assign || function(t2) {
          for (var e, n = 1, r = arguments.length; n < r; n++)
            for (var i in e = arguments[n])
              Object.prototype.hasOwnProperty.call(e, i) && (t2[i] = e[i]);
          return t2;
        }, E.apply(this, arguments);
      };
      O = { lips: C([[61, 146], [146, 91], [91, 181], [181, 84], [84, 17], [17, 314], [314, 405], [405, 321], [321, 375], [375, 291], [61, 185], [185, 40], [40, 39], [39, 37], [37, 0], [0, 267], [267, 269], [269, 270], [270, 409], [409, 291], [78, 95], [95, 88], [88, 178], [178, 87], [87, 14], [14, 317], [317, 402], [402, 318], [318, 324], [324, 308], [78, 191], [191, 80], [80, 81], [81, 82], [82, 13], [13, 312], [312, 311], [311, 310], [310, 415], [415, 308]]), leftEye: C([[263, 249], [249, 390], [390, 373], [373, 374], [374, 380], [380, 381], [381, 382], [382, 362], [263, 466], [466, 388], [388, 387], [387, 386], [386, 385], [385, 384], [384, 398], [398, 362]]), leftEyebrow: C([[276, 283], [283, 282], [282, 295], [295, 285], [300, 293], [293, 334], [334, 296], [296, 336]]), leftIris: C([[474, 475], [475, 476], [476, 477], [477, 474]]), rightEye: C([[33, 7], [7, 163], [163, 144], [144, 145], [145, 153], [153, 154], [154, 155], [155, 133], [33, 246], [246, 161], [161, 160], [160, 159], [159, 158], [158, 157], [157, 173], [173, 133]]), rightEyebrow: C([[46, 53], [53, 52], [52, 65], [65, 55], [70, 63], [63, 105], [105, 66], [66, 107]]), rightIris: C([[469, 470], [470, 471], [471, 472], [472, 469]]), faceOval: C([[10, 338], [338, 297], [297, 332], [332, 284], [284, 251], [251, 389], [389, 356], [356, 454], [454, 323], [323, 361], [361, 288], [288, 397], [397, 365], [365, 379], [379, 378], [378, 400], [400, 377], [377, 152], [152, 148], [148, 176], [176, 149], [149, 150], [150, 136], [136, 172], [172, 58], [58, 132], [132, 93], [93, 234], [234, 127], [127, 162], [162, 21], [21, 54], [54, 103], [103, 67], [67, 109], [109, 10]]) };
      _ = [[127, 34], [34, 139], [139, 127], [11, 0], [0, 37], [37, 11], [232, 231], [231, 120], [120, 232], [72, 37], [37, 39], [39, 72], [128, 121], [121, 47], [47, 128], [232, 121], [121, 128], [128, 232], [104, 69], [69, 67], [67, 104], [175, 171], [171, 148], [148, 175], [118, 50], [50, 101], [101, 118], [73, 39], [39, 40], [40, 73], [9, 151], [151, 108], [108, 9], [48, 115], [115, 131], [131, 48], [194, 204], [204, 211], [211, 194], [74, 40], [40, 185], [185, 74], [80, 42], [42, 183], [183, 80], [40, 92], [92, 186], [186, 40], [230, 229], [229, 118], [118, 230], [202, 212], [212, 214], [214, 202], [83, 18], [18, 17], [17, 83], [76, 61], [61, 146], [146, 76], [160, 29], [29, 30], [30, 160], [56, 157], [157, 173], [173, 56], [106, 204], [204, 194], [194, 106], [135, 214], [214, 192], [192, 135], [203, 165], [165, 98], [98, 203], [21, 71], [71, 68], [68, 21], [51, 45], [45, 4], [4, 51], [144, 24], [24, 23], [23, 144], [77, 146], [146, 91], [91, 77], [205, 50], [50, 187], [187, 205], [201, 200], [200, 18], [18, 201], [91, 106], [106, 182], [182, 91], [90, 91], [91, 181], [181, 90], [85, 84], [84, 17], [17, 85], [206, 203], [203, 36], [36, 206], [148, 171], [171, 140], [140, 148], [92, 40], [40, 39], [39, 92], [193, 189], [189, 244], [244, 193], [159, 158], [158, 28], [28, 159], [247, 246], [246, 161], [161, 247], [236, 3], [3, 196], [196, 236], [54, 68], [68, 104], [104, 54], [193, 168], [168, 8], [8, 193], [117, 228], [228, 31], [31, 117], [189, 193], [193, 55], [55, 189], [98, 97], [97, 99], [99, 98], [126, 47], [47, 100], [100, 126], [166, 79], [79, 218], [218, 166], [155, 154], [154, 26], [26, 155], [209, 49], [49, 131], [131, 209], [135, 136], [136, 150], [150, 135], [47, 126], [126, 217], [217, 47], [223, 52], [52, 53], [53, 223], [45, 51], [51, 134], [134, 45], [211, 170], [170, 140], [140, 211], [67, 69], [69, 108], [108, 67], [43, 106], [106, 91], [91, 43], [230, 119], [119, 120], [120, 230], [226, 130], [130, 247], [247, 226], [63, 53], [53, 52], [52, 63], [238, 20], [20, 242], [242, 238], [46, 70], [70, 156], [156, 46], [78, 62], [62, 96], [96, 78], [46, 53], [53, 63], [63, 46], [143, 34], [34, 227], [227, 143], [123, 117], [117, 111], [111, 123], [44, 125], [125, 19], [19, 44], [236, 134], [134, 51], [51, 236], [216, 206], [206, 205], [205, 216], [154, 153], [153, 22], [22, 154], [39, 37], [37, 167], [167, 39], [200, 201], [201, 208], [208, 200], [36, 142], [142, 100], [100, 36], [57, 212], [212, 202], [202, 57], [20, 60], [60, 99], [99, 20], [28, 158], [158, 157], [157, 28], [35, 226], [226, 113], [113, 35], [160, 159], [159, 27], [27, 160], [204, 202], [202, 210], [210, 204], [113, 225], [225, 46], [46, 113], [43, 202], [202, 204], [204, 43], [62, 76], [76, 77], [77, 62], [137, 123], [123, 116], [116, 137], [41, 38], [38, 72], [72, 41], [203, 129], [129, 142], [142, 203], [64, 98], [98, 240], [240, 64], [49, 102], [102, 64], [64, 49], [41, 73], [73, 74], [74, 41], [212, 216], [216, 207], [207, 212], [42, 74], [74, 184], [184, 42], [169, 170], [170, 211], [211, 169], [170, 149], [149, 176], [176, 170], [105, 66], [66, 69], [69, 105], [122, 6], [6, 168], [168, 122], [123, 147], [147, 187], [187, 123], [96, 77], [77, 90], [90, 96], [65, 55], [55, 107], [107, 65], [89, 90], [90, 180], [180, 89], [101, 100], [100, 120], [120, 101], [63, 105], [105, 104], [104, 63], [93, 137], [137, 227], [227, 93], [15, 86], [86, 85], [85, 15], [129, 102], [102, 49], [49, 129], [14, 87], [87, 86], [86, 14], [55, 8], [8, 9], [9, 55], [100, 47], [47, 121], [121, 100], [145, 23], [23, 22], [22, 145], [88, 89], [89, 179], [179, 88], [6, 122], [122, 196], [196, 6], [88, 95], [95, 96], [96, 88], [138, 172], [172, 136], [136, 138], [215, 58], [58, 172], [172, 215], [115, 48], [48, 219], [219, 115], [42, 80], [80, 81], [81, 42], [195, 3], [3, 51], [51, 195], [43, 146], [146, 61], [61, 43], [171, 175], [175, 199], [199, 171], [81, 82], [82, 38], [38, 81], [53, 46], [46, 225], [225, 53], [144, 163], [163, 110], [110, 144], [52, 65], [65, 66], [66, 52], [229, 228], [228, 117], [117, 229], [34, 127], [127, 234], [234, 34], [107, 108], [108, 69], [69, 107], [109, 108], [108, 151], [151, 109], [48, 64], [64, 235], [235, 48], [62, 78], [78, 191], [191, 62], [129, 209], [209, 126], [126, 129], [111, 35], [35, 143], [143, 111], [117, 123], [123, 50], [50, 117], [222, 65], [65, 52], [52, 222], [19, 125], [125, 141], [141, 19], [221, 55], [55, 65], [65, 221], [3, 195], [195, 197], [197, 3], [25, 7], [7, 33], [33, 25], [220, 237], [237, 44], [44, 220], [70, 71], [71, 139], [139, 70], [122, 193], [193, 245], [245, 122], [247, 130], [130, 33], [33, 247], [71, 21], [21, 162], [162, 71], [170, 169], [169, 150], [150, 170], [188, 174], [174, 196], [196, 188], [216, 186], [186, 92], [92, 216], [2, 97], [97, 167], [167, 2], [141, 125], [125, 241], [241, 141], [164, 167], [167, 37], [37, 164], [72, 38], [38, 12], [12, 72], [38, 82], [82, 13], [13, 38], [63, 68], [68, 71], [71, 63], [226, 35], [35, 111], [111, 226], [101, 50], [50, 205], [205, 101], [206, 92], [92, 165], [165, 206], [209, 198], [198, 217], [217, 209], [165, 167], [167, 97], [97, 165], [220, 115], [115, 218], [218, 220], [133, 112], [112, 243], [243, 133], [239, 238], [238, 241], [241, 239], [214, 135], [135, 169], [169, 214], [190, 173], [173, 133], [133, 190], [171, 208], [208, 32], [32, 171], [125, 44], [44, 237], [237, 125], [86, 87], [87, 178], [178, 86], [85, 86], [86, 179], [179, 85], [84, 85], [85, 180], [180, 84], [83, 84], [84, 181], [181, 83], [201, 83], [83, 182], [182, 201], [137, 93], [93, 132], [132, 137], [76, 62], [62, 183], [183, 76], [61, 76], [76, 184], [184, 61], [57, 61], [61, 185], [185, 57], [212, 57], [57, 186], [186, 212], [214, 207], [207, 187], [187, 214], [34, 143], [143, 156], [156, 34], [79, 239], [239, 237], [237, 79], [123, 137], [137, 177], [177, 123], [44, 1], [1, 4], [4, 44], [201, 194], [194, 32], [32, 201], [64, 102], [102, 129], [129, 64], [213, 215], [215, 138], [138, 213], [59, 166], [166, 219], [219, 59], [242, 99], [99, 97], [97, 242], [2, 94], [94, 141], [141, 2], [75, 59], [59, 235], [235, 75], [24, 110], [110, 228], [228, 24], [25, 130], [130, 226], [226, 25], [23, 24], [24, 229], [229, 23], [22, 23], [23, 230], [230, 22], [26, 22], [22, 231], [231, 26], [112, 26], [26, 232], [232, 112], [189, 190], [190, 243], [243, 189], [221, 56], [56, 190], [190, 221], [28, 56], [56, 221], [221, 28], [27, 28], [28, 222], [222, 27], [29, 27], [27, 223], [223, 29], [30, 29], [29, 224], [224, 30], [247, 30], [30, 225], [225, 247], [238, 79], [79, 20], [20, 238], [166, 59], [59, 75], [75, 166], [60, 75], [75, 240], [240, 60], [147, 177], [177, 215], [215, 147], [20, 79], [79, 166], [166, 20], [187, 147], [147, 213], [213, 187], [112, 233], [233, 244], [244, 112], [233, 128], [128, 245], [245, 233], [128, 114], [114, 188], [188, 128], [114, 217], [217, 174], [174, 114], [131, 115], [115, 220], [220, 131], [217, 198], [198, 236], [236, 217], [198, 131], [131, 134], [134, 198], [177, 132], [132, 58], [58, 177], [143, 35], [35, 124], [124, 143], [110, 163], [163, 7], [7, 110], [228, 110], [110, 25], [25, 228], [356, 389], [389, 368], [368, 356], [11, 302], [302, 267], [267, 11], [452, 350], [350, 349], [349, 452], [302, 303], [303, 269], [269, 302], [357, 343], [343, 277], [277, 357], [452, 453], [453, 357], [357, 452], [333, 332], [332, 297], [297, 333], [175, 152], [152, 377], [377, 175], [347, 348], [348, 330], [330, 347], [303, 304], [304, 270], [270, 303], [9, 336], [336, 337], [337, 9], [278, 279], [279, 360], [360, 278], [418, 262], [262, 431], [431, 418], [304, 408], [408, 409], [409, 304], [310, 415], [415, 407], [407, 310], [270, 409], [409, 410], [410, 270], [450, 348], [348, 347], [347, 450], [422, 430], [430, 434], [434, 422], [313, 314], [314, 17], [17, 313], [306, 307], [307, 375], [375, 306], [387, 388], [388, 260], [260, 387], [286, 414], [414, 398], [398, 286], [335, 406], [406, 418], [418, 335], [364, 367], [367, 416], [416, 364], [423, 358], [358, 327], [327, 423], [251, 284], [284, 298], [298, 251], [281, 5], [5, 4], [4, 281], [373, 374], [374, 253], [253, 373], [307, 320], [320, 321], [321, 307], [425, 427], [427, 411], [411, 425], [421, 313], [313, 18], [18, 421], [321, 405], [405, 406], [406, 321], [320, 404], [404, 405], [405, 320], [315, 16], [16, 17], [17, 315], [426, 425], [425, 266], [266, 426], [377, 400], [400, 369], [369, 377], [322, 391], [391, 269], [269, 322], [417, 465], [465, 464], [464, 417], [386, 257], [257, 258], [258, 386], [466, 260], [260, 388], [388, 466], [456, 399], [399, 419], [419, 456], [284, 332], [332, 333], [333, 284], [417, 285], [285, 8], [8, 417], [346, 340], [340, 261], [261, 346], [413, 441], [441, 285], [285, 413], [327, 460], [460, 328], [328, 327], [355, 371], [371, 329], [329, 355], [392, 439], [439, 438], [438, 392], [382, 341], [341, 256], [256, 382], [429, 420], [420, 360], [360, 429], [364, 394], [394, 379], [379, 364], [277, 343], [343, 437], [437, 277], [443, 444], [444, 283], [283, 443], [275, 440], [440, 363], [363, 275], [431, 262], [262, 369], [369, 431], [297, 338], [338, 337], [337, 297], [273, 375], [375, 321], [321, 273], [450, 451], [451, 349], [349, 450], [446, 342], [342, 467], [467, 446], [293, 334], [334, 282], [282, 293], [458, 461], [461, 462], [462, 458], [276, 353], [353, 383], [383, 276], [308, 324], [324, 325], [325, 308], [276, 300], [300, 293], [293, 276], [372, 345], [345, 447], [447, 372], [352, 345], [345, 340], [340, 352], [274, 1], [1, 19], [19, 274], [456, 248], [248, 281], [281, 456], [436, 427], [427, 425], [425, 436], [381, 256], [256, 252], [252, 381], [269, 391], [391, 393], [393, 269], [200, 199], [199, 428], [428, 200], [266, 330], [330, 329], [329, 266], [287, 273], [273, 422], [422, 287], [250, 462], [462, 328], [328, 250], [258, 286], [286, 384], [384, 258], [265, 353], [353, 342], [342, 265], [387, 259], [259, 257], [257, 387], [424, 431], [431, 430], [430, 424], [342, 353], [353, 276], [276, 342], [273, 335], [335, 424], [424, 273], [292, 325], [325, 307], [307, 292], [366, 447], [447, 345], [345, 366], [271, 303], [303, 302], [302, 271], [423, 266], [266, 371], [371, 423], [294, 455], [455, 460], [460, 294], [279, 278], [278, 294], [294, 279], [271, 272], [272, 304], [304, 271], [432, 434], [434, 427], [427, 432], [272, 407], [407, 408], [408, 272], [394, 430], [430, 431], [431, 394], [395, 369], [369, 400], [400, 395], [334, 333], [333, 299], [299, 334], [351, 417], [417, 168], [168, 351], [352, 280], [280, 411], [411, 352], [325, 319], [319, 320], [320, 325], [295, 296], [296, 336], [336, 295], [319, 403], [403, 404], [404, 319], [330, 348], [348, 349], [349, 330], [293, 298], [298, 333], [333, 293], [323, 454], [454, 447], [447, 323], [15, 16], [16, 315], [315, 15], [358, 429], [429, 279], [279, 358], [14, 15], [15, 316], [316, 14], [285, 336], [336, 9], [9, 285], [329, 349], [349, 350], [350, 329], [374, 380], [380, 252], [252, 374], [318, 402], [402, 403], [403, 318], [6, 197], [197, 419], [419, 6], [318, 319], [319, 325], [325, 318], [367, 364], [364, 365], [365, 367], [435, 367], [367, 397], [397, 435], [344, 438], [438, 439], [439, 344], [272, 271], [271, 311], [311, 272], [195, 5], [5, 281], [281, 195], [273, 287], [287, 291], [291, 273], [396, 428], [428, 199], [199, 396], [311, 271], [271, 268], [268, 311], [283, 444], [444, 445], [445, 283], [373, 254], [254, 339], [339, 373], [282, 334], [334, 296], [296, 282], [449, 347], [347, 346], [346, 449], [264, 447], [447, 454], [454, 264], [336, 296], [296, 299], [299, 336], [338, 10], [10, 151], [151, 338], [278, 439], [439, 455], [455, 278], [292, 407], [407, 415], [415, 292], [358, 371], [371, 355], [355, 358], [340, 345], [345, 372], [372, 340], [346, 347], [347, 280], [280, 346], [442, 443], [443, 282], [282, 442], [19, 94], [94, 370], [370, 19], [441, 442], [442, 295], [295, 441], [248, 419], [419, 197], [197, 248], [263, 255], [255, 359], [359, 263], [440, 275], [275, 274], [274, 440], [300, 383], [383, 368], [368, 300], [351, 412], [412, 465], [465, 351], [263, 467], [467, 466], [466, 263], [301, 368], [368, 389], [389, 301], [395, 378], [378, 379], [379, 395], [412, 351], [351, 419], [419, 412], [436, 426], [426, 322], [322, 436], [2, 164], [164, 393], [393, 2], [370, 462], [462, 461], [461, 370], [164, 0], [0, 267], [267, 164], [302, 11], [11, 12], [12, 302], [268, 12], [12, 13], [13, 268], [293, 300], [300, 301], [301, 293], [446, 261], [261, 340], [340, 446], [330, 266], [266, 425], [425, 330], [426, 423], [423, 391], [391, 426], [429, 355], [355, 437], [437, 429], [391, 327], [327, 326], [326, 391], [440, 457], [457, 438], [438, 440], [341, 382], [382, 362], [362, 341], [459, 457], [457, 461], [461, 459], [434, 430], [430, 394], [394, 434], [414, 463], [463, 362], [362, 414], [396, 369], [369, 262], [262, 396], [354, 461], [461, 457], [457, 354], [316, 403], [403, 402], [402, 316], [315, 404], [404, 403], [403, 315], [314, 405], [405, 404], [404, 314], [313, 406], [406, 405], [405, 313], [421, 418], [418, 406], [406, 421], [366, 401], [401, 361], [361, 366], [306, 408], [408, 407], [407, 306], [291, 409], [409, 408], [408, 291], [287, 410], [410, 409], [409, 287], [432, 436], [436, 410], [410, 432], [434, 416], [416, 411], [411, 434], [264, 368], [368, 383], [383, 264], [309, 438], [438, 457], [457, 309], [352, 376], [376, 401], [401, 352], [274, 275], [275, 4], [4, 274], [421, 428], [428, 262], [262, 421], [294, 327], [327, 358], [358, 294], [433, 416], [416, 367], [367, 433], [289, 455], [455, 439], [439, 289], [462, 370], [370, 326], [326, 462], [2, 326], [326, 370], [370, 2], [305, 460], [460, 455], [455, 305], [254, 449], [449, 448], [448, 254], [255, 261], [261, 446], [446, 255], [253, 450], [450, 449], [449, 253], [252, 451], [451, 450], [450, 252], [256, 452], [452, 451], [451, 256], [341, 453], [453, 452], [452, 341], [413, 464], [464, 463], [463, 413], [441, 413], [413, 414], [414, 441], [258, 442], [442, 441], [441, 258], [257, 443], [443, 442], [442, 257], [259, 444], [444, 443], [443, 259], [260, 445], [445, 444], [444, 260], [467, 342], [342, 445], [445, 467], [459, 458], [458, 250], [250, 459], [289, 392], [392, 290], [290, 289], [290, 328], [328, 460], [460, 290], [376, 433], [433, 435], [435, 376], [250, 290], [290, 392], [392, 250], [411, 416], [416, 433], [433, 411], [341, 463], [463, 464], [464, 341], [453, 464], [464, 465], [465, 453], [357, 465], [465, 412], [412, 357], [343, 412], [412, 399], [399, 343], [360, 363], [363, 440], [440, 360], [437, 399], [399, 456], [456, 437], [420, 456], [456, 363], [363, 420], [401, 435], [435, 288], [288, 401], [372, 383], [383, 353], [353, 372], [339, 255], [255, 249], [249, 339], [448, 261], [261, 255], [255, 448], [133, 243], [243, 190], [190, 133], [133, 155], [155, 112], [112, 133], [33, 246], [246, 247], [247, 33], [33, 130], [130, 25], [25, 33], [398, 384], [384, 286], [286, 398], [362, 398], [398, 414], [414, 362], [362, 463], [463, 341], [341, 362], [263, 359], [359, 467], [467, 263], [263, 249], [249, 255], [255, 263], [466, 467], [467, 260], [260, 466], [75, 60], [60, 166], [166, 75], [238, 239], [239, 79], [79, 238], [162, 127], [127, 139], [139, 162], [72, 11], [11, 37], [37, 72], [121, 232], [232, 120], [120, 121], [73, 72], [72, 39], [39, 73], [114, 128], [128, 47], [47, 114], [233, 232], [232, 128], [128, 233], [103, 104], [104, 67], [67, 103], [152, 175], [175, 148], [148, 152], [119, 118], [118, 101], [101, 119], [74, 73], [73, 40], [40, 74], [107, 9], [9, 108], [108, 107], [49, 48], [48, 131], [131, 49], [32, 194], [194, 211], [211, 32], [184, 74], [74, 185], [185, 184], [191, 80], [80, 183], [183, 191], [185, 40], [40, 186], [186, 185], [119, 230], [230, 118], [118, 119], [210, 202], [202, 214], [214, 210], [84, 83], [83, 17], [17, 84], [77, 76], [76, 146], [146, 77], [161, 160], [160, 30], [30, 161], [190, 56], [56, 173], [173, 190], [182, 106], [106, 194], [194, 182], [138, 135], [135, 192], [192, 138], [129, 203], [203, 98], [98, 129], [54, 21], [21, 68], [68, 54], [5, 51], [51, 4], [4, 5], [145, 144], [144, 23], [23, 145], [90, 77], [77, 91], [91, 90], [207, 205], [205, 187], [187, 207], [83, 201], [201, 18], [18, 83], [181, 91], [91, 182], [182, 181], [180, 90], [90, 181], [181, 180], [16, 85], [85, 17], [17, 16], [205, 206], [206, 36], [36, 205], [176, 148], [148, 140], [140, 176], [165, 92], [92, 39], [39, 165], [245, 193], [193, 244], [244, 245], [27, 159], [159, 28], [28, 27], [30, 247], [247, 161], [161, 30], [174, 236], [236, 196], [196, 174], [103, 54], [54, 104], [104, 103], [55, 193], [193, 8], [8, 55], [111, 117], [117, 31], [31, 111], [221, 189], [189, 55], [55, 221], [240, 98], [98, 99], [99, 240], [142, 126], [126, 100], [100, 142], [219, 166], [166, 218], [218, 219], [112, 155], [155, 26], [26, 112], [198, 209], [209, 131], [131, 198], [169, 135], [135, 150], [150, 169], [114, 47], [47, 217], [217, 114], [224, 223], [223, 53], [53, 224], [220, 45], [45, 134], [134, 220], [32, 211], [211, 140], [140, 32], [109, 67], [67, 108], [108, 109], [146, 43], [43, 91], [91, 146], [231, 230], [230, 120], [120, 231], [113, 226], [226, 247], [247, 113], [105, 63], [63, 52], [52, 105], [241, 238], [238, 242], [242, 241], [124, 46], [46, 156], [156, 124], [95, 78], [78, 96], [96, 95], [70, 46], [46, 63], [63, 70], [116, 143], [143, 227], [227, 116], [116, 123], [123, 111], [111, 116], [1, 44], [44, 19], [19, 1], [3, 236], [236, 51], [51, 3], [207, 216], [216, 205], [205, 207], [26, 154], [154, 22], [22, 26], [165, 39], [39, 167], [167, 165], [199, 200], [200, 208], [208, 199], [101, 36], [36, 100], [100, 101], [43, 57], [57, 202], [202, 43], [242, 20], [20, 99], [99, 242], [56, 28], [28, 157], [157, 56], [124, 35], [35, 113], [113, 124], [29, 160], [160, 27], [27, 29], [211, 204], [204, 210], [210, 211], [124, 113], [113, 46], [46, 124], [106, 43], [43, 204], [204, 106], [96, 62], [62, 77], [77, 96], [227, 137], [137, 116], [116, 227], [73, 41], [41, 72], [72, 73], [36, 203], [203, 142], [142, 36], [235, 64], [64, 240], [240, 235], [48, 49], [49, 64], [64, 48], [42, 41], [41, 74], [74, 42], [214, 212], [212, 207], [207, 214], [183, 42], [42, 184], [184, 183], [210, 169], [169, 211], [211, 210], [140, 170], [170, 176], [176, 140], [104, 105], [105, 69], [69, 104], [193, 122], [122, 168], [168, 193], [50, 123], [123, 187], [187, 50], [89, 96], [96, 90], [90, 89], [66, 65], [65, 107], [107, 66], [179, 89], [89, 180], [180, 179], [119, 101], [101, 120], [120, 119], [68, 63], [63, 104], [104, 68], [234, 93], [93, 227], [227, 234], [16, 15], [15, 85], [85, 16], [209, 129], [129, 49], [49, 209], [15, 14], [14, 86], [86, 15], [107, 55], [55, 9], [9, 107], [120, 100], [100, 121], [121, 120], [153, 145], [145, 22], [22, 153], [178, 88], [88, 179], [179, 178], [197, 6], [6, 196], [196, 197], [89, 88], [88, 96], [96, 89], [135, 138], [138, 136], [136, 135], [138, 215], [215, 172], [172, 138], [218, 115], [115, 219], [219, 218], [41, 42], [42, 81], [81, 41], [5, 195], [195, 51], [51, 5], [57, 43], [43, 61], [61, 57], [208, 171], [171, 199], [199, 208], [41, 81], [81, 38], [38, 41], [224, 53], [53, 225], [225, 224], [24, 144], [144, 110], [110, 24], [105, 52], [52, 66], [66, 105], [118, 229], [229, 117], [117, 118], [227, 34], [34, 234], [234, 227], [66, 107], [107, 69], [69, 66], [10, 109], [109, 151], [151, 10], [219, 48], [48, 235], [235, 219], [183, 62], [62, 191], [191, 183], [142, 129], [129, 126], [126, 142], [116, 111], [111, 143], [143, 116], [118, 117], [117, 50], [50, 118], [223, 222], [222, 52], [52, 223], [94, 19], [19, 141], [141, 94], [222, 221], [221, 65], [65, 222], [196, 3], [3, 197], [197, 196], [45, 220], [220, 44], [44, 45], [156, 70], [70, 139], [139, 156], [188, 122], [122, 245], [245, 188], [139, 71], [71, 162], [162, 139], [149, 170], [170, 150], [150, 149], [122, 188], [188, 196], [196, 122], [206, 216], [216, 92], [92, 206], [164, 2], [2, 167], [167, 164], [242, 141], [141, 241], [241, 242], [0, 164], [164, 37], [37, 0], [11, 72], [72, 12], [12, 11], [12, 38], [38, 13], [13, 12], [70, 63], [63, 71], [71, 70], [31, 226], [226, 111], [111, 31], [36, 101], [101, 205], [205, 36], [203, 206], [206, 165], [165, 203], [126, 209], [209, 217], [217, 126], [98, 165], [165, 97], [97, 98], [237, 220], [220, 218], [218, 237], [237, 239], [239, 241], [241, 237], [210, 214], [214, 169], [169, 210], [140, 171], [171, 32], [32, 140], [241, 125], [125, 237], [237, 241], [179, 86], [86, 178], [178, 179], [180, 85], [85, 179], [179, 180], [181, 84], [84, 180], [180, 181], [182, 83], [83, 181], [181, 182], [194, 201], [201, 182], [182, 194], [177, 137], [137, 132], [132, 177], [184, 76], [76, 183], [183, 184], [185, 61], [61, 184], [184, 185], [186, 57], [57, 185], [185, 186], [216, 212], [212, 186], [186, 216], [192, 214], [214, 187], [187, 192], [139, 34], [34, 156], [156, 139], [218, 79], [79, 237], [237, 218], [147, 123], [123, 177], [177, 147], [45, 44], [44, 4], [4, 45], [208, 201], [201, 32], [32, 208], [98, 64], [64, 129], [129, 98], [192, 213], [213, 138], [138, 192], [235, 59], [59, 219], [219, 235], [141, 242], [242, 97], [97, 141], [97, 2], [2, 141], [141, 97], [240, 75], [75, 235], [235, 240], [229, 24], [24, 228], [228, 229], [31, 25], [25, 226], [226, 31], [230, 23], [23, 229], [229, 230], [231, 22], [22, 230], [230, 231], [232, 26], [26, 231], [231, 232], [233, 112], [112, 232], [232, 233], [244, 189], [189, 243], [243, 244], [189, 221], [221, 190], [190, 189], [222, 28], [28, 221], [221, 222], [223, 27], [27, 222], [222, 223], [224, 29], [29, 223], [223, 224], [225, 30], [30, 224], [224, 225], [113, 247], [247, 225], [225, 113], [99, 60], [60, 240], [240, 99], [213, 147], [147, 215], [215, 213], [60, 20], [20, 166], [166, 60], [192, 187], [187, 213], [213, 192], [243, 112], [112, 244], [244, 243], [244, 233], [233, 245], [245, 244], [245, 128], [128, 188], [188, 245], [188, 114], [114, 174], [174, 188], [134, 131], [131, 220], [220, 134], [174, 217], [217, 236], [236, 174], [236, 198], [198, 134], [134, 236], [215, 177], [177, 58], [58, 215], [156, 143], [143, 124], [124, 156], [25, 110], [110, 7], [7, 25], [31, 228], [228, 25], [25, 31], [264, 356], [356, 368], [368, 264], [0, 11], [11, 267], [267, 0], [451, 452], [452, 349], [349, 451], [267, 302], [302, 269], [269, 267], [350, 357], [357, 277], [277, 350], [350, 452], [452, 357], [357, 350], [299, 333], [333, 297], [297, 299], [396, 175], [175, 377], [377, 396], [280, 347], [347, 330], [330, 280], [269, 303], [303, 270], [270, 269], [151, 9], [9, 337], [337, 151], [344, 278], [278, 360], [360, 344], [424, 418], [418, 431], [431, 424], [270, 304], [304, 409], [409, 270], [272, 310], [310, 407], [407, 272], [322, 270], [270, 410], [410, 322], [449, 450], [450, 347], [347, 449], [432, 422], [422, 434], [434, 432], [18, 313], [313, 17], [17, 18], [291, 306], [306, 375], [375, 291], [259, 387], [387, 260], [260, 259], [424, 335], [335, 418], [418, 424], [434, 364], [364, 416], [416, 434], [391, 423], [423, 327], [327, 391], [301, 251], [251, 298], [298, 301], [275, 281], [281, 4], [4, 275], [254, 373], [373, 253], [253, 254], [375, 307], [307, 321], [321, 375], [280, 425], [425, 411], [411, 280], [200, 421], [421, 18], [18, 200], [335, 321], [321, 406], [406, 335], [321, 320], [320, 405], [405, 321], [314, 315], [315, 17], [17, 314], [423, 426], [426, 266], [266, 423], [396, 377], [377, 369], [369, 396], [270, 322], [322, 269], [269, 270], [413, 417], [417, 464], [464, 413], [385, 386], [386, 258], [258, 385], [248, 456], [456, 419], [419, 248], [298, 284], [284, 333], [333, 298], [168, 417], [417, 8], [8, 168], [448, 346], [346, 261], [261, 448], [417, 413], [413, 285], [285, 417], [326, 327], [327, 328], [328, 326], [277, 355], [355, 329], [329, 277], [309, 392], [392, 438], [438, 309], [381, 382], [382, 256], [256, 381], [279, 429], [429, 360], [360, 279], [365, 364], [364, 379], [379, 365], [355, 277], [277, 437], [437, 355], [282, 443], [443, 283], [283, 282], [281, 275], [275, 363], [363, 281], [395, 431], [431, 369], [369, 395], [299, 297], [297, 337], [337, 299], [335, 273], [273, 321], [321, 335], [348, 450], [450, 349], [349, 348], [359, 446], [446, 467], [467, 359], [283, 293], [293, 282], [282, 283], [250, 458], [458, 462], [462, 250], [300, 276], [276, 383], [383, 300], [292, 308], [308, 325], [325, 292], [283, 276], [276, 293], [293, 283], [264, 372], [372, 447], [447, 264], [346, 352], [352, 340], [340, 346], [354, 274], [274, 19], [19, 354], [363, 456], [456, 281], [281, 363], [426, 436], [436, 425], [425, 426], [380, 381], [381, 252], [252, 380], [267, 269], [269, 393], [393, 267], [421, 200], [200, 428], [428, 421], [371, 266], [266, 329], [329, 371], [432, 287], [287, 422], [422, 432], [290, 250], [250, 328], [328, 290], [385, 258], [258, 384], [384, 385], [446, 265], [265, 342], [342, 446], [386, 387], [387, 257], [257, 386], [422, 424], [424, 430], [430, 422], [445, 342], [342, 276], [276, 445], [422, 273], [273, 424], [424, 422], [306, 292], [292, 307], [307, 306], [352, 366], [366, 345], [345, 352], [268, 271], [271, 302], [302, 268], [358, 423], [423, 371], [371, 358], [327, 294], [294, 460], [460, 327], [331, 279], [279, 294], [294, 331], [303, 271], [271, 304], [304, 303], [436, 432], [432, 427], [427, 436], [304, 272], [272, 408], [408, 304], [395, 394], [394, 431], [431, 395], [378, 395], [395, 400], [400, 378], [296, 334], [334, 299], [299, 296], [6, 351], [351, 168], [168, 6], [376, 352], [352, 411], [411, 376], [307, 325], [325, 320], [320, 307], [285, 295], [295, 336], [336, 285], [320, 319], [319, 404], [404, 320], [329, 330], [330, 349], [349, 329], [334, 293], [293, 333], [333, 334], [366, 323], [323, 447], [447, 366], [316, 15], [15, 315], [315, 316], [331, 358], [358, 279], [279, 331], [317, 14], [14, 316], [316, 317], [8, 285], [285, 9], [9, 8], [277, 329], [329, 350], [350, 277], [253, 374], [374, 252], [252, 253], [319, 318], [318, 403], [403, 319], [351, 6], [6, 419], [419, 351], [324, 318], [318, 325], [325, 324], [397, 367], [367, 365], [365, 397], [288, 435], [435, 397], [397, 288], [278, 344], [344, 439], [439, 278], [310, 272], [272, 311], [311, 310], [248, 195], [195, 281], [281, 248], [375, 273], [273, 291], [291, 375], [175, 396], [396, 199], [199, 175], [312, 311], [311, 268], [268, 312], [276, 283], [283, 445], [445, 276], [390, 373], [373, 339], [339, 390], [295, 282], [282, 296], [296, 295], [448, 449], [449, 346], [346, 448], [356, 264], [264, 454], [454, 356], [337, 336], [336, 299], [299, 337], [337, 338], [338, 151], [151, 337], [294, 278], [278, 455], [455, 294], [308, 292], [292, 415], [415, 308], [429, 358], [358, 355], [355, 429], [265, 340], [340, 372], [372, 265], [352, 346], [346, 280], [280, 352], [295, 442], [442, 282], [282, 295], [354, 19], [19, 370], [370, 354], [285, 441], [441, 295], [295, 285], [195, 248], [248, 197], [197, 195], [457, 440], [440, 274], [274, 457], [301, 300], [300, 368], [368, 301], [417, 351], [351, 465], [465, 417], [251, 301], [301, 389], [389, 251], [394, 395], [395, 379], [379, 394], [399, 412], [412, 419], [419, 399], [410, 436], [436, 322], [322, 410], [326, 2], [2, 393], [393, 326], [354, 370], [370, 461], [461, 354], [393, 164], [164, 267], [267, 393], [268, 302], [302, 12], [12, 268], [312, 268], [268, 13], [13, 312], [298, 293], [293, 301], [301, 298], [265, 446], [446, 340], [340, 265], [280, 330], [330, 425], [425, 280], [322, 426], [426, 391], [391, 322], [420, 429], [429, 437], [437, 420], [393, 391], [391, 326], [326, 393], [344, 440], [440, 438], [438, 344], [458, 459], [459, 461], [461, 458], [364, 434], [434, 394], [394, 364], [428, 396], [396, 262], [262, 428], [274, 354], [354, 457], [457, 274], [317, 316], [316, 402], [402, 317], [316, 315], [315, 403], [403, 316], [315, 314], [314, 404], [404, 315], [314, 313], [313, 405], [405, 314], [313, 421], [421, 406], [406, 313], [323, 366], [366, 361], [361, 323], [292, 306], [306, 407], [407, 292], [306, 291], [291, 408], [408, 306], [291, 287], [287, 409], [409, 291], [287, 432], [432, 410], [410, 287], [427, 434], [434, 411], [411, 427], [372, 264], [264, 383], [383, 372], [459, 309], [309, 457], [457, 459], [366, 352], [352, 401], [401, 366], [1, 274], [274, 4], [4, 1], [418, 421], [421, 262], [262, 418], [331, 294], [294, 358], [358, 331], [435, 433], [433, 367], [367, 435], [392, 289], [289, 439], [439, 392], [328, 462], [462, 326], [326, 328], [94, 2], [2, 370], [370, 94], [289, 305], [305, 455], [455, 289], [339, 254], [254, 448], [448, 339], [359, 255], [255, 446], [446, 359], [254, 253], [253, 449], [449, 254], [253, 252], [252, 450], [450, 253], [252, 256], [256, 451], [451, 252], [256, 341], [341, 452], [452, 256], [414, 413], [413, 463], [463, 414], [286, 441], [441, 414], [414, 286], [286, 258], [258, 441], [441, 286], [258, 257], [257, 442], [442, 258], [257, 259], [259, 443], [443, 257], [259, 260], [260, 444], [444, 259], [260, 467], [467, 445], [445, 260], [309, 459], [459, 250], [250, 309], [305, 289], [289, 290], [290, 305], [305, 290], [290, 460], [460, 305], [401, 376], [376, 435], [435, 401], [309, 250], [250, 392], [392, 309], [376, 411], [411, 433], [433, 376], [453, 341], [341, 464], [464, 453], [357, 453], [453, 465], [465, 357], [343, 357], [357, 412], [412, 343], [437, 343], [343, 399], [399, 437], [344, 360], [360, 440], [440, 344], [420, 437], [437, 456], [456, 420], [360, 420], [420, 363], [363, 360], [361, 401], [401, 288], [288, 361], [265, 372], [372, 353], [353, 265], [390, 339], [339, 249], [249, 390], [339, 448], [448, 255], [255, 339]];
      j = Object.entries(O).map(function(t2) {
        var e = t2[0];
        return t2[1].map(function(t3) {
          return [t3, e];
        });
      }).flat();
      k = new Map(j);
      I = { runtime: "mediapipe", maxFaces: 1, refineLandmarks: false };
      L = function() {
        function n(e) {
          var n2 = this;
          this.width = 0, this.height = 0, this.selfieMode = false, this.faceMeshSolution = new t.FaceMesh({ locateFile: function(t2, n3) {
            return e.solutionPath ? e.solutionPath.replace(/\/+$/, "") + "/" + t2 : n3 + "/" + t2;
          } }), this.faceMeshSolution.setOptions({ refineLandmarks: e.refineLandmarks, selfieMode: this.selfieMode, maxNumFaces: e.maxFaces }), this.faceMeshSolution.onResults(function(t2) {
            if (n2.height = t2.image.height, n2.width = t2.image.width, n2.faces = [], null !== t2.multiFaceLandmarks)
              for (var e2 = t2.multiFaceLandmarks, r = 0; r < e2.length; r++) {
                var i = n2.translateOutput(e2[r]);
                n2.faces.push({ keypoints: i, box: R(i).locationData.relativeBoundingBox });
              }
          });
        }
        return n.prototype.translateOutput = function(t2) {
          var e = this;
          return t2.map(function(t3, n2) {
            var r = { x: t3.x * e.width, y: t3.y * e.height, z: t3.z * e.width }, i = k.get(n2);
            return null != i && (r.name = i), r;
          });
        }, n.prototype.estimateFaces = function(t2, n2) {
          return S(this, void 0, void 0, function() {
            var r, i;
            return F(this, function(o) {
              switch (o.label) {
                case 0:
                  return n2 && n2.flipHorizontal && n2.flipHorizontal !== this.selfieMode && (this.selfieMode = n2.flipHorizontal, this.faceMeshSolution.setOptions({ selfieMode: this.selfieMode })), t2 instanceof Tensor ? (i = ImageData.bind, [4, browser_exports.toPixels(t2)]) : [3, 2];
                case 1:
                  return r = new (i.apply(ImageData, [void 0, o.sent(), t2.shape[1], t2.shape[0]]))(), [3, 3];
                case 2:
                  r = t2, o.label = 3;
                case 3:
                  return t2 = r, [4, this.faceMeshSolution.send({ image: t2 })];
                case 4:
                  return o.sent(), [2, this.faces];
              }
            });
          });
        }, n.prototype.dispose = function() {
          this.faceMeshSolution.close();
        }, n.prototype.reset = function() {
          this.faceMeshSolution.reset(), this.width = 0, this.height = 0, this.faces = null, this.selfieMode = false;
        }, n.prototype.initialize = function() {
          return this.faceMeshSolution.initialize();
        }, n;
      }();
      D = "undefined" != typeof globalThis ? globalThis : "undefined" != typeof window ? window : "undefined" != typeof global ? global : "undefined" != typeof self ? self : {};
      P = {};
      (function() {
        var t2;
        function e(t3) {
          var e2 = 0;
          return function() {
            return e2 < t3.length ? { done: false, value: t3[e2++] } : { done: true };
          };
        }
        var n = "function" == typeof Object.defineProperties ? Object.defineProperty : function(t3, e2, n2) {
          return t3 == Array.prototype || t3 == Object.prototype || (t3[e2] = n2.value), t3;
        };
        var r = function(t3) {
          t3 = ["object" == typeof globalThis && globalThis, t3, "object" == typeof window && window, "object" == typeof self && self, "object" == typeof D && D];
          for (var e2 = 0; e2 < t3.length; ++e2) {
            var n2 = t3[e2];
            if (n2 && n2.Math == Math)
              return n2;
          }
          throw Error("Cannot find global object");
        }(this);
        function i(t3, e2) {
          if (e2)
            t: {
              var i2 = r;
              t3 = t3.split(".");
              for (var o2 = 0; o2 < t3.length - 1; o2++) {
                var a6 = t3[o2];
                if (!(a6 in i2))
                  break t;
                i2 = i2[a6];
              }
              (e2 = e2(o2 = i2[t3 = t3[t3.length - 1]])) != o2 && null != e2 && n(i2, t3, { configurable: true, writable: true, value: e2 });
            }
        }
        function o(t3) {
          return (t3 = { next: t3 })[Symbol.iterator] = function() {
            return this;
          }, t3;
        }
        function a(t3) {
          var n2 = "undefined" != typeof Symbol && Symbol.iterator && t3[Symbol.iterator];
          return n2 ? n2.call(t3) : { next: e(t3) };
        }
        function u(t3) {
          if (!(t3 instanceof Array)) {
            t3 = a(t3);
            for (var e2, n2 = []; !(e2 = t3.next()).done; )
              n2.push(e2.value);
            t3 = n2;
          }
          return t3;
        }
        i("Symbol", function(t3) {
          function e2(t4, e3) {
            this.g = t4, n(this, "description", { configurable: true, writable: true, value: e3 });
          }
          if (t3)
            return t3;
          e2.prototype.toString = function() {
            return this.g;
          };
          var r2 = "jscomp_symbol_" + (1e9 * Math.random() >>> 0) + "_", i2 = 0;
          return function t4(n2) {
            if (this instanceof t4)
              throw new TypeError("Symbol is not a constructor");
            return new e2(r2 + (n2 || "") + "_" + i2++, n2);
          };
        }), i("Symbol.iterator", function(t3) {
          if (t3)
            return t3;
          t3 = Symbol("Symbol.iterator");
          for (var i2 = "Array Int8Array Uint8Array Uint8ClampedArray Int16Array Uint16Array Int32Array Uint32Array Float32Array Float64Array".split(" "), a6 = 0; a6 < i2.length; a6++) {
            var u2 = r[i2[a6]];
            "function" == typeof u2 && "function" != typeof u2.prototype[t3] && n(u2.prototype, t3, { configurable: true, writable: true, value: function() {
              return o(e(this));
            } });
          }
          return t3;
        });
        var s, c = "function" == typeof Object.create ? Object.create : function(t3) {
          function e2() {
          }
          return e2.prototype = t3, new e2();
        };
        if ("function" == typeof Object.setPrototypeOf)
          s = Object.setPrototypeOf;
        else {
          var h;
          t: {
            var l = {};
            try {
              l.__proto__ = { a: true }, h = l.a;
              break t;
            } catch (t3) {
            }
            h = false;
          }
          s = h ? function(t3, e2) {
            if (t3.__proto__ = e2, t3.__proto__ !== e2)
              throw new TypeError(t3 + " is not extensible");
            return t3;
          } : null;
        }
        var f = s;
        function d(t3, e2) {
          if (t3.prototype = c(e2.prototype), t3.prototype.constructor = t3, f)
            f(t3, e2);
          else
            for (var n2 in e2)
              if ("prototype" != n2)
                if (Object.defineProperties) {
                  var r2 = Object.getOwnPropertyDescriptor(e2, n2);
                  r2 && Object.defineProperty(t3, n2, r2);
                } else
                  t3[n2] = e2[n2];
          t3.na = e2.prototype;
        }
        function p2() {
          this.l = false, this.i = null, this.h = void 0, this.g = 1, this.u = this.o = 0, this.j = null;
        }
        function g(t3) {
          if (t3.l)
            throw new TypeError("Generator is already running");
          t3.l = true;
        }
        function v(t3, e2) {
          t3.j = { da: e2, ea: true }, t3.g = t3.o || t3.u;
        }
        function m(t3, e2, n2) {
          return t3.g = n2, { value: e2 };
        }
        function y(t3) {
          this.g = new p2(), this.h = t3;
        }
        function w(t3, e2, n2, r2) {
          try {
            var i2 = e2.call(t3.g.i, n2);
            if (!(i2 instanceof Object))
              throw new TypeError("Iterator result " + i2 + " is not an object");
            if (!i2.done)
              return t3.g.l = false, i2;
            var o2 = i2.value;
          } catch (e3) {
            return t3.g.i = null, v(t3.g, e3), b(t3);
          }
          return t3.g.i = null, r2.call(t3.g, o2), b(t3);
        }
        function b(t3) {
          for (; t3.g.g; )
            try {
              var e2 = t3.h(t3.g);
              if (e2)
                return t3.g.l = false, { value: e2.value, done: false };
            } catch (e3) {
              t3.g.h = void 0, v(t3.g, e3);
            }
          if (t3.g.l = false, t3.g.j) {
            if (e2 = t3.g.j, t3.g.j = null, e2.ea)
              throw e2.da;
            return { value: e2.return, done: true };
          }
          return { value: void 0, done: true };
        }
        function x(t3) {
          this.next = function(e2) {
            return g(t3.g), t3.g.i ? e2 = w(t3, t3.g.i.next, e2, t3.g.s) : (t3.g.s(e2), e2 = b(t3)), e2;
          }, this.throw = function(e2) {
            return g(t3.g), t3.g.i ? e2 = w(t3, t3.g.i.throw, e2, t3.g.s) : (v(t3.g, e2), e2 = b(t3)), e2;
          }, this.return = function(e2) {
            return function(t4, e3) {
              g(t4.g);
              var n2 = t4.g.i;
              return n2 ? w(t4, "return" in n2 ? n2.return : function(t5) {
                return { value: t5, done: true };
              }, e3, t4.g.return) : (t4.g.return(e3), b(t4));
            }(t3, e2);
          }, this[Symbol.iterator] = function() {
            return this;
          };
        }
        function M(t3) {
          return function(t4) {
            function e2(e3) {
              return t4.next(e3);
            }
            function n2(e3) {
              return t4.throw(e3);
            }
            return new Promise(function(r2, i2) {
              !function t5(o2) {
                o2.done ? r2(o2.value) : Promise.resolve(o2.value).then(e2, n2).then(t5, i2);
              }(t4.next());
            });
          }(new x(new y(t3)));
        }
        p2.prototype.s = function(t3) {
          this.h = t3;
        }, p2.prototype.return = function(t3) {
          this.j = { return: t3 }, this.g = this.u;
        }, i("Promise", function(t3) {
          function e2(t4) {
            this.h = 0, this.i = void 0, this.g = [], this.s = false;
            var e3 = this.j();
            try {
              t4(e3.resolve, e3.reject);
            } catch (t5) {
              e3.reject(t5);
            }
          }
          function n2() {
            this.g = null;
          }
          function i2(t4) {
            return t4 instanceof e2 ? t4 : new e2(function(e3) {
              e3(t4);
            });
          }
          if (t3)
            return t3;
          n2.prototype.h = function(t4) {
            if (null == this.g) {
              this.g = [];
              var e3 = this;
              this.i(function() {
                e3.l();
              });
            }
            this.g.push(t4);
          };
          var o2 = r.setTimeout;
          n2.prototype.i = function(t4) {
            o2(t4, 0);
          }, n2.prototype.l = function() {
            for (; this.g && this.g.length; ) {
              var t4 = this.g;
              this.g = [];
              for (var e3 = 0; e3 < t4.length; ++e3) {
                var n3 = t4[e3];
                t4[e3] = null;
                try {
                  n3();
                } catch (t5) {
                  this.j(t5);
                }
              }
            }
            this.g = null;
          }, n2.prototype.j = function(t4) {
            this.i(function() {
              throw t4;
            });
          }, e2.prototype.j = function() {
            function t4(t5) {
              return function(r2) {
                n3 || (n3 = true, t5.call(e3, r2));
              };
            }
            var e3 = this, n3 = false;
            return { resolve: t4(this.D), reject: t4(this.l) };
          }, e2.prototype.D = function(t4) {
            if (t4 === this)
              this.l(new TypeError("A Promise cannot resolve to itself"));
            else if (t4 instanceof e2)
              this.H(t4);
            else {
              t:
                switch (typeof t4) {
                  case "object":
                    var n3 = null != t4;
                    break t;
                  case "function":
                    n3 = true;
                    break t;
                  default:
                    n3 = false;
                }
              n3 ? this.A(t4) : this.o(t4);
            }
          }, e2.prototype.A = function(t4) {
            var e3 = void 0;
            try {
              e3 = t4.then;
            } catch (t5) {
              return void this.l(t5);
            }
            "function" == typeof e3 ? this.I(e3, t4) : this.o(t4);
          }, e2.prototype.l = function(t4) {
            this.u(2, t4);
          }, e2.prototype.o = function(t4) {
            this.u(1, t4);
          }, e2.prototype.u = function(t4, e3) {
            if (0 != this.h)
              throw Error("Cannot settle(" + t4 + ", " + e3 + "): Promise already settled in state" + this.h);
            this.h = t4, this.i = e3, 2 === this.h && this.G(), this.B();
          }, e2.prototype.G = function() {
            var t4 = this;
            o2(function() {
              if (t4.C()) {
                var e3 = r.console;
                void 0 !== e3 && e3.error(t4.i);
              }
            }, 1);
          }, e2.prototype.C = function() {
            if (this.s)
              return false;
            var t4 = r.CustomEvent, e3 = r.Event, n3 = r.dispatchEvent;
            return void 0 === n3 || ("function" == typeof t4 ? t4 = new t4("unhandledrejection", { cancelable: true }) : "function" == typeof e3 ? t4 = new e3("unhandledrejection", { cancelable: true }) : (t4 = r.document.createEvent("CustomEvent")).initCustomEvent("unhandledrejection", false, true, t4), t4.promise = this, t4.reason = this.i, n3(t4));
          }, e2.prototype.B = function() {
            if (null != this.g) {
              for (var t4 = 0; t4 < this.g.length; ++t4)
                u2.h(this.g[t4]);
              this.g = null;
            }
          };
          var u2 = new n2();
          return e2.prototype.H = function(t4) {
            var e3 = this.j();
            t4.M(e3.resolve, e3.reject);
          }, e2.prototype.I = function(t4, e3) {
            var n3 = this.j();
            try {
              t4.call(e3, n3.resolve, n3.reject);
            } catch (t5) {
              n3.reject(t5);
            }
          }, e2.prototype.then = function(t4, n3) {
            function r2(t5, e3) {
              return "function" == typeof t5 ? function(e4) {
                try {
                  i3(t5(e4));
                } catch (t6) {
                  o3(t6);
                }
              } : e3;
            }
            var i3, o3, a6 = new e2(function(t5, e3) {
              i3 = t5, o3 = e3;
            });
            return this.M(r2(t4, i3), r2(n3, o3)), a6;
          }, e2.prototype.catch = function(t4) {
            return this.then(void 0, t4);
          }, e2.prototype.M = function(t4, e3) {
            function n3() {
              switch (r2.h) {
                case 1:
                  t4(r2.i);
                  break;
                case 2:
                  e3(r2.i);
                  break;
                default:
                  throw Error("Unexpected state: " + r2.h);
              }
            }
            var r2 = this;
            null == this.g ? u2.h(n3) : this.g.push(n3), this.s = true;
          }, e2.resolve = i2, e2.reject = function(t4) {
            return new e2(function(e3, n3) {
              n3(t4);
            });
          }, e2.race = function(t4) {
            return new e2(function(e3, n3) {
              for (var r2 = a(t4), o3 = r2.next(); !o3.done; o3 = r2.next())
                i2(o3.value).M(e3, n3);
            });
          }, e2.all = function(t4) {
            var n3 = a(t4), r2 = n3.next();
            return r2.done ? i2([]) : new e2(function(t5, e3) {
              function o3(e4) {
                return function(n4) {
                  a6[e4] = n4, 0 == --u3 && t5(a6);
                };
              }
              var a6 = [], u3 = 0;
              do {
                a6.push(void 0), u3++, i2(r2.value).M(o3(a6.length - 1), e3), r2 = n3.next();
              } while (!r2.done);
            });
          }, e2;
        });
        var A = "function" == typeof Object.assign ? Object.assign : function(t3, e2) {
          for (var n2 = 1; n2 < arguments.length; n2++) {
            var r2 = arguments[n2];
            if (r2)
              for (var i2 in r2)
                Object.prototype.hasOwnProperty.call(r2, i2) && (t3[i2] = r2[i2]);
          }
          return t3;
        };
        i("Object.assign", function(t3) {
          return t3 || A;
        }), i("Object.is", function(t3) {
          return t3 || function(t4, e2) {
            return t4 === e2 ? 0 !== t4 || 1 / t4 == 1 / e2 : t4 != t4 && e2 != e2;
          };
        }), i("Array.prototype.includes", function(t3) {
          return t3 || function(t4, e2) {
            var n2 = this;
            n2 instanceof String && (n2 = String(n2));
            var r2 = n2.length;
            for (0 > (e2 = e2 || 0) && (e2 = Math.max(e2 + r2, 0)); e2 < r2; e2++) {
              var i2 = n2[e2];
              if (i2 === t4 || Object.is(i2, t4))
                return true;
            }
            return false;
          };
        }), i("String.prototype.includes", function(t3) {
          return t3 || function(t4, e2) {
            if (null == this)
              throw new TypeError("The 'this' value for String.prototype.includes must not be null or undefined");
            if (t4 instanceof RegExp)
              throw new TypeError("First argument to String.prototype.includes must not be a regular expression");
            return -1 !== this.indexOf(t4, e2 || 0);
          };
        }), i("Array.prototype.keys", function(t3) {
          return t3 || function() {
            return function(t4, e2) {
              t4 instanceof String && (t4 += "");
              var n2 = 0, r2 = false, i2 = { next: function() {
                if (!r2 && n2 < t4.length) {
                  var i3 = n2++;
                  return { value: e2(i3, t4[i3]), done: false };
                }
                return r2 = true, { done: true, value: void 0 };
              } };
              return i2[Symbol.iterator] = function() {
                return i2;
              }, i2;
            }(this, function(t4) {
              return t4;
            });
          };
        });
        var T = this || self;
        function E2(t3, e2) {
          t3 = t3.split(".");
          var n2, r2 = T;
          t3[0] in r2 || void 0 === r2.execScript || r2.execScript("var " + t3[0]);
          for (; t3.length && (n2 = t3.shift()); )
            t3.length || void 0 === e2 ? r2 = r2[n2] && r2[n2] !== Object.prototype[n2] ? r2[n2] : r2[n2] = {} : r2[n2] = e2;
        }
        function S2() {
          throw Error("Invalid UTF8");
        }
        function F2(t3, e2) {
          return e2 = String.fromCharCode.apply(null, e2), null == t3 ? e2 : t3 + e2;
        }
        var C2, O2, _2 = "undefined" != typeof TextDecoder, j2 = "undefined" != typeof TextEncoder, k3 = {}, R2 = null;
        function I2(t3) {
          var e2;
          void 0 === e2 && (e2 = 0), B2(), e2 = k3[e2];
          for (var n2 = Array(Math.floor(t3.length / 3)), r2 = e2[64] || "", i2 = 0, o2 = 0; i2 < t3.length - 2; i2 += 3) {
            var a6 = t3[i2], u2 = t3[i2 + 1], s2 = t3[i2 + 2], c2 = e2[a6 >> 2];
            a6 = e2[(3 & a6) << 4 | u2 >> 4], u2 = e2[(15 & u2) << 2 | s2 >> 6], s2 = e2[63 & s2], n2[o2++] = c2 + a6 + u2 + s2;
          }
          switch (c2 = 0, s2 = r2, t3.length - i2) {
            case 2:
              s2 = e2[(15 & (c2 = t3[i2 + 1])) << 2] || r2;
            case 1:
              t3 = t3[i2], n2[o2] = e2[t3 >> 2] + e2[(3 & t3) << 4 | c2 >> 4] + s2 + r2;
          }
          return n2.join("");
        }
        function L2(t3) {
          var e2 = t3.length, n2 = 3 * e2 / 4;
          n2 % 3 ? n2 = Math.floor(n2) : -1 != "=.".indexOf(t3[e2 - 1]) && (n2 = -1 != "=.".indexOf(t3[e2 - 2]) ? n2 - 2 : n2 - 1);
          var r2 = new Uint8Array(n2), i2 = 0;
          return function(t4, e3) {
            function n3(e4) {
              for (; r3 < t4.length; ) {
                var n4 = t4.charAt(r3++), i4 = R2[n4];
                if (null != i4)
                  return i4;
                if (!/^[\s\xa0]*$/.test(n4))
                  throw Error("Unknown base64 encoding at char: " + n4);
              }
              return e4;
            }
            B2();
            for (var r3 = 0; ; ) {
              var i3 = n3(-1), o2 = n3(0), a6 = n3(64), u2 = n3(64);
              if (64 === u2 && -1 === i3)
                break;
              e3(i3 << 2 | o2 >> 4), 64 != a6 && (e3(o2 << 4 & 240 | a6 >> 2), 64 != u2 && e3(a6 << 6 & 192 | u2));
            }
          }(t3, function(t4) {
            r2[i2++] = t4;
          }), i2 !== n2 ? r2.subarray(0, i2) : r2;
        }
        function B2() {
          if (!R2) {
            R2 = {};
            for (var t3 = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789".split(""), e2 = ["+/=", "+/", "-_=", "-_.", "-_"], n2 = 0; 5 > n2; n2++) {
              var r2 = t3.concat(e2[n2].split(""));
              k3[n2] = r2;
              for (var i2 = 0; i2 < r2.length; i2++) {
                var o2 = r2[i2];
                void 0 === R2[o2] && (R2[o2] = i2);
              }
            }
          }
        }
        var P2, z2 = "function" == typeof Uint8Array;
        function U2(t3) {
          return z2 && null != t3 && t3 instanceof Uint8Array;
        }
        function N2(t3) {
          if (this.L = t3, null !== t3 && 0 === t3.length)
            throw Error("ByteString should be constructed with non-empty values");
        }
        var V2 = "function" == typeof Uint8Array.prototype.slice, H2 = 0;
        function K2(t3, e2) {
          return Error("Invalid wire type: " + t3 + " (at position " + e2 + ")");
        }
        function W2() {
          return Error("Failed to read varint, encoding is invalid.");
        }
        function G2(t3, e2) {
          e2 = void 0 !== (e2 = void 0 === e2 ? {} : e2).v && e2.v, this.h = null, this.g = this.i = this.j = 0, this.v = e2, t3 && X2(this, t3);
        }
        function X2(t3, e2) {
          t3.h = function(t4, e3) {
            if (t4.constructor === Uint8Array)
              return t4;
            if (t4.constructor === ArrayBuffer)
              return new Uint8Array(t4);
            if (t4.constructor === Array)
              return new Uint8Array(t4);
            if (t4.constructor === String)
              return L2(t4);
            if (t4.constructor === N2)
              return !e3 && (e3 = t4.L) && e3.constructor === Uint8Array ? e3 : (e3 = null == (e3 = t4.L) || U2(e3) ? e3 : "string" == typeof e3 ? L2(e3) : null, (t4 = t4.L = e3) ? new Uint8Array(t4) : P2 || (P2 = new Uint8Array(0)));
            if (t4 instanceof Uint8Array)
              return new Uint8Array(t4.buffer, t4.byteOffset, t4.byteLength);
            throw Error("Type not convertible to a Uint8Array, expected a Uint8Array, an ArrayBuffer, a base64 encoded string, or Array of numbers");
          }(e2, t3.v), t3.j = 0, t3.i = t3.h.length, t3.g = t3.j;
        }
        function Y2(t3) {
          if (t3.g > t3.i)
            throw Error("Tried to read past the end of the data " + t3.g + " > " + t3.i);
        }
        function J2(t3) {
          var e2 = t3.h, n2 = e2[t3.g], r2 = 127 & n2;
          if (128 > n2)
            return t3.g += 1, Y2(t3), r2;
          if (r2 |= (127 & (n2 = e2[t3.g + 1])) << 7, 128 > n2)
            return t3.g += 2, Y2(t3), r2;
          if (r2 |= (127 & (n2 = e2[t3.g + 2])) << 14, 128 > n2)
            return t3.g += 3, Y2(t3), r2;
          if (r2 |= (127 & (n2 = e2[t3.g + 3])) << 21, 128 > n2)
            return t3.g += 4, Y2(t3), r2;
          if (n2 = e2[t3.g + 4], t3.g += 5, r2 |= (15 & n2) << 28, 128 > n2)
            return Y2(t3), r2;
          if (128 <= e2[t3.g++] && 128 <= e2[t3.g++] && 128 <= e2[t3.g++] && 128 <= e2[t3.g++] && 128 <= e2[t3.g++])
            throw W2();
          return Y2(t3), r2;
        }
        G2.prototype.reset = function() {
          this.g = this.j;
        };
        var q2 = [];
        function $2() {
          this.g = [];
        }
        function Z2(t3, e2) {
          for (; 127 < e2; )
            t3.g.push(127 & e2 | 128), e2 >>>= 7;
          t3.g.push(e2);
        }
        function Q2(t3) {
          var e2 = {}, n2 = void 0 !== e2.W && e2.W;
          this.l = { v: void 0 !== e2.v && e2.v }, this.W = n2, e2 = this.l, q2.length ? (n2 = q2.pop(), e2 && (n2.v = e2.v), t3 && X2(n2, t3), t3 = n2) : t3 = new G2(t3, e2), this.g = t3, this.j = this.g.g, this.h = this.i = -1;
        }
        function tt2(t3) {
          var e2 = t3.g;
          if (e2.g == e2.i)
            return false;
          t3.j = t3.g.g;
          var n2 = J2(t3.g) >>> 0;
          if (e2 = n2 >>> 3, !(0 <= (n2 &= 7) && 5 >= n2))
            throw K2(n2, t3.j);
          if (1 > e2)
            throw Error("Invalid field number: " + e2 + " (at position " + t3.j + ")");
          return t3.i = e2, t3.h = n2, true;
        }
        function et2(t3) {
          switch (t3.h) {
            case 0:
              if (0 != t3.h)
                et2(t3);
              else
                t: {
                  for (var e2 = (t3 = t3.g).g, n2 = e2 + 10; e2 < n2; )
                    if (0 == (128 & t3.h[e2++])) {
                      t3.g = e2, Y2(t3);
                      break t;
                    }
                  throw W2();
                }
              break;
            case 1:
              (t3 = t3.g).g += 8, Y2(t3);
              break;
            case 2:
              2 != t3.h ? et2(t3) : (e2 = J2(t3.g) >>> 0, (t3 = t3.g).g += e2, Y2(t3));
              break;
            case 5:
              (t3 = t3.g).g += 4, Y2(t3);
              break;
            case 3:
              for (e2 = t3.i; ; ) {
                if (!tt2(t3))
                  throw Error("Unmatched start-group tag: stream EOF");
                if (4 == t3.h) {
                  if (t3.i != e2)
                    throw Error("Unmatched end-group tag");
                  break;
                }
                et2(t3);
              }
              break;
            default:
              throw K2(t3.h, t3.j);
          }
        }
        $2.prototype.length = function() {
          return this.g.length;
        }, $2.prototype.end = function() {
          var t3 = this.g;
          return this.g = [], t3;
        }, Q2.prototype.reset = function() {
          this.g.reset(), this.j = this.g.g, this.h = this.i = -1;
        };
        var nt2 = [];
        function rt2() {
          this.i = [], this.h = 0, this.g = new $2();
        }
        function it2(t3, e2) {
          0 !== e2.length && (t3.i.push(e2), t3.h += e2.length);
        }
        var ot2 = "function" == typeof Symbol && "symbol" == typeof Symbol() ? Symbol(void 0) : void 0;
        function at2(t3, e2) {
          Object.isFrozen(t3) || (ot2 ? t3[ot2] |= e2 : void 0 !== t3.N ? t3.N |= e2 : Object.defineProperties(t3, { N: { value: e2, configurable: true, writable: true, enumerable: false } }));
        }
        function ut2(t3) {
          var e2;
          return null == (e2 = ot2 ? t3[ot2] : t3.N) ? 0 : e2;
        }
        function st2(t3) {
          return at2(t3, 1), t3;
        }
        function ct2(t3) {
          return !!Array.isArray(t3) && !!(2 & ut2(t3));
        }
        function ht2(t3) {
          if (!Array.isArray(t3))
            throw Error("cannot mark non-array as immutable");
          at2(t3, 2);
        }
        function lt2(t3) {
          return null !== t3 && "object" == typeof t3 && !Array.isArray(t3) && t3.constructor === Object;
        }
        var ft2 = Object.freeze(st2([]));
        function dt2(t3) {
          if (ct2(t3.m))
            throw Error("Cannot mutate an immutable Message");
        }
        var pt2, gt2 = "undefined" != typeof Symbol && void 0 !== Symbol.hasInstance;
        function vt2(t3) {
          return { value: t3, configurable: false, writable: false, enumerable: false };
        }
        function mt2(t3, e2, n2) {
          return -1 === e2 ? null : e2 >= t3.i ? t3.g ? t3.g[e2] : void 0 : void 0 !== n2 && n2 && t3.g && null != (n2 = t3.g[e2]) ? n2 : t3.m[e2 + t3.h];
        }
        function yt2(t3, e2, n2, r2) {
          r2 = void 0 !== r2 && r2, dt2(t3), e2 < t3.i && !r2 ? t3.m[e2 + t3.h] = n2 : (t3.g || (t3.g = t3.m[t3.i + t3.h] = {}))[e2] = n2;
        }
        function wt2(t3, e2, n2, r2) {
          n2 = void 0 === n2 || n2;
          var i2 = mt2(t3, e2, r2 = void 0 !== r2 && r2);
          return null == i2 && (i2 = ft2), ct2(t3.m) ? n2 && (ht2(i2), Object.freeze(i2)) : (i2 === ft2 || ct2(i2)) && yt2(t3, e2, i2 = st2(i2.slice()), r2), i2;
        }
        function bt2(t3, e2, n2) {
          return null == (t3 = null == (t3 = mt2(t3, e2)) ? t3 : +t3) ? void 0 === n2 ? 0 : n2 : t3;
        }
        function xt2(t3, e2, n2, r2) {
          t3.j || (t3.j = {});
          var i2 = ct2(t3.m), o2 = t3.j[n2];
          if (!o2) {
            r2 = wt2(t3, n2, true, void 0 !== r2 && r2), o2 = [], i2 = i2 || ct2(r2);
            for (var a6 = 0; a6 < r2.length; a6++)
              o2[a6] = new e2(r2[a6]), i2 && ht2(o2[a6].m);
            i2 && (ht2(o2), Object.freeze(o2)), t3.j[n2] = o2;
          }
          return o2;
        }
        function Mt2(t3, e2, n2, r2, i2) {
          var o2 = void 0 !== o2 && o2;
          return dt2(t3), o2 = xt2(t3, n2, e2, o2), n2 = r2 || new n2(), t3 = wt2(t3, e2), null != i2 ? (o2.splice(i2, 0, n2), t3.splice(i2, 0, n2.m)) : (o2.push(n2), t3.push(n2.m)), n2;
        }
        function At2(t3, e2) {
          return null == (t3 = mt2(t3, e2)) ? 0 : t3;
        }
        function Tt2(t3, e2) {
          return null == (t3 = mt2(t3, e2)) ? "" : t3;
        }
        function Et2(t3) {
          var e2 = Ct2;
          return Ft2(t3, e2 = void 0 === e2 ? Ot2 : e2);
        }
        function St2(t3, e2) {
          if (null != t3) {
            if (Array.isArray(t3))
              t3 = Ft2(t3, e2);
            else if (lt2(t3)) {
              var n2, r2 = {};
              for (n2 in t3)
                r2[n2] = St2(t3[n2], e2);
              t3 = r2;
            } else
              t3 = e2(t3);
            return t3;
          }
        }
        function Ft2(t3, e2) {
          for (var n2 = t3.slice(), r2 = 0; r2 < n2.length; r2++)
            n2[r2] = St2(n2[r2], e2);
          return Array.isArray(t3) && 1 & ut2(t3) && st2(n2), n2;
        }
        function Ct2(t3) {
          return t3 && "object" == typeof t3 && t3.toJSON ? t3.toJSON() : (t3 = function(t4) {
            switch (typeof t4) {
              case "number":
                return isFinite(t4) ? t4 : String(t4);
              case "object":
                if (t4 && !Array.isArray(t4)) {
                  if (U2(t4))
                    return I2(t4);
                  if (t4 instanceof N2) {
                    var e2 = t4.L;
                    return e2 = null == e2 || "string" == typeof e2 ? e2 : z2 && e2 instanceof Uint8Array ? I2(e2) : null, (t4.L = e2) || "";
                  }
                }
            }
            return t4;
          }(t3), Array.isArray(t3) ? Et2(t3) : t3);
        }
        function Ot2(t3) {
          return U2(t3) ? new Uint8Array(t3) : t3;
        }
        function _t2(t3, e2, n2) {
          t3 || (t3 = pt2), pt2 = null;
          var r2 = this.constructor.h;
          if (t3 || (t3 = r2 ? [r2] : []), this.h = (r2 ? 0 : -1) - (this.constructor.g || 0), this.j = void 0, this.m = t3, t3 = (r2 = this.m.length) - 1, r2 && lt2(r2 = this.m[t3]) ? (this.i = t3 - this.h, this.g = r2) : void 0 !== e2 && -1 < e2 ? (this.i = Math.max(e2, t3 + 1 - this.h), this.g = void 0) : this.i = Number.MAX_VALUE, n2)
            for (e2 = 0; e2 < n2.length; e2++)
              if ((t3 = n2[e2]) < this.i)
                t3 += this.h, (r2 = this.m[t3]) ? Array.isArray(r2) && st2(r2) : this.m[t3] = ft2;
              else {
                var i2 = (r2 = this.g || (this.g = this.m[this.i + this.h] = {}))[t3];
                i2 ? Array.isArray(i2) && st2(i2) : r2[t3] = ft2;
              }
        }
        function jt2() {
          _t2.apply(this, arguments);
        }
        if (_t2.prototype.toJSON = function() {
          return Et2(this.m);
        }, _t2.prototype.toString = function() {
          return this.m.toString();
        }, d(jt2, _t2), gt2) {
          var kt2 = {};
          Object.defineProperties(jt2, (kt2[Symbol.hasInstance] = vt2(function() {
            throw Error("Cannot perform instanceof checks for MutableMessage");
          }), kt2));
        }
        function Rt2(t3, e2, n2) {
          if (n2) {
            var r2, i2 = {};
            for (r2 in n2) {
              var o2 = n2[r2], a6 = o2.ha;
              a6 || (i2.F = o2.la || o2.fa.P, o2.aa ? (i2.U = Ut2(o2.aa), a6 = function(t4) {
                return function(e3, n3, r3) {
                  return t4.F(e3, n3, r3, t4.U);
                };
              }(i2)) : o2.ca ? (i2.T = Nt2(o2.X.g, o2.ca), a6 = function(t4) {
                return function(e3, n3, r3) {
                  return t4.F(e3, n3, r3, t4.T);
                };
              }(i2)) : a6 = i2.F, o2.ha = a6), a6(e2, t3, o2.X), i2 = { F: i2.F, U: i2.U, T: i2.T };
            }
          }
          !function(t4, e3) {
            if (e3 = e3.ba) {
              it2(t4, t4.g.end());
              for (var n3 = 0; n3 < e3.length; n3++)
                it2(t4, e3[n3]);
            }
          }(e2, t3);
        }
        var It2 = Symbol();
        function Lt2(t3, e2, n2) {
          return t3[It2] || (t3[It2] = function(t4, r2) {
            return e2(t4, r2, n2);
          });
        }
        function Bt2(t3) {
          var e2 = t3[It2];
          if (!e2) {
            var n2 = Qt(t3);
            e2 = function(t4, e3) {
              return te(t4, e3, n2);
            }, t3[It2] = e2;
          }
          return e2;
        }
        function Dt2(t3) {
          var e2 = function(t4) {
            var e3 = t4.aa;
            return e3 ? Bt2(e3) : (e3 = t4.ka) ? Lt2(t4.X.g, e3, t4.ca) : void 0;
          }(t3), n2 = t3.X, r2 = t3.fa.O;
          return e2 ? function(t4, i2) {
            return r2(t4, i2, n2, e2);
          } : function(t4, e3) {
            return r2(t4, e3, n2);
          };
        }
        function Pt2(t3, e2, n2, r2, i2, o2) {
          var a6 = 0;
          for ((t3 = t3()).length && "number" != typeof t3[0] && (n2(e2, t3[0]), a6++); a6 < t3.length; ) {
            n2 = t3[a6++];
            for (var u2 = a6 + 1; u2 < t3.length && "number" != typeof t3[u2]; )
              u2++;
            var s2 = t3[a6++];
            switch (u2 -= a6) {
              case 0:
                r2(e2, n2, s2);
                break;
              case 1:
                r2(e2, n2, s2, t3[a6++]);
                break;
              case 2:
                i2(e2, n2, s2, t3[a6++], t3[a6++]);
                break;
              case 3:
                u2 = t3[a6++];
                var c2 = t3[a6++], h2 = t3[a6++];
                Array.isArray(h2) ? i2(e2, n2, s2, u2, c2, h2) : o2(e2, n2, s2, u2, c2, h2);
                break;
              case 4:
                o2(e2, n2, s2, t3[a6++], t3[a6++], t3[a6++], t3[a6++]);
                break;
              default:
                throw Error("unexpected number of binary field arguments: " + u2);
            }
          }
          return e2;
        }
        var zt2 = Symbol();
        function Ut2(t3) {
          var e2 = t3[zt2];
          if (!e2) {
            var n2 = Xt2(t3);
            e2 = function(t4, e3) {
              return ne(t4, e3, n2);
            }, t3[zt2] = e2;
          }
          return e2;
        }
        function Nt2(t3, e2) {
          var n2 = t3[zt2];
          return n2 || (n2 = function(t4, n3) {
            return Rt2(t4, n3, e2);
          }, t3[zt2] = n2), n2;
        }
        var Vt2 = Symbol();
        function Ht2(t3, e2) {
          t3.push(e2);
        }
        function Kt2(t3, e2, n2) {
          t3.push(e2, n2.P);
        }
        function Wt2(t3, e2, n2, r2, i2) {
          var o2 = Ut2(i2), a6 = n2.P;
          t3.push(e2, function(t4, e3, n3) {
            return a6(t4, e3, n3, r2, o2);
          });
        }
        function Gt2(t3, e2, n2, r2, i2, o2) {
          var a6 = Nt2(r2, o2), u2 = n2.P;
          t3.push(e2, function(t4, e3, n3) {
            return u2(t4, e3, n3, r2, a6);
          });
        }
        function Xt2(t3) {
          var e2 = t3[Vt2];
          return e2 || Pt2(t3, t3[Vt2] = [], Ht2, Kt2, Wt2, Gt2);
        }
        var Yt2 = Symbol();
        function Jt2(t3, e2) {
          t3[0] = e2;
        }
        function qt2(t3, e2, n2, r2) {
          var i2 = n2.O;
          t3[e2] = r2 ? function(t4, e3, n3) {
            return i2(t4, e3, n3, r2);
          } : i2;
        }
        function $t2(t3, e2, n2, r2, i2, o2) {
          var a6 = n2.O, u2 = Bt2(i2);
          t3[e2] = function(t4, e3, n3) {
            return a6(t4, e3, n3, r2, u2, o2);
          };
        }
        function Zt2(t3, e2, n2, r2, i2, o2, a6) {
          var u2 = n2.O, s2 = Lt2(r2, i2, o2);
          t3[e2] = function(t4, e3, n3) {
            return u2(t4, e3, n3, r2, s2, a6);
          };
        }
        function Qt(t3) {
          var e2 = t3[Yt2];
          return e2 || Pt2(t3, t3[Yt2] = {}, Jt2, qt2, $t2, Zt2);
        }
        function te(t3, e2, n2) {
          for (; tt2(e2) && 4 != e2.h; ) {
            var r2 = e2.i, i2 = n2[r2];
            if (!i2) {
              var o2 = n2[0];
              o2 && (o2 = o2[r2]) && (i2 = n2[r2] = Dt2(o2));
            }
            if (!(i2 && i2(e2, t3, r2) || (i2 = e2, r2 = t3, o2 = i2.j, et2(i2), i2.W))) {
              var a6 = i2.g.h;
              i2 = o2 === (i2 = i2.g.g) ? P2 || (P2 = new Uint8Array(0)) : V2 ? a6.slice(o2, i2) : new Uint8Array(a6.subarray(o2, i2)), (o2 = r2.ba) ? o2.push(i2) : r2.ba = [i2];
            }
          }
          return t3;
        }
        function ee(t3, e2, n2) {
          if (nt2.length) {
            var r2 = nt2.pop();
            t3 && (X2(r2.g, t3), r2.i = -1, r2.h = -1), t3 = r2;
          } else
            t3 = new Q2(t3);
          try {
            return te(new e2(), t3, Qt(n2));
          } finally {
            (e2 = t3.g).h = null, e2.j = 0, e2.i = 0, e2.g = 0, e2.v = false, t3.i = -1, t3.h = -1, 100 > nt2.length && nt2.push(t3);
          }
        }
        function ne(t3, e2, n2) {
          for (var r2 = n2.length, i2 = 1 == r2 % 2, o2 = i2 ? 1 : 0; o2 < r2; o2 += 2)
            (0, n2[o2 + 1])(e2, t3, n2[o2]);
          Rt2(t3, e2, i2 ? n2[0] : void 0);
        }
        function re(t3, e2) {
          var n2 = new rt2();
          ne(t3, n2, Xt2(e2)), it2(n2, n2.g.end()), t3 = new Uint8Array(n2.h);
          for (var r2 = (e2 = n2.i).length, i2 = 0, o2 = 0; o2 < r2; o2++) {
            var a6 = e2[o2];
            t3.set(a6, i2), i2 += a6.length;
          }
          return n2.i = [t3], t3;
        }
        function ie(t3, e2) {
          return { O: t3, P: e2 };
        }
        var oe = ie(function(t3, e2, n2) {
          if (5 !== t3.h)
            return false;
          var r2 = (t3 = t3.g).h[t3.g], i2 = t3.h[t3.g + 1], o2 = t3.h[t3.g + 2], a6 = t3.h[t3.g + 3];
          return t3.g += 4, Y2(t3), t3 = 2 * ((i2 = (r2 << 0 | i2 << 8 | o2 << 16 | a6 << 24) >>> 0) >> 31) + 1, r2 = i2 >>> 23 & 255, i2 &= 8388607, yt2(e2, n2, 255 == r2 ? i2 ? NaN : 1 / 0 * t3 : 0 == r2 ? t3 * Math.pow(2, -149) * i2 : t3 * Math.pow(2, r2 - 150) * (i2 + Math.pow(2, 23))), true;
        }, function(t3, e2, n2) {
          if (null != (e2 = mt2(e2, n2))) {
            Z2(t3.g, 8 * n2 + 5), t3 = t3.g;
            var r2 = e2;
            0 === (r2 = (n2 = 0 > r2 ? 1 : 0) ? -r2 : r2) ? 0 < 1 / r2 ? H2 = 0 : (0, H2 = 2147483648) : isNaN(r2) ? (0, H2 = 2147483647) : 34028234663852886e22 < r2 ? (0, H2 = (n2 << 31 | 2139095040) >>> 0) : 11754943508222875e-54 > r2 ? (r2 = Math.round(r2 / Math.pow(2, -149)), 0, H2 = (n2 << 31 | r2) >>> 0) : (e2 = Math.floor(Math.log(r2) / Math.LN2), r2 *= Math.pow(2, -e2), 16777216 <= (r2 = Math.round(8388608 * r2)) && ++e2, 0, H2 = (n2 << 31 | e2 + 127 << 23 | 8388607 & r2) >>> 0), n2 = H2, t3.g.push(n2 >>> 0 & 255), t3.g.push(n2 >>> 8 & 255), t3.g.push(n2 >>> 16 & 255), t3.g.push(n2 >>> 24 & 255);
          }
        }), ae = ie(function(t3, e2, n2) {
          if (0 !== t3.h)
            return false;
          for (var r2 = t3.g, i2 = 128, o2 = 0, a6 = t3 = 0; 4 > a6 && 128 <= i2; a6++)
            i2 = r2.h[r2.g++], Y2(r2), o2 |= (127 & i2) << 7 * a6;
          if (128 <= i2 && (i2 = r2.h[r2.g++], Y2(r2), o2 |= (127 & i2) << 28, t3 |= (127 & i2) >> 4), 128 <= i2)
            for (a6 = 0; 5 > a6 && 128 <= i2; a6++)
              i2 = r2.h[r2.g++], Y2(r2), t3 |= (127 & i2) << 7 * a6 + 3;
          if (!(128 > i2))
            throw W2();
          return r2 = o2 >>> 0, (t3 = 2147483648 & (i2 = t3 >>> 0)) && (i2 = ~i2 >>> 0, 0 == (r2 = 1 + ~r2 >>> 0) && (i2 = i2 + 1 >>> 0)), r2 = 4294967296 * i2 + (r2 >>> 0), yt2(e2, n2, t3 ? -r2 : r2), true;
        }, function(t3, e2, n2) {
          if (null != (e2 = mt2(e2, n2)) && null != e2) {
            Z2(t3.g, 8 * n2), t3 = t3.g;
            var r2 = e2;
            for (n2 = 0 > r2, e2 = (r2 = Math.abs(r2)) >>> 0, r2 = Math.floor((r2 - e2) / 4294967296), r2 >>>= 0, n2 && (r2 = ~r2 >>> 0, 4294967295 < (e2 = 1 + (~e2 >>> 0)) && (e2 = 0, 4294967295 < ++r2 && (r2 = 0))), n2 = H2 = e2, e2 = r2; 0 < e2 || 127 < n2; )
              t3.g.push(127 & n2 | 128), n2 = (n2 >>> 7 | e2 << 25) >>> 0, e2 >>>= 7;
            t3.g.push(n2);
          }
        }), ue = ie(function(t3, e2, n2) {
          return 0 === t3.h && (yt2(e2, n2, J2(t3.g)), true);
        }, function(t3, e2, n2) {
          if (null != (e2 = mt2(e2, n2)) && null != e2)
            if (Z2(t3.g, 8 * n2), t3 = t3.g, 0 <= (n2 = e2))
              Z2(t3, n2);
            else {
              for (e2 = 0; 9 > e2; e2++)
                t3.g.push(127 & n2 | 128), n2 >>= 7;
              t3.g.push(1);
            }
        }), se = ie(function(t3, e2, n2) {
          if (2 !== t3.h)
            return false;
          var r2, i2 = J2(t3.g) >>> 0, o2 = (t3 = t3.g).g;
          if (t3.g += i2, Y2(t3), t3 = t3.h, _2)
            (r2 = C2) || (r2 = C2 = new TextDecoder("utf-8", { fatal: true })), r2 = r2.decode(t3.subarray(o2, o2 + i2));
          else {
            i2 = o2 + i2;
            for (var a6, u2, s2, c2 = [], h2 = null; o2 < i2; )
              128 > (a6 = t3[o2++]) ? c2.push(a6) : 224 > a6 ? o2 >= i2 ? S2() : (u2 = t3[o2++], 194 > a6 || 128 != (192 & u2) ? (o2--, S2()) : c2.push((31 & a6) << 6 | 63 & u2)) : 240 > a6 ? o2 >= i2 - 1 ? S2() : 128 != (192 & (u2 = t3[o2++])) || 224 === a6 && 160 > u2 || 237 === a6 && 160 <= u2 || 128 != (192 & (r2 = t3[o2++])) ? (o2--, S2()) : c2.push((15 & a6) << 12 | (63 & u2) << 6 | 63 & r2) : 244 >= a6 ? o2 >= i2 - 2 ? S2() : 128 != (192 & (u2 = t3[o2++])) || 0 != u2 - 144 + (a6 << 28) >> 30 || 128 != (192 & (r2 = t3[o2++])) || 128 != (192 & (s2 = t3[o2++])) ? (o2--, S2()) : (a6 = (7 & a6) << 18 | (63 & u2) << 12 | (63 & r2) << 6 | 63 & s2, a6 -= 65536, c2.push(55296 + (a6 >> 10 & 1023), 56320 + (1023 & a6))) : S2(), 8192 <= c2.length && (h2 = F2(h2, c2), c2.length = 0);
            r2 = F2(h2, c2);
          }
          return yt2(e2, n2, r2), true;
        }, function(t3, e2, n2) {
          if (null != (e2 = mt2(e2, n2))) {
            var r2 = false;
            if (r2 = void 0 !== r2 && r2, j2) {
              if (r2 && /(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])/.test(e2))
                throw Error("Found an unpaired surrogate");
              e2 = (O2 || (O2 = new TextEncoder())).encode(e2);
            } else {
              for (var i2 = 0, o2 = new Uint8Array(3 * e2.length), a6 = 0; a6 < e2.length; a6++) {
                var u2 = e2.charCodeAt(a6);
                if (128 > u2)
                  o2[i2++] = u2;
                else {
                  if (2048 > u2)
                    o2[i2++] = u2 >> 6 | 192;
                  else {
                    if (55296 <= u2 && 57343 >= u2) {
                      if (56319 >= u2 && a6 < e2.length) {
                        var s2 = e2.charCodeAt(++a6);
                        if (56320 <= s2 && 57343 >= s2) {
                          u2 = 1024 * (u2 - 55296) + s2 - 56320 + 65536, o2[i2++] = u2 >> 18 | 240, o2[i2++] = u2 >> 12 & 63 | 128, o2[i2++] = u2 >> 6 & 63 | 128, o2[i2++] = 63 & u2 | 128;
                          continue;
                        }
                        a6--;
                      }
                      if (r2)
                        throw Error("Found an unpaired surrogate");
                      u2 = 65533;
                    }
                    o2[i2++] = u2 >> 12 | 224, o2[i2++] = u2 >> 6 & 63 | 128;
                  }
                  o2[i2++] = 63 & u2 | 128;
                }
              }
              e2 = o2.subarray(0, i2);
            }
            Z2(t3.g, 8 * n2 + 2), Z2(t3.g, e2.length), it2(t3, t3.g.end()), it2(t3, e2);
          }
        }), ce = ie(function(t3, e2, n2, r2, i2) {
          if (2 !== t3.h)
            return false;
          e2 = Mt2(e2, n2, r2), n2 = t3.g.i, r2 = J2(t3.g) >>> 0;
          var o2 = t3.g.g + r2, a6 = o2 - n2;
          if (0 >= a6 && (t3.g.i = o2, i2(e2, t3), a6 = o2 - t3.g.g), a6)
            throw Error("Message parsing ended unexpectedly. Expected to read " + r2 + " bytes, instead read " + (r2 - a6) + " bytes, either the data ended unexpectedly or the message misreported its own length");
          return t3.g.g = o2, t3.g.i = n2, true;
        }, function(t3, e2, n2, r2, i2) {
          if (null != (e2 = xt2(e2, r2, n2)))
            for (r2 = 0; r2 < e2.length; r2++) {
              var o2 = t3;
              Z2(o2.g, 8 * n2 + 2);
              var a6 = o2.g.end();
              it2(o2, a6), a6.push(o2.h), o2 = a6, i2(e2[r2], t3), a6 = t3;
              var u2 = o2.pop();
              for (u2 = a6.h + a6.g.length() - u2; 127 < u2; )
                o2.push(127 & u2 | 128), u2 >>>= 7, a6.h++;
              o2.push(u2), a6.h++;
            }
        });
        function he() {
          jt2.apply(this, arguments);
        }
        if (d(he, jt2), gt2) {
          var le = {};
          Object.defineProperties(he, (le[Symbol.hasInstance] = vt2(Object[Symbol.hasInstance]), le));
        }
        function fe(t3) {
          he.call(this, t3);
        }
        function de() {
          return [1, ue, 2, oe, 3, se, 4, se];
        }
        function pe(t3) {
          he.call(this, t3, -1, ve);
        }
        function ge() {
          return [1, ce, fe, de];
        }
        d(fe, he), d(pe, he), pe.prototype.addClassification = function(t3, e2) {
          return Mt2(this, 1, fe, t3, e2), this;
        };
        var ve = [1];
        function me(t3) {
          he.call(this, t3);
        }
        function ye() {
          return [1, oe, 2, oe, 3, oe, 4, oe, 5, oe];
        }
        function we(t3) {
          he.call(this, t3, -1, xe);
        }
        function be() {
          return [1, ce, me, ye];
        }
        d(me, he), d(we, he);
        var xe = [1];
        function Me(t3) {
          he.call(this, t3);
        }
        function Ae() {
          return [1, oe, 2, oe, 3, oe, 4, oe, 5, oe, 6, ae];
        }
        d(Me, he);
        var Te = [[61, 146], [146, 91], [91, 181], [181, 84], [84, 17], [17, 314], [314, 405], [405, 321], [321, 375], [375, 291], [61, 185], [185, 40], [40, 39], [39, 37], [37, 0], [0, 267], [267, 269], [269, 270], [270, 409], [409, 291], [78, 95], [95, 88], [88, 178], [178, 87], [87, 14], [14, 317], [317, 402], [402, 318], [318, 324], [324, 308], [78, 191], [191, 80], [80, 81], [81, 82], [82, 13], [13, 312], [312, 311], [311, 310], [310, 415], [415, 308]], Ee = [[263, 249], [249, 390], [390, 373], [373, 374], [374, 380], [380, 381], [381, 382], [382, 362], [263, 466], [466, 388], [388, 387], [387, 386], [386, 385], [385, 384], [384, 398], [398, 362]], Se = [[276, 283], [283, 282], [282, 295], [295, 285], [300, 293], [293, 334], [334, 296], [296, 336]], Fe = [[33, 7], [7, 163], [163, 144], [144, 145], [145, 153], [153, 154], [154, 155], [155, 133], [33, 246], [246, 161], [161, 160], [160, 159], [159, 158], [158, 157], [157, 173], [173, 133]], Ce = [[46, 53], [53, 52], [52, 65], [65, 55], [70, 63], [63, 105], [105, 66], [66, 107]], Oe = [[10, 338], [338, 297], [297, 332], [332, 284], [284, 251], [251, 389], [389, 356], [356, 454], [454, 323], [323, 361], [361, 288], [288, 397], [397, 365], [365, 379], [379, 378], [378, 400], [400, 377], [377, 152], [152, 148], [148, 176], [176, 149], [149, 150], [150, 136], [136, 172], [172, 58], [58, 132], [132, 93], [93, 234], [234, 127], [127, 162], [162, 21], [21, 54], [54, 103], [103, 67], [67, 109], [109, 10]], _e = [].concat(u(Te), u(Ee), u(Se), u(Fe), u(Ce), u(Oe));
        function je(t3, e2, n2) {
          if (n2 = t3.createShader(0 === n2 ? t3.VERTEX_SHADER : t3.FRAGMENT_SHADER), t3.shaderSource(n2, e2), t3.compileShader(n2), !t3.getShaderParameter(n2, t3.COMPILE_STATUS))
            throw Error("Could not compile WebGL shader.\n\n" + t3.getShaderInfoLog(n2));
          return n2;
        }
        function ke(t3) {
          return xt2(t3, fe, 1).map(function(t4) {
            return { index: At2(t4, 1), ga: bt2(t4, 2), label: null != mt2(t4, 3) ? Tt2(t4, 3) : void 0, displayName: null != mt2(t4, 4) ? Tt2(t4, 4) : void 0 };
          });
        }
        function Re(t3) {
          return { x: bt2(t3, 1), y: bt2(t3, 2), z: bt2(t3, 3), visibility: null != mt2(t3, 4) ? bt2(t3, 4) : void 0 };
        }
        function Ie(t3, e2) {
          this.h = t3, this.g = e2, this.l = 0;
        }
        function Le(t3, e2, n2) {
          return function(t4, e3) {
            var n3 = t4.g;
            if (void 0 === t4.o) {
              var r2 = je(n3, "\n  attribute vec2 aVertex;\n  attribute vec2 aTex;\n  varying vec2 vTex;\n  void main(void) {\n    gl_Position = vec4(aVertex, 0.0, 1.0);\n    vTex = aTex;\n  }", 0), i2 = je(n3, "\n  precision mediump float;\n  varying vec2 vTex;\n  uniform sampler2D sampler0;\n  void main(){\n    gl_FragColor = texture2D(sampler0, vTex);\n  }", 1), o2 = n3.createProgram();
              if (n3.attachShader(o2, r2), n3.attachShader(o2, i2), n3.linkProgram(o2), !n3.getProgramParameter(o2, n3.LINK_STATUS))
                throw Error("Could not compile WebGL program.\n\n" + n3.getProgramInfoLog(o2));
              r2 = t4.o = o2, n3.useProgram(r2), i2 = n3.getUniformLocation(r2, "sampler0"), t4.j = { K: n3.getAttribLocation(r2, "aVertex"), J: n3.getAttribLocation(r2, "aTex"), ma: i2 }, t4.u = n3.createBuffer(), n3.bindBuffer(n3.ARRAY_BUFFER, t4.u), n3.enableVertexAttribArray(t4.j.K), n3.vertexAttribPointer(t4.j.K, 2, n3.FLOAT, false, 0, 0), n3.bufferData(n3.ARRAY_BUFFER, new Float32Array([-1, -1, -1, 1, 1, 1, 1, -1]), n3.STATIC_DRAW), n3.bindBuffer(n3.ARRAY_BUFFER, null), t4.s = n3.createBuffer(), n3.bindBuffer(n3.ARRAY_BUFFER, t4.s), n3.enableVertexAttribArray(t4.j.J), n3.vertexAttribPointer(t4.j.J, 2, n3.FLOAT, false, 0, 0), n3.bufferData(n3.ARRAY_BUFFER, new Float32Array([0, 1, 0, 0, 1, 0, 1, 1]), n3.STATIC_DRAW), n3.bindBuffer(n3.ARRAY_BUFFER, null), n3.uniform1i(i2, 0);
            }
            r2 = t4.j, n3.useProgram(t4.o), n3.canvas.width = e3.width, n3.canvas.height = e3.height, n3.viewport(0, 0, e3.width, e3.height), n3.activeTexture(n3.TEXTURE0), t4.h.bindTexture2d(e3.glName), n3.enableVertexAttribArray(r2.K), n3.bindBuffer(n3.ARRAY_BUFFER, t4.u), n3.vertexAttribPointer(r2.K, 2, n3.FLOAT, false, 0, 0), n3.enableVertexAttribArray(r2.J), n3.bindBuffer(n3.ARRAY_BUFFER, t4.s), n3.vertexAttribPointer(r2.J, 2, n3.FLOAT, false, 0, 0), n3.bindFramebuffer(n3.DRAW_FRAMEBUFFER ? n3.DRAW_FRAMEBUFFER : n3.FRAMEBUFFER, null), n3.clearColor(0, 0, 0, 0), n3.clear(n3.COLOR_BUFFER_BIT), n3.colorMask(true, true, true, true), n3.drawArrays(n3.TRIANGLE_FAN, 0, 4), n3.disableVertexAttribArray(r2.K), n3.disableVertexAttribArray(r2.J), n3.bindBuffer(n3.ARRAY_BUFFER, null), t4.h.bindTexture2d(0);
          }(t3, e2), "function" == typeof t3.g.canvas.transferToImageBitmap ? Promise.resolve(t3.g.canvas.transferToImageBitmap()) : n2 ? Promise.resolve(t3.g.canvas) : "function" == typeof createImageBitmap ? createImageBitmap(t3.g.canvas) : (void 0 === t3.i && (t3.i = document.createElement("canvas")), new Promise(function(e3) {
            t3.i.height = t3.g.canvas.height, t3.i.width = t3.g.canvas.width, t3.i.getContext("2d", {}).drawImage(t3.g.canvas, 0, 0, t3.g.canvas.width, t3.g.canvas.height), e3(t3.i);
          }));
        }
        function Be(t3) {
          this.g = t3;
        }
        var De = new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 9, 1, 7, 0, 65, 0, 253, 15, 26, 11]);
        function Pe(t3, e2) {
          return e2 + t3;
        }
        function ze(t3, e2) {
          window[t3] = e2;
        }
        function Ue(t3) {
          if (this.g = t3, this.listeners = {}, this.j = {}, this.H = {}, this.o = {}, this.u = {}, this.I = this.s = this.Z = true, this.D = Promise.resolve(), this.Y = "", this.C = {}, this.locateFile = t3 && t3.locateFile || Pe, "object" == typeof window)
            var e2 = window.location.pathname.toString().substring(0, window.location.pathname.toString().lastIndexOf("/")) + "/";
          else {
            if ("undefined" == typeof location)
              throw Error("solutions can only be loaded on a web page or in a web worker");
            e2 = location.pathname.toString().substring(0, location.pathname.toString().lastIndexOf("/")) + "/";
          }
          if (this.$ = e2, t3.options)
            for (var n2 = (e2 = a(Object.keys(t3.options))).next(); !n2.done; n2 = e2.next()) {
              n2 = n2.value;
              var r2 = t3.options[n2].default;
              void 0 !== r2 && (this.j[n2] = "function" == typeof r2 ? r2() : r2);
            }
        }
        function Ne(t3) {
          var e2, n2, r2, i2, o2, a6, s2, c2, h2, l2, f2;
          return M(function(d2) {
            switch (d2.g) {
              case 1:
                return t3.Z ? (e2 = void 0 === t3.g.files ? [] : "function" == typeof t3.g.files ? t3.g.files(t3.j) : t3.g.files, m(d2, M(function(t4) {
                  switch (t4.g) {
                    case 1:
                      return t4.o = 2, m(t4, WebAssembly.instantiate(De), 4);
                    case 4:
                      t4.g = 3, t4.o = 0;
                      break;
                    case 2:
                      return t4.o = 0, t4.j = null, t4.return(false);
                    case 3:
                      return t4.return(true);
                  }
                }), 2)) : d2.return();
              case 2:
                if (n2 = d2.h, "object" == typeof window)
                  return ze("createMediapipeSolutionsWasm", { locateFile: t3.locateFile }), ze("createMediapipeSolutionsPackedAssets", { locateFile: t3.locateFile }), a6 = e2.filter(function(t4) {
                    return void 0 !== t4.data;
                  }), s2 = e2.filter(function(t4) {
                    return void 0 === t4.data;
                  }), c2 = Promise.all(a6.map(function(e3) {
                    var n3 = Ve(t3, e3.url);
                    if (void 0 !== e3.path) {
                      var r3 = e3.path;
                      n3 = n3.then(function(e4) {
                        return t3.overrideFile(r3, e4), Promise.resolve(e4);
                      });
                    }
                    return n3;
                  })), h2 = Promise.all(s2.map(function(e3) {
                    return void 0 === e3.simd || e3.simd && n2 || !e3.simd && !n2 ? function(t4) {
                      var e4 = document.createElement("script");
                      return e4.setAttribute("src", t4), e4.setAttribute("crossorigin", "anonymous"), new Promise(function(t5) {
                        e4.addEventListener("load", function() {
                          t5();
                        }, false), e4.addEventListener("error", function() {
                          t5();
                        }, false), document.body.appendChild(e4);
                      });
                    }(t3.locateFile(e3.url, t3.$)) : Promise.resolve();
                  })).then(function() {
                    var e3, n3, r3;
                    return M(function(i3) {
                      if (1 == i3.g)
                        return e3 = window.createMediapipeSolutionsWasm, n3 = window.createMediapipeSolutionsPackedAssets, r3 = t3, m(i3, e3(n3), 2);
                      r3.h = i3.h, i3.g = 0;
                    });
                  }), l2 = M(function(e3) {
                    return t3.g.graph && t3.g.graph.url ? e3 = m(e3, Ve(t3, t3.g.graph.url), 0) : (e3.g = 0, e3 = void 0), e3;
                  }), m(d2, Promise.all([h2, c2, l2]), 7);
                if ("function" != typeof importScripts)
                  throw Error("solutions can only be loaded on a web page or in a web worker");
                return r2 = e2.filter(function(t4) {
                  return void 0 === t4.simd || t4.simd && n2 || !t4.simd && !n2;
                }).map(function(e3) {
                  return t3.locateFile(e3.url, t3.$);
                }), importScripts.apply(null, u(r2)), i2 = t3, m(d2, createMediapipeSolutionsWasm(Module), 6);
              case 6:
                i2.h = d2.h, t3.l = new OffscreenCanvas(1, 1), t3.h.canvas = t3.l, o2 = t3.h.GL.createContext(t3.l, { antialias: false, alpha: false, ja: "undefined" != typeof WebGL2RenderingContext ? 2 : 1 }), t3.h.GL.makeContextCurrent(o2), d2.g = 4;
                break;
              case 7:
                if (t3.l = document.createElement("canvas"), !(f2 = t3.l.getContext("webgl2", {})) && !(f2 = t3.l.getContext("webgl", {})))
                  return alert("Failed to create WebGL canvas context when passing video frame."), d2.return();
                t3.G = f2, t3.h.canvas = t3.l, t3.h.createContext(t3.l, true, true, {});
              case 4:
                t3.i = new t3.h.SolutionWasm(), t3.Z = false, d2.g = 0;
            }
          });
        }
        function Ve(t3, e2) {
          var n2, r2;
          return M(function(i2) {
            return e2 in t3.H ? i2.return(t3.H[e2]) : (n2 = t3.locateFile(e2, ""), r2 = fetch(n2).then(function(t4) {
              return t4.arrayBuffer();
            }), t3.H[e2] = r2, i2.return(r2));
          });
        }
        function He(t3, e2, n2) {
          var r2, i2, o2, u2, s2, c2, h2, l2, f2, d2, p3, g2, v2, y2;
          return M(function(w2) {
            switch (w2.g) {
              case 1:
                if (!n2)
                  return w2.return(e2);
                for (r2 = {}, i2 = 0, o2 = a(Object.keys(n2)), u2 = o2.next(); !u2.done; u2 = o2.next())
                  s2 = u2.value, "string" != typeof (c2 = n2[s2]) && "texture" === c2.type && void 0 !== e2[c2.stream] && ++i2;
                1 < i2 && (t3.I = false), h2 = a(Object.keys(n2)), u2 = h2.next();
              case 2:
                if (u2.done) {
                  w2.g = 4;
                  break;
                }
                if (l2 = u2.value, "string" == typeof (f2 = n2[l2]))
                  return v2 = r2, y2 = l2, m(w2, function(t4, e3, n3) {
                    var r3;
                    return M(function(i3) {
                      return "number" == typeof n3 || n3 instanceof Uint8Array || n3 instanceof t4.h.Uint8BlobList ? i3.return(n3) : n3 instanceof t4.h.Texture2dDataOut ? ((r3 = t4.u[e3]) || (r3 = new Ie(t4.h, t4.G), t4.u[e3] = r3), i3.return(Le(r3, n3, t4.I))) : i3.return(void 0);
                    });
                  }(t3, l2, e2[f2]), 14);
                if (d2 = e2[f2.stream], "detection_list" === f2.type) {
                  if (d2) {
                    for (var b2 = d2.getRectList(), x2 = d2.getLandmarksList(), A2 = d2.getClassificationsList(), T2 = [], E3 = 0; E3 < b2.size(); ++E3) {
                      var S3 = ee(b2.get(E3), Me, Ae);
                      S3 = { boundingBox: { xCenter: bt2(S3, 1), yCenter: bt2(S3, 2), height: bt2(S3, 3), width: bt2(S3, 4), rotation: bt2(S3, 5, 0), rectId: At2(S3, 6) }, landmarks: xt2(ee(x2.get(E3), we, be), me, 1).map(Re), V: ke(ee(A2.get(E3), pe, ge)) }, T2.push(S3);
                    }
                    b2 = T2;
                  } else
                    b2 = [];
                  r2[l2] = b2, w2.g = 7;
                  break;
                }
                if ("proto_list" === f2.type) {
                  if (d2) {
                    for (b2 = Array(d2.size()), x2 = 0; x2 < d2.size(); x2++)
                      b2[x2] = d2.get(x2);
                    d2.delete();
                  } else
                    b2 = [];
                  r2[l2] = b2, w2.g = 7;
                  break;
                }
                if (void 0 === d2) {
                  w2.g = 3;
                  break;
                }
                if ("float_list" === f2.type) {
                  r2[l2] = d2, w2.g = 7;
                  break;
                }
                if ("proto" === f2.type) {
                  r2[l2] = d2, w2.g = 7;
                  break;
                }
                if ("texture" !== f2.type)
                  throw Error("Unknown output config type: '" + f2.type + "'");
                return (p3 = t3.u[l2]) || (p3 = new Ie(t3.h, t3.G), t3.u[l2] = p3), m(w2, Le(p3, d2, t3.I), 13);
              case 13:
                g2 = w2.h, r2[l2] = g2;
              case 7:
                f2.transform && r2[l2] && (r2[l2] = f2.transform(r2[l2])), w2.g = 3;
                break;
              case 14:
                v2[y2] = w2.h;
              case 3:
                u2 = h2.next(), w2.g = 2;
                break;
              case 4:
                return w2.return(r2);
            }
          });
        }
        function Ke(t3, e2) {
          for (var n2 = e2.name || "$", r2 = [].concat(u(e2.wants)), i2 = new t3.h.StringList(), o2 = a(e2.wants), s2 = o2.next(); !s2.done; s2 = o2.next())
            i2.push_back(s2.value);
          o2 = t3.h.PacketListener.implement({ onResults: function(i3) {
            for (var o3 = {}, a6 = 0; a6 < e2.wants.length; ++a6)
              o3[r2[a6]] = i3.get(a6);
            var u2 = t3.listeners[n2];
            u2 && (t3.D = He(t3, o3, e2.outs).then(function(n3) {
              n3 = u2(n3);
              for (var i4 = 0; i4 < e2.wants.length; ++i4) {
                var a7 = o3[r2[i4]];
                "object" == typeof a7 && a7.hasOwnProperty && a7.hasOwnProperty("delete") && a7.delete();
              }
              n3 && (t3.D = n3);
            }));
          } }), t3.i.attachMultiListener(i2, o2), i2.delete();
        }
        function We(t3) {
          var e2 = this;
          t3 = t3 || {};
          var n2 = { url: "face_detection_short.binarypb" }, r2 = { type: 1, graphOptionXref: { calculatorType: "TensorsToDetectionsCalculator", calculatorName: "facedetectionshortrangegpu__facedetectionshortrangecommon__TensorsToDetectionsCalculator", fieldName: "min_score_thresh" } };
          this.g = new Ue({ locateFile: t3.locateFile, files: [{ data: true, url: "face_detection_short.binarypb" }, { data: true, url: "face_detection_short_range.tflite" }, { simd: true, url: "face_detection_solution_simd_wasm_bin.js" }, { simd: false, url: "face_detection_solution_wasm_bin.js" }], graph: n2, listeners: [{ wants: ["detections", "image_transformed"], outs: { image: "image_transformed", detections: { type: "detection_list", stream: "detections" } } }], inputs: { image: { type: "video", stream: "input_frames_gpu" } }, options: { useCpuInference: { type: 0, graphOptionXref: { calculatorType: "InferenceCalculator", fieldName: "use_cpu_inference" }, default: "object" == typeof window && void 0 !== window.navigator && ("iPad Simulator;iPhone Simulator;iPod Simulator;iPad;iPhone;iPod".split(";").includes(navigator.platform) || navigator.userAgent.includes("Mac") && "ontouchend" in document) }, selfieMode: { type: 0, graphOptionXref: { calculatorType: "GlScalerCalculator", calculatorIndex: 1, fieldName: "flip_horizontal" } }, model: { type: 0, onChange: function(t4) {
            var i2, o2, u2, s2, c2;
            return M(function(h2) {
              switch (h2.g) {
                case 1:
                  i2 = a("short" === t4 ? ["face_detection_short_range.tflite"] : ["face_detection_full_range_sparse.tflite"]), o2 = i2.next();
                case 2:
                  if (o2.done) {
                    h2.g = 4;
                    break;
                  }
                  return u2 = o2.value, s2 = "third_party/mediapipe/modules/face_detection/" + u2, m(h2, Ve(e2.g, u2), 5);
                case 5:
                  c2 = h2.h, e2.g.overrideFile(s2, c2), o2 = i2.next(), h2.g = 2;
                  break;
                case 4:
                  return n2.url = "short" === t4 ? "face_detection_short.binarypb" : "face_detection_full.binarypb", r2.graphOptionXref.calculatorName = "short" === t4 ? "facedetectionshortrangegpu__facedetectionshortrangecommon__TensorsToDetectionsCalculator" : "facedetectionfullrangegpu__facedetectionfullrangecommon__TensorsToDetectionsCalculator", h2.return(true);
              }
            });
          } }, minDetectionConfidence: r2 } });
        }
        (t2 = Ue.prototype).close = function() {
          return this.i && this.i.delete(), Promise.resolve();
        }, t2.reset = function() {
          var t3 = this;
          return M(function(e2) {
            t3.i && (t3.i.reset(), t3.o = {}, t3.u = {}), e2.g = 0;
          });
        }, t2.setOptions = function(t3, e2) {
          var n2 = this;
          if (e2 = e2 || this.g.options) {
            for (var r2 = [], i2 = [], o2 = {}, u2 = a(Object.keys(t3)), s2 = u2.next(); !s2.done; o2 = { R: o2.R, S: o2.S }, s2 = u2.next()) {
              var c2 = s2.value;
              c2 in this.j && this.j[c2] === t3[c2] || (this.j[c2] = t3[c2], void 0 !== (s2 = e2[c2]) && (s2.onChange && (o2.R = s2.onChange, o2.S = t3[c2], r2.push(function(t4) {
                return function() {
                  return M(function(e3) {
                    if (1 == e3.g)
                      return m(e3, t4.R(t4.S), 2);
                    true === e3.h && (n2.s = true), e3.g = 0;
                  });
                };
              }(o2))), s2.graphOptionXref && (c2 = { valueNumber: 1 === s2.type ? t3[c2] : 0, valueBoolean: 0 === s2.type && t3[c2], valueString: 2 === s2.type ? t3[c2] : "" }, s2 = Object.assign(Object.assign(Object.assign({}, { calculatorName: "", calculatorIndex: 0 }), s2.graphOptionXref), c2), i2.push(s2))));
            }
            0 === r2.length && 0 === i2.length || (this.s = true, this.B = (void 0 === this.B ? [] : this.B).concat(i2), this.A = (void 0 === this.A ? [] : this.A).concat(r2));
          }
        }, t2.initialize = function() {
          var t3 = this;
          return M(function(e2) {
            return 1 == e2.g ? m(e2, Ne(t3), 2) : 3 != e2.g ? m(e2, function(t4) {
              var e3, n2, r2, i2, o2, u2, s2, c2;
              return M(function(h2) {
                if (1 == h2.g)
                  return t4.g.graph && t4.g.graph.url && t4.Y === t4.g.graph.url ? h2.return() : (t4.s = true, t4.g.graph && t4.g.graph.url ? (t4.Y = t4.g.graph.url, m(h2, Ve(t4, t4.g.graph.url), 3)) : void (h2.g = 2));
                for (2 != h2.g && (e3 = h2.h, t4.i.loadGraph(e3)), n2 = a(Object.keys(t4.C)), r2 = n2.next(); !r2.done; r2 = n2.next())
                  i2 = r2.value, t4.i.overrideFile(i2, t4.C[i2]);
                if (t4.C = {}, t4.g.listeners)
                  for (o2 = a(t4.g.listeners), u2 = o2.next(); !u2.done; u2 = o2.next())
                    s2 = u2.value, Ke(t4, s2);
                c2 = t4.j, t4.j = {}, t4.setOptions(c2), h2.g = 0;
              });
            }(t3), 3) : m(e2, function(t4) {
              var e3, n2, r2, i2, o2, u2;
              return M(function(s2) {
                switch (s2.g) {
                  case 1:
                    if (!t4.s)
                      return s2.return();
                    if (!t4.A) {
                      s2.g = 2;
                      break;
                    }
                    e3 = a(t4.A), n2 = e3.next();
                  case 3:
                    if (n2.done) {
                      s2.g = 5;
                      break;
                    }
                    return m(s2, (0, n2.value)(), 4);
                  case 4:
                    n2 = e3.next(), s2.g = 3;
                    break;
                  case 5:
                    t4.A = void 0;
                  case 2:
                    if (t4.B) {
                      for (r2 = new t4.h.GraphOptionChangeRequestList(), i2 = a(t4.B), o2 = i2.next(); !o2.done; o2 = i2.next())
                        u2 = o2.value, r2.push_back(u2);
                      t4.i.changeOptions(r2), r2.delete(), t4.B = void 0;
                    }
                    t4.s = false, s2.g = 0;
                }
              });
            }(t3), 0);
          });
        }, t2.overrideFile = function(t3, e2) {
          this.i ? this.i.overrideFile(t3, e2) : this.C[t3] = e2;
        }, t2.clearOverriddenFiles = function() {
          this.C = {}, this.i && this.i.clearOverriddenFiles();
        }, t2.send = function(t3, e2) {
          var n2, r2, i2, o2, u2, s2, c2, h2, l2, f2 = this;
          return M(function(d2) {
            switch (d2.g) {
              case 1:
                return f2.g.inputs ? (n2 = 1e3 * (null == e2 ? performance.now() : e2), m(d2, f2.D, 2)) : d2.return();
              case 2:
                return m(d2, f2.initialize(), 3);
              case 3:
                for (r2 = new f2.h.PacketDataList(), i2 = a(Object.keys(t3)), o2 = i2.next(); !o2.done; o2 = i2.next())
                  if (u2 = o2.value, s2 = f2.g.inputs[u2]) {
                    t: {
                      var p3 = t3[u2];
                      switch (s2.type) {
                        case "video":
                          var g2 = f2.o[s2.stream];
                          if (g2 || (g2 = new Ie(f2.h, f2.G), f2.o[s2.stream] = g2), 0 === g2.l && (g2.l = g2.h.createTexture()), "undefined" != typeof HTMLVideoElement && p3 instanceof HTMLVideoElement)
                            var v2 = p3.videoWidth, y2 = p3.videoHeight;
                          else
                            "undefined" != typeof HTMLImageElement && p3 instanceof HTMLImageElement ? (v2 = p3.naturalWidth, y2 = p3.naturalHeight) : (v2 = p3.width, y2 = p3.height);
                          y2 = { glName: g2.l, width: v2, height: y2 }, (v2 = g2.g).canvas.width = y2.width, v2.canvas.height = y2.height, v2.activeTexture(v2.TEXTURE0), g2.h.bindTexture2d(g2.l), v2.texImage2D(v2.TEXTURE_2D, 0, v2.RGBA, v2.RGBA, v2.UNSIGNED_BYTE, p3), g2.h.bindTexture2d(0), g2 = y2;
                          break t;
                        case "detections":
                          for ((g2 = f2.o[s2.stream]) || (g2 = new Be(f2.h), f2.o[s2.stream] = g2), g2.data || (g2.data = new g2.g.DetectionListData()), g2.data.reset(p3.length), y2 = 0; y2 < p3.length; ++y2) {
                            v2 = p3[y2];
                            var w2 = g2.data, b2 = w2.setBoundingBox, x2 = y2, M2 = v2.boundingBox, A2 = new Me();
                            if (yt2(A2, 1, M2.xCenter), yt2(A2, 2, M2.yCenter), yt2(A2, 3, M2.height), yt2(A2, 4, M2.width), yt2(A2, 5, M2.rotation), yt2(A2, 6, M2.rectId), M2 = re(A2, Ae), b2.call(w2, x2, M2), v2.landmarks)
                              for (w2 = 0; w2 < v2.landmarks.length; ++w2) {
                                var T2 = !!(A2 = v2.landmarks[w2]).visibility;
                                x2 = (b2 = g2.data).addNormalizedLandmark, M2 = y2, A2 = Object.assign(Object.assign({}, A2), { visibility: T2 ? A2.visibility : 0 }), yt2(T2 = new me(), 1, A2.x), yt2(T2, 2, A2.y), yt2(T2, 3, A2.z), A2.visibility && yt2(T2, 4, A2.visibility), A2 = re(T2, ye), x2.call(b2, M2, A2);
                              }
                            if (v2.V)
                              for (w2 = 0; w2 < v2.V.length; ++w2)
                                x2 = (b2 = g2.data).addClassification, M2 = y2, A2 = v2.V[w2], yt2(T2 = new fe(), 2, A2.ga), A2.index && yt2(T2, 1, A2.index), A2.label && yt2(T2, 3, A2.label), A2.displayName && yt2(T2, 4, A2.displayName), A2 = re(T2, de), x2.call(b2, M2, A2);
                          }
                          g2 = g2.data;
                          break t;
                        default:
                          g2 = {};
                      }
                    }
                    switch (c2 = g2, h2 = s2.stream, s2.type) {
                      case "video":
                        r2.pushTexture2d(Object.assign(Object.assign({}, c2), { stream: h2, timestamp: n2 }));
                        break;
                      case "detections":
                        (l2 = c2).stream = h2, l2.timestamp = n2, r2.pushDetectionList(l2);
                        break;
                      default:
                        throw Error("Unknown input config type: '" + s2.type + "'");
                    }
                  }
                return f2.i.send(r2), m(d2, f2.D, 4);
              case 4:
                r2.delete(), d2.g = 0;
            }
          });
        }, t2.onResults = function(t3, e2) {
          this.listeners[e2 || "$"] = t3;
        }, E2("Solution", Ue), E2("OptionType", { BOOL: 0, NUMBER: 1, ia: 2, 0: "BOOL", 1: "NUMBER", 2: "STRING" }), (t2 = We.prototype).close = function() {
          return this.g.close(), Promise.resolve();
        }, t2.onResults = function(t3) {
          this.g.onResults(t3);
        }, t2.initialize = function() {
          var t3 = this;
          return M(function(e2) {
            return m(e2, t3.g.initialize(), 0);
          });
        }, t2.reset = function() {
          this.g.reset();
        }, t2.send = function(t3) {
          var e2 = this;
          return M(function(n2) {
            return m(n2, e2.g.send(t3), 0);
          });
        }, t2.setOptions = function(t3) {
          this.g.setOptions(t3);
        }, E2("FaceDetection", We), E2("FACEDETECTION_LIPS", Te), E2("FACEDETECTION_LEFT_EYE", Ee), E2("FACEDETECTION_LEFT_EYEBROW", Se), E2("FACEDETECTION_RIGHT_EYE", Fe), E2("FACEDETECTION_RIGHT_EYEBROW", Ce), E2("FACEDETECTION_FACE_OVAL", Oe), E2("FACEDETECTION_CONTOURS", _e), E2("FACEDETECTION_TESSELATION", [[127, 34], [34, 139], [139, 127], [11, 0], [0, 37], [37, 11], [232, 231], [231, 120], [120, 232], [72, 37], [37, 39], [39, 72], [128, 121], [121, 47], [47, 128], [232, 121], [121, 128], [128, 232], [104, 69], [69, 67], [67, 104], [175, 171], [171, 148], [148, 175], [118, 50], [50, 101], [101, 118], [73, 39], [39, 40], [40, 73], [9, 151], [151, 108], [108, 9], [48, 115], [115, 131], [131, 48], [194, 204], [204, 211], [211, 194], [74, 40], [40, 185], [185, 74], [80, 42], [42, 183], [183, 80], [40, 92], [92, 186], [186, 40], [230, 229], [229, 118], [118, 230], [202, 212], [212, 214], [214, 202], [83, 18], [18, 17], [17, 83], [76, 61], [61, 146], [146, 76], [160, 29], [29, 30], [30, 160], [56, 157], [157, 173], [173, 56], [106, 204], [204, 194], [194, 106], [135, 214], [214, 192], [192, 135], [203, 165], [165, 98], [98, 203], [21, 71], [71, 68], [68, 21], [51, 45], [45, 4], [4, 51], [144, 24], [24, 23], [23, 144], [77, 146], [146, 91], [91, 77], [205, 50], [50, 187], [187, 205], [201, 200], [200, 18], [18, 201], [91, 106], [106, 182], [182, 91], [90, 91], [91, 181], [181, 90], [85, 84], [84, 17], [17, 85], [206, 203], [203, 36], [36, 206], [148, 171], [171, 140], [140, 148], [92, 40], [40, 39], [39, 92], [193, 189], [189, 244], [244, 193], [159, 158], [158, 28], [28, 159], [247, 246], [246, 161], [161, 247], [236, 3], [3, 196], [196, 236], [54, 68], [68, 104], [104, 54], [193, 168], [168, 8], [8, 193], [117, 228], [228, 31], [31, 117], [189, 193], [193, 55], [55, 189], [98, 97], [97, 99], [99, 98], [126, 47], [47, 100], [100, 126], [166, 79], [79, 218], [218, 166], [155, 154], [154, 26], [26, 155], [209, 49], [49, 131], [131, 209], [135, 136], [136, 150], [150, 135], [47, 126], [126, 217], [217, 47], [223, 52], [52, 53], [53, 223], [45, 51], [51, 134], [134, 45], [211, 170], [170, 140], [140, 211], [67, 69], [69, 108], [108, 67], [43, 106], [106, 91], [91, 43], [230, 119], [119, 120], [120, 230], [226, 130], [130, 247], [247, 226], [63, 53], [53, 52], [52, 63], [238, 20], [20, 242], [242, 238], [46, 70], [70, 156], [156, 46], [78, 62], [62, 96], [96, 78], [46, 53], [53, 63], [63, 46], [143, 34], [34, 227], [227, 143], [123, 117], [117, 111], [111, 123], [44, 125], [125, 19], [19, 44], [236, 134], [134, 51], [51, 236], [216, 206], [206, 205], [205, 216], [154, 153], [153, 22], [22, 154], [39, 37], [37, 167], [167, 39], [200, 201], [201, 208], [208, 200], [36, 142], [142, 100], [100, 36], [57, 212], [212, 202], [202, 57], [20, 60], [60, 99], [99, 20], [28, 158], [158, 157], [157, 28], [35, 226], [226, 113], [113, 35], [160, 159], [159, 27], [27, 160], [204, 202], [202, 210], [210, 204], [113, 225], [225, 46], [46, 113], [43, 202], [202, 204], [204, 43], [62, 76], [76, 77], [77, 62], [137, 123], [123, 116], [116, 137], [41, 38], [38, 72], [72, 41], [203, 129], [129, 142], [142, 203], [64, 98], [98, 240], [240, 64], [49, 102], [102, 64], [64, 49], [41, 73], [73, 74], [74, 41], [212, 216], [216, 207], [207, 212], [42, 74], [74, 184], [184, 42], [169, 170], [170, 211], [211, 169], [170, 149], [149, 176], [176, 170], [105, 66], [66, 69], [69, 105], [122, 6], [6, 168], [168, 122], [123, 147], [147, 187], [187, 123], [96, 77], [77, 90], [90, 96], [65, 55], [55, 107], [107, 65], [89, 90], [90, 180], [180, 89], [101, 100], [100, 120], [120, 101], [63, 105], [105, 104], [104, 63], [93, 137], [137, 227], [227, 93], [15, 86], [86, 85], [85, 15], [129, 102], [102, 49], [49, 129], [14, 87], [87, 86], [86, 14], [55, 8], [8, 9], [9, 55], [100, 47], [47, 121], [121, 100], [145, 23], [23, 22], [22, 145], [88, 89], [89, 179], [179, 88], [6, 122], [122, 196], [196, 6], [88, 95], [95, 96], [96, 88], [138, 172], [172, 136], [136, 138], [215, 58], [58, 172], [172, 215], [115, 48], [48, 219], [219, 115], [42, 80], [80, 81], [81, 42], [195, 3], [3, 51], [51, 195], [43, 146], [146, 61], [61, 43], [171, 175], [175, 199], [199, 171], [81, 82], [82, 38], [38, 81], [53, 46], [46, 225], [225, 53], [144, 163], [163, 110], [110, 144], [52, 65], [65, 66], [66, 52], [229, 228], [228, 117], [117, 229], [34, 127], [127, 234], [234, 34], [107, 108], [108, 69], [69, 107], [109, 108], [108, 151], [151, 109], [48, 64], [64, 235], [235, 48], [62, 78], [78, 191], [191, 62], [129, 209], [209, 126], [126, 129], [111, 35], [35, 143], [143, 111], [117, 123], [123, 50], [50, 117], [222, 65], [65, 52], [52, 222], [19, 125], [125, 141], [141, 19], [221, 55], [55, 65], [65, 221], [3, 195], [195, 197], [197, 3], [25, 7], [7, 33], [33, 25], [220, 237], [237, 44], [44, 220], [70, 71], [71, 139], [139, 70], [122, 193], [193, 245], [245, 122], [247, 130], [130, 33], [33, 247], [71, 21], [21, 162], [162, 71], [170, 169], [169, 150], [150, 170], [188, 174], [174, 196], [196, 188], [216, 186], [186, 92], [92, 216], [2, 97], [97, 167], [167, 2], [141, 125], [125, 241], [241, 141], [164, 167], [167, 37], [37, 164], [72, 38], [38, 12], [12, 72], [38, 82], [82, 13], [13, 38], [63, 68], [68, 71], [71, 63], [226, 35], [35, 111], [111, 226], [101, 50], [50, 205], [205, 101], [206, 92], [92, 165], [165, 206], [209, 198], [198, 217], [217, 209], [165, 167], [167, 97], [97, 165], [220, 115], [115, 218], [218, 220], [133, 112], [112, 243], [243, 133], [239, 238], [238, 241], [241, 239], [214, 135], [135, 169], [169, 214], [190, 173], [173, 133], [133, 190], [171, 208], [208, 32], [32, 171], [125, 44], [44, 237], [237, 125], [86, 87], [87, 178], [178, 86], [85, 86], [86, 179], [179, 85], [84, 85], [85, 180], [180, 84], [83, 84], [84, 181], [181, 83], [201, 83], [83, 182], [182, 201], [137, 93], [93, 132], [132, 137], [76, 62], [62, 183], [183, 76], [61, 76], [76, 184], [184, 61], [57, 61], [61, 185], [185, 57], [212, 57], [57, 186], [186, 212], [214, 207], [207, 187], [187, 214], [34, 143], [143, 156], [156, 34], [79, 239], [239, 237], [237, 79], [123, 137], [137, 177], [177, 123], [44, 1], [1, 4], [4, 44], [201, 194], [194, 32], [32, 201], [64, 102], [102, 129], [129, 64], [213, 215], [215, 138], [138, 213], [59, 166], [166, 219], [219, 59], [242, 99], [99, 97], [97, 242], [2, 94], [94, 141], [141, 2], [75, 59], [59, 235], [235, 75], [24, 110], [110, 228], [228, 24], [25, 130], [130, 226], [226, 25], [23, 24], [24, 229], [229, 23], [22, 23], [23, 230], [230, 22], [26, 22], [22, 231], [231, 26], [112, 26], [26, 232], [232, 112], [189, 190], [190, 243], [243, 189], [221, 56], [56, 190], [190, 221], [28, 56], [56, 221], [221, 28], [27, 28], [28, 222], [222, 27], [29, 27], [27, 223], [223, 29], [30, 29], [29, 224], [224, 30], [247, 30], [30, 225], [225, 247], [238, 79], [79, 20], [20, 238], [166, 59], [59, 75], [75, 166], [60, 75], [75, 240], [240, 60], [147, 177], [177, 215], [215, 147], [20, 79], [79, 166], [166, 20], [187, 147], [147, 213], [213, 187], [112, 233], [233, 244], [244, 112], [233, 128], [128, 245], [245, 233], [128, 114], [114, 188], [188, 128], [114, 217], [217, 174], [174, 114], [131, 115], [115, 220], [220, 131], [217, 198], [198, 236], [236, 217], [198, 131], [131, 134], [134, 198], [177, 132], [132, 58], [58, 177], [143, 35], [35, 124], [124, 143], [110, 163], [163, 7], [7, 110], [228, 110], [110, 25], [25, 228], [356, 389], [389, 368], [368, 356], [11, 302], [302, 267], [267, 11], [452, 350], [350, 349], [349, 452], [302, 303], [303, 269], [269, 302], [357, 343], [343, 277], [277, 357], [452, 453], [453, 357], [357, 452], [333, 332], [332, 297], [297, 333], [175, 152], [152, 377], [377, 175], [347, 348], [348, 330], [330, 347], [303, 304], [304, 270], [270, 303], [9, 336], [336, 337], [337, 9], [278, 279], [279, 360], [360, 278], [418, 262], [262, 431], [431, 418], [304, 408], [408, 409], [409, 304], [310, 415], [415, 407], [407, 310], [270, 409], [409, 410], [410, 270], [450, 348], [348, 347], [347, 450], [422, 430], [430, 434], [434, 422], [313, 314], [314, 17], [17, 313], [306, 307], [307, 375], [375, 306], [387, 388], [388, 260], [260, 387], [286, 414], [414, 398], [398, 286], [335, 406], [406, 418], [418, 335], [364, 367], [367, 416], [416, 364], [423, 358], [358, 327], [327, 423], [251, 284], [284, 298], [298, 251], [281, 5], [5, 4], [4, 281], [373, 374], [374, 253], [253, 373], [307, 320], [320, 321], [321, 307], [425, 427], [427, 411], [411, 425], [421, 313], [313, 18], [18, 421], [321, 405], [405, 406], [406, 321], [320, 404], [404, 405], [405, 320], [315, 16], [16, 17], [17, 315], [426, 425], [425, 266], [266, 426], [377, 400], [400, 369], [369, 377], [322, 391], [391, 269], [269, 322], [417, 465], [465, 464], [464, 417], [386, 257], [257, 258], [258, 386], [466, 260], [260, 388], [388, 466], [456, 399], [399, 419], [419, 456], [284, 332], [332, 333], [333, 284], [417, 285], [285, 8], [8, 417], [346, 340], [340, 261], [261, 346], [413, 441], [441, 285], [285, 413], [327, 460], [460, 328], [328, 327], [355, 371], [371, 329], [329, 355], [392, 439], [439, 438], [438, 392], [382, 341], [341, 256], [256, 382], [429, 420], [420, 360], [360, 429], [364, 394], [394, 379], [379, 364], [277, 343], [343, 437], [437, 277], [443, 444], [444, 283], [283, 443], [275, 440], [440, 363], [363, 275], [431, 262], [262, 369], [369, 431], [297, 338], [338, 337], [337, 297], [273, 375], [375, 321], [321, 273], [450, 451], [451, 349], [349, 450], [446, 342], [342, 467], [467, 446], [293, 334], [334, 282], [282, 293], [458, 461], [461, 462], [462, 458], [276, 353], [353, 383], [383, 276], [308, 324], [324, 325], [325, 308], [276, 300], [300, 293], [293, 276], [372, 345], [345, 447], [447, 372], [352, 345], [345, 340], [340, 352], [274, 1], [1, 19], [19, 274], [456, 248], [248, 281], [281, 456], [436, 427], [427, 425], [425, 436], [381, 256], [256, 252], [252, 381], [269, 391], [391, 393], [393, 269], [200, 199], [199, 428], [428, 200], [266, 330], [330, 329], [329, 266], [287, 273], [273, 422], [422, 287], [250, 462], [462, 328], [328, 250], [258, 286], [286, 384], [384, 258], [265, 353], [353, 342], [342, 265], [387, 259], [259, 257], [257, 387], [424, 431], [431, 430], [430, 424], [342, 353], [353, 276], [276, 342], [273, 335], [335, 424], [424, 273], [292, 325], [325, 307], [307, 292], [366, 447], [447, 345], [345, 366], [271, 303], [303, 302], [302, 271], [423, 266], [266, 371], [371, 423], [294, 455], [455, 460], [460, 294], [279, 278], [278, 294], [294, 279], [271, 272], [272, 304], [304, 271], [432, 434], [434, 427], [427, 432], [272, 407], [407, 408], [408, 272], [394, 430], [430, 431], [431, 394], [395, 369], [369, 400], [400, 395], [334, 333], [333, 299], [299, 334], [351, 417], [417, 168], [168, 351], [352, 280], [280, 411], [411, 352], [325, 319], [319, 320], [320, 325], [295, 296], [296, 336], [336, 295], [319, 403], [403, 404], [404, 319], [330, 348], [348, 349], [349, 330], [293, 298], [298, 333], [333, 293], [323, 454], [454, 447], [447, 323], [15, 16], [16, 315], [315, 15], [358, 429], [429, 279], [279, 358], [14, 15], [15, 316], [316, 14], [285, 336], [336, 9], [9, 285], [329, 349], [349, 350], [350, 329], [374, 380], [380, 252], [252, 374], [318, 402], [402, 403], [403, 318], [6, 197], [197, 419], [419, 6], [318, 319], [319, 325], [325, 318], [367, 364], [364, 365], [365, 367], [435, 367], [367, 397], [397, 435], [344, 438], [438, 439], [439, 344], [272, 271], [271, 311], [311, 272], [195, 5], [5, 281], [281, 195], [273, 287], [287, 291], [291, 273], [396, 428], [428, 199], [199, 396], [311, 271], [271, 268], [268, 311], [283, 444], [444, 445], [445, 283], [373, 254], [254, 339], [339, 373], [282, 334], [334, 296], [296, 282], [449, 347], [347, 346], [346, 449], [264, 447], [447, 454], [454, 264], [336, 296], [296, 299], [299, 336], [338, 10], [10, 151], [151, 338], [278, 439], [439, 455], [455, 278], [292, 407], [407, 415], [415, 292], [358, 371], [371, 355], [355, 358], [340, 345], [345, 372], [372, 340], [346, 347], [347, 280], [280, 346], [442, 443], [443, 282], [282, 442], [19, 94], [94, 370], [370, 19], [441, 442], [442, 295], [295, 441], [248, 419], [419, 197], [197, 248], [263, 255], [255, 359], [359, 263], [440, 275], [275, 274], [274, 440], [300, 383], [383, 368], [368, 300], [351, 412], [412, 465], [465, 351], [263, 467], [467, 466], [466, 263], [301, 368], [368, 389], [389, 301], [395, 378], [378, 379], [379, 395], [412, 351], [351, 419], [419, 412], [436, 426], [426, 322], [322, 436], [2, 164], [164, 393], [393, 2], [370, 462], [462, 461], [461, 370], [164, 0], [0, 267], [267, 164], [302, 11], [11, 12], [12, 302], [268, 12], [12, 13], [13, 268], [293, 300], [300, 301], [301, 293], [446, 261], [261, 340], [340, 446], [330, 266], [266, 425], [425, 330], [426, 423], [423, 391], [391, 426], [429, 355], [355, 437], [437, 429], [391, 327], [327, 326], [326, 391], [440, 457], [457, 438], [438, 440], [341, 382], [382, 362], [362, 341], [459, 457], [457, 461], [461, 459], [434, 430], [430, 394], [394, 434], [414, 463], [463, 362], [362, 414], [396, 369], [369, 262], [262, 396], [354, 461], [461, 457], [457, 354], [316, 403], [403, 402], [402, 316], [315, 404], [404, 403], [403, 315], [314, 405], [405, 404], [404, 314], [313, 406], [406, 405], [405, 313], [421, 418], [418, 406], [406, 421], [366, 401], [401, 361], [361, 366], [306, 408], [408, 407], [407, 306], [291, 409], [409, 408], [408, 291], [287, 410], [410, 409], [409, 287], [432, 436], [436, 410], [410, 432], [434, 416], [416, 411], [411, 434], [264, 368], [368, 383], [383, 264], [309, 438], [438, 457], [457, 309], [352, 376], [376, 401], [401, 352], [274, 275], [275, 4], [4, 274], [421, 428], [428, 262], [262, 421], [294, 327], [327, 358], [358, 294], [433, 416], [416, 367], [367, 433], [289, 455], [455, 439], [439, 289], [462, 370], [370, 326], [326, 462], [2, 326], [326, 370], [370, 2], [305, 460], [460, 455], [455, 305], [254, 449], [449, 448], [448, 254], [255, 261], [261, 446], [446, 255], [253, 450], [450, 449], [449, 253], [252, 451], [451, 450], [450, 252], [256, 452], [452, 451], [451, 256], [341, 453], [453, 452], [452, 341], [413, 464], [464, 463], [463, 413], [441, 413], [413, 414], [414, 441], [258, 442], [442, 441], [441, 258], [257, 443], [443, 442], [442, 257], [259, 444], [444, 443], [443, 259], [260, 445], [445, 444], [444, 260], [467, 342], [342, 445], [445, 467], [459, 458], [458, 250], [250, 459], [289, 392], [392, 290], [290, 289], [290, 328], [328, 460], [460, 290], [376, 433], [433, 435], [435, 376], [250, 290], [290, 392], [392, 250], [411, 416], [416, 433], [433, 411], [341, 463], [463, 464], [464, 341], [453, 464], [464, 465], [465, 453], [357, 465], [465, 412], [412, 357], [343, 412], [412, 399], [399, 343], [360, 363], [363, 440], [440, 360], [437, 399], [399, 456], [456, 437], [420, 456], [456, 363], [363, 420], [401, 435], [435, 288], [288, 401], [372, 383], [383, 353], [353, 372], [339, 255], [255, 249], [249, 339], [448, 261], [261, 255], [255, 448], [133, 243], [243, 190], [190, 133], [133, 155], [155, 112], [112, 133], [33, 246], [246, 247], [247, 33], [33, 130], [130, 25], [25, 33], [398, 384], [384, 286], [286, 398], [362, 398], [398, 414], [414, 362], [362, 463], [463, 341], [341, 362], [263, 359], [359, 467], [467, 263], [263, 249], [249, 255], [255, 263], [466, 467], [467, 260], [260, 466], [75, 60], [60, 166], [166, 75], [238, 239], [239, 79], [79, 238], [162, 127], [127, 139], [139, 162], [72, 11], [11, 37], [37, 72], [121, 232], [232, 120], [120, 121], [73, 72], [72, 39], [39, 73], [114, 128], [128, 47], [47, 114], [233, 232], [232, 128], [128, 233], [103, 104], [104, 67], [67, 103], [152, 175], [175, 148], [148, 152], [119, 118], [118, 101], [101, 119], [74, 73], [73, 40], [40, 74], [107, 9], [9, 108], [108, 107], [49, 48], [48, 131], [131, 49], [32, 194], [194, 211], [211, 32], [184, 74], [74, 185], [185, 184], [191, 80], [80, 183], [183, 191], [185, 40], [40, 186], [186, 185], [119, 230], [230, 118], [118, 119], [210, 202], [202, 214], [214, 210], [84, 83], [83, 17], [17, 84], [77, 76], [76, 146], [146, 77], [161, 160], [160, 30], [30, 161], [190, 56], [56, 173], [173, 190], [182, 106], [106, 194], [194, 182], [138, 135], [135, 192], [192, 138], [129, 203], [203, 98], [98, 129], [54, 21], [21, 68], [68, 54], [5, 51], [51, 4], [4, 5], [145, 144], [144, 23], [23, 145], [90, 77], [77, 91], [91, 90], [207, 205], [205, 187], [187, 207], [83, 201], [201, 18], [18, 83], [181, 91], [91, 182], [182, 181], [180, 90], [90, 181], [181, 180], [16, 85], [85, 17], [17, 16], [205, 206], [206, 36], [36, 205], [176, 148], [148, 140], [140, 176], [165, 92], [92, 39], [39, 165], [245, 193], [193, 244], [244, 245], [27, 159], [159, 28], [28, 27], [30, 247], [247, 161], [161, 30], [174, 236], [236, 196], [196, 174], [103, 54], [54, 104], [104, 103], [55, 193], [193, 8], [8, 55], [111, 117], [117, 31], [31, 111], [221, 189], [189, 55], [55, 221], [240, 98], [98, 99], [99, 240], [142, 126], [126, 100], [100, 142], [219, 166], [166, 218], [218, 219], [112, 155], [155, 26], [26, 112], [198, 209], [209, 131], [131, 198], [169, 135], [135, 150], [150, 169], [114, 47], [47, 217], [217, 114], [224, 223], [223, 53], [53, 224], [220, 45], [45, 134], [134, 220], [32, 211], [211, 140], [140, 32], [109, 67], [67, 108], [108, 109], [146, 43], [43, 91], [91, 146], [231, 230], [230, 120], [120, 231], [113, 226], [226, 247], [247, 113], [105, 63], [63, 52], [52, 105], [241, 238], [238, 242], [242, 241], [124, 46], [46, 156], [156, 124], [95, 78], [78, 96], [96, 95], [70, 46], [46, 63], [63, 70], [116, 143], [143, 227], [227, 116], [116, 123], [123, 111], [111, 116], [1, 44], [44, 19], [19, 1], [3, 236], [236, 51], [51, 3], [207, 216], [216, 205], [205, 207], [26, 154], [154, 22], [22, 26], [165, 39], [39, 167], [167, 165], [199, 200], [200, 208], [208, 199], [101, 36], [36, 100], [100, 101], [43, 57], [57, 202], [202, 43], [242, 20], [20, 99], [99, 242], [56, 28], [28, 157], [157, 56], [124, 35], [35, 113], [113, 124], [29, 160], [160, 27], [27, 29], [211, 204], [204, 210], [210, 211], [124, 113], [113, 46], [46, 124], [106, 43], [43, 204], [204, 106], [96, 62], [62, 77], [77, 96], [227, 137], [137, 116], [116, 227], [73, 41], [41, 72], [72, 73], [36, 203], [203, 142], [142, 36], [235, 64], [64, 240], [240, 235], [48, 49], [49, 64], [64, 48], [42, 41], [41, 74], [74, 42], [214, 212], [212, 207], [207, 214], [183, 42], [42, 184], [184, 183], [210, 169], [169, 211], [211, 210], [140, 170], [170, 176], [176, 140], [104, 105], [105, 69], [69, 104], [193, 122], [122, 168], [168, 193], [50, 123], [123, 187], [187, 50], [89, 96], [96, 90], [90, 89], [66, 65], [65, 107], [107, 66], [179, 89], [89, 180], [180, 179], [119, 101], [101, 120], [120, 119], [68, 63], [63, 104], [104, 68], [234, 93], [93, 227], [227, 234], [16, 15], [15, 85], [85, 16], [209, 129], [129, 49], [49, 209], [15, 14], [14, 86], [86, 15], [107, 55], [55, 9], [9, 107], [120, 100], [100, 121], [121, 120], [153, 145], [145, 22], [22, 153], [178, 88], [88, 179], [179, 178], [197, 6], [6, 196], [196, 197], [89, 88], [88, 96], [96, 89], [135, 138], [138, 136], [136, 135], [138, 215], [215, 172], [172, 138], [218, 115], [115, 219], [219, 218], [41, 42], [42, 81], [81, 41], [5, 195], [195, 51], [51, 5], [57, 43], [43, 61], [61, 57], [208, 171], [171, 199], [199, 208], [41, 81], [81, 38], [38, 41], [224, 53], [53, 225], [225, 224], [24, 144], [144, 110], [110, 24], [105, 52], [52, 66], [66, 105], [118, 229], [229, 117], [117, 118], [227, 34], [34, 234], [234, 227], [66, 107], [107, 69], [69, 66], [10, 109], [109, 151], [151, 10], [219, 48], [48, 235], [235, 219], [183, 62], [62, 191], [191, 183], [142, 129], [129, 126], [126, 142], [116, 111], [111, 143], [143, 116], [118, 117], [117, 50], [50, 118], [223, 222], [222, 52], [52, 223], [94, 19], [19, 141], [141, 94], [222, 221], [221, 65], [65, 222], [196, 3], [3, 197], [197, 196], [45, 220], [220, 44], [44, 45], [156, 70], [70, 139], [139, 156], [188, 122], [122, 245], [245, 188], [139, 71], [71, 162], [162, 139], [149, 170], [170, 150], [150, 149], [122, 188], [188, 196], [196, 122], [206, 216], [216, 92], [92, 206], [164, 2], [2, 167], [167, 164], [242, 141], [141, 241], [241, 242], [0, 164], [164, 37], [37, 0], [11, 72], [72, 12], [12, 11], [12, 38], [38, 13], [13, 12], [70, 63], [63, 71], [71, 70], [31, 226], [226, 111], [111, 31], [36, 101], [101, 205], [205, 36], [203, 206], [206, 165], [165, 203], [126, 209], [209, 217], [217, 126], [98, 165], [165, 97], [97, 98], [237, 220], [220, 218], [218, 237], [237, 239], [239, 241], [241, 237], [210, 214], [214, 169], [169, 210], [140, 171], [171, 32], [32, 140], [241, 125], [125, 237], [237, 241], [179, 86], [86, 178], [178, 179], [180, 85], [85, 179], [179, 180], [181, 84], [84, 180], [180, 181], [182, 83], [83, 181], [181, 182], [194, 201], [201, 182], [182, 194], [177, 137], [137, 132], [132, 177], [184, 76], [76, 183], [183, 184], [185, 61], [61, 184], [184, 185], [186, 57], [57, 185], [185, 186], [216, 212], [212, 186], [186, 216], [192, 214], [214, 187], [187, 192], [139, 34], [34, 156], [156, 139], [218, 79], [79, 237], [237, 218], [147, 123], [123, 177], [177, 147], [45, 44], [44, 4], [4, 45], [208, 201], [201, 32], [32, 208], [98, 64], [64, 129], [129, 98], [192, 213], [213, 138], [138, 192], [235, 59], [59, 219], [219, 235], [141, 242], [242, 97], [97, 141], [97, 2], [2, 141], [141, 97], [240, 75], [75, 235], [235, 240], [229, 24], [24, 228], [228, 229], [31, 25], [25, 226], [226, 31], [230, 23], [23, 229], [229, 230], [231, 22], [22, 230], [230, 231], [232, 26], [26, 231], [231, 232], [233, 112], [112, 232], [232, 233], [244, 189], [189, 243], [243, 244], [189, 221], [221, 190], [190, 189], [222, 28], [28, 221], [221, 222], [223, 27], [27, 222], [222, 223], [224, 29], [29, 223], [223, 224], [225, 30], [30, 224], [224, 225], [113, 247], [247, 225], [225, 113], [99, 60], [60, 240], [240, 99], [213, 147], [147, 215], [215, 213], [60, 20], [20, 166], [166, 60], [192, 187], [187, 213], [213, 192], [243, 112], [112, 244], [244, 243], [244, 233], [233, 245], [245, 244], [245, 128], [128, 188], [188, 245], [188, 114], [114, 174], [174, 188], [134, 131], [131, 220], [220, 134], [174, 217], [217, 236], [236, 174], [236, 198], [198, 134], [134, 236], [215, 177], [177, 58], [58, 215], [156, 143], [143, 124], [124, 156], [25, 110], [110, 7], [7, 25], [31, 228], [228, 25], [25, 31], [264, 356], [356, 368], [368, 264], [0, 11], [11, 267], [267, 0], [451, 452], [452, 349], [349, 451], [267, 302], [302, 269], [269, 267], [350, 357], [357, 277], [277, 350], [350, 452], [452, 357], [357, 350], [299, 333], [333, 297], [297, 299], [396, 175], [175, 377], [377, 396], [280, 347], [347, 330], [330, 280], [269, 303], [303, 270], [270, 269], [151, 9], [9, 337], [337, 151], [344, 278], [278, 360], [360, 344], [424, 418], [418, 431], [431, 424], [270, 304], [304, 409], [409, 270], [272, 310], [310, 407], [407, 272], [322, 270], [270, 410], [410, 322], [449, 450], [450, 347], [347, 449], [432, 422], [422, 434], [434, 432], [18, 313], [313, 17], [17, 18], [291, 306], [306, 375], [375, 291], [259, 387], [387, 260], [260, 259], [424, 335], [335, 418], [418, 424], [434, 364], [364, 416], [416, 434], [391, 423], [423, 327], [327, 391], [301, 251], [251, 298], [298, 301], [275, 281], [281, 4], [4, 275], [254, 373], [373, 253], [253, 254], [375, 307], [307, 321], [321, 375], [280, 425], [425, 411], [411, 280], [200, 421], [421, 18], [18, 200], [335, 321], [321, 406], [406, 335], [321, 320], [320, 405], [405, 321], [314, 315], [315, 17], [17, 314], [423, 426], [426, 266], [266, 423], [396, 377], [377, 369], [369, 396], [270, 322], [322, 269], [269, 270], [413, 417], [417, 464], [464, 413], [385, 386], [386, 258], [258, 385], [248, 456], [456, 419], [419, 248], [298, 284], [284, 333], [333, 298], [168, 417], [417, 8], [8, 168], [448, 346], [346, 261], [261, 448], [417, 413], [413, 285], [285, 417], [326, 327], [327, 328], [328, 326], [277, 355], [355, 329], [329, 277], [309, 392], [392, 438], [438, 309], [381, 382], [382, 256], [256, 381], [279, 429], [429, 360], [360, 279], [365, 364], [364, 379], [379, 365], [355, 277], [277, 437], [437, 355], [282, 443], [443, 283], [283, 282], [281, 275], [275, 363], [363, 281], [395, 431], [431, 369], [369, 395], [299, 297], [297, 337], [337, 299], [335, 273], [273, 321], [321, 335], [348, 450], [450, 349], [349, 348], [359, 446], [446, 467], [467, 359], [283, 293], [293, 282], [282, 283], [250, 458], [458, 462], [462, 250], [300, 276], [276, 383], [383, 300], [292, 308], [308, 325], [325, 292], [283, 276], [276, 293], [293, 283], [264, 372], [372, 447], [447, 264], [346, 352], [352, 340], [340, 346], [354, 274], [274, 19], [19, 354], [363, 456], [456, 281], [281, 363], [426, 436], [436, 425], [425, 426], [380, 381], [381, 252], [252, 380], [267, 269], [269, 393], [393, 267], [421, 200], [200, 428], [428, 421], [371, 266], [266, 329], [329, 371], [432, 287], [287, 422], [422, 432], [290, 250], [250, 328], [328, 290], [385, 258], [258, 384], [384, 385], [446, 265], [265, 342], [342, 446], [386, 387], [387, 257], [257, 386], [422, 424], [424, 430], [430, 422], [445, 342], [342, 276], [276, 445], [422, 273], [273, 424], [424, 422], [306, 292], [292, 307], [307, 306], [352, 366], [366, 345], [345, 352], [268, 271], [271, 302], [302, 268], [358, 423], [423, 371], [371, 358], [327, 294], [294, 460], [460, 327], [331, 279], [279, 294], [294, 331], [303, 271], [271, 304], [304, 303], [436, 432], [432, 427], [427, 436], [304, 272], [272, 408], [408, 304], [395, 394], [394, 431], [431, 395], [378, 395], [395, 400], [400, 378], [296, 334], [334, 299], [299, 296], [6, 351], [351, 168], [168, 6], [376, 352], [352, 411], [411, 376], [307, 325], [325, 320], [320, 307], [285, 295], [295, 336], [336, 285], [320, 319], [319, 404], [404, 320], [329, 330], [330, 349], [349, 329], [334, 293], [293, 333], [333, 334], [366, 323], [323, 447], [447, 366], [316, 15], [15, 315], [315, 316], [331, 358], [358, 279], [279, 331], [317, 14], [14, 316], [316, 317], [8, 285], [285, 9], [9, 8], [277, 329], [329, 350], [350, 277], [253, 374], [374, 252], [252, 253], [319, 318], [318, 403], [403, 319], [351, 6], [6, 419], [419, 351], [324, 318], [318, 325], [325, 324], [397, 367], [367, 365], [365, 397], [288, 435], [435, 397], [397, 288], [278, 344], [344, 439], [439, 278], [310, 272], [272, 311], [311, 310], [248, 195], [195, 281], [281, 248], [375, 273], [273, 291], [291, 375], [175, 396], [396, 199], [199, 175], [312, 311], [311, 268], [268, 312], [276, 283], [283, 445], [445, 276], [390, 373], [373, 339], [339, 390], [295, 282], [282, 296], [296, 295], [448, 449], [449, 346], [346, 448], [356, 264], [264, 454], [454, 356], [337, 336], [336, 299], [299, 337], [337, 338], [338, 151], [151, 337], [294, 278], [278, 455], [455, 294], [308, 292], [292, 415], [415, 308], [429, 358], [358, 355], [355, 429], [265, 340], [340, 372], [372, 265], [352, 346], [346, 280], [280, 352], [295, 442], [442, 282], [282, 295], [354, 19], [19, 370], [370, 354], [285, 441], [441, 295], [295, 285], [195, 248], [248, 197], [197, 195], [457, 440], [440, 274], [274, 457], [301, 300], [300, 368], [368, 301], [417, 351], [351, 465], [465, 417], [251, 301], [301, 389], [389, 251], [394, 395], [395, 379], [379, 394], [399, 412], [412, 419], [419, 399], [410, 436], [436, 322], [322, 410], [326, 2], [2, 393], [393, 326], [354, 370], [370, 461], [461, 354], [393, 164], [164, 267], [267, 393], [268, 302], [302, 12], [12, 268], [312, 268], [268, 13], [13, 312], [298, 293], [293, 301], [301, 298], [265, 446], [446, 340], [340, 265], [280, 330], [330, 425], [425, 280], [322, 426], [426, 391], [391, 322], [420, 429], [429, 437], [437, 420], [393, 391], [391, 326], [326, 393], [344, 440], [440, 438], [438, 344], [458, 459], [459, 461], [461, 458], [364, 434], [434, 394], [394, 364], [428, 396], [396, 262], [262, 428], [274, 354], [354, 457], [457, 274], [317, 316], [316, 402], [402, 317], [316, 315], [315, 403], [403, 316], [315, 314], [314, 404], [404, 315], [314, 313], [313, 405], [405, 314], [313, 421], [421, 406], [406, 313], [323, 366], [366, 361], [361, 323], [292, 306], [306, 407], [407, 292], [306, 291], [291, 408], [408, 306], [291, 287], [287, 409], [409, 291], [287, 432], [432, 410], [410, 287], [427, 434], [434, 411], [411, 427], [372, 264], [264, 383], [383, 372], [459, 309], [309, 457], [457, 459], [366, 352], [352, 401], [401, 366], [1, 274], [274, 4], [4, 1], [418, 421], [421, 262], [262, 418], [331, 294], [294, 358], [358, 331], [435, 433], [433, 367], [367, 435], [392, 289], [289, 439], [439, 392], [328, 462], [462, 326], [326, 328], [94, 2], [2, 370], [370, 94], [289, 305], [305, 455], [455, 289], [339, 254], [254, 448], [448, 339], [359, 255], [255, 446], [446, 359], [254, 253], [253, 449], [449, 254], [253, 252], [252, 450], [450, 253], [252, 256], [256, 451], [451, 252], [256, 341], [341, 452], [452, 256], [414, 413], [413, 463], [463, 414], [286, 441], [441, 414], [414, 286], [286, 258], [258, 441], [441, 286], [258, 257], [257, 442], [442, 258], [257, 259], [259, 443], [443, 257], [259, 260], [260, 444], [444, 259], [260, 467], [467, 445], [445, 260], [309, 459], [459, 250], [250, 309], [305, 289], [289, 290], [290, 305], [305, 290], [290, 460], [460, 305], [401, 376], [376, 435], [435, 401], [309, 250], [250, 392], [392, 309], [376, 411], [411, 433], [433, 376], [453, 341], [341, 464], [464, 453], [357, 453], [453, 465], [465, 357], [343, 357], [357, 412], [412, 343], [437, 343], [343, 399], [399, 437], [344, 360], [360, 440], [440, 344], [420, 437], [437, 456], [456, 420], [360, 420], [420, 363], [363, 360], [361, 401], [401, 288], [288, 361], [265, 372], [372, 353], [353, 265], [390, 339], [339, 249], [249, 390], [339, 448], [448, 255], [255, 339]]), E2("VERSION", "0.4.1646425229");
      }).call(D);
      z = function() {
        return z = Object.assign || function(t2) {
          for (var e, n = 1, r = arguments.length; n < r; n++)
            for (var i in e = arguments[n])
              Object.prototype.hasOwnProperty.call(e, i) && (t2[i] = e[i]);
          return t2;
        }, z.apply(this, arguments);
      };
      V = ["rightEye", "leftEye", "noseTip", "mouthCenter", "rightEarTragion", "leftEarTragion"];
      H = { modelType: "short", runtime: "mediapipe", maxFaces: 1 };
      K = function() {
        function t2(t3) {
          var e = this;
          this.width = 0, this.height = 0, this.selfieMode = false, this.faceDetectorSolution = new P.FaceDetection({ locateFile: function(e2, n) {
            return t3.solutionPath ? t3.solutionPath.replace(/\/+$/, "") + "/" + e2 : n + "/" + e2;
          } }), this.faceDetectorSolution.setOptions({ selfieMode: this.selfieMode, model: t3.modelType }), this.faceDetectorSolution.onResults(function(t4) {
            if (e.height = t4.image.height, e.width = t4.image.width, e.faces = [], null !== t4.detections)
              for (var n = 0, r = t4.detections; n < r.length; n++) {
                var i = r[n];
                e.faces.push(e.normalizedToAbsolute(i.landmarks, (void 0, void 0, void 0, { xMin: a = (o = i.boundingBox).xCenter - o.width / 2, xMax: a + o.width, yMin: u = o.yCenter - o.height / 2, yMax: u + o.height, width: o.width, height: o.height })));
              }
            var o, a, u;
          });
        }
        return t2.prototype.normalizedToAbsolute = function(t3, e) {
          var n = this;
          return { keypoints: t3.map(function(t4, e2) {
            return { x: t4.x * n.width, y: t4.y * n.height, name: V[e2] };
          }), box: { xMin: e.xMin * this.width, yMin: e.yMin * this.height, xMax: e.xMax * this.width, yMax: e.yMax * this.height, width: e.width * this.width, height: e.height * this.height } };
        }, t2.prototype.estimateFaces = function(t3, e) {
          return U(this, void 0, void 0, function() {
            var i, o;
            return N(this, function(a) {
              switch (a.label) {
                case 0:
                  return e && e.flipHorizontal && e.flipHorizontal !== this.selfieMode && (this.selfieMode = e.flipHorizontal, this.faceDetectorSolution.setOptions({ selfieMode: this.selfieMode })), t3 instanceof Tensor ? (o = ImageData.bind, [4, browser_exports.toPixels(t3)]) : [3, 2];
                case 1:
                  return i = new (o.apply(ImageData, [void 0, a.sent(), t3.shape[1], t3.shape[0]]))(), [3, 3];
                case 2:
                  i = t3, a.label = 3;
                case 3:
                  return t3 = i, [4, this.faceDetectorSolution.send({ image: t3 })];
                case 4:
                  return a.sent(), [2, this.faces];
              }
            });
          });
        }, t2.prototype.dispose = function() {
          this.faceDetectorSolution.close();
        }, t2.prototype.reset = function() {
          this.faceDetectorSolution.reset(), this.width = 0, this.height = 0, this.faces = null, this.selfieMode = false;
        }, t2.prototype.initialize = function() {
          return this.faceDetectorSolution.initialize();
        }, t2;
      }();
      it = { reduceBoxesInLowestLayer: false, interpolatedScaleAspectRatio: 1, featureMapHeight: [], featureMapWidth: [], numLayers: 4, minScale: 0.1484375, maxScale: 0.75, inputSizeHeight: 128, inputSizeWidth: 128, anchorOffsetX: 0.5, anchorOffsetY: 0.5, strides: [8, 16, 16, 16], aspectRatios: [1], fixedAnchorSize: true };
      ot = { reduceBoxesInLowestLayer: false, interpolatedScaleAspectRatio: 0, featureMapHeight: [], featureMapWidth: [], numLayers: 1, minScale: 0.1484375, maxScale: 0.75, inputSizeHeight: 192, inputSizeWidth: 192, anchorOffsetX: 0.5, anchorOffsetY: 0.5, strides: [4], aspectRatios: [1], fixedAnchorSize: true };
      at = { runtime: "tfjs", modelType: "short", maxFaces: 1, detectorModelUrl: "https://tfhub.dev/mediapipe/tfjs-model/face_detection/short/1" };
      ut = { applyExponentialOnBoxSize: false, flipVertically: false, ignoreClasses: [], numClasses: 1, numBoxes: 896, numCoords: 16, boxCoordOffset: 0, keypointCoordOffset: 4, numKeypoints: 6, numValuesPerKeypoint: 2, sigmoidScore: true, scoreClippingThresh: 100, reverseOutputOrder: true, xScale: 128, yScale: 128, hScale: 128, wScale: 128, minScoreThresh: 0.5 };
      st = { applyExponentialOnBoxSize: false, flipVertically: false, ignoreClasses: [], numClasses: 1, numBoxes: 2304, numCoords: 16, boxCoordOffset: 0, keypointCoordOffset: 4, numKeypoints: 6, numValuesPerKeypoint: 2, sigmoidScore: true, scoreClippingThresh: 100, reverseOutputOrder: true, xScale: 192, yScale: 192, hScale: 192, wScale: 192, minScoreThresh: 0.6 };
      ct = { outputTensorSize: { width: 128, height: 128 }, keepAspectRatio: true, outputTensorFloatRange: [-1, 1], borderMode: "zero" };
      ht = { outputTensorSize: { width: 192, height: 192 }, keepAspectRatio: true, outputTensorFloatRange: [-1, 1], borderMode: "zero" };
      lt = function() {
        function t2(t3, e, n) {
          this.detectorModel = e, this.maxFaces = n, "full" === t3 ? (this.imageToTensorConfig = ht, this.tensorsToDetectionConfig = st, this.anchors = q(ot)) : (this.imageToTensorConfig = ct, this.tensorsToDetectionConfig = ut, this.anchors = q(it));
          var r = tensor1d(this.anchors.map(function(t4) {
            return t4.width;
          })), o = tensor1d(this.anchors.map(function(t4) {
            return t4.height;
          })), a = tensor1d(this.anchors.map(function(t4) {
            return t4.xCenter;
          })), u = tensor1d(this.anchors.map(function(t4) {
            return t4.yCenter;
          }));
          this.anchorTensor = { x: a, y: u, w: r, h: o };
        }
        return t2.prototype.dispose = function() {
          this.detectorModel.dispose(), dispose([this.anchorTensor.x, this.anchorTensor.y, this.anchorTensor.w, this.anchorTensor.h]);
        }, t2.prototype.reset = function() {
        }, t2.prototype.detectFaces = function(t3, e) {
          return void 0 === e && (e = false), U(this, void 0, void 0, function() {
            var n, r, i, a, d, p2, g, v, m, y, w;
            return N(this, function(b) {
              switch (b.label) {
                case 0:
                  return null == t3 ? (this.reset(), [2, []]) : (n = tidy(function() {
                    var n2 = cast(X(t3), "float32");
                    return e && (n2 = squeeze(image.flipLeftRight(expandDims(n2, 0)), [0])), n2;
                  }), r = J(n, this.imageToTensorConfig), i = r.imageTensor, a = r.transformationMatrix, d = this.detectorModel.execute(i, "Identity:0"), p2 = function(t4) {
                    return tidy(function() {
                      var e2 = function(t5) {
                        return tidy(function() {
                          return [slice(t5, [0, 0, 0], [1, -1, 1]), slice(t5, [0, 0, 1], [1, -1, -1])];
                        });
                      }(t4), n2 = e2[0], r2 = e2[1];
                      return { boxes: squeeze(r2), logits: squeeze(n2) };
                    });
                  }(d), g = p2.boxes, [4, tt([v = p2.logits, g], this.anchorTensor, this.tensorsToDetectionConfig)]);
                case 1:
                  return 0 === (m = b.sent()).length ? (dispose([n, i, d, v, g]), [2, m]) : [4, Q(m, this.maxFaces, 0.3)];
                case 2:
                  return y = b.sent(), w = function(t4, e2) {
                    void 0 === t4 && (t4 = []);
                    var n2, r2 = (n2 = e2, [].concat.apply([], n2));
                    return t4.forEach(function(t5) {
                      var e3 = t5.locationData;
                      e3.relativeKeypoints.forEach(function(t6) {
                        var e4 = Z(r2, [t6.x, t6.y]), n4 = e4[0], i3 = e4[1];
                        t6.x = n4, t6.y = i3;
                      });
                      var n3 = e3.relativeBoundingBox, i2 = Number.MAX_VALUE, o = Number.MAX_VALUE, a6 = Number.MIN_VALUE, u = Number.MIN_VALUE;
                      [[n3.xMin, n3.yMin], [n3.xMin + n3.width, n3.yMin], [n3.xMin + n3.width, n3.yMin + n3.height], [n3.xMin, n3.yMin + n3.height]].forEach(function(t6) {
                        var e4 = Z(r2, t6), n4 = e4[0], s = e4[1];
                        i2 = Math.min(i2, n4), a6 = Math.max(a6, n4), o = Math.min(o, s), u = Math.max(u, s);
                      }), e3.relativeBoundingBox = { xMin: i2, xMax: a6, yMin: o, yMax: u, width: a6 - i2, height: u - o };
                    }), t4;
                  }(y, a), dispose([n, i, d, v, g]), [2, w];
              }
            });
          });
        }, t2.prototype.estimateFaces = function(t3, e) {
          return U(this, void 0, void 0, function() {
            var n, r;
            return N(this, function(i) {
              return n = G(t3), r = !!e && e.flipHorizontal, [2, this.detectFaces(t3, r).then(function(t4) {
                return t4.map(function(t5) {
                  for (var e2 = t5.locationData.relativeKeypoints.map(function(t6, e3) {
                    return z(z({}, t6), { x: t6.x * n.width, y: t6.y * n.height, name: V[e3] });
                  }), r2 = t5.locationData.relativeBoundingBox, i2 = 0, o = ["width", "xMax", "xMin"]; i2 < o.length; i2++)
                    r2[o[i2]] *= n.width;
                  for (var a = 0, u = ["height", "yMax", "yMin"]; a < u.length; a++)
                    r2[u[a]] *= n.height;
                  return { keypoints: e2, box: r2 };
                });
              })];
            });
          });
        }, t2;
      }();
      (rt || (rt = {})).MediaPipeFaceDetector = "MediaPipeFaceDetector";
      It = { runtime: "tfjs", maxFaces: 1, refineLandmarks: false, landmarkModelUrl: "https://tfhub.dev/mediapipe/tfjs-model/face_landmarks_detection/face_mesh/1" };
      Lt = { flipHorizontal: false, staticImageMode: false };
      Bt = { shiftX: 0, shiftY: 0, scaleX: 1.5, scaleY: 1.5, squareLong: true };
      Dt = { outputTensorSize: { width: 192, height: 192 }, outputTensorFloatRange: [0, 1], borderMode: "replicate" };
      Pt = { numLandmarks: 468, inputImageWidth: 192, inputImageHeight: 192, visibilityActivation: "none", flipHorizontally: false, flipVertically: false };
      zt = { numLandmarks: 80, inputImageWidth: 192, inputImageHeight: 192, visibilityActivation: "none", flipHorizontally: false, flipVertically: false };
      Ut = { numLandmarks: 71, inputImageWidth: 192, inputImageHeight: 192, visibilityActivation: "none", flipHorizontally: false, flipVertically: false };
      Nt = { numLandmarks: 5, inputImageWidth: 192, inputImageHeight: 192, visibilityActivation: "none", flipHorizontally: false, flipVertically: false };
      Vt = { indexesMapping: Array.from(Array(468).keys()), zRefinement: "copy" };
      Ht = { indexesMapping: [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 185, 40, 39, 37, 0, 267, 269, 270, 409, 78, 95, 88, 178, 87, 14, 317, 402, 318, 324, 308, 191, 80, 81, 82, 13, 312, 311, 310, 415, 76, 77, 90, 180, 85, 16, 315, 404, 320, 307, 306, 184, 74, 73, 72, 11, 302, 303, 304, 408, 62, 96, 89, 179, 86, 15, 316, 403, 319, 325, 292, 183, 42, 41, 38, 12, 268, 271, 272, 407], zRefinement: "none" };
      Kt = { indexesMapping: [33, 7, 163, 144, 145, 153, 154, 155, 133, 246, 161, 160, 159, 158, 157, 173, 130, 25, 110, 24, 23, 22, 26, 112, 243, 247, 30, 29, 27, 28, 56, 190, 226, 31, 228, 229, 230, 231, 232, 233, 244, 113, 225, 224, 223, 222, 221, 189, 35, 124, 46, 53, 52, 65, 143, 111, 117, 118, 119, 120, 121, 128, 245, 156, 70, 63, 105, 66, 107, 55, 193], zRefinement: "none" };
      Wt = { indexesMapping: [263, 249, 390, 373, 374, 380, 381, 382, 362, 466, 388, 387, 386, 385, 384, 398, 359, 255, 339, 254, 253, 252, 256, 341, 463, 467, 260, 259, 257, 258, 286, 414, 446, 261, 448, 449, 450, 451, 452, 453, 464, 342, 445, 444, 443, 442, 441, 413, 265, 353, 276, 283, 282, 295, 372, 340, 346, 347, 348, 349, 350, 357, 465, 383, 300, 293, 334, 296, 336, 285, 417], zRefinement: "none" };
      Gt = { indexesMapping: [468, 469, 470, 471, 472], zRefinement: [33, 7, 163, 144, 145, 153, 154, 155, 133, 246, 161, 160, 159, 158, 157, 173] };
      Xt = { indexesMapping: [473, 474, 475, 476, 477], zRefinement: [263, 249, 390, 373, 374, 380, 381, 382, 362, 466, 388, 387, 386, 385, 384, 398] };
      Jt = function() {
        function t2(t3, e, n, r) {
          this.detector = t3, this.landmarkModel = e, this.maxFaces = n, this.withAttention = r, this.prevFaceRectsFromLandmarks = null;
        }
        return t2.prototype.estimateFaces = function(t3, n) {
          return S(this, void 0, void 0, function() {
            var r, i, o, a, u, s, c, h, l, f, d, p2, g, v = this;
            return F(this, function(m) {
              switch (m.label) {
                case 0:
                  return r = function(t4) {
                    if (null == t4)
                      return E({}, Lt);
                    var e = E({}, t4);
                    return null == e.flipHorizontal && (e.flipHorizontal = Lt.flipHorizontal), null == e.staticImageMode && (e.staticImageMode = Lt.staticImageMode), e;
                  }(n), null == t3 ? (this.reset(), [2, []]) : (i = yt(t3), o = tidy(function() {
                    var n2 = cast(bt(t3), "float32");
                    if (r.flipHorizontal) {
                      n2 = squeeze(image.flipLeftRight(expandDims(n2, 0)), [0]);
                    }
                    return n2;
                  }), a = this.prevFaceRectsFromLandmarks, r.staticImageMode || null == a || a.length < this.maxFaces ? [4, this.detector.detectFaces(o, false)] : [3, 2]);
                case 1:
                  return 0 === (s = m.sent()).length ? (this.reset(), o.dispose(), [2, []]) : (u = s.map(function(t4) {
                    return v.faceDetectionFrontDetectionToRoi(t4, i);
                  }), [3, 3]);
                case 2:
                  u = [], m.label = 3;
                case 3:
                  return y = 0.5, w = [], [u, a || []].forEach(function(t4) {
                    return t4.forEach(function(t5) {
                      (w = w.filter(function(e) {
                        return vt(t5, e) <= y;
                      })).push(t5);
                    });
                  }), c = w, [4, Promise.all(c.map(function(t4) {
                    return v.faceLandmark(t4, o);
                  }))];
                case 4:
                  for (h = m.sent(), l = [], this.prevFaceRectsFromLandmarks = [], f = 0; f < h.length; ++f)
                    null != (d = h[f]) && (this.prevFaceRectsFromLandmarks.push(this.faceLandmarksToRoi(d, i)), null != (p2 = _t(d, i)) && p2.forEach(function(t4, e) {
                      var n2 = k.get(e);
                      null != n2 && (t4.name = n2);
                    }), g = R(p2), l.push({ keypoints: p2, box: g.locationData.relativeBoundingBox }));
                  return o.dispose(), [2, l];
              }
              var y, w;
            });
          });
        }, t2.prototype.dispose = function() {
          this.detector.dispose(), this.landmarkModel.dispose();
        }, t2.prototype.reset = function() {
          this.detector.reset(), this.prevFaceRectsFromLandmarks = null;
        }, t2.prototype.faceDetectionFrontDetectionToRoi = function(t3, e) {
          return Rt(St(t3, "boundingbox", "normRect", e, { rotationVectorStartKeypointIndex: 0, rotationVectorEndKeypointIndex: 1, rotationVectorTargetAngleDegree: 0 }), e, Bt);
        }, t2.prototype.faceLandmark = function(t3, n) {
          return S(this, void 0, void 0, function() {
            var r, i, o, a, u, s, c;
            return F(this, function(h) {
              switch (h.label) {
                case 0:
                  return r = At(n, Dt, t3).imageTensor, i = ["output_faceflag"].concat(this.withAttention ? ["output_mesh_identity", "output_lips", "Identity_6:0", "Identity_1:0", "Identity_2:0", "Identity_5:0"] : ["output_mesh"]), o = this.landmarkModel.execute(r, i), a = o[0], u = o.slice(1), [4, a.data()];
                case 1:
                  return h.sent()[0] < 0.5 ? (dispose(o), dispose(r), [2, null]) : this.withAttention ? [4, this.tensorsToFaceLandmarksWithAttention(u)] : [3, 3];
                case 2:
                  return s = h.sent(), [3, 5];
                case 3:
                  return [4, this.tensorsToFaceLandmarks(u)];
                case 4:
                  s = h.sent(), h.label = 5;
                case 5:
                  return c = function(t4, e, n2) {
                    void 0 === n2 && (n2 = { ignoreRotation: false });
                    for (var r2 = [], i2 = 0, o2 = t4; i2 < o2.length; i2++) {
                      var a6 = o2[i2], u2 = a6.x - 0.5, s2 = a6.y - 0.5, c2 = n2.ignoreRotation ? 0 : e.rotation, h2 = Math.cos(c2) * u2 - Math.sin(c2) * s2, l = Math.sin(c2) * u2 + Math.cos(c2) * s2;
                      h2 = h2 * e.width + e.xCenter, l = l * e.height + e.yCenter;
                      var f = a6.z * e.width, d = E({}, a6);
                      d.x = h2, d.y = l, d.z = f, r2.push(d);
                    }
                    return r2;
                  }(s, t3), dispose(o), dispose(r), [2, c];
              }
            });
          });
        }, t2.prototype.tensorsToFaceLandmarks = function(t3) {
          return S(this, void 0, void 0, function() {
            return F(this, function(e) {
              return [2, kt(t3[0], Pt)];
            });
          });
        }, t2.prototype.tensorsToFaceLandmarksWithAttention = function(t3) {
          return S(this, void 0, void 0, function() {
            var e, n, r, i, o, a;
            return F(this, function(u) {
              switch (u.label) {
                case 0:
                  return [4, kt(t3[0], Pt)];
                case 1:
                  return e = u.sent(), [4, kt(t3[1], zt)];
                case 2:
                  return n = u.sent(), [4, kt(t3[3], Ut)];
                case 3:
                  return r = u.sent(), [4, kt(t3[5], Ut)];
                case 4:
                  return i = u.sent(), [4, kt(t3[4], Nt)];
                case 5:
                  return o = u.sent(), [4, kt(t3[2], Nt)];
                case 6:
                  return a = u.sent(), [2, Ot([e, n, r, i, o, a], [Vt, Ht, Kt, Wt, Gt, Xt])];
              }
            });
          });
        }, t2.prototype.faceLandmarksToRoi = function(t3, e) {
          return Rt(St(R(t3), "boundingbox", "normRect", e, { rotationVectorStartKeypointIndex: 33, rotationVectorEndKeypointIndex: 263, rotationVectorTargetAngleDegree: 0 }), e, Bt);
        }, t2;
      }();
      !function(t2) {
        t2.MediaPipeFaceMesh = "MediaPipeFaceMesh";
      }(Yt || (Yt = {}));
      Zt = Object.freeze({ __proto__: null, getKeypointIndexByContour: function(t2) {
        if (t2 === Yt.MediaPipeFaceMesh)
          return O;
        throw new Error("Model " + t2 + " is not supported.");
      }, getAdjacentPairs: function(t2) {
        if (t2 === Yt.MediaPipeFaceMesh)
          return _;
        throw new Error("Model " + t2 + " is not supported.");
      } });
    }
  });

  // dist/components/shared/params.js
  function createDetector() {
    return __async(this, null, function* () {
      return $t(Yt.MediaPipeFaceMesh, {
        runtime: "tfjs",
        refineLandmarks: true,
        maxFaces: 1
        // solutionPath: `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4.1633559619`
      });
    });
  }
  var NUM_KEYPOINTS, NUM_IRIS_KEYPOINTS, GREEN, RED, VIDEO_SIZE, STATE, MODEL_BACKEND_MAP;
  var init_params = __esm({
    "dist/components/shared/params.js"() {
      init_face_landmarks_detection_esm();
      init_face_landmarks_detection_esm();
      NUM_KEYPOINTS = 468;
      NUM_IRIS_KEYPOINTS = 5;
      GREEN = "#32EEDB";
      RED = "#FF2C35";
      VIDEO_SIZE = {
        "640 X 480": { width: 640, height: 480 },
        "640 X 360": { width: 640, height: 360 },
        "360 X 270": { width: 360, height: 270 }
      };
      STATE = {
        camera: { targetFPS: 60, sizeOption: "640 X 480" },
        backend: "",
        flags: {},
        modelConfig: {}
      };
      MODEL_BACKEND_MAP = {
        [Yt.MediaPipeFaceMesh]: [
          "mediapipe-gpu",
          "tfjs-webgl"
        ]
      };
    }
  });

  // dist/components/shared/triangulation.js
  var TRIANGULATION;
  var init_triangulation = __esm({
    "dist/components/shared/triangulation.js"() {
      TRIANGULATION = [
        127,
        34,
        139,
        11,
        0,
        37,
        232,
        231,
        120,
        72,
        37,
        39,
        128,
        121,
        47,
        232,
        121,
        128,
        104,
        69,
        67,
        175,
        171,
        148,
        157,
        154,
        155,
        118,
        50,
        101,
        73,
        39,
        40,
        9,
        151,
        108,
        48,
        115,
        131,
        194,
        204,
        211,
        74,
        40,
        185,
        80,
        42,
        183,
        40,
        92,
        186,
        230,
        229,
        118,
        202,
        212,
        214,
        83,
        18,
        17,
        76,
        61,
        146,
        160,
        29,
        30,
        56,
        157,
        173,
        106,
        204,
        194,
        135,
        214,
        192,
        203,
        165,
        98,
        21,
        71,
        68,
        51,
        45,
        4,
        144,
        24,
        23,
        77,
        146,
        91,
        205,
        50,
        187,
        201,
        200,
        18,
        91,
        106,
        182,
        90,
        91,
        181,
        85,
        84,
        17,
        206,
        203,
        36,
        148,
        171,
        140,
        92,
        40,
        39,
        193,
        189,
        244,
        159,
        158,
        28,
        247,
        246,
        161,
        236,
        3,
        196,
        54,
        68,
        104,
        193,
        168,
        8,
        117,
        228,
        31,
        189,
        193,
        55,
        98,
        97,
        99,
        126,
        47,
        100,
        166,
        79,
        218,
        155,
        154,
        26,
        209,
        49,
        131,
        135,
        136,
        150,
        47,
        126,
        217,
        223,
        52,
        53,
        45,
        51,
        134,
        211,
        170,
        140,
        67,
        69,
        108,
        43,
        106,
        91,
        230,
        119,
        120,
        226,
        130,
        247,
        63,
        53,
        52,
        238,
        20,
        242,
        46,
        70,
        156,
        78,
        62,
        96,
        46,
        53,
        63,
        143,
        34,
        227,
        173,
        155,
        133,
        123,
        117,
        111,
        44,
        125,
        19,
        236,
        134,
        51,
        216,
        206,
        205,
        154,
        153,
        22,
        39,
        37,
        167,
        200,
        201,
        208,
        36,
        142,
        100,
        57,
        212,
        202,
        20,
        60,
        99,
        28,
        158,
        157,
        35,
        226,
        113,
        160,
        159,
        27,
        204,
        202,
        210,
        113,
        225,
        46,
        43,
        202,
        204,
        62,
        76,
        77,
        137,
        123,
        116,
        41,
        38,
        72,
        203,
        129,
        142,
        64,
        98,
        240,
        49,
        102,
        64,
        41,
        73,
        74,
        212,
        216,
        207,
        42,
        74,
        184,
        169,
        170,
        211,
        170,
        149,
        176,
        105,
        66,
        69,
        122,
        6,
        168,
        123,
        147,
        187,
        96,
        77,
        90,
        65,
        55,
        107,
        89,
        90,
        180,
        101,
        100,
        120,
        63,
        105,
        104,
        93,
        137,
        227,
        15,
        86,
        85,
        129,
        102,
        49,
        14,
        87,
        86,
        55,
        8,
        9,
        100,
        47,
        121,
        145,
        23,
        22,
        88,
        89,
        179,
        6,
        122,
        196,
        88,
        95,
        96,
        138,
        172,
        136,
        215,
        58,
        172,
        115,
        48,
        219,
        42,
        80,
        81,
        195,
        3,
        51,
        43,
        146,
        61,
        171,
        175,
        199,
        81,
        82,
        38,
        53,
        46,
        225,
        144,
        163,
        110,
        246,
        33,
        7,
        52,
        65,
        66,
        229,
        228,
        117,
        34,
        127,
        234,
        107,
        108,
        69,
        109,
        108,
        151,
        48,
        64,
        235,
        62,
        78,
        191,
        129,
        209,
        126,
        111,
        35,
        143,
        163,
        161,
        246,
        117,
        123,
        50,
        222,
        65,
        52,
        19,
        125,
        141,
        221,
        55,
        65,
        3,
        195,
        197,
        25,
        7,
        33,
        220,
        237,
        44,
        70,
        71,
        139,
        122,
        193,
        245,
        247,
        130,
        33,
        71,
        21,
        162,
        153,
        158,
        159,
        170,
        169,
        150,
        188,
        174,
        196,
        216,
        186,
        92,
        144,
        160,
        161,
        2,
        97,
        167,
        141,
        125,
        241,
        164,
        167,
        37,
        72,
        38,
        12,
        145,
        159,
        160,
        38,
        82,
        13,
        63,
        68,
        71,
        226,
        35,
        111,
        158,
        153,
        154,
        101,
        50,
        205,
        206,
        92,
        165,
        209,
        198,
        217,
        165,
        167,
        97,
        220,
        115,
        218,
        133,
        112,
        243,
        239,
        238,
        241,
        214,
        135,
        169,
        190,
        173,
        133,
        171,
        208,
        32,
        125,
        44,
        237,
        86,
        87,
        178,
        85,
        86,
        179,
        84,
        85,
        180,
        83,
        84,
        181,
        201,
        83,
        182,
        137,
        93,
        132,
        76,
        62,
        183,
        61,
        76,
        184,
        57,
        61,
        185,
        212,
        57,
        186,
        214,
        207,
        187,
        34,
        143,
        156,
        79,
        239,
        237,
        123,
        137,
        177,
        44,
        1,
        4,
        201,
        194,
        32,
        64,
        102,
        129,
        213,
        215,
        138,
        59,
        166,
        219,
        242,
        99,
        97,
        2,
        94,
        141,
        75,
        59,
        235,
        24,
        110,
        228,
        25,
        130,
        226,
        23,
        24,
        229,
        22,
        23,
        230,
        26,
        22,
        231,
        112,
        26,
        232,
        189,
        190,
        243,
        221,
        56,
        190,
        28,
        56,
        221,
        27,
        28,
        222,
        29,
        27,
        223,
        30,
        29,
        224,
        247,
        30,
        225,
        238,
        79,
        20,
        166,
        59,
        75,
        60,
        75,
        240,
        147,
        177,
        215,
        20,
        79,
        166,
        187,
        147,
        213,
        112,
        233,
        244,
        233,
        128,
        245,
        128,
        114,
        188,
        114,
        217,
        174,
        131,
        115,
        220,
        217,
        198,
        236,
        198,
        131,
        134,
        177,
        132,
        58,
        143,
        35,
        124,
        110,
        163,
        7,
        228,
        110,
        25,
        356,
        389,
        368,
        11,
        302,
        267,
        452,
        350,
        349,
        302,
        303,
        269,
        357,
        343,
        277,
        452,
        453,
        357,
        333,
        332,
        297,
        175,
        152,
        377,
        384,
        398,
        382,
        347,
        348,
        330,
        303,
        304,
        270,
        9,
        336,
        337,
        278,
        279,
        360,
        418,
        262,
        431,
        304,
        408,
        409,
        310,
        415,
        407,
        270,
        409,
        410,
        450,
        348,
        347,
        422,
        430,
        434,
        313,
        314,
        17,
        306,
        307,
        375,
        387,
        388,
        260,
        286,
        414,
        398,
        335,
        406,
        418,
        364,
        367,
        416,
        423,
        358,
        327,
        251,
        284,
        298,
        281,
        5,
        4,
        373,
        374,
        253,
        307,
        320,
        321,
        425,
        427,
        411,
        421,
        313,
        18,
        321,
        405,
        406,
        320,
        404,
        405,
        315,
        16,
        17,
        426,
        425,
        266,
        377,
        400,
        369,
        322,
        391,
        269,
        417,
        465,
        464,
        386,
        257,
        258,
        466,
        260,
        388,
        456,
        399,
        419,
        284,
        332,
        333,
        417,
        285,
        8,
        346,
        340,
        261,
        413,
        441,
        285,
        327,
        460,
        328,
        355,
        371,
        329,
        392,
        439,
        438,
        382,
        341,
        256,
        429,
        420,
        360,
        364,
        394,
        379,
        277,
        343,
        437,
        443,
        444,
        283,
        275,
        440,
        363,
        431,
        262,
        369,
        297,
        338,
        337,
        273,
        375,
        321,
        450,
        451,
        349,
        446,
        342,
        467,
        293,
        334,
        282,
        458,
        461,
        462,
        276,
        353,
        383,
        308,
        324,
        325,
        276,
        300,
        293,
        372,
        345,
        447,
        382,
        398,
        362,
        352,
        345,
        340,
        274,
        1,
        19,
        456,
        248,
        281,
        436,
        427,
        425,
        381,
        256,
        252,
        269,
        391,
        393,
        200,
        199,
        428,
        266,
        330,
        329,
        287,
        273,
        422,
        250,
        462,
        328,
        258,
        286,
        384,
        265,
        353,
        342,
        387,
        259,
        257,
        424,
        431,
        430,
        342,
        353,
        276,
        273,
        335,
        424,
        292,
        325,
        307,
        366,
        447,
        345,
        271,
        303,
        302,
        423,
        266,
        371,
        294,
        455,
        460,
        279,
        278,
        294,
        271,
        272,
        304,
        432,
        434,
        427,
        272,
        407,
        408,
        394,
        430,
        431,
        395,
        369,
        400,
        334,
        333,
        299,
        351,
        417,
        168,
        352,
        280,
        411,
        325,
        319,
        320,
        295,
        296,
        336,
        319,
        403,
        404,
        330,
        348,
        349,
        293,
        298,
        333,
        323,
        454,
        447,
        15,
        16,
        315,
        358,
        429,
        279,
        14,
        15,
        316,
        285,
        336,
        9,
        329,
        349,
        350,
        374,
        380,
        252,
        318,
        402,
        403,
        6,
        197,
        419,
        318,
        319,
        325,
        367,
        364,
        365,
        435,
        367,
        397,
        344,
        438,
        439,
        272,
        271,
        311,
        195,
        5,
        281,
        273,
        287,
        291,
        396,
        428,
        199,
        311,
        271,
        268,
        283,
        444,
        445,
        373,
        254,
        339,
        263,
        466,
        249,
        282,
        334,
        296,
        449,
        347,
        346,
        264,
        447,
        454,
        336,
        296,
        299,
        338,
        10,
        151,
        278,
        439,
        455,
        292,
        407,
        415,
        358,
        371,
        355,
        340,
        345,
        372,
        390,
        249,
        466,
        346,
        347,
        280,
        442,
        443,
        282,
        19,
        94,
        370,
        441,
        442,
        295,
        248,
        419,
        197,
        263,
        255,
        359,
        440,
        275,
        274,
        300,
        383,
        368,
        351,
        412,
        465,
        263,
        467,
        466,
        301,
        368,
        389,
        380,
        374,
        386,
        395,
        378,
        379,
        412,
        351,
        419,
        436,
        426,
        322,
        373,
        390,
        388,
        2,
        164,
        393,
        370,
        462,
        461,
        164,
        0,
        267,
        302,
        11,
        12,
        374,
        373,
        387,
        268,
        12,
        13,
        293,
        300,
        301,
        446,
        261,
        340,
        385,
        384,
        381,
        330,
        266,
        425,
        426,
        423,
        391,
        429,
        355,
        437,
        391,
        327,
        326,
        440,
        457,
        438,
        341,
        382,
        362,
        459,
        457,
        461,
        434,
        430,
        394,
        414,
        463,
        362,
        396,
        369,
        262,
        354,
        461,
        457,
        316,
        403,
        402,
        315,
        404,
        403,
        314,
        405,
        404,
        313,
        406,
        405,
        421,
        418,
        406,
        366,
        401,
        361,
        306,
        408,
        407,
        291,
        409,
        408,
        287,
        410,
        409,
        432,
        436,
        410,
        434,
        416,
        411,
        264,
        368,
        383,
        309,
        438,
        457,
        352,
        376,
        401,
        274,
        275,
        4,
        421,
        428,
        262,
        294,
        327,
        358,
        433,
        416,
        367,
        289,
        455,
        439,
        462,
        370,
        326,
        2,
        326,
        370,
        305,
        460,
        455,
        254,
        449,
        448,
        255,
        261,
        446,
        253,
        450,
        449,
        252,
        451,
        450,
        256,
        452,
        451,
        341,
        453,
        452,
        413,
        464,
        463,
        441,
        413,
        414,
        258,
        442,
        441,
        257,
        443,
        442,
        259,
        444,
        443,
        260,
        445,
        444,
        467,
        342,
        445,
        459,
        458,
        250,
        289,
        392,
        290,
        290,
        328,
        460,
        376,
        433,
        435,
        250,
        290,
        392,
        411,
        416,
        433,
        341,
        463,
        464,
        453,
        464,
        465,
        357,
        465,
        412,
        343,
        412,
        399,
        360,
        363,
        440,
        437,
        399,
        456,
        420,
        456,
        363,
        401,
        435,
        288,
        372,
        383,
        353,
        339,
        255,
        249,
        448,
        261,
        255,
        133,
        243,
        190,
        133,
        155,
        112,
        33,
        246,
        247,
        33,
        130,
        25,
        398,
        384,
        286,
        362,
        398,
        414,
        362,
        463,
        341,
        263,
        359,
        467,
        263,
        249,
        255,
        466,
        467,
        260,
        75,
        60,
        166,
        238,
        239,
        79,
        162,
        127,
        139,
        72,
        11,
        37,
        121,
        232,
        120,
        73,
        72,
        39,
        114,
        128,
        47,
        233,
        232,
        128,
        103,
        104,
        67,
        152,
        175,
        148,
        173,
        157,
        155,
        119,
        118,
        101,
        74,
        73,
        40,
        107,
        9,
        108,
        49,
        48,
        131,
        32,
        194,
        211,
        184,
        74,
        185,
        191,
        80,
        183,
        185,
        40,
        186,
        119,
        230,
        118,
        210,
        202,
        214,
        84,
        83,
        17,
        77,
        76,
        146,
        161,
        160,
        30,
        190,
        56,
        173,
        182,
        106,
        194,
        138,
        135,
        192,
        129,
        203,
        98,
        54,
        21,
        68,
        5,
        51,
        4,
        145,
        144,
        23,
        90,
        77,
        91,
        207,
        205,
        187,
        83,
        201,
        18,
        181,
        91,
        182,
        180,
        90,
        181,
        16,
        85,
        17,
        205,
        206,
        36,
        176,
        148,
        140,
        165,
        92,
        39,
        245,
        193,
        244,
        27,
        159,
        28,
        30,
        247,
        161,
        174,
        236,
        196,
        103,
        54,
        104,
        55,
        193,
        8,
        111,
        117,
        31,
        221,
        189,
        55,
        240,
        98,
        99,
        142,
        126,
        100,
        219,
        166,
        218,
        112,
        155,
        26,
        198,
        209,
        131,
        169,
        135,
        150,
        114,
        47,
        217,
        224,
        223,
        53,
        220,
        45,
        134,
        32,
        211,
        140,
        109,
        67,
        108,
        146,
        43,
        91,
        231,
        230,
        120,
        113,
        226,
        247,
        105,
        63,
        52,
        241,
        238,
        242,
        124,
        46,
        156,
        95,
        78,
        96,
        70,
        46,
        63,
        116,
        143,
        227,
        116,
        123,
        111,
        1,
        44,
        19,
        3,
        236,
        51,
        207,
        216,
        205,
        26,
        154,
        22,
        165,
        39,
        167,
        199,
        200,
        208,
        101,
        36,
        100,
        43,
        57,
        202,
        242,
        20,
        99,
        56,
        28,
        157,
        124,
        35,
        113,
        29,
        160,
        27,
        211,
        204,
        210,
        124,
        113,
        46,
        106,
        43,
        204,
        96,
        62,
        77,
        227,
        137,
        116,
        73,
        41,
        72,
        36,
        203,
        142,
        235,
        64,
        240,
        48,
        49,
        64,
        42,
        41,
        74,
        214,
        212,
        207,
        183,
        42,
        184,
        210,
        169,
        211,
        140,
        170,
        176,
        104,
        105,
        69,
        193,
        122,
        168,
        50,
        123,
        187,
        89,
        96,
        90,
        66,
        65,
        107,
        179,
        89,
        180,
        119,
        101,
        120,
        68,
        63,
        104,
        234,
        93,
        227,
        16,
        15,
        85,
        209,
        129,
        49,
        15,
        14,
        86,
        107,
        55,
        9,
        120,
        100,
        121,
        153,
        145,
        22,
        178,
        88,
        179,
        197,
        6,
        196,
        89,
        88,
        96,
        135,
        138,
        136,
        138,
        215,
        172,
        218,
        115,
        219,
        41,
        42,
        81,
        5,
        195,
        51,
        57,
        43,
        61,
        208,
        171,
        199,
        41,
        81,
        38,
        224,
        53,
        225,
        24,
        144,
        110,
        105,
        52,
        66,
        118,
        229,
        117,
        227,
        34,
        234,
        66,
        107,
        69,
        10,
        109,
        151,
        219,
        48,
        235,
        183,
        62,
        191,
        142,
        129,
        126,
        116,
        111,
        143,
        7,
        163,
        246,
        118,
        117,
        50,
        223,
        222,
        52,
        94,
        19,
        141,
        222,
        221,
        65,
        196,
        3,
        197,
        45,
        220,
        44,
        156,
        70,
        139,
        188,
        122,
        245,
        139,
        71,
        162,
        145,
        153,
        159,
        149,
        170,
        150,
        122,
        188,
        196,
        206,
        216,
        92,
        163,
        144,
        161,
        164,
        2,
        167,
        242,
        141,
        241,
        0,
        164,
        37,
        11,
        72,
        12,
        144,
        145,
        160,
        12,
        38,
        13,
        70,
        63,
        71,
        31,
        226,
        111,
        157,
        158,
        154,
        36,
        101,
        205,
        203,
        206,
        165,
        126,
        209,
        217,
        98,
        165,
        97,
        237,
        220,
        218,
        237,
        239,
        241,
        210,
        214,
        169,
        140,
        171,
        32,
        241,
        125,
        237,
        179,
        86,
        178,
        180,
        85,
        179,
        181,
        84,
        180,
        182,
        83,
        181,
        194,
        201,
        182,
        177,
        137,
        132,
        184,
        76,
        183,
        185,
        61,
        184,
        186,
        57,
        185,
        216,
        212,
        186,
        192,
        214,
        187,
        139,
        34,
        156,
        218,
        79,
        237,
        147,
        123,
        177,
        45,
        44,
        4,
        208,
        201,
        32,
        98,
        64,
        129,
        192,
        213,
        138,
        235,
        59,
        219,
        141,
        242,
        97,
        97,
        2,
        141,
        240,
        75,
        235,
        229,
        24,
        228,
        31,
        25,
        226,
        230,
        23,
        229,
        231,
        22,
        230,
        232,
        26,
        231,
        233,
        112,
        232,
        244,
        189,
        243,
        189,
        221,
        190,
        222,
        28,
        221,
        223,
        27,
        222,
        224,
        29,
        223,
        225,
        30,
        224,
        113,
        247,
        225,
        99,
        60,
        240,
        213,
        147,
        215,
        60,
        20,
        166,
        192,
        187,
        213,
        243,
        112,
        244,
        244,
        233,
        245,
        245,
        128,
        188,
        188,
        114,
        174,
        134,
        131,
        220,
        174,
        217,
        236,
        236,
        198,
        134,
        215,
        177,
        58,
        156,
        143,
        124,
        25,
        110,
        7,
        31,
        228,
        25,
        264,
        356,
        368,
        0,
        11,
        267,
        451,
        452,
        349,
        267,
        302,
        269,
        350,
        357,
        277,
        350,
        452,
        357,
        299,
        333,
        297,
        396,
        175,
        377,
        381,
        384,
        382,
        280,
        347,
        330,
        269,
        303,
        270,
        151,
        9,
        337,
        344,
        278,
        360,
        424,
        418,
        431,
        270,
        304,
        409,
        272,
        310,
        407,
        322,
        270,
        410,
        449,
        450,
        347,
        432,
        422,
        434,
        18,
        313,
        17,
        291,
        306,
        375,
        259,
        387,
        260,
        424,
        335,
        418,
        434,
        364,
        416,
        391,
        423,
        327,
        301,
        251,
        298,
        275,
        281,
        4,
        254,
        373,
        253,
        375,
        307,
        321,
        280,
        425,
        411,
        200,
        421,
        18,
        335,
        321,
        406,
        321,
        320,
        405,
        314,
        315,
        17,
        423,
        426,
        266,
        396,
        377,
        369,
        270,
        322,
        269,
        413,
        417,
        464,
        385,
        386,
        258,
        248,
        456,
        419,
        298,
        284,
        333,
        168,
        417,
        8,
        448,
        346,
        261,
        417,
        413,
        285,
        326,
        327,
        328,
        277,
        355,
        329,
        309,
        392,
        438,
        381,
        382,
        256,
        279,
        429,
        360,
        365,
        364,
        379,
        355,
        277,
        437,
        282,
        443,
        283,
        281,
        275,
        363,
        395,
        431,
        369,
        299,
        297,
        337,
        335,
        273,
        321,
        348,
        450,
        349,
        359,
        446,
        467,
        283,
        293,
        282,
        250,
        458,
        462,
        300,
        276,
        383,
        292,
        308,
        325,
        283,
        276,
        293,
        264,
        372,
        447,
        346,
        352,
        340,
        354,
        274,
        19,
        363,
        456,
        281,
        426,
        436,
        425,
        380,
        381,
        252,
        267,
        269,
        393,
        421,
        200,
        428,
        371,
        266,
        329,
        432,
        287,
        422,
        290,
        250,
        328,
        385,
        258,
        384,
        446,
        265,
        342,
        386,
        387,
        257,
        422,
        424,
        430,
        445,
        342,
        276,
        422,
        273,
        424,
        306,
        292,
        307,
        352,
        366,
        345,
        268,
        271,
        302,
        358,
        423,
        371,
        327,
        294,
        460,
        331,
        279,
        294,
        303,
        271,
        304,
        436,
        432,
        427,
        304,
        272,
        408,
        395,
        394,
        431,
        378,
        395,
        400,
        296,
        334,
        299,
        6,
        351,
        168,
        376,
        352,
        411,
        307,
        325,
        320,
        285,
        295,
        336,
        320,
        319,
        404,
        329,
        330,
        349,
        334,
        293,
        333,
        366,
        323,
        447,
        316,
        15,
        315,
        331,
        358,
        279,
        317,
        14,
        316,
        8,
        285,
        9,
        277,
        329,
        350,
        253,
        374,
        252,
        319,
        318,
        403,
        351,
        6,
        419,
        324,
        318,
        325,
        397,
        367,
        365,
        288,
        435,
        397,
        278,
        344,
        439,
        310,
        272,
        311,
        248,
        195,
        281,
        375,
        273,
        291,
        175,
        396,
        199,
        312,
        311,
        268,
        276,
        283,
        445,
        390,
        373,
        339,
        295,
        282,
        296,
        448,
        449,
        346,
        356,
        264,
        454,
        337,
        336,
        299,
        337,
        338,
        151,
        294,
        278,
        455,
        308,
        292,
        415,
        429,
        358,
        355,
        265,
        340,
        372,
        388,
        390,
        466,
        352,
        346,
        280,
        295,
        442,
        282,
        354,
        19,
        370,
        285,
        441,
        295,
        195,
        248,
        197,
        457,
        440,
        274,
        301,
        300,
        368,
        417,
        351,
        465,
        251,
        301,
        389,
        385,
        380,
        386,
        394,
        395,
        379,
        399,
        412,
        419,
        410,
        436,
        322,
        387,
        373,
        388,
        326,
        2,
        393,
        354,
        370,
        461,
        393,
        164,
        267,
        268,
        302,
        12,
        386,
        374,
        387,
        312,
        268,
        13,
        298,
        293,
        301,
        265,
        446,
        340,
        380,
        385,
        381,
        280,
        330,
        425,
        322,
        426,
        391,
        420,
        429,
        437,
        393,
        391,
        326,
        344,
        440,
        438,
        458,
        459,
        461,
        364,
        434,
        394,
        428,
        396,
        262,
        274,
        354,
        457,
        317,
        316,
        402,
        316,
        315,
        403,
        315,
        314,
        404,
        314,
        313,
        405,
        313,
        421,
        406,
        323,
        366,
        361,
        292,
        306,
        407,
        306,
        291,
        408,
        291,
        287,
        409,
        287,
        432,
        410,
        427,
        434,
        411,
        372,
        264,
        383,
        459,
        309,
        457,
        366,
        352,
        401,
        1,
        274,
        4,
        418,
        421,
        262,
        331,
        294,
        358,
        435,
        433,
        367,
        392,
        289,
        439,
        328,
        462,
        326,
        94,
        2,
        370,
        289,
        305,
        455,
        339,
        254,
        448,
        359,
        255,
        446,
        254,
        253,
        449,
        253,
        252,
        450,
        252,
        256,
        451,
        256,
        341,
        452,
        414,
        413,
        463,
        286,
        441,
        414,
        286,
        258,
        441,
        258,
        257,
        442,
        257,
        259,
        443,
        259,
        260,
        444,
        260,
        467,
        445,
        309,
        459,
        250,
        305,
        289,
        290,
        305,
        290,
        460,
        401,
        376,
        435,
        309,
        250,
        392,
        376,
        411,
        433,
        453,
        341,
        464,
        357,
        453,
        465,
        343,
        357,
        412,
        437,
        343,
        399,
        344,
        360,
        440,
        420,
        437,
        456,
        360,
        420,
        363,
        361,
        401,
        288,
        265,
        372,
        353,
        390,
        339,
        249,
        339,
        448,
        255
      ];
    }
  });

  // dist/components/shared/util.js
  function isiOS() {
    return /iPhone|iPad|iPod/i.test(navigator.userAgent);
  }
  function isAndroid() {
    return /Android/i.test(navigator.userAgent);
  }
  function isMobile() {
    return isAndroid() || isiOS();
  }
  function distance(a, b) {
    return Math.sqrt(Math.pow(a[0] - b[0], 2) + Math.pow(a[1] - b[1], 2));
  }
  function drawPath(ctx, points, closePath) {
    const region = new Path2D();
    region.moveTo(points[0][0], points[0][1]);
    for (let i = 1; i < points.length; i++) {
      const point = points[i];
      region.lineTo(point[0], point[1]);
    }
    if (closePath) {
      region.closePath();
    }
    ctx.stroke(region);
  }
  function drawResults(ctx, faces, triangulateMesh, boundingBox) {
    faces.forEach((face) => {
      const keypoints = face.keypoints.map((keypoint) => [
        keypoint.x,
        keypoint.y
      ]);
      if (boundingBox) {
        ctx.strokeStyle = RED;
        ctx.lineWidth = 1;
        const box = face.box;
        drawPath(ctx, [
          [box.xMin, box.yMin],
          [box.xMax, box.yMin],
          [box.xMax, box.yMax],
          [box.xMin, box.yMax]
        ], true);
      }
      if (triangulateMesh) {
        ctx.strokeStyle = GREEN;
        ctx.lineWidth = 0.5;
        for (let i = 0; i < TRIANGULATION.length / 3; i++) {
          const points = [
            TRIANGULATION[i * 3],
            TRIANGULATION[i * 3 + 1],
            TRIANGULATION[i * 3 + 2]
          ].map((index) => keypoints[index]);
          drawPath(ctx, points, true);
        }
      } else {
        ctx.fillStyle = GREEN;
        for (let i = 0; i < NUM_KEYPOINTS; i++) {
          const x = keypoints[i][0];
          const y = keypoints[i][1];
          ctx.beginPath();
          ctx.arc(x, y, 1, 0, 2 * Math.PI);
          ctx.fill();
        }
      }
      if (keypoints.length > NUM_KEYPOINTS) {
        ctx.strokeStyle = RED;
        ctx.lineWidth = 1;
        const leftCenter = keypoints[NUM_KEYPOINTS];
        const leftDiameterY = distance(keypoints[NUM_KEYPOINTS + 4], keypoints[NUM_KEYPOINTS + 2]);
        const leftDiameterX = distance(keypoints[NUM_KEYPOINTS + 3], keypoints[NUM_KEYPOINTS + 1]);
        ctx.beginPath();
        ctx.ellipse(leftCenter[0], leftCenter[1], leftDiameterX / 2, leftDiameterY / 2, 0, 0, 2 * Math.PI);
        ctx.stroke();
        if (keypoints.length > NUM_KEYPOINTS + NUM_IRIS_KEYPOINTS) {
          const rightCenter = keypoints[NUM_KEYPOINTS + NUM_IRIS_KEYPOINTS];
          const rightDiameterY = distance(keypoints[NUM_KEYPOINTS + NUM_IRIS_KEYPOINTS + 2], keypoints[NUM_KEYPOINTS + NUM_IRIS_KEYPOINTS + 4]);
          const rightDiameterX = distance(keypoints[NUM_KEYPOINTS + NUM_IRIS_KEYPOINTS + 3], keypoints[NUM_KEYPOINTS + NUM_IRIS_KEYPOINTS + 1]);
          ctx.beginPath();
          ctx.ellipse(rightCenter[0], rightCenter[1], rightDiameterX / 2, rightDiameterY / 2, 0, 0, 2 * Math.PI);
          ctx.stroke();
        }
      }
      const contours = Zt.getKeypointIndexByContour(Yt.MediaPipeFaceMesh);
      for (const [label, contour] of Object.entries(contours)) {
        ctx.strokeStyle = "#E0E0E0";
        ctx.lineWidth = 3;
        const path = contour.map((index) => keypoints[index]);
        if (path.every((value) => value != void 0)) {
          drawPath(ctx, path, false);
        }
      }
    });
  }
  var init_util2 = __esm({
    "dist/components/shared/util.js"() {
      init_face_landmarks_detection_esm();
      init_dist();
      init_params();
      init_triangulation();
    }
  });

  // dist/components/camera.js
  var Camera;
  var init_camera = __esm({
    "dist/components/camera.js"() {
      init_params();
      init_util2();
      Camera = class {
        constructor(video, canvas) {
          __publicField(this, "video");
          __publicField(this, "canvas");
          __publicField(this, "ctx");
          var _a;
          this.video = video;
          this.canvas = canvas;
          this.ctx = (_a = this.canvas) == null ? void 0 : _a.getContext("2d");
        }
        /**
         * Initiate a Camera instance and wait for the camera stream to be ready.
         * @param cameraParam From app `STATE.camera`.
         */
        static setupCamera(cameraParam, video, canvas) {
          return __async(this, null, function* () {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
              console.log("notSupport");
              throw new Error("Browser API navigator.mediaDevices.getUserMedia not available");
            }
            const { targetFPS, sizeOption } = cameraParam;
            const $size = VIDEO_SIZE["640 X 480"];
            const videoConfig = {
              audio: false,
              video: {
                facingMode: "user",
                // Only setting the video to a specified size for large screen, on
                // mobile devices accept the default size.
                width: isMobile() ? VIDEO_SIZE["360 X 270"].width : $size.width,
                height: isMobile() ? VIDEO_SIZE["360 X 270"].height : $size.height,
                frameRate: {
                  ideal: targetFPS
                }
              }
            };
            const camera2 = new Camera(video, canvas);
            const videoWidth = camera2.video.videoWidth;
            const videoHeight = camera2.video.videoHeight;
            camera2.video.width = videoWidth;
            camera2.video.height = videoHeight;
            if (camera2.canvas && camera2.ctx) {
              camera2.canvas.width = videoWidth;
              camera2.canvas.height = videoHeight;
              const canvasContainer = document.querySelector(".canvas-wrapper");
              camera2.ctx.translate(camera2.video.videoWidth, 0);
              camera2.ctx.scale(-1, 1);
            }
            return camera2;
          });
        }
        drawCtx() {
          if (!this.ctx) {
            return;
          }
          this.ctx.drawImage(this.video, 0, 0, this.video.videoWidth, this.video.videoHeight);
        }
        drawResults(faces, triangulateMesh, boundingBox) {
          if (!this.ctx) {
            return;
          }
          drawResults(this.ctx, faces, triangulateMesh, boundingBox);
        }
      };
    }
  });

  // dist/components/indices/MediaPipeIndexes.js
  var HEAD_OX_AXIS, HEAD_OY_AXIS, RIGHT_EYE_VERTICAL, LEFT_EYE_VERTICAL, EYEBROWS, NOSE_BRIDGE, MOUTH_HEIGHT, MOUTH_WIDTH;
  var init_MediaPipeIndexes = __esm({
    "dist/components/indices/MediaPipeIndexes.js"() {
      HEAD_OX_AXIS = [123, 352];
      HEAD_OY_AXIS = [199, 151];
      RIGHT_EYE_VERTICAL = [159, 145];
      LEFT_EYE_VERTICAL = [386, 374];
      EYEBROWS = [107, 336];
      NOSE_BRIDGE = [168];
      MOUTH_HEIGHT = [11, 16];
      MOUTH_WIDTH = [61, 291];
    }
  });

  // dist/components/indices/CutomMath.js
  function getAngle(lhs, rhs) {
    const cos3 = lhs.dot(rhs) / (lhs.getLength() * rhs.getLength());
    return Math.acos(cos3) * 180 / Math.PI;
  }
  function clamp2(num, min3, max3) {
    return Math.min(Math.max(num, min3), max3);
  }
  var Vector;
  var init_CutomMath = __esm({
    "dist/components/indices/CutomMath.js"() {
      Vector = class {
        constructor(x, y, z2) {
          __publicField(this, "x");
          __publicField(this, "y");
          __publicField(this, "z");
          this.x = x;
          this.y = y;
          this.z = z2;
        }
        static fromKeyPoint(keypoint) {
          if (keypoint.z === void 0)
            throw new Error("Only 3D vectors allowed");
          return new Vector(keypoint.x, keypoint.y, keypoint.z);
        }
        minus(other) {
          return new Vector(this.x - other.x, this.y - other.y, this.z - other.z);
        }
        plus(other) {
          return new Vector(this.x + other.x, this.y + other.y, this.z + other.z);
        }
        dot(other) {
          return this.x * other.x + this.y * other.y + this.z * other.z;
        }
        getLength() {
          return Math.sqrt(this.dot(this));
        }
      };
    }
  });

  // dist/components/indices/IndexesController.js
  var IndexesController;
  var init_IndexesController = __esm({
    "dist/components/indices/IndexesController.js"() {
      init_MediaPipeIndexes();
      init_CutomMath();
      IndexesController = class {
        constructor() {
          __publicField(this, "everySecondAttention", true);
          __publicField(this, "tiredness", 0);
          __publicField(this, "happiness", 0);
          __publicField(this, "amazement", 0);
          __publicField(this, "eyesClosed", false);
          __publicField(this, "eyesClosedWithFrames", false);
          __publicField(this, "eyesClosedFrames", 0);
          __publicField(this, "eyesClosedTime", /* @__PURE__ */ new Date());
          __publicField(this, "blinkTime", 0);
          __publicField(this, "blinks", 0);
          __publicField(this, "blinked", false);
          __publicField(this, "isMouthOpened", false);
          __publicField(this, "yawns", 0);
          __publicField(this, "headHeight", 0);
          __publicField(this, "initialHeadHeight", null);
          __publicField(this, "zeroAttnetionCounter", 0);
          __publicField(this, "zeroAttentionTime", 0);
          __publicField(this, "lastAttentioLostTime", /* @__PURE__ */ new Date());
          __publicField(this, "isCountingLostAttentionPeriod", false);
          __publicField(this, "lastMinuteIndexes", []);
          __publicField(this, "lastSecondIndexes", []);
          __publicField(this, "lastMinuteBlinks", 0);
          __publicField(this, "CONSTANTS", {
            DEFAULT: {
              BLINKS_IN_MINUTE: 10,
              BLINKS_TIME: 200,
              SMILE_SIZE: 60,
              EYEBROWS_HEIGHT: 25
            },
            MAX: {
              SMILE_SIZE: 70,
              EYEBROWS_HEIGHT: 30
            }
          });
        }
        calculateIndexes(face) {
          if (face === void 0) {
            this.handleNotAtScreen();
            const indexPackage2 = {
              attention: 0,
              happiness: 0,
              tiredness: 0,
              amazement: 0,
              involvement: 0,
              presence: false,
              statistic: {
                headAngleOX: -1,
                headAngleOY: -1,
                eyesClosedFrames: this.eyesClosedFrames,
                blinks: this.blinks,
                blinkTime: this.blinkTime,
                eyebrowsHeight: {
                  left: -1,
                  right: -1
                },
                yawns: this.yawns,
                smile: -1,
                attentionLostTimes: this.zeroAttnetionCounter,
                attentionLostMillieseconds: this.zeroAttentionTime,
                everySecondAttention: this.everySecondAttention
              }
            };
            this.updateCache(indexPackage2);
            return indexPackage2;
          }
          const headAngleOX = this.calculateHeadOXAngle(face);
          const headAngleOY = this.calculateHeadOYAngle(face);
          let eyebrowsHeight = this.calculateEyebrowsHeight(face);
          let smile = this.calculateSmile(face);
          let eyesHeight = this.calculateEyesHeight(face);
          let attention = headAngleOX < 36 && !this.eyesClosed ? 1 : 0;
          if (attention == 1) {
            attention = headAngleOY < 30 && !this.eyesClosed ? 1 : 0;
          }
          this.handleAttention(attention);
          if (this.initialHeadHeight !== null) {
            const scaleCoefficient = this.headHeight / this.initialHeadHeight;
            this.CONSTANTS.DEFAULT.SMILE_SIZE = this.initialHeadHeight * 0.4;
            this.CONSTANTS.MAX.SMILE_SIZE = this.initialHeadHeight * 0.45;
            this.CONSTANTS.DEFAULT.EYEBROWS_HEIGHT = this.initialHeadHeight * 0.18;
            this.CONSTANTS.MAX.EYEBROWS_HEIGHT = this.initialHeadHeight * 0.22;
            smile = smile / scaleCoefficient;
            eyebrowsHeight = {
              left: eyebrowsHeight.left / scaleCoefficient,
              right: eyebrowsHeight.right / scaleCoefficient
            };
            eyesHeight = {
              left: eyesHeight.left / scaleCoefficient,
              right: eyesHeight.right / scaleCoefficient
            };
          }
          this.calculateAmazement(eyebrowsHeight);
          this.calculateHappiness(smile);
          this.handleEyes(eyesHeight);
          this.handleYawn(face);
          if (attention === 0) {
            this.happiness = 0;
            this.amazement = 0;
          }
          const indexPackage = {
            attention,
            happiness: this.happiness,
            tiredness: this.tiredness,
            amazement: this.amazement,
            involvement: 0,
            presence: attention === 1 ? true : false,
            statistic: {
              headAngleOX,
              headAngleOY,
              eyesClosedFrames: this.eyesClosedFrames,
              blinks: this.blinks,
              blinkTime: this.blinkTime,
              eyebrowsHeight,
              yawns: this.yawns,
              smile,
              attentionLostTimes: this.zeroAttnetionCounter,
              attentionLostMillieseconds: this.zeroAttentionTime,
              everySecondAttention: this.everySecondAttention
            }
          };
          this.updateCache(indexPackage);
          return indexPackage;
        }
        calculateHeadOXAngle(face) {
          const rightCheekPosition = Vector.fromKeyPoint(face.keypoints[HEAD_OX_AXIS[0]]);
          const leftCheekPosition = Vector.fromKeyPoint(face.keypoints[HEAD_OX_AXIS[1]]);
          const headVectorOX = leftCheekPosition.minus(rightCheekPosition);
          headVectorOX.y = 0;
          const normalVectorOX = new Vector(1, 0, 0);
          return getAngle(headVectorOX, normalVectorOX);
        }
        calculateEyesHeight(face) {
          const leftEyeUpPosition = Vector.fromKeyPoint(face.keypoints[LEFT_EYE_VERTICAL[0]]);
          const leftEyeDownPosition = Vector.fromKeyPoint(face.keypoints[LEFT_EYE_VERTICAL[1]]);
          const rightEyeUpPosition = Vector.fromKeyPoint(face.keypoints[RIGHT_EYE_VERTICAL[0]]);
          const rightEyeDownPosition = Vector.fromKeyPoint(face.keypoints[RIGHT_EYE_VERTICAL[1]]);
          const leftEyeVerticalVector = leftEyeUpPosition.minus(leftEyeDownPosition);
          const rightEyeVerticalVector = rightEyeUpPosition.minus(rightEyeDownPosition);
          const leftEyeHeight = leftEyeVerticalVector.getLength();
          const rightEyeHeight = rightEyeVerticalVector.getLength();
          return {
            left: leftEyeHeight,
            right: rightEyeHeight
          };
        }
        handleEyes(eyesHeight) {
          const { left, right } = eyesHeight;
          console.log("Left: " + left);
          console.log("Left: " + right);
          if ((left < 7 || right < 7) && !this.eyesClosed && !this.eyesClosedWithFrames) {
            this.eyesClosedWithFrames = true;
            this.eyesClosedFrames = 0;
            this.eyesClosedTime = /* @__PURE__ */ new Date();
          } else if ((left < 7 || right < 7) && this.eyesClosedWithFrames) {
            if (this.eyesClosedFrames > 15) {
              this.eyesClosed = true;
            }
            this.eyesClosedFrames++;
          } else if (this.eyesClosed && this.eyesClosedWithFrames) {
            this.eyesClosedWithFrames = false;
            this.eyesClosed = false;
            if (this.eyesClosedFrames < 20) {
              this.blinks++;
              this.blinkTime = (/* @__PURE__ */ new Date()).getTime() - this.eyesClosedTime.getTime();
              this.blinked = true;
            }
          }
        }
        calculateEyebrowsHeight(face) {
          const rightEyebrow = Vector.fromKeyPoint(face.keypoints[EYEBROWS[0]]);
          const leftEyebrow = Vector.fromKeyPoint(face.keypoints[EYEBROWS[1]]);
          const noseBridge = Vector.fromKeyPoint(face.keypoints[NOSE_BRIDGE[0]]);
          const leftToNoseBridge = leftEyebrow.minus(noseBridge);
          const rightToNoseBridge = rightEyebrow.minus(noseBridge);
          return {
            left: leftToNoseBridge.getLength(),
            right: rightToNoseBridge.getLength()
          };
        }
        handleYawn(face) {
          const mouthUp = Vector.fromKeyPoint(face.keypoints[MOUTH_HEIGHT[0]]);
          const mouthDown = Vector.fromKeyPoint(face.keypoints[MOUTH_HEIGHT[1]]);
          const mouthHeight = mouthUp.minus(mouthDown).getLength();
          if (mouthHeight > 30 && !this.isMouthOpened) {
            this.isMouthOpened = true;
          }
          if (mouthHeight <= 30 && this.isMouthOpened) {
            this.yawns++;
            this.isMouthOpened = false;
          }
        }
        calculateSmile(face) {
          const right = Vector.fromKeyPoint(face.keypoints[MOUTH_WIDTH[0]]);
          const left = Vector.fromKeyPoint(face.keypoints[MOUTH_WIDTH[1]]);
          return right.minus(left).getLength();
        }
        handleAttention(attention) {
          if (this.blinked) {
            this.isCountingLostAttentionPeriod = false;
            this.blinked = false;
            return;
          }
          if (attention === 0 && !this.isCountingLostAttentionPeriod) {
            this.lastAttentioLostTime = /* @__PURE__ */ new Date();
            this.isCountingLostAttentionPeriod = true;
          }
          if (attention === 1 && this.isCountingLostAttentionPeriod) {
            this.isCountingLostAttentionPeriod = false;
            this.zeroAttentionTime += (/* @__PURE__ */ new Date()).getTime() - this.lastAttentioLostTime.getTime();
            this.zeroAttnetionCounter++;
          }
        }
        handleNotAtScreen() {
          const attention = 0;
          this.blinked = false;
          this.handleAttention(attention);
        }
        calculateTiredness() {
          const blinks = this.lastMinuteIndexes[this.lastMinuteIndexes.length - 1].statistic.blinks - this.lastMinuteBlinks;
          this.lastMinuteBlinks += blinks;
          const blinksTime = this.lastMinuteIndexes.reduce((accum, current) => accum + current.statistic.blinkTime, 0) / this.lastMinuteIndexes.length;
          let normalizedTiredness = 0.2 * ((blinks - this.CONSTANTS.DEFAULT.BLINKS_IN_MINUTE) / this.CONSTANTS.DEFAULT.BLINKS_IN_MINUTE) + 0.8 * ((blinksTime - this.CONSTANTS.DEFAULT.BLINKS_TIME) / this.CONSTANTS.DEFAULT.BLINKS_TIME);
          normalizedTiredness *= 100;
          normalizedTiredness = clamp2(normalizedTiredness, 0, 100);
          this.tiredness = Math.round(normalizedTiredness / 20);
        }
        calculateHappiness(smileSize) {
          const offsetSmile = smileSize - this.CONSTANTS.DEFAULT.SMILE_SIZE;
          const offsetMaxSmile = this.CONSTANTS.MAX.SMILE_SIZE - this.CONSTANTS.DEFAULT.SMILE_SIZE;
          this.happiness = Math.round(offsetSmile / offsetMaxSmile * 100);
          this.happiness = clamp2(this.happiness, 0, 100);
        }
        calculateAmazement(eyebrowsHeight) {
          const { left, right } = eyebrowsHeight;
          const chosen = Math.max(left, right);
          const offsetEyebrowsHeight = chosen - this.CONSTANTS.DEFAULT.EYEBROWS_HEIGHT;
          const offsetMaxEyebrowsHeight = this.CONSTANTS.MAX.EYEBROWS_HEIGHT - this.CONSTANTS.DEFAULT.EYEBROWS_HEIGHT;
          this.amazement = Math.round(offsetEyebrowsHeight / offsetMaxEyebrowsHeight * 100);
          this.amazement = clamp2(this.amazement, 0, 100);
        }
        updateCache(index) {
          this.lastSecondIndexes.push(index);
          this.lastMinuteIndexes.push(index);
        }
        calculateHeadOYAngle(face) {
          const top = Vector.fromKeyPoint(face.keypoints[HEAD_OY_AXIS[1]]);
          const bottom = Vector.fromKeyPoint(face.keypoints[HEAD_OY_AXIS[0]]);
          const headVectorOY = top.minus(bottom);
          const normalOY = new Vector(0, 1, 0);
          this.headHeight = headVectorOY.getLength();
          if (this.initialHeadHeight === null)
            this.initialHeadHeight = this.headHeight;
          headVectorOY.x = 0;
          return 180 - getAngle(headVectorOY, normalOY);
        }
        calculateAttention() {
          const attentionSum = this.lastSecondIndexes.reduce((accum, current) => accum + current.attention, 0);
          if (attentionSum / this.lastSecondIndexes.length > 0.5) {
            this.everySecondAttention = true;
          } else {
            this.everySecondAttention = false;
          }
        }
        //TODO:   
        exportingIndex() {
          return {
            video_sec: 1,
            video_id: 1,
            attention: this.everySecondAttention,
            happiness: this.happiness,
            tiredness: this.tiredness,
            amazement: this.amazement,
            involvement: 0,
            uuid: "123e4567-e89b-12d3-a456-426655440000",
            time: /* @__PURE__ */ new Date()
          };
        }
        handleSecond() {
          this.calculateAttention();
          this.lastSecondIndexes = [];
          return this.exportingIndex();
        }
        handleMinute() {
          this.calculateTiredness();
          this.lastMinuteIndexes = [];
        }
      };
    }
  });

  // dist/interfaces/indexes.js
  var INDEXES_KEYS, INDEXES_TITLES, INDEXES_COLORS, INDEXES_INFO, defaultIndex;
  var init_indexes = __esm({
    "dist/interfaces/indexes.js"() {
      INDEXES_KEYS = [
        "attention",
        "amazement",
        "happiness",
        "tiredness",
        "involvement"
      ];
      INDEXES_TITLES = {
        attention: "\u0412\u043D\u0438\u043C\u0430\u0442\u0435\u043B\u044C\u043D\u043E\u0441\u0442\u044C",
        amazement: "\u0423\u0434\u0438\u0432\u043B\u0435\u043D\u0438\u0435",
        happiness: "\u042D\u043C\u043E\u0446\u0438\u043E\u043D\u0430\u043B\u044C\u043D\u043E\u0441\u0442\u044C",
        tiredness: "\u0423\u0442\u043E\u043C\u043B\u044F\u0435\u043C\u043E\u0441\u0442\u044C",
        involvement: "\u0412\u043E\u0432\u043B\u0435\u0447\u0435\u043D\u043D\u043E\u0441\u0442\u044C"
      };
      INDEXES_COLORS = {
        attention: "rgb(24, 113, 248)",
        amazement: "rgb(125, 128, 135)",
        happiness: "rgb(255, 157, 10)",
        tiredness: "rgb(250, 85, 85)",
        involvement: "rgb(180, 106, 238)"
      };
      INDEXES_INFO = Object.fromEntries(INDEXES_KEYS.map((indexKey) => [
        indexKey,
        {
          title: INDEXES_TITLES[indexKey],
          color: INDEXES_COLORS[indexKey]
        }
      ]));
      defaultIndex = {
        attention: 0,
        happiness: 0,
        tiredness: 0,
        amazement: 0,
        involvement: 0,
        presence: false,
        faces: 0,
        activeFaces: 0,
        attentions: [],
        statistic: {
          headAngleOX: -1,
          headAngleOY: -1,
          eyesClosedFrames: 0,
          blinks: 0,
          blinkTime: 0,
          eyebrowsHeight: {
            left: -1,
            right: -1
          },
          yawns: 0,
          smile: -1,
          attentionLostTimes: 0,
          attentionLostMillieseconds: 0,
          everySecondAttention: false
        }
      };
    }
  });

  // dist/components/index.js
  function renderResult(callback) {
    return __async(this, null, function* () {
      if (camera.video.readyState < 2) {
        yield new Promise((resolve) => {
          camera.video.onloadeddata = () => {
            resolve(true);
          };
        });
      }
      let faces = null;
      if (detector != null) {
        try {
          faces = yield detector.estimateFaces(camera.video, {
            flipHorizontal: false
          });
          if (faces.length !== 0) {
            let activeFaces = 0;
            const attentions = [];
            for (const face of faces) {
              const index = indexesController.calculateIndexes(face);
              if (index.attention === 1) {
                activeFaces += 1;
              }
              attentions.push(index.attention);
            }
            const firstIndex = indexesController.calculateIndexes(faces[0]);
            const exportIndex = __spreadValues({
              faces: faces.length,
              activeFaces,
              attentions
            }, firstIndex);
            callback(exportIndex);
          } else {
            callback(defaultIndex);
          }
        } catch (error) {
          detector.dispose();
          detector = null;
          alert(error);
        }
      }
      camera.drawCtx();
      if (faces && faces.length > 0) {
        camera.drawResults(faces, true, true);
      }
    });
  }
  function renderPrediction() {
    return __async(this, null, function* () {
      yield renderResult(indexCallback);
      requestAnimationFrame(renderPrediction);
    });
  }
  function app(video, canvas, _indexCallback = (index) => {
    console.table(index);
  }) {
    return __async(this, null, function* () {
      indexCallback = _indexCallback;
      camera = yield Camera.setupCamera(STATE.camera, video, canvas);
      detector = yield createDetector();
      indexesController = new IndexesController();
      renderPrediction();
    });
  }
  function handleSecond() {
    if (!indexesController) {
      return;
    }
    return indexesController.handleSecond();
  }
  function handleMinute() {
    if (!indexesController) {
      return;
    }
    indexesController.handleMinute();
  }
  var detector, camera, indexesController, indexCallback;
  var init_components = __esm({
    "dist/components/index.js"() {
      init_camera();
      init_params();
      init_IndexesController();
      init_indexes();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/cpu_util.js
  function assertNotComplex(tensor2, opName) {
    if (!Array.isArray(tensor2)) {
      tensor2 = [tensor2];
    }
    tensor2.forEach((t2) => {
      if (t2 != null) {
        util_exports.assert(t2.dtype !== "complex64", () => `${opName} does not support complex64 tensors in the CPU backend.`);
      }
    });
  }
  var init_cpu_util = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/cpu_util.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/backend_cpu.js
  var whereImpl2, MathBackendCPU;
  var init_backend_cpu = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/backend_cpu.js"() {
      init_dist();
      init_cpu_util();
      whereImpl2 = kernel_impls_exports.whereImpl;
      MathBackendCPU = class extends KernelBackend {
        constructor() {
          super();
          this.blockSize = 48;
          this.firstUse = true;
          this.data = new DataStorage(this, engine());
        }
        nextDataId() {
          return MathBackendCPU.nextDataId++;
        }
        write(values, shape, dtype) {
          if (this.firstUse) {
            this.firstUse = false;
            if (env().get("IS_NODE")) {
              backend_util_exports.warn("\n============================\nHi, looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, visit https://github.com/tensorflow/tfjs-node for more details. \n============================");
            }
          }
          const dataId = { id: this.nextDataId() };
          this.data.set(dataId, { values, dtype, refCount: 1 });
          return dataId;
        }
        /**
         * Create a data bucket in cpu backend.
         * @param shape Shape of the `TensorInfo`.
         * @param dtype DType of the `TensorInfo`.
         * @param values The value of the `TensorInfo` stored as a flattened array.
         */
        makeTensorInfo(shape, dtype, values) {
          let outId;
          if (dtype === "string" && values != null && values.length > 0 && util_exports.isString(values[0])) {
            const encodedValues = values.map((d) => util_exports.encodeString(d));
            outId = this.write(encodedValues, shape, dtype);
          } else {
            outId = this.write(values, shape, dtype);
          }
          return { dataId: outId, shape, dtype };
        }
        /** Return refCount of a `TensorData`. */
        refCount(dataId) {
          if (this.data.has(dataId)) {
            const tensorData = this.data.get(dataId);
            return tensorData.refCount;
          }
          return 0;
        }
        /** Increase refCount of a `TensorData`. */
        incRef(dataId) {
          const tensorData = this.data.get(dataId);
          tensorData.refCount++;
        }
        /** Decrease refCount of a `TensorData`. */
        decRef(dataId) {
          if (this.data.has(dataId)) {
            const tensorData = this.data.get(dataId);
            tensorData.refCount--;
          }
        }
        move(dataId, values, shape, dtype, refCount) {
          this.data.set(dataId, { values, dtype, refCount });
        }
        numDataIds() {
          return this.data.numDataIds();
        }
        read(dataId) {
          return __async(this, null, function* () {
            return this.readSync(dataId);
          });
        }
        readSync(dataId) {
          const { dtype, complexTensorInfos } = this.data.get(dataId);
          if (dtype === "complex64") {
            const realValues = this.readSync(complexTensorInfos.real.dataId);
            const imagValues = this.readSync(complexTensorInfos.imag.dataId);
            return backend_util_exports.mergeRealAndImagArrays(realValues, imagValues);
          }
          return util_exports.convertBackendValuesAndArrayBuffer(this.data.get(dataId).values, dtype);
        }
        bufferSync(t2) {
          const data = this.readSync(t2.dataId);
          if (t2.dtype === "string") {
            try {
              const strings = data.map((d) => util_exports.decodeString(d));
              return buffer(t2.shape, t2.dtype, strings);
            } catch (_a) {
              throw new Error("Failed to decode encoded string bytes into utf-8");
            }
          }
          return buffer(t2.shape, t2.dtype, data);
        }
        makeOutput(values, shape, dtype) {
          return engine().makeTensorFromTensorInfo(this.makeTensorInfo(shape, dtype, values), this);
        }
        /**
         * Dispose the memory if the dataId has 0 refCount. Return true if the memory
         * is released or memory is not managed in this backend, false if memory is
         * not cleared.
         * @param dataId
         * @oaram force Optional, remove the data regardless of refCount
         */
        disposeData(dataId, force = false) {
          if (this.data.has(dataId)) {
            this.data.get(dataId).refCount--;
            if (!force && this.data.get(dataId).refCount > 0) {
              return false;
            }
            const { complexTensorInfos } = this.data.get(dataId);
            if (complexTensorInfos != null) {
              this.disposeData(complexTensorInfos.real.dataId, true);
              this.disposeData(complexTensorInfos.imag.dataId, true);
            }
            this.data.delete(dataId);
          }
          return true;
        }
        disposeIntermediateTensorInfo(tensorInfo) {
          this.disposeData(tensorInfo.dataId);
        }
        time(f) {
          return __async(this, null, function* () {
            const start = util_exports.now();
            f();
            const kernelMs = util_exports.now() - start;
            return { kernelMs };
          });
        }
        memory() {
          return {
            // Unreliable due to automatic gc. The numbers above are cumulative.
            unreliable: true,
            reasons: ["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]
          };
        }
        where(condition) {
          assertNotComplex([condition], "where");
          const condVals = this.readSync(condition.dataId);
          return whereImpl2(condition.shape, condVals);
        }
        dispose() {
        }
        floatPrecision() {
          return 32;
        }
        /** Returns the smallest representable number.  */
        epsilon() {
          return super.epsilon();
        }
      };
      MathBackendCPU.nextDataId = 0;
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Abs.js
  function simpleAbsImpl(vals) {
    const resultValues = new Float32Array(vals.length);
    for (let i = 0; i < vals.length; ++i) {
      resultValues[i] = Math.abs(vals[i]);
    }
    return resultValues;
  }
  var abs2, absConfig;
  var init_Abs = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Abs.js"() {
      init_dist();
      init_cpu_util();
      abs2 = (args) => {
        const { x } = args.inputs;
        const cpuBackend = args.backend;
        assertNotComplex(x, "abs");
        let resultValues = new Float32Array(util_exports.sizeFromShape(x.shape));
        const values = cpuBackend.data.get(x.dataId).values;
        resultValues = simpleAbsImpl(values);
        return cpuBackend.makeOutput(resultValues, x.shape, x.dtype);
      };
      absConfig = {
        kernelName: Abs,
        backendName: "cpu",
        kernelFunc: abs2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_impl.js
  function createSimpleBinaryKernelImpl(op2) {
    return (aShape, bShape, aVals, bVals, dtype) => {
      const newShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
      const resultRank = newShape.length;
      const resultStrides = util_exports.computeStrides(newShape);
      const resultSize = util_exports.sizeFromShape(newShape);
      const result = util_exports.getTypedArrayFromDType(dtype, resultSize);
      const aRank = aShape.length;
      const bRank = bShape.length;
      const aStrides = util_exports.computeStrides(aShape);
      const bStrides = util_exports.computeStrides(bShape);
      const aBroadcastDims = backend_util_exports.getBroadcastDims(aShape, newShape);
      const bBroadcastDims = backend_util_exports.getBroadcastDims(bShape, newShape);
      if (aBroadcastDims.length + bBroadcastDims.length === 0) {
        for (let i = 0; i < result.length; ++i) {
          result[i] = op2(aVals[i % aVals.length], bVals[i % bVals.length]);
        }
      } else {
        for (let i = 0; i < result.length; ++i) {
          const loc = util_exports.indexToLoc(i, resultRank, resultStrides);
          const aLoc = loc.slice(-aRank);
          aBroadcastDims.forEach((d) => aLoc[d] = 0);
          const aIndex = util_exports.locToIndex(aLoc, aRank, aStrides);
          const bLoc = loc.slice(-bRank);
          bBroadcastDims.forEach((d) => bLoc[d] = 0);
          const bIndex = util_exports.locToIndex(bLoc, bRank, bStrides);
          result[i] = op2(aVals[aIndex], bVals[bIndex]);
        }
      }
      return [result, newShape];
    };
  }
  var init_binary_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Complex.js
  function complex2(args) {
    const { inputs, backend } = args;
    const { real: real3, imag: imag3 } = inputs;
    const realVals = backend.data.get(real3.dataId).values;
    const imagVals = backend.data.get(imag3.dataId).values;
    const complexInfo = backend.makeTensorInfo(real3.shape, "complex64");
    const complex3 = backend.data.get(complexInfo.dataId);
    complex3.complexTensorInfos = {
      real: backend.makeTensorInfo(real3.shape, "float32", realVals),
      imag: backend.makeTensorInfo(imag3.shape, "float32", imagVals)
    };
    return complexInfo;
  }
  var complexConfig;
  var init_Complex = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Complex.js"() {
      init_dist();
      complexConfig = {
        kernelName: Complex,
        backendName: "cpu",
        kernelFunc: complex2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/zeros_impl.js
  function zeros2(backend, shape, dtype = "float32") {
    if (dtype === "complex64") {
      const real3 = zeros2(backend, shape, "float32");
      const imag3 = zeros2(backend, shape, "float32");
      return complex2({ inputs: { real: real3, imag: imag3 }, backend });
    }
    const values = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(shape), dtype);
    return backend.makeTensorInfo(shape, dtype, values);
  }
  var init_zeros_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/zeros_impl.js"() {
      init_dist();
      init_Complex();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Identity.js
  function identity(args) {
    const { inputs, backend } = args;
    const { x } = inputs;
    backend.incRef(x.dataId);
    return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };
  }
  var identityConfig;
  var init_Identity = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Identity.js"() {
      init_dist();
      identityConfig = {
        kernelName: Identity,
        backendName: "cpu",
        kernelFunc: identity
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Real.js
  function real2(args) {
    const { inputs, backend } = args;
    const { input } = inputs;
    const real3 = backend.data.get(input.dataId).complexTensorInfos.real;
    const realVal = backend.data.get(real3.dataId).values;
    return backend.makeTensorInfo(real3.shape, real3.dtype, realVal);
  }
  var realConfig;
  var init_Real = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Real.js"() {
      init_dist();
      realConfig = {
        kernelName: Real,
        backendName: "cpu",
        kernelFunc: real2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cast.js
  function castImpl(values, shape, inputType, dtype) {
    if (dtype === "int32") {
      const resultValues = Int32Array.from(values);
      return [shape, "int32", resultValues];
    }
    if (dtype === "bool") {
      const zero = util_exports.toTypedArray([0], inputType);
      const [resultData, resultShape] = createSimpleBinaryKernelImpl((a, b) => a !== b ? 1 : 0)(shape, [], values, zero, "bool");
      return [resultShape, "bool", resultData];
    }
    throw new Error(`Error in Cast: failed to cast ${inputType} to ${dtype}`);
  }
  function cast2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { dtype } = attrs;
    if (dtype === "complex64") {
      if (x.dtype === "complex64") {
        return identity({ inputs: { x }, backend });
      }
      const zerosTensorInfo = zeros2(backend, x.shape, x.dtype);
      const floatX = cast2({ inputs: { x }, backend, attrs: { dtype: "float32" } });
      const result = complex2({ inputs: { real: floatX, imag: zerosTensorInfo }, backend });
      backend.disposeIntermediateTensorInfo(zerosTensorInfo);
      backend.disposeIntermediateTensorInfo(floatX);
      return result;
    }
    if (x.dtype === "complex64") {
      const realPart = real2({ inputs: { input: x }, backend });
      const result = cast2({ inputs: { x: realPart }, backend, attrs: { dtype } });
      backend.disposeIntermediateTensorInfo(realPart);
      return result;
    }
    if (!util_exports.hasEncodingLoss(x.dtype, dtype)) {
      const result = identity({ inputs: { x }, backend });
      return { dataId: result.dataId, shape: result.shape, dtype };
    }
    const values = backend.data.get(x.dataId).values;
    const [resultShape, resultType, resultData] = castImpl(values, x.shape, x.dtype, dtype);
    return backend.makeTensorInfo(resultShape, resultType, resultData);
  }
  var castConfig;
  var init_Cast = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cast.js"() {
      init_dist();
      init_binary_impl();
      init_zeros_impl();
      init_Complex();
      init_Identity();
      init_Real();
      castConfig = {
        kernelName: Cast,
        backendName: "cpu",
        kernelFunc: cast2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_utils.js
  function binaryKernelFunc(name, simpleImpl, complexImpl, dtype) {
    if (complexImpl == null) {
      return ({ inputs, backend }) => {
        const { a, b } = inputs;
        const cpuBackend = backend;
        assertNotComplex([a, b], name);
        const aVals = cpuBackend.data.get(a.dataId).values;
        const bVals = cpuBackend.data.get(b.dataId).values;
        const decodedAVals = a.dtype === "string" ? (
          // tslint:disable-next-line: no-any
          backend_util_exports.fromUint8ToStringArray(aVals)
        ) : aVals;
        const decodedBVals = a.dtype === "string" ? (
          // tslint:disable-next-line: no-any
          backend_util_exports.fromUint8ToStringArray(bVals)
        ) : bVals;
        const $dtype = dtype || a.dtype;
        const [resultData, resultShape] = simpleImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);
        return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
      };
    }
    return ({ inputs, backend }) => {
      const { a, b } = inputs;
      const cpuBackend = backend;
      if (a.dtype === "complex64" || b.dtype === "complex64") {
        const $aComplex = cast2({ inputs: { x: a }, backend: cpuBackend, attrs: { dtype: "complex64" } });
        const $aComplexVals = cpuBackend.data.get($aComplex.dataId);
        const aReal = $aComplexVals.complexTensorInfos.real;
        const aImag = $aComplexVals.complexTensorInfos.imag;
        const aRealVals = cpuBackend.data.get(aReal.dataId).values;
        const aImagVals = cpuBackend.data.get(aImag.dataId).values;
        const $bComplex = cast2({ inputs: { x: b }, backend: cpuBackend, attrs: { dtype: "complex64" } });
        const $bComplexVals = cpuBackend.data.get($bComplex.dataId);
        const bReal = $bComplexVals.complexTensorInfos.real;
        const bImag = $bComplexVals.complexTensorInfos.imag;
        const bRealVals = cpuBackend.data.get(bReal.dataId).values;
        const bImagVals = cpuBackend.data.get(bImag.dataId).values;
        const [resultRealData, resultImagData, resultShape] = complexImpl(a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals);
        const resultReal = cpuBackend.makeTensorInfo(resultShape, "float32", resultRealData);
        const resultImag = cpuBackend.makeTensorInfo(resultShape, "float32", resultImagData);
        const result = complex2({ inputs: { real: resultReal, imag: resultImag }, backend: cpuBackend });
        cpuBackend.disposeIntermediateTensorInfo($aComplex);
        cpuBackend.disposeIntermediateTensorInfo($bComplex);
        cpuBackend.disposeIntermediateTensorInfo(resultReal);
        cpuBackend.disposeIntermediateTensorInfo(resultImag);
        return result;
      } else {
        const aVals = cpuBackend.data.get(a.dataId).values;
        const bVals = cpuBackend.data.get(b.dataId).values;
        const $dtype = dtype || a.dtype;
        const [resultData, resultShape] = simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);
        return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
      }
    };
  }
  function createComplexBinaryKernelImpl(op2) {
    return (aShape, bShape, aRealVals, aImagVals, bRealVals, bImagVals) => {
      const resultShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
      const resultSize = util_exports.sizeFromShape(resultShape);
      const resultRank = resultShape.length;
      const resultStrides = util_exports.computeStrides(resultShape);
      const resultRealVals = util_exports.getTypedArrayFromDType("float32", resultSize);
      const resultImagVals = util_exports.getTypedArrayFromDType("float32", resultSize);
      const aBroadcastDims = backend_util_exports.getBroadcastDims(aShape, resultShape);
      const bBroadcastDims = backend_util_exports.getBroadcastDims(bShape, resultShape);
      const aVals = backend_util_exports.mergeRealAndImagArrays(aRealVals, aImagVals);
      const bVals = backend_util_exports.mergeRealAndImagArrays(bRealVals, bImagVals);
      const aRank = aShape.length;
      const aStrides = util_exports.computeStrides(aShape);
      const bRank = bShape.length;
      const bStrides = util_exports.computeStrides(bShape);
      if (aBroadcastDims.length + bBroadcastDims.length === 0) {
        for (let i = 0; i < resultRealVals.length; i++) {
          const aIdx = i % aVals.length;
          const bIdx = i % bVals.length;
          const result = op2(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2], bVals[bIdx * 2 + 1]);
          resultRealVals[i] = result.real;
          resultImagVals[i] = result.imag;
        }
      } else {
        for (let i = 0; i < resultRealVals.length; i++) {
          const loc = util_exports.indexToLoc(i, resultRank, resultStrides);
          const aLoc = loc.slice(-aRank);
          aBroadcastDims.forEach((d) => aLoc[d] = 0);
          const aIndex = util_exports.locToIndex(aLoc, aRank, aStrides);
          const bLoc = loc.slice(-bRank);
          bBroadcastDims.forEach((d) => bLoc[d] = 0);
          const bIndex = util_exports.locToIndex(bLoc, bRank, bStrides);
          const opResult = op2(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2], bVals[bIndex * 2 + 1]);
          resultRealVals[i] = opResult.real;
          resultImagVals[i] = opResult.imag;
        }
      }
      return [resultRealVals, resultImagVals, resultShape];
    };
  }
  var init_binary_utils = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_utils.js"() {
      init_dist();
      init_cpu_util();
      init_Cast();
      init_Complex();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Add.js
  var addImpl, addComplexImpl, add3, addConfig;
  var init_Add = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Add.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      addImpl = createSimpleBinaryKernelImpl((a, b) => a + b);
      addComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
        return { real: aReal + bReal, imag: aImag + bImag };
      });
      add3 = binaryKernelFunc(Add, addImpl, addComplexImpl);
      addConfig = {
        kernelName: Add,
        backendName: "cpu",
        kernelFunc: add3
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount_impl.js
  function bincountImpl(xVals, weightsVals, weightsDtype, weightsShape, size) {
    const weightsSize = util_exports.sizeFromShape(weightsShape);
    const outVals = util_exports.makeZerosTypedArray(size, weightsDtype);
    for (let i = 0; i < xVals.length; i++) {
      const value = xVals[i];
      if (value < 0) {
        throw new Error("Input x must be non-negative!");
      }
      if (value >= size) {
        continue;
      }
      if (weightsSize > 0) {
        outVals[value] += weightsVals[i];
      } else {
        outVals[value] += 1;
      }
    }
    return outVals;
  }
  function bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput = false) {
    const numRows = xBuf.shape[0];
    const numCols = xBuf.shape[1];
    const outBuf = buffer([numRows, size], weightsBuf.dtype);
    for (let i = 0; i < numRows; i++) {
      for (let j2 = 0; j2 < numCols; j2++) {
        const value = xBuf.get(i, j2);
        if (value < 0) {
          throw new Error("Input x must be non-negative!");
        }
        if (value >= size) {
          continue;
        }
        if (binaryOutput) {
          outBuf.set(1, i, value);
        } else {
          if (weightsBuf.size > 0) {
            outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j2), i, value);
          } else {
            outBuf.set(outBuf.get(i, value) + 1, i, value);
          }
        }
      }
    }
    return outBuf;
  }
  var init_Bincount_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/unary_impl.js
  function createSimpleUnaryImpl(op2) {
    return (values, dtype, attrs) => {
      const newValues = util_exports.getTypedArrayFromDType(dtype, values.length);
      for (let i = 0; i < values.length; ++i) {
        newValues[i] = op2(values[i], attrs);
      }
      return newValues;
    };
  }
  var init_unary_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/unary_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/unary_utils.js
  function unaryKernelFunc(name, op2, dtype) {
    return ({ inputs, attrs, backend }) => {
      const { x } = inputs;
      assertNotComplex(x, name);
      if (x.dtype === "string" || dtype === "string") {
        throw new Error("unaryKernelFunc does not support string input/output");
      }
      const cpuBackend = backend;
      const values = cpuBackend.data.get(x.dataId).values;
      const xSize = util_exports.sizeFromShape(x.shape);
      const $dtype = dtype || x.dtype;
      const newValues = util_exports.getArrayFromDType($dtype, xSize);
      for (let i = 0; i < xSize; ++i) {
        newValues[i] = op2(values[i], attrs);
      }
      return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);
    };
  }
  function unaryKernelFuncFromImpl(name, unaryImpl, dtype) {
    return ({ inputs, attrs, backend }) => {
      const { x } = inputs;
      assertNotComplex(x, name);
      if (x.dtype === "string" || dtype === "string") {
        throw new Error("unaryKernelFunc does not support string input/output");
      }
      const cpuBackend = backend;
      const values = cpuBackend.data.get(x.dataId).values;
      const $dtype = dtype || x.dtype;
      const newValues = unaryImpl(values, $dtype, attrs);
      return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);
    };
  }
  var init_unary_utils = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/unary_utils.js"() {
      init_dist();
      init_cpu_util();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Ceil.js
  var ceilImpl, ceil2, ceilConfig;
  var init_Ceil = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Ceil.js"() {
      init_dist();
      init_unary_impl();
      init_unary_utils();
      ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));
      ceil2 = unaryKernelFuncFromImpl(Ceil, ceilImpl);
      ceilConfig = {
        kernelName: Ceil,
        backendName: "cpu",
        kernelFunc: ceil2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Concat_impl.js
  function concatImpl(inputs, outShape, dtype, simplyConcat) {
    const outVals = util_exports.getArrayFromDType(dtype, util_exports.sizeFromShape(outShape));
    if (simplyConcat && dtype !== "string") {
      let offset = 0;
      inputs.forEach((input) => {
        const size = util_exports.sizeFromShape(input.shape);
        outVals.set(input.vals, offset);
        offset += size;
      });
    } else {
      let colOffset = 0;
      inputs.forEach((input) => {
        const decodedData = dtype === "string" ? backend_util_exports.fromUint8ToStringArray(input.vals) : input.vals;
        let tIdx = 0;
        for (let row = 0; row < input.shape[0]; ++row) {
          const resIdx = row * outShape[1] + colOffset;
          for (let col = 0; col < input.shape[1]; ++col) {
            outVals[resIdx + col] = decodedData[tIdx++];
          }
        }
        colOffset += input.shape[1];
      });
    }
    return outVals;
  }
  var init_Concat_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Concat_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Equal.js
  var equalImpl, equal2, equalConfig;
  var init_Equal = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Equal.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      equalImpl = createSimpleBinaryKernelImpl((a, b) => a === b ? 1 : 0);
      equal2 = binaryKernelFunc(Equal, equalImpl, null, "bool");
      equalConfig = {
        kernelName: Equal,
        backendName: "cpu",
        kernelFunc: equal2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Exp.js
  var expImpl, exp2, expConfig;
  var init_Exp = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Exp.js"() {
      init_dist();
      init_unary_impl();
      init_unary_utils();
      expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));
      exp2 = unaryKernelFuncFromImpl(Exp, expImpl, "float32");
      expConfig = {
        kernelName: Exp,
        backendName: "cpu",
        kernelFunc: exp2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Expm1.js
  var expm1Impl, expm12, expm1Config;
  var init_Expm1 = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Expm1.js"() {
      init_dist();
      init_unary_impl();
      init_unary_utils();
      expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));
      expm12 = unaryKernelFuncFromImpl(Expm1, expm1Impl);
      expm1Config = {
        kernelName: Expm1,
        backendName: "cpu",
        kernelFunc: expm12
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Floor.js
  var floorImpl, floor2, floorConfig;
  var init_Floor = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Floor.js"() {
      init_dist();
      init_unary_impl();
      init_unary_utils();
      floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));
      floor2 = unaryKernelFuncFromImpl(Floor, floorImpl);
      floorConfig = {
        kernelName: Floor,
        backendName: "cpu",
        kernelFunc: floor2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd_Impl.js
  function gatherNdImpl(indicesData, paramsBuf, dtype, numSlices, sliceRank, sliceSize, strides, paramsShape, paramsSize) {
    const outBuf = buffer([numSlices, sliceSize], dtype);
    for (let i = 0; i < numSlices; i++) {
      const index = [];
      let flattenIndex = 0;
      for (let j2 = 0; j2 < sliceRank; j2++) {
        const dim = indicesData[i * sliceRank + j2];
        flattenIndex += dim * strides[j2];
        index.push(dim);
      }
      if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {
        throw new Error(`Invalid indices: ${index} does not index into ${paramsShape}`);
      }
      for (let k3 = 0; k3 < sliceSize; k3++) {
        outBuf.values[i * sliceSize + k3] = paramsBuf.get(...paramsBuf.indexToLoc(flattenIndex * sliceSize + k3));
      }
    }
    return outBuf;
  }
  var init_GatherNd_Impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd_Impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2_impl.js
  function gatherV2Impl(xBuf, indicesBuf, flattenOutputShape) {
    const outBuf = buffer(flattenOutputShape, xBuf.dtype);
    for (let i = 0; i < outBuf.size; ++i) {
      const newLoc = outBuf.indexToLoc(i);
      const originalLoc = newLoc.slice();
      const batchIdx = originalLoc[0];
      const indicesIdx = originalLoc[2];
      const indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);
      originalLoc[2] = indicesBuf.values[indicesIndex];
      const originalIndex = xBuf.locToIndex(originalLoc);
      if (0 <= originalIndex && originalIndex < xBuf.values.length) {
        outBuf.values[i] = xBuf.values[originalIndex];
      }
    }
    return outBuf;
  }
  var init_GatherV2_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Greater.js
  var greaterImpl, greater2, greaterConfig;
  var init_Greater = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Greater.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      greaterImpl = createSimpleBinaryKernelImpl((a, b) => a > b ? 1 : 0);
      greater2 = binaryKernelFunc(Greater, greaterImpl, null, "bool");
      greaterConfig = {
        kernelName: Greater,
        backendName: "cpu",
        kernelFunc: greater2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GreaterEqual.js
  var greaterEqualImpl, greaterEqual2, greaterEqualConfig;
  var init_GreaterEqual = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GreaterEqual.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      greaterEqualImpl = createSimpleBinaryKernelImpl((a, b) => a >= b ? 1 : 0);
      greaterEqual2 = binaryKernelFunc(GreaterEqual, greaterEqualImpl, null, "bool");
      greaterEqualConfig = {
        kernelName: GreaterEqual,
        backendName: "cpu",
        kernelFunc: greaterEqual2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Less.js
  var lessImpl, less2, lessConfig;
  var init_Less = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Less.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      lessImpl = createSimpleBinaryKernelImpl((a, b) => a < b ? 1 : 0);
      less2 = binaryKernelFunc(Less, lessImpl, null, "bool");
      lessConfig = {
        kernelName: Less,
        backendName: "cpu",
        kernelFunc: less2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LessEqual.js
  var lessEqualImpl, lessEqual2, lessEqualConfig;
  var init_LessEqual = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LessEqual.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      lessEqualImpl = createSimpleBinaryKernelImpl((a, b) => a <= b ? 1 : 0);
      lessEqual2 = binaryKernelFunc(LessEqual, lessEqualImpl, null, "bool");
      lessEqualConfig = {
        kernelName: LessEqual,
        backendName: "cpu",
        kernelFunc: lessEqual2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace_impl.js
  function linSpaceImpl(start, stop, num) {
    const step3 = (stop - start) / (num - 1);
    const values = util_exports.makeZerosTypedArray(num, "float32");
    values[0] = start;
    for (let i = 1; i < values.length; i++) {
      values[i] = values[i - 1] + step3;
    }
    return values;
  }
  var init_LinSpace_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Log.js
  var logImpl, log3, logConfig;
  var init_Log = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Log.js"() {
      init_dist();
      init_unary_impl();
      init_unary_utils();
      logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));
      log3 = unaryKernelFuncFromImpl(Log, logImpl);
      logConfig = {
        kernelName: Log,
        backendName: "cpu",
        kernelFunc: log3
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Max_impl.js
  function maxImpl(aVals, reduceSize, outShape, dtype) {
    const vals = util_exports.getTypedArrayFromDType(dtype, util_exports.sizeFromShape(outShape));
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let max3 = aVals[offset];
      for (let j2 = 0; j2 < reduceSize; ++j2) {
        const value = aVals[offset + j2];
        if (Number.isNaN(value) || value > max3) {
          max3 = value;
        }
      }
      vals[i] = max3;
    }
    return vals;
  }
  var init_Max_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Max_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Maximum.js
  var maximumImpl, maximum2, maximumConfig;
  var init_Maximum = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Maximum.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      maximumImpl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.max(aValue, bValue));
      maximum2 = binaryKernelFunc(Maximum, maximumImpl);
      maximumConfig = {
        kernelName: Maximum,
        backendName: "cpu",
        kernelFunc: maximum2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Minimum.js
  var minimumImpl, minimum2, minimumConfig;
  var init_Minimum = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Minimum.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      minimumImpl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.min(aValue, bValue));
      minimum2 = binaryKernelFunc(Minimum, minimumImpl);
      minimumConfig = {
        kernelName: Minimum,
        backendName: "cpu",
        kernelFunc: minimum2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Multiply.js
  var multiplyImpl, multiplyComplexImpl, multiply, multiplyConfig;
  var init_Multiply = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Multiply.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      multiplyImpl = createSimpleBinaryKernelImpl((aValue, bValue) => aValue * bValue);
      multiplyComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
        return {
          real: aReal * bReal - aImag * bImag,
          imag: aReal * bImag + aImag * bReal
        };
      });
      multiply = binaryKernelFunc(Multiply, multiplyImpl, multiplyComplexImpl);
      multiplyConfig = {
        kernelName: Multiply,
        backendName: "cpu",
        kernelFunc: multiply
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Neg.js
  function negImpl(xVals, xShape, xDtype) {
    const minusOne = util_exports.createScalarValue(-1, xDtype);
    return multiplyImpl([], xShape, minusOne, xVals, xDtype);
  }
  function neg2(args) {
    const { inputs, backend } = args;
    const { x } = inputs;
    assertNotComplex(x, "neg");
    const xVals = backend.data.get(x.dataId).values;
    const [res, newShape] = negImpl(xVals, x.shape, x.dtype);
    return backend.makeTensorInfo(newShape, x.dtype, res);
  }
  var negConfig;
  var init_Neg = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Neg.js"() {
      init_dist();
      init_cpu_util();
      init_Multiply();
      negConfig = {
        kernelName: Neg,
        backendName: "cpu",
        kernelFunc: neg2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NotEqual.js
  var notEqualImpl, notEqual2, notEqualConfig;
  var init_NotEqual = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NotEqual.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      notEqualImpl = createSimpleBinaryKernelImpl((a, b) => a !== b ? 1 : 0);
      notEqual2 = binaryKernelFunc(NotEqual, notEqualImpl, null, "bool");
      notEqualConfig = {
        kernelName: NotEqual,
        backendName: "cpu",
        kernelFunc: notEqual2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose_impl.js
  function transposeImpl(xVals, xShape, dtype, perm, newShape) {
    const xRank = xShape.length;
    const xSize = util_exports.sizeFromShape(xShape);
    const xStrides = util_exports.computeStrides(xShape);
    const newStrides = util_exports.computeStrides(newShape);
    const result = util_exports.getTypedArrayFromDType(dtype, util_exports.sizeFromShape(newShape));
    for (let i = 0; i < xSize; ++i) {
      const loc = util_exports.indexToLoc(i, xRank, xStrides);
      const newLoc = new Array(loc.length);
      for (let i2 = 0; i2 < newLoc.length; i2++) {
        newLoc[i2] = loc[perm[i2]];
      }
      const newIndex = util_exports.locToIndex(newLoc, xRank, newStrides);
      result[newIndex] = xVals[i];
    }
    return result;
  }
  var init_Transpose_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose.js
  function transpose2(args) {
    const { inputs, attrs, backend } = args;
    const { x } = inputs;
    const { perm } = attrs;
    assertNotComplex(x, "transpose");
    const xRank = x.shape.length;
    const newShape = new Array(xRank);
    for (let i = 0; i < newShape.length; i++) {
      newShape[i] = x.shape[perm[i]];
    }
    const values = backend.data.get(x.dataId).values;
    const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);
    const dataId = backend.write(result, newShape, x.dtype);
    return { dataId, shape: newShape, dtype: x.dtype };
  }
  var transposeConfig;
  var init_Transpose = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose.js"() {
      init_dist();
      init_cpu_util();
      init_Transpose_impl();
      transposeConfig = {
        kernelName: Transpose,
        backendName: "cpu",
        kernelFunc: transpose2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Prod.js
  function prodImpl(xShape, xDtype, xVals, reductionAxes) {
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(xShape, reductionAxes);
    const outDtype = upcastType(xDtype, "int32");
    const outVals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), outDtype);
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    for (let i = 0; i < outVals.length; ++i) {
      const offset = i * reduceSize;
      let prod3 = 1;
      for (let j2 = 0; j2 < reduceSize; ++j2) {
        prod3 *= xVals[offset + j2];
      }
      outVals[i] = prod3;
    }
    return { outVals, outShape, outDtype };
  }
  function prod2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    assertNotComplex(x, "prod");
    const xRank = x.shape.length;
    const axes = util_exports.parseAxisParam(axis, x.shape);
    const permutation = backend_util_exports.getAxesPermutation(axes, xRank);
    let reductionAxes = axes;
    let permutedX = x;
    const intermediateTensorInfos = [];
    if (permutation != null) {
      permutedX = transpose2({ inputs: { x }, backend, attrs: { perm: permutation } });
      intermediateTensorInfos.push(permutedX);
      reductionAxes = backend_util_exports.getInnerMostAxes(reductionAxes.length, xRank);
    }
    const xVals = backend.data.get(permutedX.dataId).values;
    const { outVals, outShape, outDtype } = prodImpl(permutedX.shape, permutedX.dtype, xVals, reductionAxes);
    let resultShape = outShape;
    if (keepDims) {
      resultShape = backend_util_exports.expandShapeToKeepDim(outShape, axes);
    }
    intermediateTensorInfos.forEach((t2) => backend.disposeIntermediateTensorInfo(t2));
    return backend.makeTensorInfo(resultShape, outDtype, outVals);
  }
  var prodConfig;
  var init_Prod = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Prod.js"() {
      init_dist();
      init_cpu_util();
      init_Transpose();
      prodConfig = {
        kernelName: Prod,
        backendName: "cpu",
        kernelFunc: prod2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather_impl.js
  function validateIndices(indices, indicesShape, numParams) {
    indices.forEach((index, i) => {
      if (index < 0 || index >= numParams) {
        const locString = util_exports.indexToLoc(i, indicesShape.length, util_exports.computeStrides(indicesShape)).join(",");
        throw new Error(`indices[${locString}] = ${index} is not in [0, ${numParams})`);
      }
    });
  }
  function validateSplits(paramsNestedSplits, numParamsDenseValues) {
    for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {
      const splits = paramsNestedSplits[dim];
      const lastSplit = dim === paramsNestedSplits.length - 1 ? numParamsDenseValues : paramsNestedSplits[dim + 1].length;
      if (splits.length === 0) {
        throw new Error("Ragged splits may not be empty");
      }
      if (splits[0] < 0) {
        throw new Error("Ragged splits must be non-negative");
      }
      if (splits[splits.length - 1] > lastSplit) {
        throw new Error("Ragged splits must not point past values");
      }
      for (let i = 1; i < splits.length; ++i) {
        if (splits[i - 1] > splits[i]) {
          throw new Error("Ragged splits must be sorted in ascending order");
        }
      }
    }
  }
  function makeSplits(indices, indicesShape, paramsNestedSplits, numParamsDenseValues) {
    const valueSlices = [];
    let numValues = 0;
    const numSplits = indicesShape.length - 1 + paramsNestedSplits.length;
    const outSplits = new Array(numSplits).fill(null).map(() => [0]);
    validateSplits(paramsNestedSplits, numParamsDenseValues);
    let nrows = 1;
    for (let dim = 0; dim < indicesShape.length - 1; ++dim) {
      nrows *= indicesShape[dim];
      const rowLength = indicesShape[dim + 1];
      for (let i = 1; i < nrows + 1; ++i) {
        outSplits[dim].push(i * rowLength);
      }
    }
    for (let i = 0; i < indices.length; ++i) {
      let start = indices[i];
      let limit = indices[i] + 1;
      for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {
        const splits = paramsNestedSplits[dim];
        const outDim = dim + indicesShape.length - 1;
        if (outDim >= 0) {
          const outSplitsOutDim = outSplits[outDim];
          const delta = outSplitsOutDim[outSplitsOutDim.length - 1] - splits[start];
          for (let j2 = start; j2 < limit; ++j2) {
            outSplits[outDim].push(splits[j2 + 1] + delta);
          }
        }
        start = splits[start];
        limit = splits[limit];
      }
      if (limit !== start) {
        valueSlices.push([start, limit]);
        numValues += limit - start;
      }
    }
    return { outSplits, valueSlices, numValues };
  }
  function getSplits(outSplits) {
    const splitsOut = [];
    for (let i = 0; i < outSplits.length; ++i) {
      const numSplits = outSplits[i].length;
      const splits = util_exports.getArrayFromDType("int32", numSplits);
      splitsOut.push(splits);
      outSplits[i].forEach((value, j2) => splits[j2] = value);
    }
    return splitsOut;
  }
  function computeFlatOuterDims(orig, numOutDims) {
    const outDims = orig.slice(0, numOutDims);
    while (outDims.length < numOutDims) {
      outDims.push(1);
    }
    for (let inDim = numOutDims; inDim < orig.length; inDim++) {
      outDims[numOutDims - 1] *= orig[inDim];
    }
    return outDims;
  }
  function writeValueSlices(paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize, values, valuesShape) {
    const denseM = computeFlatOuterDims(paramsDenseValuesShape, 2)[1];
    const valuesM = computeFlatOuterDims(valuesShape, 2)[1];
    let outPos = 0;
    for (const slice3 of valueSlices) {
      for (let i = slice3[0]; i < slice3[1]; ++i) {
        for (let j2 = 0; j2 < valueSize; ++j2) {
          values[outPos * valuesM + j2] = paramsDenseValues[i * denseM + j2];
        }
        ++outPos;
      }
    }
  }
  function getValues(paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, valueSlices, numValues) {
    const valuesShape = paramsDenseValuesShape.slice();
    valuesShape[0] = numValues;
    const valuesOut = util_exports.getArrayFromDType(paramsDenseValuesDType, util_exports.sizeFromShape(valuesShape));
    const numElements = paramsDenseValues.length;
    const valueSize = numElements === 0 ? 0 : numElements / paramsDenseValuesShape[0];
    writeValueSlices(paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize, valuesOut, valuesShape);
    return [valuesOut, valuesShape];
  }
  function raggedGatherImpl(paramsNestedSplits, paramsNestedSplitsShapes, paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, indices, indicesShape, outputRaggedRank) {
    if (paramsNestedSplits.length === 0) {
      throw new Error("paramsNestedSplits must be non empty");
    }
    if (paramsNestedSplitsShapes[0].length === 0) {
      throw new Error("Split tensors must not be scalars");
    }
    const numParams = paramsNestedSplitsShapes[0][0] - 1;
    validateIndices(indices, indicesShape, numParams);
    if (paramsDenseValuesShape.length === 0) {
      throw new Error("params.rank must be nonzero");
    }
    const numParamsDenseValues = paramsDenseValuesShape[0];
    const { outSplits, valueSlices, numValues } = makeSplits(indices, indicesShape, paramsNestedSplits, numParamsDenseValues);
    const outputNestedSplits = getSplits(outSplits);
    const outputDenseValues = getValues(paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, valueSlices, numValues);
    return [outputNestedSplits, outputDenseValues[0], outputDenseValues[1]];
  }
  var init_RaggedGather_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange_impl.js
  function raggedRangeImpl(starts, startsShape, startsDType, limits, limitsShape, deltas, deltasShape) {
    if (startsShape.length > 1) {
      throw new Error("starts must be a scalar or vector");
    }
    if (limitsShape.length > 1) {
      throw new Error("limits must be a scalar or vector");
    }
    if (deltasShape.length > 1) {
      throw new Error("deltas must be a scalar or vector");
    }
    const broadcastStarts = startsShape.length === 0;
    const broadcastLimits = limitsShape.length === 0;
    const broadcastDeltas = deltasShape.length === 0;
    const inSizes = [];
    if (!broadcastStarts) {
      inSizes.push(startsShape[0]);
    }
    if (!broadcastLimits) {
      inSizes.push(limitsShape[0]);
    }
    if (!broadcastDeltas) {
      inSizes.push(deltasShape[0]);
    }
    for (let i = 1; i < inSizes.length; ++i) {
      if (inSizes[i] !== inSizes[i - 1]) {
        throw new Error("starts, limits, and deltas must have the same shape");
      }
    }
    const nRows = inSizes.length === 0 ? 1 : inSizes[0];
    const rtNestedSplits = util_exports.getArrayFromDType("int32", nRows + 1);
    rtNestedSplits[0] = 0;
    for (let row = 0; row < nRows; ++row) {
      const start = broadcastStarts ? starts[0] : starts[row];
      const limit = broadcastLimits ? limits[0] : limits[row];
      const delta = broadcastDeltas ? deltas[0] : deltas[row];
      if (delta === 0) {
        throw new Error("Requires delta != 0");
      }
      let size;
      if (delta > 0 && limit < start || delta < 0 && limit > start) {
        size = 0;
      } else {
        size = Math.ceil(Math.abs((limit - start) / delta));
        if (size > INT32_MAX2) {
          throw new Error(`Requires ((limit - start) / delta) <= ${INT32_MAX2}`);
        }
      }
      rtNestedSplits[row + 1] = rtNestedSplits[row] + size;
    }
    const nVals = rtNestedSplits[nRows];
    const rtDenseValues = util_exports.getArrayFromDType(startsDType, nVals);
    let valueIndex = 0;
    for (let row = 0; row < nRows; ++row) {
      const rowSize = rtNestedSplits[row + 1] - rtNestedSplits[row];
      let value = broadcastStarts ? starts[0] : starts[row];
      const delta = broadcastDeltas ? deltas[0] : deltas[row];
      for (let i = 0; i < rowSize; ++i) {
        rtDenseValues[valueIndex++] = value;
        value += delta;
      }
    }
    return [rtNestedSplits, rtDenseValues];
  }
  var INT32_MAX2;
  var init_RaggedRange_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange_impl.js"() {
      init_dist();
      INT32_MAX2 = 2147483647;
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor_impl.js
  function copyArray(dst, src, size) {
    for (let i = 0; i < size; i++) {
      dst[i] = src[i];
    }
  }
  function makeShape(shape, isPartial) {
    const out = [];
    for (let dim of shape) {
      if (dim < 0) {
        if (!isPartial) {
          throw new Error(`Dimension ${dim} must be >= 0`);
        }
        if (dim < -1) {
          throw new Error(`Dimension ${dim} must be >= -1`);
        }
        dim = -1;
      }
      out.push(dim);
    }
    return out;
  }
  function raggedTensorToTensorImpl(shape, shapesShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes) {
    return new RaggedTensorToTensorOp(shape, shapesShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes).compute();
  }
  var RowPartitionType2, RaggedTensorToTensorOp;
  var init_RaggedTensorToTensor_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor_impl.js"() {
      init_dist();
      RowPartitionType2 = backend_util_exports.RowPartitionType;
      RaggedTensorToTensorOp = class {
        constructor(shape, shapeShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypeStrings) {
          this.shape = shape;
          this.shapeShape = shapeShape;
          this.values = values;
          this.valuesShape = valuesShape;
          this.valuesDType = valuesDType;
          this.defaultValue = defaultValue;
          this.defaultValueShape = defaultValueShape;
          this.rowPartitionValues = rowPartitionValues;
          this.rowPartitionValuesShapes = rowPartitionValuesShapes;
          this.rowPartitionTypes = backend_util_exports.getRowPartitionTypesHelper(rowPartitionTypeStrings);
          this.raggedRank = backend_util_exports.getRaggedRank(this.rowPartitionTypes);
        }
        getRowPartitionTypeByDimension(dimension) {
          if (this.rowPartitionTypes[0] === RowPartitionType2.FIRST_DIM_SIZE) {
            return this.rowPartitionTypes[dimension + 1];
          } else {
            return this.rowPartitionTypes[dimension];
          }
        }
        // Returns the relationship between dimension and dimension + 1.
        getRowPartitionTensor(dimension) {
          if (this.rowPartitionTypes[0] === RowPartitionType2.FIRST_DIM_SIZE) {
            return this.rowPartitionValues[dimension + 1];
          } else {
            return this.rowPartitionValues[dimension];
          }
        }
        getMaxWidth(dimension) {
          const rowPartitionTensor = this.getRowPartitionTensor(dimension - 1);
          switch (this.getRowPartitionTypeByDimension(dimension - 1)) {
            case RowPartitionType2.VALUE_ROWIDS:
              return RaggedTensorToTensorOp.getMaxWidthValueRowID(rowPartitionTensor);
            case RowPartitionType2.ROW_SPLITS:
              return RaggedTensorToTensorOp.getMaxWidthRowSplit(rowPartitionTensor);
            default:
              throw new Error(`Cannot handle partition type ${RowPartitionType2[this.getRowPartitionTypeByDimension(dimension - 1)]}`);
          }
        }
        static getMaxWidthRowSplit(rowSplit) {
          const tensorLength = rowSplit.length;
          if (tensorLength === 0 || tensorLength === 1) {
            return 0;
          }
          let maxWidth = 0;
          for (let i = 0; i < tensorLength - 1; ++i) {
            const currentWidth = rowSplit[i + 1] - rowSplit[i];
            if (currentWidth > maxWidth) {
              maxWidth = currentWidth;
            }
          }
          return maxWidth;
        }
        static getMaxWidthValueRowID(valueRowIds) {
          const indexLength = valueRowIds.length;
          if (indexLength === 0) {
            return 0;
          }
          let firstEqualIndex = 0;
          let firstEqualIndexValue = valueRowIds[0];
          let maxWidth = 0;
          for (let i = 1; i < indexLength; ++i) {
            const value = valueRowIds[i];
            if (value !== firstEqualIndexValue) {
              firstEqualIndexValue = value;
              maxWidth = Math.max(i - firstEqualIndex, maxWidth);
              firstEqualIndex = i;
            }
          }
          return Math.max(indexLength - firstEqualIndex, maxWidth);
        }
        tensorShapeFromTensor(t2, tShape, isPartial = true) {
          if (tShape.length === 0) {
            if (t2[0] === -1) {
              return [];
            }
            throw new Error(`The only valid scalar shape tensor is the fully unknown shape specified as -1.`);
          }
          return makeShape(t2, isPartial);
        }
        calculateOutputSize(firstDim) {
          const valueShape = this.valuesShape;
          const defaultValueShape = this.defaultValueShape;
          backend_util_exports.validateDefaultValueShape(defaultValueShape, valueShape);
          const shape = this.tensorShapeFromTensor(this.shape, this.shapeShape);
          const outputShape = backend_util_exports.combineRaggedTensorToTensorShapes(this.raggedRank, shape, valueShape);
          const result = outputShape;
          if (result[0] < 0) {
            result[0] = firstDim;
          }
          for (let i = 1; i <= this.raggedRank; ++i) {
            if (result[i] < 0) {
              result[i] = this.getMaxWidth(i);
            }
          }
          return result;
        }
        /**
         * The outputIndex represents the index in the output tensor
         * where the first element of a particular dimension would be written.
         * If it is -1, it indicates that the index is out of scope.
         * Example, given firstDimension = 10, firstDimensionOutput = 6,
         * and outputIndexMultiplier = 100:
         * result = [0 100 200 300 400 500 -1 -1 -1 -1]
         * If firstDimensionOutput = 11 instead, then:
         * result = [0 100 200 300 400 500 600 700 800 900]
         */
        calculateFirstParentOutputIndex(firstDimension, outputIndexMultiplier, firstDimensionOutput) {
          const minDimension = Math.min(firstDimension, firstDimensionOutput);
          const result = [];
          let currentOutputIndex = 0;
          for (let i = 0; i < minDimension; ++i, currentOutputIndex += outputIndexMultiplier) {
            result.push(currentOutputIndex);
          }
          for (let i = minDimension; i < firstDimension; ++i) {
            result.push(-1);
          }
          util_exports.assert(result.length === firstDimension, () => "Final length of result must be equal to firstDimension.");
          return result;
        }
        calculateOutputIndexRowSplit(rowSplit, parentOutputIndex, outputIndexMultiplier, outputSize) {
          const rowSplitSize = rowSplit.length;
          const result = [];
          for (let i = 0; i < rowSplitSize - 1; ++i) {
            const rowLength = rowSplit[i + 1] - rowSplit[i];
            let realLength = Math.min(outputSize, rowLength);
            let parentOutputIndexCurrent = parentOutputIndex[i];
            if (parentOutputIndexCurrent === -1) {
              realLength = 0;
            }
            for (let j2 = 0; j2 < realLength; ++j2) {
              result.push(parentOutputIndexCurrent);
              parentOutputIndexCurrent += outputIndexMultiplier;
            }
            for (let j2 = 0; j2 < rowLength - realLength; ++j2) {
              result.push(-1);
            }
          }
          if (rowSplitSize > 0 && result.length !== rowSplit[rowSplitSize - 1]) {
            throw new Error("Invalid row split size.");
          }
          return result;
        }
        // Calculate the output index of the first element of a list.
        // The parentOutputIndex is the same computation for the previous list.
        // -1 indicates an element or list that is out of range.
        // The outputIndexMultiplier is the number of output indices one moves
        // forward for each column.
        // E.g., given:
        // valueRowIds:[0 1 2 2 2 3 5 5 6]
        // parentOutputIndex:[1000 1100 2000 2100 -1 3000 4000]
        // outputIndexMultiplier: 10
        // outputSize: 2
        // You get:
        // result = [1000 1100 2000 2010 -1 2100 -1 -1 3000]
        // result[0] = parentOutputIndex[valueRowIds[0]]
        // result[1] = parentOutputIndex[valueRowIds[1]]
        // result[2] = parentOutputIndex[valueRowIds[2]]
        // result[3] = parentOutputIndex[valueRowIds[2] + 10]
        // result[4] = -1 because it is the third element the size is 2.
        // result[5] = parentOutputIndex[valueRowIds[3]]
        // result[6] = -1 because parentOutputIndex[valueRowIds[6]] == -1
        // result[7] = -1 because parentOutputIndex[valueRowIds[6]] == -1
        // result[8] = parentOutputIndex[valueRowIds[7]]
        calculateOutputIndexValueRowID(valueRowIds, parentOutputIndex, outputIndexMultiplier, outputSize) {
          const indexSize = valueRowIds.length;
          const result = [];
          if (indexSize === 0) {
            return [];
          }
          let currentOutputColumn = 0;
          let currentValueRowId = valueRowIds[0];
          if (currentValueRowId >= parentOutputIndex.length) {
            throw new Error(`Got currentValueRowId=${currentValueRowId}, which is not less than ${parentOutputIndex.length}`);
          }
          let currentOutputIndex = parentOutputIndex[currentValueRowId];
          result.push(currentOutputIndex);
          for (let i = 1; i < indexSize; ++i) {
            const nextValueRowId = valueRowIds[i];
            if (nextValueRowId === currentValueRowId) {
              if (currentOutputIndex >= 0) {
                ++currentOutputColumn;
                if (currentOutputColumn < outputSize) {
                  currentOutputIndex += outputIndexMultiplier;
                } else {
                  currentOutputIndex = -1;
                }
              }
            } else {
              currentOutputColumn = 0;
              currentValueRowId = nextValueRowId;
              if (nextValueRowId >= parentOutputIndex.length) {
                throw new Error(`Got nextValueRowId=${nextValueRowId} which is not less than ${parentOutputIndex.length}`);
              }
              currentOutputIndex = parentOutputIndex[nextValueRowId];
            }
            result.push(currentOutputIndex);
          }
          if (result.length !== valueRowIds.length) {
            throw new Error("Invalid row ids.");
          }
          return result;
        }
        calculateOutputIndex(dimension, parentOutputIndex, outputIndexMultiplier, outputSize) {
          const rowPartitionTensor = this.getRowPartitionTensor(dimension);
          const partitionType = this.getRowPartitionTypeByDimension(dimension);
          switch (partitionType) {
            case RowPartitionType2.VALUE_ROWIDS:
              return this.calculateOutputIndexValueRowID(rowPartitionTensor, parentOutputIndex, outputIndexMultiplier, outputSize);
            case RowPartitionType2.ROW_SPLITS:
              if (rowPartitionTensor.length - 1 > parentOutputIndex.length) {
                throw new Error(`Row partition size is greater than output size: ${rowPartitionTensor.length - 1} > ${parentOutputIndex.length}`);
              }
              return this.calculateOutputIndexRowSplit(rowPartitionTensor, parentOutputIndex, outputIndexMultiplier, outputSize);
            default:
              throw new Error(`Unsupported partition type: ${RowPartitionType2[partitionType]}`);
          }
        }
        getFirstDimensionSize() {
          const firstPartitionTensor = this.rowPartitionValues[0];
          if (this.rowPartitionTypes.length === 0) {
            throw new Error("No row_partition_types given.");
          }
          const firstPartitionType = this.rowPartitionTypes[0];
          switch (firstPartitionType) {
            case RowPartitionType2.FIRST_DIM_SIZE:
              return firstPartitionTensor[0];
            case RowPartitionType2.VALUE_ROWIDS:
              throw new Error("Cannot handle VALUE_ROWIDS in first dimension.");
            case RowPartitionType2.ROW_SPLITS:
              return this.rowPartitionValuesShapes[0][0] - 1;
            default:
              throw new Error(`Cannot handle type ${RowPartitionType2[firstPartitionType]}`);
          }
        }
        compute() {
          const firstPartitionTensor = this.rowPartitionValues[0];
          if (firstPartitionTensor.length <= 0) {
            throw new Error("Invalid first partition input. Tensor requires at least one element.");
          }
          const firstDimension = this.getFirstDimensionSize();
          const outputSize = this.calculateOutputSize(firstDimension);
          const multiplier = new Array(this.raggedRank + 1);
          multiplier[multiplier.length - 1] = 1;
          for (let i = multiplier.length - 2; i >= 0; --i) {
            multiplier[i] = multiplier[i + 1] * outputSize[i + 1];
          }
          const outputShape = makeShape(outputSize, false);
          const outputTensor = util_exports.getArrayFromDType(this.valuesDType, util_exports.sizeFromShape(outputShape));
          const fullSize = multiplier[0] * outputSize[0];
          if (fullSize > 0) {
            let outputIndex = this.calculateFirstParentOutputIndex(firstDimension, multiplier[0], outputSize[0]);
            for (let i = 1; i <= this.raggedRank; ++i) {
              const newOutputIndex = this.calculateOutputIndex(i - 1, outputIndex, multiplier[i], outputSize[i]);
              outputIndex = newOutputIndex;
            }
            this.setOutput(this.raggedRank, outputIndex, outputTensor, outputShape);
          }
          return [outputShape, outputTensor];
        }
        setOutput(raggedRank, outputIndex, outputTensor, outputShape) {
          if (outputTensor.length === 0) {
            return;
          }
          const valuesBase = this.values;
          const outputBase = outputTensor;
          let elementShape = outputShape.slice();
          elementShape = elementShape.slice(raggedRank + 1);
          const valueElementSize = util_exports.sizeFromShape(elementShape);
          const outputIndexSize = outputIndex.length;
          let defaultValue = this.defaultValue;
          if (defaultValue.length !== valueElementSize && defaultValue.length !== 1) {
            const srcShape = this.defaultValueShape;
            tidy(() => {
              const defaultValueTensor = reshape(defaultValue, srcShape);
              const bCastDefault = broadcastTo(defaultValueTensor, elementShape);
              defaultValue = bCastDefault.dataSync();
            });
          }
          let srcStart = 0;
          let dstStart = 0;
          let dstEnd = 0;
          for (let srcI = 0; srcI <= outputIndexSize; ++srcI) {
            let dstI = srcI < outputIndexSize ? outputIndex[srcI] : -1;
            if (dstI === dstEnd) {
              ++dstEnd;
              continue;
            }
            if (dstStart < dstEnd) {
              const src = valuesBase.subarray(srcStart * valueElementSize);
              const dst = outputBase.subarray(dstStart * valueElementSize);
              const nVals = (dstEnd - dstStart) * valueElementSize;
              copyArray(dst, src, nVals);
            }
            if (srcI >= outputIndexSize) {
              const outputSize = outputTensor.length;
              dstI = Math.floor(outputSize / valueElementSize);
            }
            if (dstI > dstEnd) {
              if (this.defaultValue.length === 1) {
                outputBase.subarray(dstEnd * valueElementSize, dstI * valueElementSize).fill(this.defaultValue[0]);
                dstEnd = dstI;
              } else {
                while (dstI > dstEnd) {
                  const dst = outputBase.slice(dstEnd * valueElementSize);
                  copyArray(dst, defaultValue, valueElementSize);
                  ++dstEnd;
                }
              }
            }
            if (dstI < 0) {
              srcStart = srcI + 1;
              dstStart = dstEnd;
            } else {
              srcStart = srcI;
              dstStart = dstEnd;
              dstEnd = dstStart + 1;
            }
          }
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Range_impl.js
  function rangeImpl(start, stop, step3, dtype) {
    const sameStartStop = start === stop;
    const increasingRangeNegativeStep = start < stop && step3 < 0;
    const decreasingRangePositiveStep = stop < start && step3 > 1;
    if (sameStartStop || increasingRangeNegativeStep || decreasingRangePositiveStep) {
      return util_exports.makeZerosTypedArray(0, dtype);
    }
    const numElements = Math.abs(Math.ceil((stop - start) / step3));
    const values = util_exports.makeZerosTypedArray(numElements, dtype);
    if (stop < start && step3 === 1) {
      step3 = -1;
    }
    values[0] = start;
    for (let i = 1; i < values.length; i++) {
      values[i] = values[i - 1] + step3;
    }
    return values;
  }
  var init_Range_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Range_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Rsqrt.js
  var rsqrtImpl, rsqrt2, rsqrtConfig;
  var init_Rsqrt = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Rsqrt.js"() {
      init_dist();
      init_unary_impl();
      init_unary_utils();
      rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));
      rsqrt2 = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl);
      rsqrtConfig = {
        kernelName: Rsqrt,
        backendName: "cpu",
        kernelFunc: rsqrt2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Scatter_impl.js
  function scatterImpl(indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices) {
    const flattenShape = [outputSize / sliceSize, sliceSize];
    const indicesData = indices.values;
    const updatesData = updates.values;
    if (outputSize === 0) {
      return buffer(shape, updates.dtype);
    }
    const outBuf = buffer(flattenShape, updates.dtype);
    if (typeof defaultValue === "string") {
      outBuf.values.fill(defaultValue);
    } else if (typeof defaultValue === "number") {
      outBuf.values.fill(defaultValue);
    } else if (typeof defaultValue === "boolean") {
      outBuf.values.fill(+defaultValue);
    }
    for (let i = 0; i < numUpdates; i++) {
      const index = [];
      let flattenIndex = 0;
      for (let j2 = 0; j2 < sliceRank; j2++) {
        const dim = indicesData[i * sliceRank + j2];
        index.push(dim);
        flattenIndex += dim * strides[j2];
      }
      if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {
        throw new Error(`Invalid indices: ${index} does not index into ${shape}`);
      }
      for (let k3 = 0; k3 < sliceSize; k3++) {
        if (sumDupeIndices) {
          outBuf.values[flattenIndex * sliceSize + k3] += updatesData[i * sliceSize + k3];
        } else {
          outBuf.values[flattenIndex * sliceSize + k3] = updates.rank === 0 ? updatesData[0] : updatesData[i * sliceSize + k3];
        }
      }
    }
    return outBuf;
  }
  var init_Scatter_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Scatter_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sigmoid.js
  var sigmoidImpl, sigmoid2, sigmoidConfig;
  var init_Sigmoid = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sigmoid.js"() {
      init_dist();
      init_unary_impl();
      init_unary_utils();
      sigmoidImpl = createSimpleUnaryImpl((xi) => 1 / (1 + Math.exp(-xi)));
      sigmoid2 = unaryKernelFunc(Sigmoid, (xi) => 1 / (1 + Math.exp(-xi)));
      sigmoidConfig = {
        kernelName: Sigmoid,
        backendName: "cpu",
        kernelFunc: sigmoid2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Slice.js
  function sliceImpl(vals, begin, size, shape, dtype) {
    const isContinous = slice_util_exports.isSliceContinous(shape, begin, size);
    const length = util_exports.sizeFromShape(size);
    const xStrides = util_exports.computeStrides(shape);
    if (isContinous) {
      const flatOffset = slice_util_exports.computeFlatOffset(begin, xStrides);
      if (dtype === "string") {
        return vals.slice(flatOffset, flatOffset + length);
      }
      return vals.subarray(flatOffset, flatOffset + length);
    }
    const decodedData = dtype === "string" ? backend_util_exports.fromUint8ToStringArray(vals) : vals;
    const inBuf = buffer(shape, dtype, decodedData);
    const outBuf = buffer(size, dtype);
    for (let i = 0; i < outBuf.size; ++i) {
      const outLoc = outBuf.indexToLoc(i);
      const inLoc = outLoc.map((idx, j2) => idx + begin[j2]);
      outBuf.set(inBuf.get(...inLoc), ...outLoc);
    }
    if (dtype === "string") {
      return backend_util_exports.fromStringArrayToUint8(outBuf.values);
    }
    return outBuf.values;
  }
  function slice2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { begin, size } = attrs;
    assertNotComplex(x, "slice");
    const [$begin, $size] = slice_util_exports.parseSliceParams(x, begin, size);
    slice_util_exports.assertParamsValid(x, $begin, $size);
    const vals = backend.data.get(x.dataId).values;
    const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);
    return backend.makeTensorInfo($size, x.dtype, outVals);
  }
  var sliceConfig;
  var init_Slice = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Slice.js"() {
      init_dist();
      init_cpu_util();
      sliceConfig = {
        kernelName: Slice,
        backendName: "cpu",
        kernelFunc: slice2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows_impl.js
  function sparseFillEmptyRowsImpl(indices, indicesShape, indicesDType, values, valuesDType, denseShape, defaultValue) {
    const indicesCount = indicesShape[0];
    const denseRows = denseShape[0];
    const emptyRowIndicator = new Array(denseRows);
    const reverseIndexMap = new Array(indicesCount);
    const rank = indicesShape[1];
    if (denseRows === 0) {
      if (indicesCount !== 0) {
        throw new Error(backend_util_exports.getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesCount));
      }
      const outputIndices = util_exports.getArrayFromDType(indicesDType, 0);
      const outputValues = util_exports.getArrayFromDType(valuesDType, 0);
      return [
        outputIndices,
        [0, rank],
        outputValues,
        emptyRowIndicator,
        reverseIndexMap
      ];
    }
    let rowsAreOrdered = true;
    let lastIndicesRow = 0;
    const csrOffset = new Array(denseRows).fill(0);
    for (let i = 0; i < indicesCount; ++i) {
      const row = indices[i * rank];
      if (row < 0) {
        throw new Error(backend_util_exports.getSparseFillEmptyRowsNegativeIndexErrorMessage(i, row));
      }
      if (row >= denseRows) {
        throw new Error(backend_util_exports.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(i, row, denseRows));
      }
      ++csrOffset[row];
      rowsAreOrdered = rowsAreOrdered && row >= lastIndicesRow;
      lastIndicesRow = row;
    }
    let allRowsFull = true;
    for (let row = 0; row < denseRows; ++row) {
      const rowEmpty = csrOffset[row] === 0;
      emptyRowIndicator[row] = rowEmpty;
      allRowsFull = allRowsFull && !rowEmpty;
      csrOffset[row] = Math.max(csrOffset[row], 1);
      if (row > 0) {
        csrOffset[row] += csrOffset[row - 1];
      }
    }
    if (allRowsFull && rowsAreOrdered) {
      const outputIndices = indices;
      const outputValues = values;
      for (let i = 0; i < indicesCount; ++i) {
        reverseIndexMap[i] = i;
      }
      return [
        outputIndices,
        [indicesCount, rank],
        outputValues,
        emptyRowIndicator,
        reverseIndexMap
      ];
    } else {
      const fullIndicesCount = csrOffset[denseRows - 1];
      const outputIndices = util_exports.getArrayFromDType(indicesDType, fullIndicesCount * rank);
      const outputValues = util_exports.getArrayFromDType(valuesDType, fullIndicesCount);
      const filledCount = new Array(denseRows).fill(0);
      for (let i = 0; i < indicesCount; ++i) {
        const row = indices[i * rank];
        const offset = filledCount[row];
        const outputI = (row === 0 ? 0 : csrOffset[row - 1]) + offset;
        filledCount[row]++;
        for (let j2 = 0; j2 < rank; ++j2) {
          outputIndices[outputI * rank + j2] = indices[i * rank + j2];
        }
        outputValues[outputI] = values[i];
        reverseIndexMap[i] = outputI;
      }
      for (let row = 0; row < denseRows; ++row) {
        const rowCount = filledCount[row];
        if (rowCount === 0) {
          const startingIndex = row === 0 ? 0 : csrOffset[row - 1];
          outputIndices[startingIndex * rank + 0] = row;
          for (let col = 1; col < rank; ++col) {
            outputIndices[startingIndex * rank + col] = 0;
          }
          outputValues[startingIndex] = defaultValue;
        }
      }
      return [
        outputIndices,
        [fullIndicesCount, rank],
        outputValues,
        emptyRowIndicator,
        reverseIndexMap
      ];
    }
  }
  var init_SparseFillEmptyRows_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape_impl.js
  function sparseReshapeImpl(inputIndices, inputIndicesShape, inputDType, inputShape, targetShape) {
    const denseSize = util_exports.sizeFromShape(inputShape);
    const nnz = inputIndicesShape[0];
    const outputRank = targetShape.length;
    const outputShape = [];
    let product = 1;
    let unknownIndex = -1;
    for (let d = 0; d < outputRank; ++d) {
      const size = targetShape[d];
      if (size === -1) {
        if (unknownIndex !== -1) {
          throw new Error(backend_util_exports.getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(unknownIndex, d));
        }
        unknownIndex = d;
        outputShape.push(1);
      } else {
        if (size < 0) {
          throw new Error(backend_util_exports.getSparseReshapeNegativeOutputDimErrorMessage(d, size));
        }
        product *= size;
        outputShape.push(size);
      }
    }
    if (unknownIndex !== -1) {
      if (product <= 0) {
        throw new Error(backend_util_exports.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());
      }
      const missing = Math.trunc(denseSize / product);
      if (product * missing !== denseSize) {
        throw new Error(backend_util_exports.getSparseReshapeInputOutputMultipleErrorMessage(inputShape, outputShape));
      }
      outputShape[unknownIndex] = missing;
    }
    const outputSize = util_exports.sizeFromShape(outputShape);
    if (outputSize !== denseSize) {
      throw new Error(backend_util_exports.getSparseReshapeInputOutputMismatchErrorMessage(inputShape, outputShape));
    }
    const inputRank = inputShape.length;
    const inputStrides = [];
    if (inputRank > 0) {
      inputStrides[inputRank - 1] = 1;
      for (let d = inputRank - 2; d >= 0; --d) {
        inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];
      }
    }
    const outputStrides = [];
    if (outputRank > 0) {
      outputStrides[outputRank - 1] = 1;
      for (let d = outputRank - 2; d >= 0; --d) {
        outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];
      }
    }
    const newIndices = util_exports.getArrayFromDType(inputDType, nnz * outputRank);
    for (let i = 0; i < nnz; ++i) {
      let id = 0;
      for (let j2 = 0; j2 < inputRank; ++j2) {
        id += inputIndices[i * inputRank + j2] * inputStrides[j2];
      }
      for (let j2 = 0; j2 < outputRank; ++j2) {
        newIndices[i * outputRank + j2] = Math.trunc(id / outputStrides[j2]);
        id %= outputStrides[j2];
      }
    }
    return [newIndices, [nnz, outputRank], outputShape];
  }
  var init_SparseReshape_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentReduction_impl.js
  function sparseSegmentReductionImpl(input, inputShape, inputDType, indices, segmentIds, isMean = false, defaultValue = 0) {
    const numIndices = indices.length;
    const inputFlat = [inputShape[0], input.length / inputShape[0]];
    const numCol = inputFlat[1];
    const lastSegmentIdPlusOne = numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;
    const outputRows = lastSegmentIdPlusOne;
    if (outputRows < 0) {
      throw new Error(backend_util_exports.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
    }
    const outputShape = inputShape.slice();
    outputShape[0] = outputRows;
    const outputLength = outputShape.reduce((product, value) => product * value, 1);
    const output = util_exports.getArrayFromDType(inputDType, outputLength);
    if (numIndices === 0) {
      if (outputRows > 0) {
        output.fill(defaultValue);
      }
      return [output, outputShape];
    }
    if (outputRows <= 0) {
      throw new Error(backend_util_exports.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
    }
    let start = 0, end = 1;
    let uninitializedIndex = 0;
    let outIndex = segmentIds[start];
    while (true) {
      let nextIndex = 0;
      if (end < numIndices) {
        nextIndex = segmentIds[end];
        if (outIndex === nextIndex) {
          ++end;
          continue;
        }
        if (outIndex >= nextIndex) {
          throw new Error(backend_util_exports.getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage());
        }
      }
      if (outIndex < 0 || outIndex >= outputRows) {
        throw new Error(backend_util_exports.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(outIndex, outputRows));
      }
      if (outIndex > uninitializedIndex) {
        output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);
      }
      for (let i = start; i < end; ++i) {
        const index = indices[i];
        if (index < 0 || index >= inputFlat[0]) {
          throw new Error(backend_util_exports.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(i, indices[i], inputFlat[0]));
        }
        for (let j2 = 0; j2 < numCol; j2++) {
          output[outIndex * numCol + j2] += input[index * numCol + j2];
        }
      }
      if (isMean) {
        for (let j2 = 0; j2 < numCol; j2++) {
          output[outIndex * numCol + j2] /= end - start;
        }
      }
      start = end;
      ++end;
      uninitializedIndex = outIndex + 1;
      outIndex = nextIndex;
      if (end > numIndices) {
        break;
      }
    }
    if (uninitializedIndex < outputRows) {
      output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);
    }
    return [output, outputShape];
  }
  var init_SparseSegmentReduction_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentReduction_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sqrt.js
  var sqrtImpl, sqrt2, sqrtConfig;
  var init_Sqrt = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sqrt.js"() {
      init_dist();
      init_unary_impl();
      init_unary_utils();
      sqrtImpl = createSimpleUnaryImpl((xi) => Math.sqrt(xi));
      sqrt2 = unaryKernelFunc(Sqrt, (xi) => Math.sqrt(xi));
      sqrtConfig = {
        kernelName: Sqrt,
        backendName: "cpu",
        kernelFunc: sqrt2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SquaredDifference.js
  var squaredDifferenceImpl, squaredDifference2, squaredDifferenceConfig;
  var init_SquaredDifference = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SquaredDifference.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      squaredDifferenceImpl = createSimpleBinaryKernelImpl((a, b) => {
        const diff = a - b;
        return diff * diff;
      });
      squaredDifference2 = binaryKernelFunc(SquaredDifference, squaredDifferenceImpl);
      squaredDifferenceConfig = {
        kernelName: SquaredDifference,
        backendName: "cpu",
        kernelFunc: squaredDifference2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice_impl.js
  function stridedSliceImpl(outShape, xBuf, strides, begin) {
    const outBuf = buffer(outShape, xBuf.dtype);
    for (let i = 0; i < outBuf.size; i++) {
      const loc = outBuf.indexToLoc(i);
      const newLoc = new Array(loc.length);
      for (let j2 = 0; j2 < newLoc.length; j2++) {
        newLoc[j2] = loc[j2] * strides[j2] + begin[j2];
      }
      outBuf.set(xBuf.get(...newLoc), ...loc);
    }
    return outBuf;
  }
  var init_StridedSlice_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams_impl.js
  function stringNGramsImpl(data, dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
    return new StringNGramsOp(separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences).compute(data, dataSplits);
  }
  var StringNGramsOp;
  var init_StringNGrams_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams_impl.js"() {
      init_dist();
      StringNGramsOp = class {
        constructor(separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
          this.separator = util_exports.encodeString(separator);
          this.nGramWidths = nGramWidths;
          this.leftPad = util_exports.encodeString(leftPad);
          this.rightPad = util_exports.encodeString(rightPad2);
          this.padWidth = padWidth;
          this.preserveShort = preserveShortSequences;
        }
        getPadWidth(nGramWidth) {
          return Math.min(this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);
        }
        getNumNGrams(length, nGramWidth) {
          const padWidth = this.getPadWidth(nGramWidth);
          return Math.max(0, length + 2 * padWidth - nGramWidth + 1);
        }
        createNGrams(data, splitIndex, output, outputStartIndex, numNGrams, nGramWidth) {
          for (let nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {
            const padWidth = this.getPadWidth(nGramWidth);
            const leftPadding = Math.max(0, padWidth - nGramIndex);
            const rightPadding = Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));
            const numTokens = nGramWidth - (leftPadding + rightPadding);
            const dataStartIndex = splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);
            let nGramSize = 0;
            nGramSize += leftPadding * this.leftPad.length;
            for (let n = 0; n < numTokens; ++n) {
              nGramSize += data[dataStartIndex + n].length;
            }
            nGramSize += rightPadding * this.rightPad.length;
            const numSeparators = leftPadding + rightPadding + numTokens - 1;
            nGramSize += numSeparators * this.separator.length;
            output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);
            const nGram = output[outputStartIndex + nGramIndex];
            let nextNGramIndex = 0;
            const appendToNGram = (str) => str.forEach((value) => nGram[nextNGramIndex++] = value);
            for (let n = 0; n < leftPadding; ++n) {
              appendToNGram(this.leftPad);
              appendToNGram(this.separator);
            }
            for (let n = 0; n < numTokens - 1; ++n) {
              appendToNGram(data[dataStartIndex + n]);
              appendToNGram(this.separator);
            }
            if (numTokens > 0) {
              appendToNGram(data[dataStartIndex + numTokens - 1]);
              for (let n = 0; n < rightPadding; ++n) {
                appendToNGram(this.separator);
                appendToNGram(this.rightPad);
              }
            } else {
              for (let n = 0; n < rightPadding - 1; ++n) {
                appendToNGram(this.rightPad);
                appendToNGram(this.separator);
              }
              appendToNGram(this.rightPad);
            }
          }
        }
        // Data and splits together form the definition of the ragged tensor,
        // where data is 1 dimensional and contains the values of the tensor
        // and splits denotes the indices at which each row starts.
        compute(data, splits) {
          const inputDataSize = data.length;
          const splitsSize = splits.length;
          if (splitsSize > 0) {
            let prevSplit = splits[0];
            if (prevSplit !== 0) {
              throw new Error(`First split value must be 0, got ${prevSplit}`);
            }
            for (let i = 1; i < splitsSize; ++i) {
              let validSplits = splits[i] >= prevSplit;
              validSplits = validSplits && splits[i] <= inputDataSize;
              if (!validSplits) {
                throw new Error(`Invalid split value ${splits[i]}, must be in [${prevSplit}, ${inputDataSize}]`);
              }
              prevSplit = splits[i];
            }
            if (prevSplit !== inputDataSize) {
              throw new Error(`Last split value must be data size. Expected ${inputDataSize}, got ${prevSplit}`);
            }
          }
          const numBatchItems = splitsSize - 1;
          const nGramsSplits = util_exports.getArrayFromDType("int32", splitsSize);
          if (inputDataSize === 0 || splitsSize === 0) {
            const empty = new Array(inputDataSize);
            for (let i = 0; i <= numBatchItems; ++i) {
              nGramsSplits[i] = 0;
            }
            return [empty, nGramsSplits];
          }
          nGramsSplits[0] = 0;
          for (let i = 1; i <= numBatchItems; ++i) {
            const length = splits[i] - splits[i - 1];
            let numNGrams = 0;
            this.nGramWidths.forEach((nGramWidth) => {
              numNGrams += this.getNumNGrams(length, nGramWidth);
            });
            if (this.preserveShort && length > 0 && numNGrams === 0) {
              numNGrams = 1;
            }
            nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;
          }
          const nGrams = new Array(nGramsSplits[numBatchItems]);
          for (let i = 0; i < numBatchItems; ++i) {
            const splitIndex = splits[i];
            let outputStartIdx = nGramsSplits[i];
            this.nGramWidths.forEach((nGramWidth) => {
              const length = splits[i + 1] - splits[i];
              const numNGrams = this.getNumNGrams(length, nGramWidth);
              this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
              outputStartIdx += numNGrams;
            });
            if (this.preserveShort && outputStartIdx === nGramsSplits[i]) {
              const dataLength = splits[i + 1] - splits[i];
              if (dataLength === 0) {
                continue;
              }
              const nGramWidth = dataLength + 2 * this.padWidth;
              const numNGrams = 1;
              this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
            }
          }
          return [nGrams, nGramsSplits];
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit_impl.js
  function split3(str, delimiters, skipEmpty, result) {
    if (!str.length) {
      return;
    }
    if (delimiters.length === 0) {
      for (let i = 0; i < str.length; ++i) {
        result.push(str.subarray(i, i + 1));
      }
      return;
    }
    if (delimiters.length === 1) {
      const delimiter = delimiters[0];
      let f = str.indexOf(delimiter);
      while (f !== -1) {
        const token = str.subarray(0, f);
        if (!skipEmpty || token.length !== 0) {
          result.push(token);
        }
        str = str.subarray(f + 1);
        f = str.indexOf(delimiter);
      }
      if (!skipEmpty || str.length !== 0) {
        result.push(str);
      }
      return;
    }
    let tokenStart = 0;
    for (let i = 0; i < str.length + 1; i++) {
      if (i === str.length || delimiters.indexOf(str[i]) !== -1) {
        const token = str.subarray(tokenStart, i);
        if (!skipEmpty || token.length !== 0) {
          result.push(token);
        }
        tokenStart = i + 1;
      }
    }
  }
  function stringSplitImpl(input, delimiter, skipEmpty) {
    const batchSize = input.length;
    const tokens = [];
    let outputSize = 0;
    let maxNumEntries = 0;
    const numIndices = new Array(batchSize);
    for (let i = 0; i < batchSize; ++i) {
      const prevTokensLength = tokens.length;
      split3(input[i], delimiter, skipEmpty, tokens);
      const nEntries = tokens.length - prevTokensLength;
      numIndices[i] = nEntries;
      outputSize += nEntries;
      maxNumEntries = Math.max(maxNumEntries, nEntries);
    }
    const indices = util_exports.getArrayFromDType("int32", outputSize * 2);
    const values = new Array(outputSize);
    const shape = [batchSize, maxNumEntries];
    let c = 0;
    for (let i = 0; i < batchSize; ++i) {
      for (let j2 = 0; j2 < numIndices[i]; ++j2) {
        indices[c * 2] = i;
        indices[c * 2 + 1] = j2;
        values[c] = tokens[c];
        ++c;
      }
    }
    return [indices, values, shape];
  }
  var init_StringSplit_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast_impl.js
  function stringToHashBucketFastImpl(input, numBuckets) {
    const output = util_exports.getArrayFromDType("int32", input.length);
    for (let i = 0; i < input.length; ++i) {
      output[i] = util_exports.fingerPrint64(input[i]).modulo(numBuckets).getLowBitsUnsigned();
    }
    return output;
  }
  var init_StringToHashBucketFast_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sub.js
  var subImpl, subComplexImpl, sub2, subConfig;
  var init_Sub = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sub.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      subImpl = createSimpleBinaryKernelImpl((aValue, bValue) => aValue - bValue);
      subComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
        return { real: aReal - bReal, imag: aImag - bImag };
      });
      sub2 = binaryKernelFunc(Sub, subImpl, subComplexImpl);
      subConfig = {
        kernelName: Sub,
        backendName: "cpu",
        kernelFunc: sub2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tile_impl.js
  function tileImpl(xBuf, reps) {
    const newShape = new Array(xBuf.rank);
    for (let i = 0; i < newShape.length; i++) {
      newShape[i] = xBuf.shape[i] * reps[i];
    }
    const result = buffer(newShape, xBuf.dtype);
    for (let i = 0; i < result.values.length; ++i) {
      const newLoc = result.indexToLoc(i);
      const originalLoc = new Array(xBuf.rank);
      for (let j2 = 0; j2 < originalLoc.length; j2++) {
        originalLoc[j2] = newLoc[j2] % xBuf.shape[j2];
      }
      const originalIndex = xBuf.locToIndex(originalLoc);
      result.values[i] = xBuf.values[originalIndex];
    }
    return result;
  }
  var init_Tile_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tile_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/TopK_impl.js
  function select(array, k3, left = 0, right = array.length - 1) {
    while (right > left) {
      if (right - left > 600) {
        const n = right - left + 1;
        const i2 = k3 - left + 1;
        const z2 = Math.log(n);
        const s = 0.5 * Math.exp(2 * z2 / 3);
        const sd = 0.5 * Math.sqrt(z2 * s * (n - s) / n) * Math.sign(i2 - n / 2);
        const newLeft = Math.max(left, Math.floor(k3 - i2 * s / n + sd));
        const newRight = Math.min(right, Math.floor(k3 + (n - i2) * s / n + sd));
        select(array, k3, newLeft, newRight);
      }
      const t2 = array[k3];
      let i = left;
      let j2 = right;
      util_exports.swap(array, left, k3);
      if (comparePair(array[right], t2) > 0) {
        util_exports.swap(array, left, right);
      }
      while (i < j2) {
        util_exports.swap(array, i, j2);
        i++;
        j2--;
        while (comparePair(array[i], t2) < 0) {
          i = i + 1;
        }
        while (comparePair(array[j2], t2) > 0) {
          j2 = j2 - 1;
        }
      }
      if (comparePair(array[left], t2) === 0) {
        util_exports.swap(array, left, j2);
      } else {
        j2 = j2 + 1;
        util_exports.swap(array, j2, right);
      }
      if (j2 <= k3) {
        left = j2 + 1;
      }
      if (k3 <= j2) {
        right = j2 - 1;
      }
    }
  }
  function topKImpl(x, xShape, xDtype, k3, sorted) {
    const lastDim = xShape[xShape.length - 1];
    const [batch, size] = [x.length / lastDim, lastDim];
    const allTopKVals = util_exports.getTypedArrayFromDType(xDtype, batch * k3);
    const allTopKIndices = util_exports.getTypedArrayFromDType("int32", batch * k3);
    for (let b = 0; b < batch; b++) {
      const offset = b * size;
      const vals = x.subarray(offset, offset + size);
      let valAndInd = new Array(vals.length);
      vals.forEach((value, index) => valAndInd[index] = { value, index });
      if (k3 < valAndInd.length) {
        select(valAndInd, k3);
        valAndInd = valAndInd.slice(0, k3);
      }
      if (sorted) {
        valAndInd.sort(comparePair);
      }
      const outOffset = b * k3;
      const topKVals = allTopKVals.subarray(outOffset, outOffset + k3);
      const topKIndices = allTopKIndices.subarray(outOffset, outOffset + k3);
      for (let i = 0; i < k3; i++) {
        topKVals[i] = valAndInd[i].value;
        topKIndices[i] = valAndInd[i].index;
      }
    }
    const outputShape = xShape.slice();
    outputShape[outputShape.length - 1] = k3;
    return [
      buffer(outputShape, xDtype, allTopKVals),
      buffer(outputShape, "int32", allTopKIndices)
    ];
  }
  var comparePair;
  var init_TopK_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/TopK_impl.js"() {
      init_dist();
      comparePair = (a, b) => {
        const valueDiff = b.value - a.value;
        return valueDiff === 0 ? a.index - b.index : valueDiff;
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unique_impl.js
  function uniqueImpl(values, axis, shape, dtype) {
    const $axis = util_exports.parseAxisParam(axis, shape)[0];
    const newShape = [1, shape[0], 1];
    for (let i = 0; i < $axis; i++) {
      newShape[0] *= shape[i];
    }
    newShape[1] = shape[$axis];
    for (let i = $axis + 1; i < shape.length; i++) {
      newShape[2] *= shape[i];
    }
    const uniqueElements = {};
    const indices = new Int32Array(shape[$axis]);
    const inputBuffer = new TensorBuffer(newShape, dtype, values);
    const uniqueIndices = [];
    const is1DTensor = newShape[0] === 1 && newShape[2] === 1;
    for (let i = 0; i < shape[$axis]; i++) {
      let element;
      if (is1DTensor) {
        element = values[i].toString();
      } else {
        const axisValues = [];
        for (let m = 0; m < newShape[0]; m++) {
          for (let n = 0; n < newShape[2]; n++) {
            axisValues.push(inputBuffer.get(m, i, n));
          }
        }
        element = axisValues.join(",");
      }
      if (uniqueElements[element] !== void 0) {
        indices[i] = uniqueElements[element];
      } else {
        const uniqueIndex = Object.keys(uniqueElements).length;
        uniqueElements[element] = uniqueIndex;
        indices[i] = uniqueIndex;
        uniqueIndices.push(i);
      }
    }
    const outputTmpShape = newShape.slice();
    outputTmpShape[1] = Object.keys(uniqueElements).length;
    const outputBuffer = new TensorBuffer(outputTmpShape, dtype);
    uniqueIndices.forEach((uniqueElementIndex, i) => {
      for (let m = 0; m < newShape[0]; m++) {
        for (let n = 0; n < newShape[2]; n++) {
          outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);
        }
      }
    });
    const outputShape = shape.slice();
    outputShape[$axis] = outputTmpShape[1];
    return {
      outputValues: outputBuffer.values,
      outputShape,
      indices
    };
  }
  var init_Unique_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unique_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/base.js
  var init_base2 = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/base.js"() {
      init_dist();
      init_backend_cpu();
      registerBackend(
        "cpu",
        () => new MathBackendCPU(),
        1
        /* priority */
      );
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Elu.js
  var elu2, eluConfig;
  var init_Elu = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Elu.js"() {
      init_dist();
      init_unary_utils();
      elu2 = unaryKernelFunc(Elu, (xi) => xi >= 0 ? xi : Math.exp(xi) - 1);
      eluConfig = {
        kernelName: Elu,
        backendName: "cpu",
        kernelFunc: elu2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LeakyRelu.js
  function leakyRelu2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { alpha } = attrs;
    assertNotComplex([x], "leakyRelu");
    const xSize = util_exports.sizeFromShape(x.shape);
    const xVals = backend.data.get(x.dataId).values;
    const outVals = util_exports.getTypedArrayFromDType("float32", xSize);
    for (let i = 0; i < xVals.length; i++) {
      outVals[i] = xVals[i] < 0 ? alpha * xVals[i] : xVals[i];
    }
    return backend.makeTensorInfo(x.shape, "float32", outVals);
  }
  var leakyReluConfig;
  var init_LeakyRelu = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LeakyRelu.js"() {
      init_dist();
      init_cpu_util();
      leakyReluConfig = {
        kernelName: LeakyRelu,
        backendName: "cpu",
        kernelFunc: leakyRelu2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Prelu.js
  function prelu2(args) {
    const { inputs, backend } = args;
    const { x, alpha } = inputs;
    assertNotComplex([x, alpha], "prelu");
    const aVals = backend.data.get(x.dataId).values;
    const bVals = backend.data.get(alpha.dataId).values;
    const [resultData, resultShape] = preluImpl(x.shape, alpha.shape, aVals, bVals, "float32");
    return backend.makeTensorInfo(resultShape, "float32", resultData);
  }
  var preluImpl, preluConfig;
  var init_Prelu = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Prelu.js"() {
      init_dist();
      init_cpu_util();
      init_binary_impl();
      preluImpl = createSimpleBinaryKernelImpl((xValue, aValue) => xValue < 0 ? aValue * xValue : xValue);
      preluConfig = {
        kernelName: Prelu,
        backendName: "cpu",
        kernelFunc: prelu2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Relu.js
  var relu2, reluConfig;
  var init_Relu = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Relu.js"() {
      init_dist();
      init_unary_utils();
      relu2 = unaryKernelFunc(Relu, (xi) => Math.max(0, xi));
      reluConfig = {
        kernelName: Relu,
        backendName: "cpu",
        kernelFunc: relu2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Relu6.js
  var relu62, relu6Config;
  var init_Relu6 = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Relu6.js"() {
      init_dist();
      init_unary_utils();
      relu62 = unaryKernelFunc(Relu6, (xi) => Math.min(Math.max(0, xi), 6));
      relu6Config = {
        kernelName: Relu6,
        backendName: "cpu",
        kernelFunc: relu62
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/fused_utils.js
  function applyActivation2(backend, x, activation, preluActivationWeights, leakyreluAlpha) {
    if (activation === "linear") {
      return identity({ inputs: { x }, backend });
    } else if (activation === "relu") {
      return relu2({ inputs: { x }, backend });
    } else if (activation === "elu") {
      return elu2({ inputs: { x }, backend });
    } else if (activation === "relu6") {
      return relu62({ inputs: { x }, backend });
    } else if (activation === "prelu") {
      return prelu2({ inputs: { x, alpha: preluActivationWeights }, backend });
    } else if (activation === "leakyrelu") {
      return leakyRelu2({ inputs: { x }, backend, attrs: { alpha: leakyreluAlpha } });
    } else if (activation === "sigmoid") {
      return sigmoid2({ inputs: { x }, backend });
    }
    throw new Error(`Activation ${activation} has not been implemented for the CPU backend.`);
  }
  var init_fused_utils = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/fused_utils.js"() {
      init_Elu();
      init_Identity();
      init_LeakyRelu();
      init_Prelu();
      init_Relu();
      init_Relu6();
      init_Sigmoid();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Reshape.js
  function reshape2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { shape } = attrs;
    const xSize = util_exports.sizeFromShape(x.shape);
    const $shape = util_exports.inferFromImplicitShape(shape, xSize);
    const $xSize = util_exports.sizeFromShape($shape);
    util_exports.assert(xSize === $xSize, () => `The new shape (${$shape}) has ${$xSize} elements and the old shape (${x.shape}) has ${xSize} elements. The new shape and old shape must have the same number of elements.`);
    backend.incRef(x.dataId);
    const xData = backend.data.get(x.dataId);
    if (xData.complexTensorInfos != null) {
      const real3 = xData.complexTensorInfos.real;
      const imag3 = xData.complexTensorInfos.imag;
      real3.shape = $shape;
      imag3.shape = $shape;
    }
    return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
  }
  var reshapeConfig;
  var init_Reshape = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Reshape.js"() {
      init_dist();
      reshapeConfig = {
        kernelName: Reshape,
        backendName: "cpu",
        kernelFunc: reshape2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BatchMatMul.js
  function batchMatMul(args) {
    const { inputs, backend, attrs } = args;
    const { a, b } = inputs;
    const { transposeA, transposeB } = attrs;
    assertNotComplex([a, b], "matMul");
    const aRank = a.shape.length;
    const bRank = b.shape.length;
    const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
    const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
    const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
    const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
    const outerDimsA = a.shape.slice(0, -2);
    const outerDimsB = b.shape.slice(0, -2);
    const batchDimA = util_exports.sizeFromShape(outerDimsA);
    const batchDimB = util_exports.sizeFromShape(outerDimsB);
    const outShapeOuterDims = broadcast_util_exports.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));
    const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
    util_exports.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${a.shape} and ${b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
    const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];
    const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];
    const a3d = reshape2({ inputs: { x: a }, backend, attrs: { shape: a3dShape } });
    const b3d = reshape2({ inputs: { x: b }, backend, attrs: { shape: b3dShape } });
    const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];
    const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];
    const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];
    const batchDim = Math.max(batchDimA, batchDimB);
    const a3dValues = backend.data.get(a3d.dataId).values;
    const b3dValues = backend.data.get(b3d.dataId).values;
    const a3dStrides = util_exports.computeStrides(a3d.shape);
    const b3dStrides = util_exports.computeStrides(b3d.shape);
    const [aBatch, aOuterStep, aInnerStep] = transposeA ? [a3dStrides[0], 1, a3dStrides[1]] : [a3dStrides[0], a3dStrides[1], 1];
    const [bInnerStep, bOuterStep, bBatch] = transposeB ? [1, b3dStrides[1], b3dStrides[0]] : [b3dStrides[1], 1, b3dStrides[0]];
    const size = leftDim * rightDim;
    const result = buffer([batchDim, leftDim, rightDim], a3d.dtype);
    const resVals = result.values;
    const blockSize = backend.blockSize;
    for (let bi = 0; bi < batchDim; bi++) {
      const batchIndexA = bi % batchDimA;
      const batchIndexB = bi % batchDimB;
      for (let i0 = 0; i0 < leftDim; i0 += blockSize) {
        const iBlock = Math.min(i0 + blockSize, leftDim);
        for (let j0 = 0; j0 < rightDim; j0 += blockSize) {
          const jBlock = Math.min(j0 + blockSize, rightDim);
          for (let k02 = 0; k02 < sharedDim; k02 += blockSize) {
            const kBlock = Math.min(k02 + blockSize, sharedDim);
            for (let i = i0; i < iBlock; i++) {
              for (let j2 = j0; j2 < jBlock; j2++) {
                let sum4 = 0;
                for (let k3 = k02; k3 < kBlock; k3++) {
                  const aVal = (
                    // tslint:disable-next-line: max-line-length
                    a3dValues[batchIndexA * aBatch + i * aOuterStep + k3 * aInnerStep]
                  );
                  const bVal = (
                    // tslint:disable-next-line: max-line-length
                    b3dValues[k3 * bInnerStep + j2 * bOuterStep + batchIndexB * bBatch]
                  );
                  sum4 += aVal * bVal;
                }
                resVals[bi * size + (i * rightDim + j2)] += sum4;
              }
            }
          }
        }
      }
    }
    backend.disposeIntermediateTensorInfo(a3d);
    backend.disposeIntermediateTensorInfo(b3d);
    return backend.makeTensorInfo(outShape, result.dtype, result.values);
  }
  var batchMatMulConfig;
  var init_BatchMatMul = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BatchMatMul.js"() {
      init_dist();
      init_cpu_util();
      init_Reshape();
      batchMatMulConfig = {
        kernelName: BatchMatMul,
        backendName: "cpu",
        kernelFunc: batchMatMul
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/_FusedMatMul.js
  function _fusedMatMul(args) {
    const { inputs, backend, attrs } = args;
    const { a, b, bias, preluActivationWeights } = inputs;
    const { transposeA, transposeB, activation, leakyreluAlpha } = attrs;
    let current;
    let addRes;
    let activationRes;
    const intermediates = [];
    const matMulRes = batchMatMul({ inputs: { a, b }, attrs: { transposeA, transposeB }, backend });
    current = matMulRes;
    if (bias) {
      addRes = add3({ inputs: { a: current, b: bias }, backend });
      intermediates.push(current);
      current = addRes;
    }
    if (activation) {
      activationRes = applyActivation2(backend, current, activation, preluActivationWeights, leakyreluAlpha);
      intermediates.push(current);
      current = activationRes;
    }
    for (const i of intermediates) {
      backend.disposeIntermediateTensorInfo(i);
    }
    return current;
  }
  var _fusedMatMulConfig;
  var init_FusedMatMul = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/_FusedMatMul.js"() {
      init_dist();
      init_fused_utils();
      init_Add();
      init_BatchMatMul();
      _fusedMatMulConfig = {
        kernelName: _FusedMatMul,
        backendName: "cpu",
        kernelFunc: _fusedMatMul
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Acos.js
  var acos2, acosConfig;
  var init_Acos = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Acos.js"() {
      init_dist();
      init_unary_utils();
      acos2 = unaryKernelFunc(Acos, (xi) => Math.acos(xi));
      acosConfig = {
        kernelName: Acos,
        backendName: "cpu",
        kernelFunc: acos2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Acosh.js
  var acosh2, acoshConfig;
  var init_Acosh = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Acosh.js"() {
      init_dist();
      init_unary_utils();
      acosh2 = unaryKernelFunc(Acosh, (xi) => Math.acosh(xi));
      acoshConfig = {
        kernelName: Acosh,
        backendName: "cpu",
        kernelFunc: acosh2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AddN.js
  function addN2(args) {
    const { inputs, backend } = args;
    const tensors = inputs;
    assertNotComplex(inputs, "addN");
    const vals = tensors.map((t2) => backend.data.get(t2.dataId).values);
    const outBuf = buffer(tensors[0].shape, tensors[0].dtype);
    const outVals = outBuf.values;
    for (let i = 0; i < tensors.length; i++) {
      const currVals = vals[i];
      for (let j2 = 0; j2 < outVals.length; j2++) {
        outVals[j2] += currVals[j2];
      }
    }
    return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
  }
  var addNConfig;
  var init_AddN = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AddN.js"() {
      init_dist();
      init_cpu_util();
      addNConfig = {
        kernelName: AddN,
        backendName: "cpu",
        kernelFunc: addN2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/All.js
  function all2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    assertNotComplex(x, "all");
    const origAxes = util_exports.parseAxisParam(axis, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
    let $x = x;
    if (permutedAxes != null) {
      $x = transpose2({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
      axes = backend_util_exports.getInnerMostAxes(axes.length, x.shape.length);
    }
    backend_util_exports.assertAxesAreInnerMostDims("all", axes, $x.shape.length);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const vals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), $x.dtype);
    const aVals = backend.data.get($x.dataId).values;
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let all3 = aVals[offset];
      for (let j2 = 0; j2 < reduceSize; ++j2) {
        const value = aVals[offset + j2];
        all3 = all3 && value;
      }
      vals[i] = all3;
    }
    if (permutedAxes != null) {
      backend.disposeIntermediateTensorInfo($x);
    }
    const result = backend.makeTensorInfo(outShape, $x.dtype, vals);
    if (keepDims) {
      const expandedShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
      const reshapedResult = reshape2({ inputs: { x: result }, backend, attrs: { shape: expandedShape } });
      backend.disposeIntermediateTensorInfo(result);
      return reshapedResult;
    }
    return result;
  }
  var allConfig;
  var init_All = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/All.js"() {
      init_dist();
      init_cpu_util();
      init_Reshape();
      init_Transpose();
      allConfig = {
        kernelName: All,
        backendName: "cpu",
        kernelFunc: all2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Any.js
  function any2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    assertNotComplex(x, "any");
    const origAxes = util_exports.parseAxisParam(axis, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
    let $x = x;
    if (permutedAxes != null) {
      $x = transpose2({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
      axes = backend_util_exports.getInnerMostAxes(axes.length, x.shape.length);
    }
    backend_util_exports.assertAxesAreInnerMostDims("any", axes, $x.shape.length);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const vals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), $x.dtype);
    const aVals = backend.data.get($x.dataId).values;
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let anyVal = aVals[offset];
      for (let j2 = 0; j2 < reduceSize; ++j2) {
        const value = aVals[offset + j2];
        anyVal = anyVal || value;
      }
      vals[i] = anyVal;
    }
    if (permutedAxes != null) {
      backend.disposeIntermediateTensorInfo($x);
    }
    const result = backend.makeTensorInfo(outShape, $x.dtype, vals);
    if (keepDims) {
      const expandedShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
      const reshapedResult = reshape2({ inputs: { x: result }, backend, attrs: { shape: expandedShape } });
      backend.disposeIntermediateTensorInfo(result);
      return reshapedResult;
    }
    return result;
  }
  var anyConfig;
  var init_Any = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Any.js"() {
      init_dist();
      init_cpu_util();
      init_Reshape();
      init_Transpose();
      anyConfig = {
        kernelName: Any,
        backendName: "cpu",
        kernelFunc: any2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ArgMax.js
  function argMax2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { axis } = attrs;
    assertNotComplex(x, "argMax");
    let axes = util_exports.parseAxisParam(axis, x.shape);
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
    let $x = x;
    const intermediateTensorInfos = [];
    if (permutedAxes != null) {
      $x = transpose2({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
      intermediateTensorInfos.push($x);
      axes = backend_util_exports.getInnerMostAxes(axes.length, $x.shape.length);
    }
    axes = [axes[0]];
    backend_util_exports.assertAxesAreInnerMostDims("argMax", axes, $x.shape.length);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
    const outSize = util_exports.sizeFromShape(outShape);
    const vals = util_exports.makeZerosTypedArray(outSize, "int32");
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const aVals = backend.data.get($x.dataId).values;
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let max3 = aVals[offset];
      let maxIndex = 0;
      for (let j2 = 0; j2 < reduceSize; ++j2) {
        const value = aVals[offset + j2];
        if (value > max3) {
          max3 = value;
          maxIndex = j2;
        }
      }
      vals[i] = maxIndex;
    }
    intermediateTensorInfos.forEach((t2) => backend.disposeIntermediateTensorInfo(t2));
    return backend.makeTensorInfo(outShape, "int32", vals);
  }
  var argMaxConfig;
  var init_ArgMax = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ArgMax.js"() {
      init_dist();
      init_cpu_util();
      init_Transpose();
      argMaxConfig = {
        kernelName: ArgMax,
        backendName: "cpu",
        kernelFunc: argMax2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ArgMin.js
  function argMin2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { axis } = attrs;
    assertNotComplex(x, "argMin");
    let axes = util_exports.parseAxisParam(axis, x.shape);
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
    let $x = x;
    const intermediateTensorInfos = [];
    if (permutedAxes != null) {
      $x = transpose2({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
      intermediateTensorInfos.push($x);
      axes = backend_util_exports.getInnerMostAxes(axes.length, $x.shape.length);
    }
    axes = [axes[0]];
    backend_util_exports.assertAxesAreInnerMostDims("argMin", axes, $x.shape.length);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
    const outSize = util_exports.sizeFromShape(outShape);
    const vals = util_exports.makeZerosTypedArray(outSize, "int32");
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const aVals = backend.data.get($x.dataId).values;
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let min3 = aVals[offset];
      let minIndex = 0;
      for (let j2 = 0; j2 < reduceSize; ++j2) {
        const value = aVals[offset + j2];
        if (value < min3) {
          min3 = value;
          minIndex = j2;
        }
      }
      vals[i] = minIndex;
    }
    intermediateTensorInfos.forEach((t2) => backend.disposeIntermediateTensorInfo(t2));
    return backend.makeTensorInfo(outShape, "int32", vals);
  }
  var argMinConfig;
  var init_ArgMin = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ArgMin.js"() {
      init_dist();
      init_cpu_util();
      init_Transpose();
      argMinConfig = {
        kernelName: ArgMin,
        backendName: "cpu",
        kernelFunc: argMin2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Asin.js
  var asin2, asinConfig;
  var init_Asin = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Asin.js"() {
      init_dist();
      init_unary_utils();
      asin2 = unaryKernelFunc(Asin, (xi) => Math.asin(xi));
      asinConfig = {
        kernelName: Asin,
        backendName: "cpu",
        kernelFunc: asin2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Asinh.js
  var asinh2, asinhConfig;
  var init_Asinh = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Asinh.js"() {
      init_dist();
      init_unary_utils();
      asinh2 = unaryKernelFunc(Asinh, (xi) => Math.asinh(xi));
      asinhConfig = {
        kernelName: Asinh,
        backendName: "cpu",
        kernelFunc: asinh2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Atan.js
  var atan3, atanConfig;
  var init_Atan = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Atan.js"() {
      init_dist();
      init_unary_utils();
      atan3 = unaryKernelFunc(Atan, (xi) => Math.atan(xi));
      atanConfig = {
        kernelName: Atan,
        backendName: "cpu",
        kernelFunc: atan3
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Atan2.js
  var atan2Impl, atan22, atan2Config;
  var init_Atan2 = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Atan2.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      atan2Impl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.atan2(aValue, bValue));
      atan22 = binaryKernelFunc(Atan2, atan2Impl);
      atan2Config = {
        kernelName: Atan2,
        backendName: "cpu",
        kernelFunc: atan22
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Atanh.js
  var atanh2, atanhConfig;
  var init_Atanh = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Atanh.js"() {
      init_dist();
      init_unary_utils();
      atanh2 = unaryKernelFunc(Atanh, (xi) => Math.atanh(xi));
      atanhConfig = {
        kernelName: Atanh,
        backendName: "cpu",
        kernelFunc: atanh2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/pool_utils.js
  function pool2(xValues, xShape, dtype, strides, convInfo, poolType) {
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    const initialValue = poolType === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY;
    const output = buffer(convInfo.outShape, dtype);
    const outputVals = output.values;
    const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];
    const outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];
    const outputColStrides = convInfo.outShape[3];
    for (let b = 0; b < convInfo.batchSize; ++b) {
      const outputBatchOffset = b * outputBatchStrides;
      const inputBatchOffset = b * strides[0];
      for (let d = 0; d < convInfo.inChannels; ++d) {
        for (let yR = 0; yR < convInfo.outHeight; ++yR) {
          const xRCorner = yR * strideHeight - padTop;
          const xRMin = Math.max(0, xRCorner);
          const xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);
          const outputRowOffset = outputBatchOffset + yR * outputRowStrides;
          for (let yC = 0; yC < convInfo.outWidth; ++yC) {
            const xCCorner = yC * strideWidth - padLeft;
            const xCMin = Math.max(0, xCCorner);
            const xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);
            let minMaxValue = initialValue;
            let avgValue = 0;
            let count = 0;
            for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {
              const xROffset = inputBatchOffset + xR * strides[1];
              for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {
                const xCOffset = xROffset + xC * strides[2];
                const pixel = xValues[xCOffset + d];
                if (poolType === "max" && pixel > minMaxValue) {
                  minMaxValue = pixel;
                } else if (poolType === "avg") {
                  avgValue += pixel;
                  count++;
                }
              }
              if (isNaN(minMaxValue)) {
                break;
              }
            }
            const outputOffset = outputRowOffset + yC * outputColStrides + d;
            outputVals[outputOffset] = poolType === "avg" ? avgValue / count : minMaxValue;
          }
        }
      }
    }
    return output;
  }
  function maxPoolPositions(xValues, xShape, dtype, convInfo, flattenPositions = false, includeBatchInIndex = false) {
    const maxPositions = buffer(convInfo.outShape, "int32");
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    const xBuf = buffer(xShape, dtype, xValues);
    for (let b = 0; b < convInfo.batchSize; ++b) {
      for (let d = 0; d < convInfo.inChannels; ++d) {
        for (let yR = 0; yR < convInfo.outHeight; ++yR) {
          const xRCorner = yR * strideHeight - padTop;
          let xRMin = xRCorner;
          while (xRMin < 0) {
            xRMin += dilationHeight;
          }
          const xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);
          for (let yC = 0; yC < convInfo.outWidth; ++yC) {
            const xCCorner = yC * strideWidth - padLeft;
            let xCMin = xCCorner;
            while (xCMin < 0) {
              xCMin += dilationWidth;
            }
            const xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);
            let maxValue = Number.NEGATIVE_INFINITY;
            let maxPosition = -1;
            for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {
              const wR = xR - xRCorner;
              for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {
                const wC = xC - xCCorner;
                const pixel = xBuf.get(b, xR, xC, d);
                if (pixel > maxValue) {
                  maxValue = pixel;
                  if (flattenPositions) {
                    maxPosition = includeBatchInIndex ? ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) * convInfo.inChannels + d : (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;
                  } else {
                    maxPosition = wR * effectiveFilterWidth + wC;
                  }
                }
              }
            }
            maxPositions.set(maxPosition, b, yR, yC, d);
          }
        }
      }
    }
    return maxPositions;
  }
  function pool3d(xValues, xShape, dtype, strides, convInfo, poolType) {
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationDepth = convInfo.dilationDepth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterDepth = convInfo.effectiveFilterDepth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padFront = convInfo.padInfo.front;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    const initialValue = poolType === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY;
    const output = buffer(convInfo.outShape, dtype);
    const outputVals = output.values;
    const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];
    const outputDepthStrides = convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];
    const outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];
    const outputColStrides = convInfo.outShape[4];
    for (let batch = 0; batch < convInfo.batchSize; ++batch) {
      const outputBatchOffset = batch * outputBatchStrides;
      const inputBatchOffset = batch * strides[0];
      for (let channel = 0; channel < convInfo.inChannels; ++channel) {
        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {
          const xDepthCorner = yDepth * strideDepth - padFront;
          let xDepthMin = xDepthCorner;
          while (xDepthMin < 0) {
            xDepthMin += dilationDepth;
          }
          const xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);
          const outputDepthOffset = outputBatchOffset + yDepth * outputDepthStrides;
          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {
            const xRowCorner = yRow * strideHeight - padTop;
            let xRowMin = xRowCorner;
            while (xRowMin < 0) {
              xRowMin += dilationHeight;
            }
            const xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);
            const outputRowOffset = outputDepthOffset + yRow * outputRowStrides;
            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {
              const xColCorner = yCol * strideWidth - padLeft;
              let xColMin = xColCorner;
              while (xColMin < 0) {
                xColMin += dilationWidth;
              }
              const xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);
              const outputColOffset = outputRowOffset + yCol * outputColStrides;
              let minMaxValue = initialValue;
              let avgValue = 0;
              let count = 0;
              for (let xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {
                const xDepthOffset = inputBatchOffset + xDepth * strides[1];
                for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {
                  const xRowOffset = xDepthOffset + xRow * strides[2];
                  for (let xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {
                    const xColOffset = xRowOffset + xCol * strides[3];
                    const pixel = xValues[xColOffset + channel];
                    if (poolType === "max" && pixel > minMaxValue) {
                      minMaxValue = pixel;
                    } else if (poolType === "avg") {
                      avgValue += pixel;
                      count++;
                    }
                    if (isNaN(minMaxValue)) {
                      break;
                    }
                  }
                  if (isNaN(minMaxValue)) {
                    break;
                  }
                }
                if (isNaN(minMaxValue)) {
                  break;
                }
              }
              const outputOffset = outputColOffset + channel;
              outputVals[outputOffset] = poolType === "avg" ? avgValue / Math.max(count, 1) : minMaxValue;
            }
          }
        }
      }
    }
    return output;
  }
  function maxPool3dPositions(xBuf, convInfo) {
    const maxPositions = buffer(convInfo.outShape, "int32");
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationDepth = convInfo.dilationDepth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterDepth = convInfo.effectiveFilterDepth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padFront = convInfo.padInfo.front;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    for (let batch = 0; batch < convInfo.batchSize; ++batch) {
      for (let channel = 0; channel < convInfo.inChannels; ++channel) {
        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {
          const xDepthCorner = yDepth * strideDepth - padFront;
          let xDepthMin = xDepthCorner;
          while (xDepthMin < 0) {
            xDepthMin += dilationDepth;
          }
          const xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);
          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {
            const xRowCorner = yRow * strideHeight - padTop;
            let xRowMin = xRowCorner;
            while (xRowMin < 0) {
              xRowMin += dilationHeight;
            }
            const xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);
            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {
              const xColCorner = yCol * strideWidth - padLeft;
              let xColMin = xColCorner;
              while (xColMin < 0) {
                xColMin += dilationWidth;
              }
              const xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);
              let maxValue = Number.NEGATIVE_INFINITY;
              let maxPosition = -1;
              for (let xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {
                const wDepth = xDepth - xDepthCorner;
                for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {
                  const wRow = xRow - xRowCorner;
                  for (let xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {
                    const wCol = xCol - xColCorner;
                    const pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);
                    if (pixel >= maxValue) {
                      maxValue = pixel;
                      maxPosition = wDepth * effectiveFilterHeight * effectiveFilterWidth + wRow * effectiveFilterHeight + wCol;
                    }
                  }
                }
              }
              maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);
            }
          }
        }
      }
    }
    return maxPositions;
  }
  var init_pool_utils = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/pool_utils.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool.js
  function avgPool2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    assertNotComplex(x, "avgPool");
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    const dilations = 1;
    util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
    let res;
    if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports.arraysEqual(convInfo.inShape, convInfo.outShape)) {
      res = identity({ inputs: { x }, backend });
    } else {
      const xValues = backend.data.get(x.dataId).values;
      const strides2 = util_exports.computeStrides(x.shape);
      const buffer2 = pool2(xValues, x.shape, x.dtype, strides2, convInfo, "avg");
      res = backend.makeTensorInfo(convInfo.outShape, x.dtype, buffer2.values);
    }
    return res;
  }
  var avgPoolConfig;
  var init_AvgPool = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool.js"() {
      init_dist();
      init_cpu_util();
      init_pool_utils();
      init_Identity();
      avgPoolConfig = {
        kernelName: AvgPool,
        backendName: "cpu",
        kernelFunc: avgPool2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3D.js
  function avgPool3D(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat } = attrs;
    assertNotComplex(x, "avgPool3d");
    const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode, dataFormat);
    const xValues = backend.data.get(x.dataId).values;
    const outBuf = pool3d(xValues, x.shape, x.dtype, util_exports.computeStrides(x.shape), convInfo, "avg");
    return backend.makeTensorInfo(outBuf.shape, "float32", outBuf.values);
  }
  var avgPool3DConfig;
  var init_AvgPool3D = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3D.js"() {
      init_dist();
      init_cpu_util();
      init_pool_utils();
      avgPool3DConfig = {
        kernelName: AvgPool3D,
        backendName: "cpu",
        kernelFunc: avgPool3D
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3DGrad.js
  function avgPool3DGrad(args) {
    const { inputs, backend, attrs } = args;
    const { dy, input } = inputs;
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    assertNotComplex([dy, input], "avgPool3DGrad");
    const convInfo = backend_util_exports.computePool3DInfo(input.shape, filterSize, strides, 1, pad2, dimRoundingMode);
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const filterDepth = convInfo.filterDepth;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const dilationDepth = convInfo.dilationDepth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterDepth = convInfo.effectiveFilterDepth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
    const dx = buffer(input.shape, "float32");
    const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);
    const dyBuf = backend.bufferSync(dy);
    for (let batch = 0; batch < convInfo.batchSize; ++batch) {
      for (let channel = 0; channel < convInfo.inChannels; ++channel) {
        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {
          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {
            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {
              const dyDepthCorner = dxDepth - padFront;
              const dyRowCorner = dxRow - padTop;
              const dyColCorner = dxCol - padLeft;
              let dotProd = 0;
              for (let wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {
                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;
                if (dyDepth < 0 || dyDepth >= convInfo.outDepth || Math.floor(dyDepth) !== dyDepth) {
                  continue;
                }
                for (let wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {
                  const dyRow = (dyRowCorner + wRow) / strideHeight;
                  if (dyRow < 0 || dyRow >= convInfo.outHeight || Math.floor(dyRow) !== dyRow) {
                    continue;
                  }
                  for (let wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {
                    const dyCol = (dyColCorner + wCol) / strideWidth;
                    if (dyCol < 0 || dyCol >= convInfo.outWidth || Math.floor(dyCol) !== dyCol) {
                      continue;
                    }
                    const pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                    dotProd += pixel;
                  }
                }
              }
              dx.set(dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol, channel);
            }
          }
        }
      }
    }
    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var avgPool3DGradConfig;
  var init_AvgPool3DGrad = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3DGrad.js"() {
      init_dist();
      init_cpu_util();
      avgPool3DGradConfig = {
        kernelName: AvgPool3DGrad,
        backendName: "cpu",
        kernelFunc: avgPool3DGrad
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPoolGrad.js
  function avgPoolGrad(args) {
    const { inputs, backend, attrs } = args;
    const { dy, input } = inputs;
    const x = input;
    assertNotComplex([dy, input], "avgPoolGrad");
    const { filterSize, strides, pad: pad2 } = attrs;
    const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, 1, pad2);
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
    const dx = buffer(x.shape, "float32");
    const avgMultiplier = 1 / (filterHeight * filterWidth);
    const dyData = backend.data.get(dy.dataId).values;
    const dyBuf = buffer(dy.shape, "float32", dyData);
    for (let b = 0; b < convInfo.batchSize; ++b) {
      for (let d = 0; d < convInfo.inChannels; ++d) {
        for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {
          for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {
            const dyRCorner = dxR - padTop;
            const dyCCorner = dxC - padLeft;
            let dotProd = 0;
            for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {
              const dyR = (dyRCorner + wR) / strideHeight;
              if (dyR < 0 || dyR >= convInfo.outHeight || Math.floor(dyR) !== dyR) {
                continue;
              }
              for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {
                const dyC = (dyCCorner + wC) / strideWidth;
                if (dyC < 0 || dyC >= convInfo.outWidth || Math.floor(dyC) !== dyC) {
                  continue;
                }
                const pixel = dyBuf.get(b, dyR, dyC, d);
                dotProd += pixel;
              }
            }
            dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);
          }
        }
      }
    }
    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var avgPoolGradConfig;
  var init_AvgPoolGrad = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPoolGrad.js"() {
      init_dist();
      init_cpu_util();
      avgPoolGradConfig = {
        kernelName: AvgPoolGrad,
        backendName: "cpu",
        kernelFunc: avgPoolGrad
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BatchNorm.js
  function batchNorm2(args) {
    const { inputs, backend, attrs } = args;
    const { x, scale: scale2, offset, mean: mean3, variance } = inputs;
    util_exports.assert(mean3.shape.length === variance.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
    util_exports.assert(offset == null || mean3.shape.length === offset.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
    util_exports.assert(scale2 == null || mean3.shape.length === scale2.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
    assertNotComplex([x, mean3, variance, scale2, offset], "batchNorm");
    let { varianceEpsilon } = attrs;
    if (varianceEpsilon == null) {
      varianceEpsilon = 1e-3;
    }
    const xVals = backend.data.get(x.dataId).values;
    const mVals = backend.data.get(mean3.dataId).values;
    const varVals = backend.data.get(variance.dataId).values;
    const sVals = scale2 ? backend.data.get(scale2.dataId).values : new Float32Array([1]);
    const offVals = offset ? backend.data.get(offset.dataId).values : new Float32Array([0]);
    const outVals = new Float32Array(xVals.length);
    const offValsLength = offVals.length;
    const sValsLength = sVals.length;
    const varValsLength = varVals.length;
    const mValsLength = mVals.length;
    let offi = 0;
    let mi = 0;
    let si = 0;
    let vi = 0;
    for (let i = 0; i < xVals.length; ++i) {
      outVals[i] = offVals[offi++] + (xVals[i] - mVals[mi++]) * sVals[si++] / Math.sqrt(varVals[vi++] + varianceEpsilon);
      if (offi >= offValsLength) {
        offi = 0;
      }
      if (mi >= mValsLength) {
        mi = 0;
      }
      if (si >= sValsLength) {
        si = 0;
      }
      if (vi >= varValsLength) {
        vi = 0;
      }
    }
    return backend.makeTensorInfo(x.shape, x.dtype, outVals);
  }
  var batchNormConfig;
  var init_BatchNorm = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BatchNorm.js"() {
      init_dist();
      init_cpu_util();
      batchNormConfig = {
        kernelName: FusedBatchNorm,
        backendName: "cpu",
        kernelFunc: batchNorm2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BatchToSpaceND.js
  function batchToSpaceND2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { blockShape, crops } = attrs;
    assertNotComplex([x], "batchToSpaceND");
    const prod3 = blockShape.reduce((a, b) => a * b);
    const reshaped = backend_util_exports.getReshaped(x.shape, blockShape, prod3);
    const permuted = backend_util_exports.getPermuted(reshaped.length, blockShape.length);
    const reshapedPermuted = backend_util_exports.getReshapedPermuted(x.shape, blockShape, prod3);
    const sliceBeginCoords = backend_util_exports.getSliceBeginCoords(crops, blockShape.length);
    const sliceSize = backend_util_exports.getSliceSize(reshapedPermuted, crops, blockShape.length);
    const xReshaped = reshape2({ inputs: { x }, backend, attrs: { shape: reshaped } });
    const xTransposed = transpose2({ inputs: { x: xReshaped }, backend, attrs: { perm: permuted } });
    const xTransposedReshaped = reshape2({ inputs: { x: xTransposed }, backend, attrs: { shape: reshapedPermuted } });
    const result = slice2({
      inputs: { x: xTransposedReshaped },
      backend,
      attrs: { begin: sliceBeginCoords, size: sliceSize }
    });
    backend.disposeIntermediateTensorInfo(xReshaped);
    backend.disposeIntermediateTensorInfo(xTransposed);
    backend.disposeIntermediateTensorInfo(xTransposedReshaped);
    return result;
  }
  var batchToSpaceNDConfig;
  var init_BatchToSpaceND = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BatchToSpaceND.js"() {
      init_dist();
      init_cpu_util();
      init_Reshape();
      init_Slice();
      init_Transpose();
      batchToSpaceNDConfig = {
        kernelName: BatchToSpaceND,
        backendName: "cpu",
        kernelFunc: batchToSpaceND2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount.js
  function bincount2(args) {
    const { inputs, backend, attrs } = args;
    const { x, weights } = inputs;
    const { size } = attrs;
    const xVals = backend.data.get(x.dataId).values;
    const weightsVals = backend.data.get(weights.dataId).values;
    const outVals = bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);
    return backend.makeTensorInfo([size], weights.dtype, outVals);
  }
  var bincountConfig;
  var init_Bincount = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount.js"() {
      init_dist();
      init_Bincount_impl();
      bincountConfig = {
        kernelName: Bincount,
        backendName: "cpu",
        kernelFunc: bincount2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BroadcastArgs.js
  function broadcastArgs2(args) {
    const { inputs, backend } = args;
    const { s0, s1 } = inputs;
    const s0Vals = backend.data.get(s0.dataId).values;
    const s1Vals = backend.data.get(s1.dataId).values;
    const broadcastShape = backend_util_exports.assertAndGetBroadcastShape(Array.from(s0Vals), Array.from(s1Vals));
    return backend.makeTensorInfo([broadcastShape.length], "int32", Int32Array.from(broadcastShape));
  }
  var broadcastArgsConfig;
  var init_BroadcastArgs = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BroadcastArgs.js"() {
      init_dist();
      broadcastArgsConfig = {
        kernelName: BroadcastArgs,
        backendName: "cpu",
        kernelFunc: broadcastArgs2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ClipByValue.js
  var clipByValue2, clipByValueConfig;
  var init_ClipByValue = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ClipByValue.js"() {
      init_dist();
      init_unary_utils();
      clipByValue2 = unaryKernelFunc(ClipByValue, (xi, attrs) => {
        const clipAttrs = attrs;
        if (xi > clipAttrs.clipValueMax) {
          return clipAttrs.clipValueMax;
        }
        return xi < clipAttrs.clipValueMin ? clipAttrs.clipValueMin : xi;
      });
      clipByValueConfig = {
        kernelName: ClipByValue,
        backendName: "cpu",
        kernelFunc: clipByValue2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ComplexAbs.js
  var complexAbs, complexAbsConfig;
  var init_ComplexAbs = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ComplexAbs.js"() {
      init_dist();
      complexAbs = (args) => {
        const { x } = args.inputs;
        const cpuBackend = args.backend;
        const resultValues = new Float32Array(util_exports.sizeFromShape(x.shape));
        const complexVals = cpuBackend.data.get(x.dataId);
        const real3 = complexVals.complexTensorInfos.real;
        const imag3 = complexVals.complexTensorInfos.imag;
        const realVals = cpuBackend.data.get(real3.dataId).values;
        const imagVals = cpuBackend.data.get(imag3.dataId).values;
        for (let i = 0; i < realVals.length; i++) {
          const real4 = realVals[i];
          const imag4 = imagVals[i];
          resultValues[i] = Math.hypot(real4, imag4);
        }
        return cpuBackend.makeOutput(resultValues, x.shape, "float32");
      };
      complexAbsConfig = {
        kernelName: ComplexAbs,
        backendName: "cpu",
        kernelFunc: complexAbs
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Imag.js
  function imag2(args) {
    const { inputs, backend } = args;
    const { input } = inputs;
    const imag3 = backend.data.get(input.dataId).complexTensorInfos.imag;
    const imagVal = backend.data.get(imag3.dataId).values;
    return backend.makeTensorInfo(imag3.shape, imag3.dtype, imagVal);
  }
  var imagConfig;
  var init_Imag = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Imag.js"() {
      init_dist();
      imagConfig = {
        kernelName: Imag,
        backendName: "cpu",
        kernelFunc: imag2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Concat.js
  function concat2(args) {
    const { inputs, backend, attrs } = args;
    const { axis } = attrs;
    const $axis = util_exports.parseAxisParam(axis, inputs[0].shape)[0];
    const shapes = inputs.map((t2) => t2.shape);
    backend_util_exports.assertParamsConsistent(shapes, $axis);
    let outShape = backend_util_exports.computeOutShape(inputs.map((t2) => t2.shape), $axis);
    if (util_exports.sizeFromShape(outShape) === 0) {
      return backend.makeTensorInfo(outShape, inputs[0].dtype, []);
    }
    const $inputs = inputs.filter((t2) => util_exports.sizeFromShape(t2.shape) > 0);
    if ($inputs.length === 1) {
      return identity({ inputs: { x: $inputs[0] }, backend });
    }
    if ($inputs[0].dtype === "complex64") {
      const reals = $inputs.map((t2) => real2({ inputs: { input: t2 }, backend }));
      const imags = $inputs.map((t2) => imag2({ inputs: { input: t2 }, backend }));
      const realConcated = concat2({ inputs: reals, backend, attrs: { axis: $axis } });
      const imagConcated = concat2({ inputs: imags, backend, attrs: { axis: $axis } });
      const result = complex2({ inputs: { real: realConcated, imag: imagConcated }, backend });
      reals.forEach((r) => backend.disposeIntermediateTensorInfo(r));
      imags.forEach((i) => backend.disposeIntermediateTensorInfo(i));
      backend.disposeIntermediateTensorInfo(realConcated);
      backend.disposeIntermediateTensorInfo(imagConcated);
      return result;
    }
    const inputs2D = $inputs.map((t2) => {
      const innerSize = util_exports.sizeFromShape(t2.shape.slice($axis));
      const shape = [-1, innerSize];
      return reshape2({ inputs: { x: t2 }, backend, attrs: { shape } });
    });
    const inputsValShapes = inputs2D.map((t2) => {
      return { vals: backend.data.get(t2.dataId).values, shape: t2.shape };
    });
    outShape = backend_util_exports.computeOutShape(
      inputs2D.map((t2) => t2.shape),
      1
      /* axis */
    );
    const simplyConcat = inputs2D[0].shape[0] === 1;
    const outVals = concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);
    const finalOutShape = backend_util_exports.computeOutShape($inputs.map((t2) => t2.shape), $axis);
    const outInfo = backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);
    inputs2D.forEach((t2) => backend.disposeIntermediateTensorInfo(t2));
    return outInfo;
  }
  var concatConfig;
  var init_Concat = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Concat.js"() {
      init_dist();
      init_Complex();
      init_Concat_impl();
      init_Identity();
      init_Imag();
      init_Real();
      init_Reshape();
      concatConfig = {
        kernelName: Concat,
        backendName: "cpu",
        kernelFunc: concat2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2D.js
  function conv2D(args) {
    const { inputs, backend, attrs } = args;
    const { x, filter } = inputs;
    const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode } = attrs;
    assertNotComplex([x, filter], "conv2d");
    const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
    const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad2, dimRoundingMode, false, $dataFormat);
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const padLeft = convInfo.padInfo.left;
    const padTop = convInfo.padInfo.top;
    const isChannelsLast = convInfo.dataFormat === "channelsLast";
    const y = new TensorBuffer(convInfo.outShape, x.dtype);
    const xStrides = util_exports.computeStrides(x.shape);
    const filterStrides = util_exports.computeStrides(filter.shape);
    const xBatchStride = xStrides[0];
    const xRowStride = isChannelsLast ? xStrides[1] : xStrides[2];
    const xColStride = isChannelsLast ? xStrides[2] : 1;
    const xChannelStride = isChannelsLast ? 1 : xStrides[1];
    const yBatchStride = y.strides[0];
    const yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];
    const yColStride = isChannelsLast ? y.strides[2] : 1;
    const yChannelStride = isChannelsLast ? 1 : y.strides[1];
    const xVals = backend.data.get(x.dataId).values;
    const wVals = backend.data.get(filter.dataId).values;
    const yVals = y.values;
    for (let b = 0; b < convInfo.batchSize; ++b) {
      const xOffset1 = b * xBatchStride;
      const yOffset1 = b * yBatchStride;
      for (let yR = 0; yR < convInfo.outHeight; ++yR) {
        const yOffset2 = yOffset1 + yR * yRowStride;
        const xRCorner = yR * convInfo.strideHeight - padTop;
        for (let wR = 0; wR < filterHeight; ++wR) {
          const xR = xRCorner + wR * dilationHeight;
          if (xR < 0 || xR >= convInfo.inHeight) {
            continue;
          }
          const wOffset1 = wR * filterStrides[0];
          const xOffset2 = xOffset1 + xR * xRowStride;
          for (let yC = 0; yC < convInfo.outWidth; ++yC) {
            const yOffset3 = yOffset2 + yC * yColStride;
            const xCCorner = yC * convInfo.strideWidth - padLeft;
            for (let wC = 0; wC < filterWidth; ++wC) {
              const xC = xCCorner + wC * dilationWidth;
              if (xC < 0 || xC >= convInfo.inWidth) {
                continue;
              }
              const wOffset2 = wOffset1 + wC * filterStrides[1];
              const xOffset3 = xOffset2 + xC * xColStride;
              let wOffset3 = wOffset2;
              for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
                const xVal = xVals[xOffset3 + d1 * xChannelStride];
                for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
                  yVals[yOffset3 + d2 * yChannelStride] += xVal * wVals[wOffset3 + d2];
                }
                wOffset3 += convInfo.outChannels;
              }
            }
          }
        }
      }
    }
    return backend.makeTensorInfo(y.shape, y.dtype, yVals);
  }
  var conv2DConfig;
  var init_Conv2D = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2D.js"() {
      init_dist();
      init_cpu_util();
      conv2DConfig = {
        kernelName: Conv2D,
        backendName: "cpu",
        kernelFunc: conv2D
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropFilter.js
  function conv2DBackpropFilter2(args) {
    const { inputs, backend, attrs } = args;
    const { x, dy } = inputs;
    const { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape } = attrs;
    assertNotComplex([x, dy], "conv2dBackpropFilter");
    const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
    const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filterShape, strides, 1, pad2, dimRoundingMode, false, $dataFormat);
    const { strideHeight, strideWidth, filterHeight, filterWidth } = convInfo;
    const isChannelsLast = convInfo.dataFormat === "channelsLast";
    const dW = new TensorBuffer(convInfo.filterShape, "float32");
    const leftPad = convInfo.padInfo.left;
    const topPad = convInfo.padInfo.top;
    const xVals = backend.data.get(x.dataId).values;
    const dyVals = backend.data.get(dy.dataId).values;
    const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);
    const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);
    for (let wR = 0; wR < filterHeight; ++wR) {
      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
      const yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
      for (let wC = 0; wC < filterWidth; ++wC) {
        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
        const yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
            let dotProd = 0;
            for (let b = 0; b < convInfo.batchSize; ++b) {
              for (let yR = yRMin; yR < yRMax; ++yR) {
                const xR = wR + yR * strideHeight - topPad;
                for (let yC = yCMin; yC < yCMax; ++yC) {
                  const xC = wC + yC * strideWidth - leftPad;
                  if (isChannelsLast) {
                    dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);
                  } else {
                    dotProd += xBuf.get(b, d1, xR, xC) * dyBuf.get(b, d2, yR, yC);
                  }
                }
              }
            }
            dW.set(dotProd, wR, wC, d1, d2);
          }
        }
      }
    }
    return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);
  }
  var conv2DBackpropFilterConfig;
  var init_Conv2DBackpropFilter = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropFilter.js"() {
      init_dist();
      init_cpu_util();
      conv2DBackpropFilterConfig = {
        kernelName: Conv2DBackpropFilter,
        backendName: "cpu",
        kernelFunc: conv2DBackpropFilter2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropInput.js
  function conv2DBackpropInput2(args) {
    const { inputs, backend, attrs } = args;
    const { dy, filter } = inputs;
    const { inputShape, strides, pad: pad2, dataFormat, dimRoundingMode } = attrs;
    assertNotComplex([dy, filter], "conv2dBackpropInput");
    const filterStrides = util_exports.computeStrides(filter.shape);
    const dyStrides = util_exports.computeStrides(dy.shape);
    let $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
    const convInfo = backend_util_exports.computeConv2DInfo(inputShape, filter.shape, strides, 1, pad2, dimRoundingMode, false, $dataFormat);
    const dx = new TensorBuffer(convInfo.inShape, "float32");
    const dxValues = dx.values;
    const dyValues = backend.data.get(dy.dataId).values;
    const fltValues = backend.data.get(filter.dataId).values;
    const [fltS0, fltS1, fltS2] = filterStrides;
    const { batchSize, filterHeight, filterWidth, inChannels, inHeight, inWidth, outChannels, outHeight, outWidth, strideHeight, strideWidth } = convInfo;
    $dataFormat = convInfo.dataFormat;
    const topPad = filterHeight - 1 - convInfo.padInfo.top;
    const leftPad = filterWidth - 1 - convInfo.padInfo.left;
    const isChannelsLast = $dataFormat === "channelsLast";
    const xBatchStride = dx.strides[0];
    const xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];
    const xColStride = isChannelsLast ? dx.strides[2] : 1;
    const xChannelStride = isChannelsLast ? 1 : dx.strides[1];
    const yBatchStride = dyStrides[0];
    const yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];
    const yColStride = isChannelsLast ? dyStrides[2] : 1;
    const yChannelStride = isChannelsLast ? 1 : dyStrides[1];
    for (let b = 0; b < batchSize; ++b) {
      for (let d1 = 0; d1 < inChannels; ++d1) {
        for (let xR = 0; xR < inHeight; ++xR) {
          const xRCorner = xR - topPad;
          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
          const yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
          for (let xC = 0; xC < inWidth; ++xC) {
            const xCCorner = xC - leftPad;
            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
            const yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
            let dotProd = 0;
            for (let yR = xRMin; yR < yRMax; ++yR) {
              const wR = yR * strideHeight - xRCorner;
              for (let yC = xCMin; yC < yCMax; ++yC) {
                const wC = yC * strideWidth - xCCorner;
                const dyOffset = yBatchStride * b + yRowStride * yR + yColStride * yC;
                const fltOffset = fltS0 * (filterHeight - 1 - wR) + fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;
                for (let d2 = 0; d2 < outChannels; ++d2) {
                  const pixel = dyValues[dyOffset + yChannelStride * d2];
                  const weight = fltValues[fltOffset + d2];
                  dotProd += pixel * weight;
                }
              }
            }
            const dxOffset = xBatchStride * b + xRowStride * xR + xColStride * xC + xChannelStride * d1;
            dxValues[dxOffset] = dotProd;
          }
        }
      }
    }
    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var conv2DBackpropInputConfig;
  var init_Conv2DBackpropInput = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropInput.js"() {
      init_dist();
      init_cpu_util();
      conv2DBackpropInputConfig = {
        kernelName: Conv2DBackpropInput,
        backendName: "cpu",
        kernelFunc: conv2DBackpropInput2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3D.js
  function conv3D(args) {
    const { inputs, backend, attrs } = args;
    const { x, filter } = inputs;
    const { strides, pad: pad2, dilations } = attrs;
    assertNotComplex([x, filter], "conv3d");
    const convInfo = backend_util_exports.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad2);
    const { filterDepth, filterHeight, filterWidth, dilationDepth, dilationHeight, dilationWidth, padInfo } = convInfo;
    const padFront = padInfo.front;
    const padLeft = padInfo.left;
    const padTop = padInfo.top;
    const y = new TensorBuffer(convInfo.outShape, x.dtype);
    const xVals = backend.data.get(x.dataId).values;
    const wVals = backend.data.get(filter.dataId).values;
    const yVals = y.values;
    const xStrides = util_exports.computeStrides(x.shape);
    const filterStrides = util_exports.computeStrides(filter.shape);
    for (let b = 0; b < convInfo.batchSize; ++b) {
      const xOffset1 = b * xStrides[0];
      const yOffset1 = b * y.strides[0];
      for (let yF = 0; yF < convInfo.outDepth; ++yF) {
        const yOffset2 = yOffset1 + yF * y.strides[1];
        const xFCorner = yF * convInfo.strideDepth - padFront;
        for (let wF = 0; wF < filterDepth; ++wF) {
          const xF = xFCorner + wF * dilationDepth;
          if (xF < 0 || xF >= convInfo.inDepth) {
            continue;
          }
          const wOffset1 = wF * filterStrides[0];
          const xOffset2 = xOffset1 + xF * xStrides[1];
          for (let yR = 0; yR < convInfo.outHeight; ++yR) {
            const yOffset3 = yOffset2 + yR * y.strides[2];
            const xRCorner = yR * convInfo.strideHeight - padTop;
            for (let wR = 0; wR < filterHeight; ++wR) {
              const xR = xRCorner + wR * dilationHeight;
              if (xR < 0 || xR >= convInfo.inHeight) {
                continue;
              }
              const wOffset2 = wOffset1 + wR * filterStrides[1];
              const xOffset3 = xOffset2 + xR * xStrides[2];
              for (let yC = 0; yC < convInfo.outWidth; ++yC) {
                const yOffset4 = yOffset3 + yC * convInfo.outChannels;
                const xCCorner = yC * convInfo.strideWidth - padLeft;
                for (let wC = 0; wC < filterWidth; ++wC) {
                  const xC = xCCorner + wC * dilationWidth;
                  if (xC < 0 || xC >= convInfo.inWidth) {
                    continue;
                  }
                  const wOffset3 = wOffset2 + wC * filterStrides[2];
                  const xOffset4 = xOffset3 + xC * convInfo.inChannels;
                  let wOffset4 = wOffset3;
                  for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
                    const xVal = xVals[xOffset4 + d1];
                    for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
                      yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];
                    }
                    wOffset4 += convInfo.outChannels;
                  }
                }
              }
            }
          }
        }
      }
    }
    return backend.makeTensorInfo(y.shape, y.dtype, y.values);
  }
  var conv3DConfig;
  var init_Conv3D = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3D.js"() {
      init_dist();
      init_cpu_util();
      conv3DConfig = {
        kernelName: Conv3D,
        backendName: "cpu",
        kernelFunc: conv3D
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropFilterV2.js
  function conv3DBackpropFilterV2(args) {
    const { inputs, backend, attrs } = args;
    const { x, dy } = inputs;
    const { strides, pad: pad2, filterShape } = attrs;
    assertNotComplex([x, dy], "conv3dBackpropFilterV2");
    const xStrides = util_exports.computeStrides(x.shape);
    const dyStrides = util_exports.computeStrides(dy.shape);
    const convInfo = backend_util_exports.computeConv3DInfo(x.shape, filterShape, strides, 1, pad2);
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const filterDepth = convInfo.filterDepth;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const dw = new TensorBuffer(convInfo.filterShape, "float32");
    const dwValues = dw.values;
    const [dwS0, dwS1, dwS2, dwS3] = dw.strides;
    const dyValues = backend.data.get(dy.dataId).values;
    const [dyS0, dyS1, dyS2, dyS3] = dyStrides;
    const xValues = backend.data.get(x.dataId).values;
    const [xS0, xS1, xS2, xS3] = xStrides;
    const frontPad = convInfo.padInfo.front;
    const leftPad = convInfo.padInfo.left;
    const topPad = convInfo.padInfo.top;
    for (let wF = 0; wF < filterDepth; ++wF) {
      const yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));
      const yFMax = Math.min(convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);
      const wOffset1 = wF * dwS0;
      for (let wR = 0; wR < filterHeight; ++wR) {
        const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
        const yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
        const wOffset2 = wR * dwS1 + wOffset1;
        for (let wC = 0; wC < filterWidth; ++wC) {
          const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
          const yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
          const wOffset3 = wC * dwS2 + wOffset2;
          for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
            const wOffset4 = d1 * dwS3 + wOffset3;
            for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
              let dotProd = 0;
              for (let b = 0; b < convInfo.batchSize; ++b) {
                const xOffset1 = b * xS0;
                const yOffset1 = b * dyS0;
                for (let yF = yFMin; yF < yFMax; ++yF) {
                  const xF = wF + yF * strideDepth - frontPad;
                  const xOffset2 = xF * xS1 + xOffset1;
                  const yOffset2 = yF * dyS1 + yOffset1;
                  for (let yR = yRMin; yR < yRMax; ++yR) {
                    const xR = wR + yR * strideHeight - topPad;
                    const xOffset3 = xR * xS2 + xOffset2;
                    const yOffset3 = yR * dyS2 + yOffset2;
                    for (let yC = yCMin; yC < yCMax; ++yC) {
                      const xC = wC + yC * strideWidth - leftPad;
                      const xOffset4 = xC * xS3 + xOffset3;
                      const yOffset4 = yC * dyS3 + yOffset3;
                      dotProd += xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];
                    }
                  }
                }
              }
              dwValues[wOffset4 + d2] = dotProd;
            }
          }
        }
      }
    }
    return backend.makeTensorInfo(dw.shape, dw.dtype, dw.values);
  }
  var conv3DBackpropFilterV2Config;
  var init_Conv3DBackpropFilterV2 = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropFilterV2.js"() {
      init_dist();
      init_cpu_util();
      conv3DBackpropFilterV2Config = {
        kernelName: Conv3DBackpropFilterV2,
        backendName: "cpu",
        kernelFunc: conv3DBackpropFilterV2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropInputV2.js
  function conv3DBackpropInputV2(args) {
    const { inputs, backend, attrs } = args;
    const { dy, filter } = inputs;
    const { pad: pad2, strides, inputShape } = attrs;
    assertNotComplex([dy], "conv3dBackpropInputV2");
    const dyStrides = util_exports.computeStrides(dy.shape);
    const filterStrides = util_exports.computeStrides(filter.shape);
    const convInfo = backend_util_exports.computeConv3DInfo(inputShape, filter.shape, strides, 1, pad2);
    const dx = new TensorBuffer(convInfo.inShape, "float32");
    const dxValues = dx.values;
    const [dxS0, dxS1, dxS2, dxS3] = dx.strides;
    const dyValues = backend.data.get(dy.dataId).values;
    const [dyS0, dyS1, dyS2, dyS3] = dyStrides;
    const fltValues = backend.data.get(filter.dataId).values;
    const [fltS0, fltS1, fltS2, fltS3] = filterStrides;
    const { batchSize, filterDepth, filterHeight, filterWidth, inChannels, inDepth, inHeight, inWidth, outChannels, outDepth, outHeight, outWidth, strideDepth, strideHeight, strideWidth } = convInfo;
    const frontPad = filterDepth - 1 - convInfo.padInfo.front;
    const topPad = filterHeight - 1 - convInfo.padInfo.top;
    const leftPad = filterWidth - 1 - convInfo.padInfo.left;
    for (let b = 0; b < batchSize; ++b) {
      for (let d1 = 0; d1 < inChannels; ++d1) {
        for (let xF = 0; xF < inDepth; ++xF) {
          const xFCorner = xF - frontPad;
          const xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));
          const yFMax = Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);
          for (let xR = 0; xR < inHeight; ++xR) {
            const xRCorner = xR - topPad;
            const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
            const yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
            for (let xC = 0; xC < inWidth; ++xC) {
              const xCCorner = xC - leftPad;
              const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
              const yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
              let dotProd = 0;
              for (let yF = xFMin; yF < yFMax; ++yF) {
                const wF = yF * strideDepth - xFCorner;
                for (let yR = xRMin; yR < yRMax; ++yR) {
                  const wR = yR * strideHeight - xRCorner;
                  for (let yC = xCMin; yC < yCMax; ++yC) {
                    const wC = yC * strideWidth - xCCorner;
                    const dyOffset = dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;
                    const fltOffset = fltS0 * (filterDepth - 1 - wF) + fltS1 * (filterHeight - 1 - wR) + fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;
                    for (let d2 = 0; d2 < outChannels; ++d2) {
                      const pixel = dyValues[dyOffset + d2];
                      const weight = fltValues[fltOffset + d2];
                      dotProd += pixel * weight;
                    }
                  }
                }
              }
              dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] = dotProd;
            }
          }
        }
      }
    }
    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var conv3DBackpropInputV2Config;
  var init_Conv3DBackpropInputV2 = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropInputV2.js"() {
      init_dist();
      init_cpu_util();
      conv3DBackpropInputV2Config = {
        kernelName: Conv3DBackpropInputV2,
        backendName: "cpu",
        kernelFunc: conv3DBackpropInputV2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cos.js
  var cos2, cosConfig;
  var init_Cos = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cos.js"() {
      init_dist();
      init_unary_utils();
      cos2 = unaryKernelFunc(Cos, (xi) => Math.cos(xi));
      cosConfig = {
        kernelName: Cos,
        backendName: "cpu",
        kernelFunc: cos2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cosh.js
  var cosh2, coshConfig;
  var init_Cosh = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cosh.js"() {
      init_dist();
      init_unary_utils();
      cosh2 = unaryKernelFunc(Cosh, (xi) => Math.cosh(xi));
      coshConfig = {
        kernelName: Cosh,
        backendName: "cpu",
        kernelFunc: cosh2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/CropAndResize.js
  function cropAndResize2(args) {
    const { inputs, backend, attrs } = args;
    const { image: image2, boxes, boxInd } = inputs;
    const { cropSize, method, extrapolationValue } = attrs;
    const [batch, imageHeight, imageWidth, numChannels] = image2.shape;
    const numBoxes = boxes.shape[0];
    const [cropHeight, cropWidth] = cropSize;
    const output = buffer([numBoxes, cropHeight, cropWidth, numChannels], "float32");
    const boxVals = backend.data.get(boxes.dataId).values;
    const boxIndVals = backend.data.get(boxInd.dataId).values;
    const imageVals = backend.data.get(image2.dataId).values;
    const inStride = util_exports.computeStrides(image2.shape);
    const outStride = util_exports.computeStrides(output.shape);
    for (let b = 0; b < numBoxes; b++) {
      const startInd = b * 4;
      const y1 = boxVals[startInd];
      const x1 = boxVals[startInd + 1];
      const y2 = boxVals[startInd + 2];
      const x2 = boxVals[startInd + 3];
      const bInd = boxIndVals[b];
      if (bInd >= batch) {
        continue;
      }
      const heightScale = cropHeight > 1 ? (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) : 0;
      const widthScale = cropWidth > 1 ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;
      for (let y = 0; y < cropHeight; y++) {
        const yInd = cropHeight > 1 ? y1 * (imageHeight - 1) + y * heightScale : 0.5 * (y1 + y2) * (imageHeight - 1);
        if (yInd < 0 || yInd > imageHeight - 1) {
          for (let x = 0; x < cropWidth; x++) {
            for (let c = 0; c < numChannels; c++) {
              const ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
              output.values[ind] = extrapolationValue;
            }
          }
          continue;
        }
        if (method === "bilinear") {
          const topInd = Math.floor(yInd);
          const bottomInd = Math.ceil(yInd);
          const yLerp = yInd - topInd;
          for (let x = 0; x < cropWidth; x++) {
            const xInd = cropWidth > 1 ? x1 * (imageWidth - 1) + x * widthScale : 0.5 * (x1 + x2) * (imageWidth - 1);
            if (xInd < 0 || xInd > imageWidth - 1) {
              for (let c = 0; c < numChannels; c++) {
                const ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
                output.values[ind] = extrapolationValue;
              }
              continue;
            }
            const leftInd = Math.floor(xInd);
            const rightInd = Math.ceil(xInd);
            const xLerp = xInd - leftInd;
            for (let c = 0; c < numChannels; c++) {
              let ind = c + leftInd * inStride[2] + topInd * inStride[1] + bInd * inStride[0];
              const topLeft = imageVals[ind];
              ind = c + rightInd * inStride[2] + topInd * inStride[1] + bInd * inStride[0];
              const topRight = imageVals[ind];
              ind = c + leftInd * inStride[2] + bottomInd * inStride[1] + bInd * inStride[0];
              const bottomLeft = imageVals[ind];
              ind = c + rightInd * inStride[2] + bottomInd * inStride[1] + bInd * inStride[0];
              const bottomRight = imageVals[ind];
              const top = topLeft + (topRight - topLeft) * xLerp;
              const bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;
              ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
              output.values[ind] = top + (bottom - top) * yLerp;
            }
          }
        } else {
          for (let x = 0; x < cropWidth; ++x) {
            const xInd = cropWidth > 1 ? x1 * (imageWidth - 1) + x * widthScale : 0.5 * (x1 + x2) * (imageWidth - 1);
            if (xInd < 0 || xInd > imageWidth - 1) {
              for (let c = 0; c < numChannels; c++) {
                const ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
                output.values[ind] = extrapolationValue;
              }
              continue;
            }
            const closestX = Math.round(xInd);
            const closestY = Math.round(yInd);
            for (let c = 0; c < numChannels; c++) {
              const inInd = c + closestX * inStride[2] + closestY * inStride[1] + bInd * inStride[0];
              const outInd = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
              output.values[outInd] = imageVals[inInd];
            }
          }
        }
      }
    }
    return backend.makeTensorInfo(output.shape, output.dtype, output.values);
  }
  var cropAndResizeConfig;
  var init_CropAndResize = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/CropAndResize.js"() {
      init_dist();
      cropAndResizeConfig = {
        kernelName: CropAndResize,
        backendName: "cpu",
        kernelFunc: cropAndResize2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cumprod.js
  function cumprod2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { axis, exclusive, reverse: reverse3 } = attrs;
    assertNotComplex(x, "cumprod");
    const permutation = backend_util_exports.getAxesPermutation([axis], x.shape.length);
    let $x = x;
    if (permutation != null) {
      $x = transpose2({ inputs: { x }, backend, attrs: { perm: permutation } });
    }
    const permutedAxis = backend_util_exports.getInnerMostAxes(1, x.shape.length)[0];
    if (permutedAxis !== $x.shape.length - 1) {
      throw new Error(`backend.cumprod in CPU expects an inner-most axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);
    }
    const resultDtype = upcastType($x.dtype, "int32");
    const vals = util_exports.makeOnesTypedArray(util_exports.sizeFromShape($x.shape), resultDtype);
    const aVals = backend.data.get($x.dataId).values;
    const finalDim = $x.shape[$x.shape.length - 1];
    const indexAdjuster = reverse3 ? (i, j2) => i + finalDim - j2 - 1 : (i, j2) => i + j2;
    for (let i = 0; i < aVals.length; i += finalDim) {
      for (let j2 = 0; j2 < finalDim; j2++) {
        const idx = indexAdjuster(i, j2);
        if (j2 === 0) {
          vals[idx] = exclusive ? 1 : aVals[idx];
        } else {
          const prevIdx = indexAdjuster(i, j2 - 1);
          vals[idx] = exclusive ? aVals[prevIdx] * vals[prevIdx] : aVals[idx] * vals[prevIdx];
        }
      }
    }
    const result = backend.makeTensorInfo($x.shape, resultDtype, vals);
    if (permutation != null) {
      const reversePermutation = backend_util_exports.getUndoAxesPermutation(permutation);
      const reverseTransposedResult = transpose2({ inputs: { x: result }, backend, attrs: { perm: reversePermutation } });
      backend.disposeIntermediateTensorInfo(result);
      backend.disposeIntermediateTensorInfo($x);
      return reverseTransposedResult;
    }
    return result;
  }
  var cumprodConfig;
  var init_Cumprod = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cumprod.js"() {
      init_dist();
      init_cpu_util();
      init_Transpose();
      cumprodConfig = {
        kernelName: Cumprod,
        backendName: "cpu",
        kernelFunc: cumprod2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cumsum.js
  function cumsum2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { axis, exclusive, reverse: reverse3 } = attrs;
    assertNotComplex(x, "cumsum");
    const permutation = backend_util_exports.getAxesPermutation([axis], x.shape.length);
    let $x = x;
    if (permutation != null) {
      $x = transpose2({ inputs: { x }, backend, attrs: { perm: permutation } });
    }
    const permutedAxis = backend_util_exports.getInnerMostAxes(1, x.shape.length)[0];
    if (permutedAxis !== $x.shape.length - 1) {
      throw new Error(`backend.cumsum in CPU expects an inner-most axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);
    }
    const resultDtype = upcastType($x.dtype, "int32");
    const vals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape($x.shape), resultDtype);
    const aVals = backend.data.get($x.dataId).values;
    const finalDim = $x.shape[$x.shape.length - 1];
    const indexAdjuster = reverse3 ? (i, j2) => i + finalDim - j2 - 1 : (i, j2) => i + j2;
    for (let i = 0; i < aVals.length; i += finalDim) {
      for (let j2 = 0; j2 < finalDim; j2++) {
        const idx = indexAdjuster(i, j2);
        if (j2 === 0) {
          vals[idx] = exclusive ? 0 : aVals[idx];
        } else {
          const prevIdx = indexAdjuster(i, j2 - 1);
          vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] : aVals[idx] + vals[prevIdx];
        }
      }
    }
    const result = backend.makeTensorInfo($x.shape, resultDtype, vals);
    if (permutation != null) {
      const reversePermutation = backend_util_exports.getUndoAxesPermutation(permutation);
      const reverseTransposedResult = transpose2({ inputs: { x: result }, backend, attrs: { perm: reversePermutation } });
      backend.disposeIntermediateTensorInfo(result);
      backend.disposeIntermediateTensorInfo($x);
      return reverseTransposedResult;
    }
    return result;
  }
  var cumsumConfig;
  var init_Cumsum = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cumsum.js"() {
      init_dist();
      init_cpu_util();
      init_Transpose();
      cumsumConfig = {
        kernelName: Cumsum,
        backendName: "cpu",
        kernelFunc: cumsum2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DenseBincount.js
  function denseBincount2(args) {
    const { inputs, backend, attrs } = args;
    const { x, weights } = inputs;
    const { size, binaryOutput } = attrs;
    if (x.shape.length === 1) {
      const xVals = backend.data.get(x.dataId).values;
      const weightsVals = backend.data.get(weights.dataId).values;
      const outVals = bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);
      return backend.makeTensorInfo([size], weights.dtype, outVals);
    } else if (x.shape.length === 2) {
      const xBuf = backend.bufferSync(x);
      const weightsBuf = backend.bufferSync(weights);
      const outBuf = bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput);
      return backend.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);
    }
    throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${x.shape.length}.`);
  }
  var denseBincountConfig;
  var init_DenseBincount = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DenseBincount.js"() {
      init_dist();
      init_Bincount_impl();
      denseBincountConfig = {
        kernelName: DenseBincount,
        backendName: "cpu",
        kernelFunc: denseBincount2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthToSpace.js
  function depthToSpace2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { blockSize, dataFormat } = attrs;
    util_exports.assert(dataFormat === "NHWC", () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${dataFormat}`);
    const batchSize = x.shape[0];
    const inputHeight = x.shape[1];
    const inputWidth = x.shape[2];
    const inputDepth = x.shape[3];
    const outputHeight = inputHeight * blockSize;
    const outputWidth = inputWidth * blockSize;
    const outputDepth = inputDepth / (blockSize * blockSize);
    const xValues = backend.data.get(x.dataId).values;
    const result = new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);
    let outputIdx = 0;
    for (let b = 0; b < batchSize; ++b) {
      for (let h = 0; h < outputHeight; ++h) {
        const inH = Math.floor(h / blockSize);
        const offsetH = h % blockSize;
        for (let w = 0; w < outputWidth; ++w) {
          const inW = Math.floor(w / blockSize);
          const offsetW = w % blockSize;
          const offsetD = (offsetH * blockSize + offsetW) * outputDepth;
          for (let d = 0; d < outputDepth; ++d) {
            const inD = d + offsetD;
            const inputIdx = inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));
            result[outputIdx++] = xValues[inputIdx];
          }
        }
      }
    }
    return backend.makeTensorInfo([batchSize, outputHeight, outputWidth, outputDepth], x.dtype, result);
  }
  var depthToSpaceConfig;
  var init_DepthToSpace = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthToSpace.js"() {
      init_dist();
      depthToSpaceConfig = {
        kernelName: DepthToSpace,
        backendName: "cpu",
        kernelFunc: depthToSpace2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNative.js
  function depthwiseConv2dNative(args) {
    const { inputs, backend, attrs } = args;
    const { x, filter } = inputs;
    const { strides, pad: pad2, dilations, dimRoundingMode } = attrs;
    assertNotComplex([x, filter], "depthwiseConv2DNative");
    const xStrides = util_exports.computeStrides(x.shape);
    const filterStrides = util_exports.computeStrides(filter.shape);
    let $dilations = dilations;
    if ($dilations == null) {
      $dilations = [1, 1];
    }
    util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);
    const convInfo = backend_util_exports.computeConv2DInfo(
      x.shape,
      filter.shape,
      strides,
      $dilations,
      pad2,
      dimRoundingMode,
      true
      /* depthwise */
    );
    const { filterHeight, filterWidth, dilationHeight, dilationWidth, padInfo } = convInfo;
    const padLeft = padInfo.left;
    const padTop = padInfo.top;
    const chMul = convInfo.outChannels / convInfo.inChannels;
    const y = new TensorBuffer(convInfo.outShape, x.dtype);
    const xVals = backend.data.get(x.dataId).values;
    const wVals = backend.data.get(filter.dataId).values;
    const yVals = y.values;
    for (let b = 0; b < convInfo.batchSize; ++b) {
      const xOffset1 = b * xStrides[0];
      const yOffset1 = b * y.strides[0];
      for (let yR = 0; yR < convInfo.outHeight; ++yR) {
        const yOffset2 = yOffset1 + yR * y.strides[1];
        const xRCorner = yR * convInfo.strideHeight - padTop;
        for (let wR = 0; wR < filterHeight; ++wR) {
          const xR = xRCorner + wR * dilationHeight;
          if (xR < 0 || xR >= convInfo.inHeight) {
            continue;
          }
          const wOffset1 = wR * filterStrides[0];
          const xOffset2 = xOffset1 + xR * xStrides[1];
          for (let yC = 0; yC < convInfo.outWidth; ++yC) {
            const yOffset3 = yOffset2 + yC * y.strides[2];
            const xCCorner = yC * convInfo.strideWidth - padLeft;
            for (let wC = 0; wC < filterWidth; ++wC) {
              const xC = xCCorner + wC * dilationWidth;
              if (xC < 0 || xC >= convInfo.inWidth) {
                continue;
              }
              const wOffset2 = wOffset1 + wC * filterStrides[1];
              const xOffset3 = xOffset2 + xC * convInfo.inChannels;
              let yOffset4 = yOffset3;
              let wOffset3 = wOffset2;
              for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
                const xVal = xVals[xOffset3 + d1];
                for (let q2 = 0; q2 < chMul; ++q2) {
                  yVals[yOffset4 + q2] += xVal * wVals[wOffset3 + q2];
                }
                yOffset4 += chMul;
                wOffset3 += chMul;
              }
            }
          }
        }
      }
    }
    return backend.makeTensorInfo(y.shape, y.dtype, y.values);
  }
  var depthwiseConv2dNativeConfig;
  var init_DepthwiseConv2dNative = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNative.js"() {
      init_dist();
      init_cpu_util();
      depthwiseConv2dNativeConfig = {
        kernelName: DepthwiseConv2dNative,
        backendName: "cpu",
        kernelFunc: depthwiseConv2dNative
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js
  function depthwiseConv2dNativeBackpropFilter2(args) {
    const { inputs, backend, attrs } = args;
    const { x, dy } = inputs;
    const { strides, dilations, pad: pad2, dimRoundingMode, filterShape } = attrs;
    assertNotComplex([x, dy], "depthwiseConv2dNativeBackpropFilter");
    const convInfo = backend_util_exports.computeConv2DInfo(
      x.shape,
      filterShape,
      strides,
      dilations,
      pad2,
      dimRoundingMode,
      true
      /* depthwise */
    );
    const { strideHeight, strideWidth, filterHeight, filterWidth } = convInfo;
    const dW = new TensorBuffer(convInfo.filterShape, "float32");
    const leftPad = convInfo.padInfo.left;
    const topPad = convInfo.padInfo.top;
    const chMul = convInfo.outChannels / convInfo.inChannels;
    const xVals = backend.data.get(x.dataId).values;
    const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);
    const dyVals = backend.data.get(dy.dataId).values;
    const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);
    for (let wR = 0; wR < filterHeight; ++wR) {
      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
      const yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
      for (let wC = 0; wC < filterWidth; ++wC) {
        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
        const yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
        for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
          const d1 = Math.trunc(d2 / chMul);
          const dm = d2 % chMul;
          let dotProd = 0;
          for (let b = 0; b < convInfo.batchSize; ++b) {
            for (let yR = yRMin; yR < yRMax; ++yR) {
              const xR = wR + yR * strideHeight - topPad;
              for (let yC = yCMin; yC < yCMax; ++yC) {
                const xC = wC + yC * strideWidth - leftPad;
                dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);
              }
            }
          }
          dW.set(dotProd, wR, wC, d1, dm);
        }
      }
    }
    return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);
  }
  var depthwiseConv2dNativeBackpropFilterConfig;
  var init_DepthwiseConv2dNativeBackpropFilter = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js"() {
      init_dist();
      init_cpu_util();
      depthwiseConv2dNativeBackpropFilterConfig = {
        kernelName: DepthwiseConv2dNativeBackpropFilter,
        backendName: "cpu",
        kernelFunc: depthwiseConv2dNativeBackpropFilter2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropInput.js
  function depthwiseConv2dNativeBackpropInput2(args) {
    const { inputs, backend, attrs } = args;
    const { dy, filter } = inputs;
    const { strides, dilations, pad: pad2, dimRoundingMode, inputShape } = attrs;
    assertNotComplex([dy, filter], "depthwiseConv2DNativeBackpropInput");
    const dyStrides = util_exports.computeStrides(dy.shape);
    const filterStrides = util_exports.computeStrides(filter.shape);
    const convInfo = backend_util_exports.computeConv2DInfo(
      inputShape,
      filter.shape,
      strides,
      dilations,
      pad2,
      dimRoundingMode,
      true
      /* depthwise */
    );
    const dx = new TensorBuffer(convInfo.inShape, "float32");
    const dxValues = dx.values;
    const [dxS0, dxS1, dxS2] = dx.strides;
    const dyValues = backend.data.get(dy.dataId).values;
    const [dyS0, dyS1, dyS2] = dyStrides;
    const fltValues = backend.data.get(filter.dataId).values;
    const [fltS0, fltS1, fltS2] = filterStrides;
    const { batchSize, filterHeight, filterWidth, inChannels, inHeight, inWidth, outChannels, outHeight, outWidth, strideHeight, strideWidth } = convInfo;
    const topPad = filterHeight - 1 - convInfo.padInfo.top;
    const leftPad = filterWidth - 1 - convInfo.padInfo.left;
    const chMul = outChannels / inChannels;
    for (let b = 0; b < batchSize; ++b) {
      for (let d1 = 0; d1 < inChannels; ++d1) {
        for (let xR = 0; xR < inHeight; ++xR) {
          const xRCorner = xR - topPad;
          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
          const yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
          for (let xC = 0; xC < inWidth; ++xC) {
            const xCCorner = xC - leftPad;
            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
            const yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
            let dotProd = 0;
            for (let yR = xRMin; yR < yRMax; ++yR) {
              const wR = yR * strideHeight - xRCorner;
              for (let yC = xCMin; yC < yCMax; ++yC) {
                const wC = yC * strideWidth - xCCorner;
                const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;
                const fltOffset = fltS0 * (filterHeight - 1 - wR) + fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;
                for (let dm = 0; dm < chMul; ++dm) {
                  const d2 = d1 * chMul + dm;
                  const pixel = dyValues[dyOffset + d2];
                  const weight = fltValues[fltOffset + dm];
                  dotProd += pixel * weight;
                }
              }
            }
            dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;
          }
        }
      }
    }
    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var depthwiseConv2dNativeBackpropInputConfig;
  var init_DepthwiseConv2dNativeBackpropInput = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropInput.js"() {
      init_dist();
      init_cpu_util();
      depthwiseConv2dNativeBackpropInputConfig = {
        kernelName: DepthwiseConv2dNativeBackpropInput,
        backendName: "cpu",
        kernelFunc: depthwiseConv2dNativeBackpropInput2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Diag.js
  function diag2(args) {
    const { inputs, backend } = args;
    const { x } = inputs;
    const xSize = util_exports.sizeFromShape(x.shape);
    const xVals = backend.data.get(x.dataId).values;
    const outBuf = buffer([xSize, xSize], x.dtype);
    const vals = outBuf.values;
    for (let i = 0; i < xVals.length; i++) {
      vals[i * xSize + i] = xVals[i];
    }
    const outShape = [...x.shape, ...x.shape];
    return backend.makeTensorInfo(outShape, outBuf.dtype, outBuf.values);
  }
  var diagConfig;
  var init_Diag = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Diag.js"() {
      init_dist();
      diagConfig = {
        kernelName: Diag,
        backendName: "cpu",
        kernelFunc: diag2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2D.js
  var dilation2DConfig;
  var init_Dilation2D = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2D.js"() {
      init_dist();
      dilation2DConfig = {
        kernelName: Dilation2D,
        backendName: "cpu",
        kernelFunc: ({ inputs, backend, attrs }) => {
          const { x, filter } = inputs;
          const { strides, pad: pad2, dilations } = attrs;
          const cpuBackend = backend;
          const xVals = cpuBackend.data.get(x.dataId).values;
          const xRank = x.shape.length;
          const filterVals = cpuBackend.data.get(filter.dataId).values;
          const filterRank = filter.shape.length;
          const { batchSize, inHeight, inWidth, inChannels, outHeight, outWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth, outShape } = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
          const outSize = util_exports.sizeFromShape(outShape);
          const outRank = outShape.length;
          const outputVals = util_exports.getArrayFromDType(x.dtype, outSize);
          for (let b = 0; b < batchSize; ++b) {
            for (let hOut = 0; hOut < outHeight; ++hOut) {
              const hBeg = hOut * strideHeight - padInfo.top;
              for (let wOut = 0; wOut < outWidth; ++wOut) {
                const wBeg = wOut * strideWidth - padInfo.left;
                for (let d = 0; d < inChannels; ++d) {
                  let curVal = Number.MIN_SAFE_INTEGER;
                  for (let h = 0; h < filterHeight; ++h) {
                    const hIn = hBeg + h * dilationHeight;
                    if (hIn >= 0 && hIn < inHeight) {
                      for (let w = 0; w < filterWidth; ++w) {
                        const wIn = wBeg + w * dilationWidth;
                        if (wIn >= 0 && wIn < inWidth) {
                          const xIndex = util_exports.locToIndex([b, hIn, wIn, d], xRank, util_exports.computeStrides(x.shape));
                          const filterIndex = util_exports.locToIndex([h, w, d], filterRank, util_exports.computeStrides(filter.shape));
                          const val = xVals[xIndex] + filterVals[filterIndex];
                          if (val > curVal) {
                            curVal = val;
                          }
                        }
                      }
                    }
                  }
                  const outputIndex = util_exports.locToIndex([b, hOut, wOut, d], outRank, util_exports.computeStrides(outShape));
                  outputVals[outputIndex] = curVal;
                }
              }
            }
          }
          const dataId = cpuBackend.write(util_exports.toTypedArray(outputVals, x.dtype), outShape, x.dtype);
          return { dataId, shape: outShape, dtype: x.dtype };
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropFilter.js
  var dilation2DBackpropFilterConfig;
  var init_Dilation2DBackpropFilter = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropFilter.js"() {
      init_dist();
      dilation2DBackpropFilterConfig = {
        kernelName: Dilation2DBackpropFilter,
        backendName: "cpu",
        kernelFunc: ({ inputs, backend, attrs }) => {
          const { x, filter, dy } = inputs;
          const { strides, pad: pad2, dilations } = attrs;
          const cpuBackend = backend;
          const $x = util_exports.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);
          const $filter = util_exports.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);
          const { batchSize, inHeight, inWidth, inChannels, outHeight, outWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth, outShape } = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
          util_exports.assert(dy.rank === outShape.length, () => `Error in ${Dilation2DBackpropFilter}, dy must have the same rank as output ${outShape.length}, but got ${dy.rank}`);
          const $dy = util_exports.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);
          const gradients = util_exports.makeZerosNestedTypedArray(filter.shape, filter.dtype);
          for (let b = 0; b < batchSize; ++b) {
            for (let hOut = 0; hOut < outHeight; ++hOut) {
              const hBeg = hOut * strideHeight - padInfo.top;
              for (let wOut = 0; wOut < outWidth; ++wOut) {
                const wBeg = wOut * strideWidth - padInfo.left;
                for (let d = 0; d < inChannels; ++d) {
                  let curVal = Number.MIN_SAFE_INTEGER;
                  let hMax = 0;
                  let wMax = 0;
                  for (let h = 0; h < filterHeight; ++h) {
                    const hIn = hBeg + h * dilationHeight;
                    if (hIn >= 0 && hIn < inHeight) {
                      for (let w = 0; w < filterWidth; ++w) {
                        const wIn = wBeg + w * dilationWidth;
                        if (wIn >= 0 && wIn < inWidth) {
                          const val = $x[b][hIn][wIn][d] + $filter[h][w][d];
                          if (val > curVal) {
                            curVal = val;
                            hMax = h;
                            wMax = w;
                          }
                        }
                      }
                    }
                  }
                  gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];
                }
              }
            }
          }
          const dataId = cpuBackend.write(util_exports.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);
          return { dataId, shape: filter.shape, dtype: filter.dtype };
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropInput.js
  var dilation2DBackpropInputConfig;
  var init_Dilation2DBackpropInput = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropInput.js"() {
      init_dist();
      dilation2DBackpropInputConfig = {
        kernelName: Dilation2DBackpropInput,
        backendName: "cpu",
        kernelFunc: ({ inputs, backend, attrs }) => {
          const { x, filter, dy } = inputs;
          const { strides, pad: pad2, dilations } = attrs;
          const cpuBackend = backend;
          const $x = util_exports.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);
          const $filter = util_exports.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);
          const { batchSize, inHeight, inWidth, inChannels, outHeight, outWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth, outShape } = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
          util_exports.assert(dy.rank === outShape.length, () => `Error in ${Dilation2DBackpropInput}, dy must have the same rank as output ${outShape.length}, but got ${dy.rank}`);
          const $dy = util_exports.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);
          const gradients = util_exports.makeZerosNestedTypedArray(x.shape, x.dtype);
          for (let b = 0; b < batchSize; ++b) {
            for (let hOut = 0; hOut < outHeight; ++hOut) {
              const hBeg = hOut * strideHeight - padInfo.top;
              for (let wOut = 0; wOut < outWidth; ++wOut) {
                const wBeg = wOut * strideWidth - padInfo.left;
                for (let d = 0; d < inChannels; ++d) {
                  let curVal = Number.MIN_SAFE_INTEGER;
                  let hInMax = hBeg < 0 ? 0 : hBeg;
                  let wInMax = wBeg < 0 ? 0 : wBeg;
                  for (let h = 0; h < filterHeight; ++h) {
                    const hIn = hBeg + h * dilationHeight;
                    if (hIn >= 0 && hIn < inHeight) {
                      for (let w = 0; w < filterWidth; ++w) {
                        const wIn = wBeg + w * dilationWidth;
                        if (wIn >= 0 && wIn < inWidth) {
                          const val = $x[b][hIn][wIn][d] + $filter[h][w][d];
                          if (val > curVal) {
                            curVal = val;
                            hInMax = hIn;
                            wInMax = wIn;
                          }
                        }
                      }
                    }
                  }
                  gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];
                }
              }
            }
          }
          const dataId = cpuBackend.write(util_exports.toTypedArray(gradients, x.dtype), x.shape, x.dtype);
          return { dataId, shape: x.shape, dtype: x.dtype };
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sum.js
  function sum3(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    assertNotComplex(x, "sum");
    let $x;
    if (x.dtype === "bool") {
      $x = cast2({ inputs: { x }, backend, attrs: { dtype: "int32" } });
    } else {
      $x = identity({ inputs: { x }, backend });
    }
    const xRank = $x.shape.length;
    const axes = util_exports.parseAxisParam(axis, $x.shape);
    const permutation = backend_util_exports.getAxesPermutation(axes, xRank);
    let reductionAxes = axes;
    let permutedX = $x;
    if (permutation != null) {
      permutedX = transpose2({ inputs: { x: $x }, backend, attrs: { perm: permutation } });
      reductionAxes = backend_util_exports.getInnerMostAxes(reductionAxes.length, xRank);
    }
    backend_util_exports.assertAxesAreInnerMostDims("sum", reductionAxes, permutedX.shape.length);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(permutedX.shape, reductionAxes);
    const resultDtype = backend_util_exports.upcastType(permutedX.dtype, "int32");
    let result = zeros2(backend, outShape, resultDtype);
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const vals = backend.data.get(result.dataId).values;
    const aVals = backend.data.get(permutedX.dataId).values;
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let sum4 = 0;
      for (let j2 = 0; j2 < reduceSize; ++j2) {
        sum4 += aVals[offset + j2];
      }
      vals[i] = sum4;
    }
    if (keepDims) {
      const newShape = backend_util_exports.expandShapeToKeepDim(result.shape, axes);
      const oldResult = result;
      result = reshape2({ inputs: { x: result }, backend, attrs: { shape: newShape } });
      backend.disposeIntermediateTensorInfo(oldResult);
    }
    backend.disposeIntermediateTensorInfo($x);
    if (permutation != null) {
      backend.disposeIntermediateTensorInfo(permutedX);
    }
    return result;
  }
  var sumConfig;
  var init_Sum = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sum.js"() {
      init_dist();
      init_cpu_util();
      init_zeros_impl();
      init_Cast();
      init_Identity();
      init_Reshape();
      init_Transpose();
      sumConfig = {
        kernelName: Sum,
        backendName: "cpu",
        kernelFunc: sum3
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Einsum.js
  function einsum2(args) {
    const { inputs, backend, attrs } = args;
    const { equation } = attrs;
    const tensors = inputs;
    const { allDims, summedDims, idDims } = backend_util_exports.decodeEinsumEquation(equation, tensors.length);
    backend_util_exports.checkEinsumDimSizes(allDims.length, idDims, tensors);
    const { path, steps } = backend_util_exports.getEinsumComputePath(summedDims, idDims);
    const nSteps = steps.length;
    let out = null;
    let numDimsRemaining = allDims.length;
    const tensorsToDispose = [];
    for (let i = 0; i < nSteps; ++i) {
      for (const idTerm of steps[i]) {
        const { permutationIndices: perm, expandDims: dimsToExpand } = backend_util_exports.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);
        let x;
        if (backend_util_exports.isIdentityPermutation(perm)) {
          x = tensors[idTerm];
        } else {
          x = transpose2({ inputs: { x: tensors[idTerm] }, backend, attrs: { perm } });
          tensorsToDispose.push(x);
        }
        const targetShape = x.shape.slice();
        for (let k3 = 0; k3 < dimsToExpand.length; ++k3) {
          targetShape.splice(dimsToExpand[k3], 0, 1);
        }
        if (!util_exports.arraysEqual(x.shape, targetShape)) {
          x = reshape2({ inputs: { x }, backend, attrs: { shape: targetShape } });
          tensorsToDispose.push(x);
        }
        if (out === null) {
          out = x;
        } else {
          out = multiply({ inputs: { a: x, b: out }, backend });
          tensorsToDispose.push(out);
        }
      }
      if (i < nSteps - 1) {
        if (path[i] >= 0) {
          out = sum3({
            inputs: { x: out },
            backend,
            attrs: {
              axis: path[i] - (allDims.length - numDimsRemaining),
              keepDims: false
            }
          });
          tensorsToDispose.push(out);
        }
        numDimsRemaining--;
      }
    }
    for (const tensorInfo of tensorsToDispose) {
      if (tensorInfo === out) {
        continue;
      }
      backend.disposeIntermediateTensorInfo(tensorInfo);
    }
    return out;
  }
  var einsumConfig;
  var init_Einsum = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Einsum.js"() {
      init_dist();
      init_Multiply();
      init_Reshape();
      init_Sum();
      init_Transpose();
      einsumConfig = {
        kernelName: Einsum,
        backendName: "cpu",
        kernelFunc: einsum2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/EluGrad.js
  function eluGrad(args) {
    const { inputs, backend } = args;
    const { dy, y } = inputs;
    assertNotComplex([dy, y], "eluGrad");
    const resultValues = new Float32Array(util_exports.sizeFromShape(y.shape));
    const values = backend.data.get(y.dataId).values;
    const dyValues = backend.data.get(dy.dataId).values;
    for (let i = 0; i < values.length; ++i) {
      const v = values[i];
      if (v >= 1) {
        resultValues[i] = dyValues[i];
      } else {
        resultValues[i] = dyValues[i] * (v + 1);
      }
    }
    return backend.makeTensorInfo(y.shape, "float32", resultValues);
  }
  var eluGradConfig;
  var init_EluGrad = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/EluGrad.js"() {
      init_dist();
      init_cpu_util();
      eluGradConfig = {
        kernelName: EluGrad,
        backendName: "cpu",
        kernelFunc: eluGrad
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Erf.js
  var p, a1, a2, a3, a4, a5, erf2, erfConfig;
  var init_Erf = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Erf.js"() {
      init_dist();
      init_unary_utils();
      p = backend_util_exports.ERF_P;
      a1 = backend_util_exports.ERF_A1;
      a2 = backend_util_exports.ERF_A2;
      a3 = backend_util_exports.ERF_A3;
      a4 = backend_util_exports.ERF_A4;
      a5 = backend_util_exports.ERF_A5;
      erf2 = unaryKernelFunc(Erf, (xi) => {
        const sign3 = Math.sign(xi);
        const v = Math.abs(xi);
        const t2 = 1 / (1 + p * v);
        return sign3 * (1 - ((((a5 * t2 + a4) * t2 + a3) * t2 + a2) * t2 + a1) * t2 * Math.exp(-v * v));
      });
      erfConfig = {
        kernelName: Erf,
        backendName: "cpu",
        kernelFunc: erf2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ExpandDims.js
  function expandDims2(args) {
    const { inputs, backend, attrs } = args;
    const { input } = inputs;
    const { dim } = attrs;
    const inputRank = input.shape.length;
    const newShape = input.shape.slice();
    let $dim = dim;
    if (dim < 0) {
      util_exports.assert(-(inputRank + 1) <= dim, () => `Axis must be in the interval [${-(inputRank + 1)}, ${inputRank}]`);
      $dim = inputRank + dim + 1;
    }
    newShape.splice($dim, 0, 1);
    return reshape2({ inputs: { x: input }, backend, attrs: { shape: newShape } });
  }
  var expandDimsConfig;
  var init_ExpandDims = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ExpandDims.js"() {
      init_dist();
      init_Reshape();
      expandDimsConfig = {
        kernelName: ExpandDims,
        backendName: "cpu",
        kernelFunc: expandDims2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RealDiv.js
  var realDivImpl, div2, realDivConfig;
  var init_RealDiv = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RealDiv.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      realDivImpl = createSimpleBinaryKernelImpl((a, b) => a / b);
      div2 = binaryKernelFunc(RealDiv, realDivImpl);
      realDivConfig = {
        kernelName: RealDiv,
        backendName: "cpu",
        kernelFunc: div2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/fft_utils.js
  function fftBatch(input, inverse, cpuBackend) {
    const inputShape = input.shape;
    const batch = inputShape[0];
    const innerDim = inputShape[1];
    const inputVals = cpuBackend.data.get(input.dataId);
    const real2D = inputVals.complexTensorInfos.real;
    const imag2D = inputVals.complexTensorInfos.imag;
    const resultShape = [batch, innerDim];
    const resultSize = util_exports.sizeFromShape(resultShape);
    const resultReal = util_exports.getTypedArrayFromDType("float32", resultSize);
    const resultImag = util_exports.getTypedArrayFromDType("float32", resultSize);
    for (let b = 0; b < batch; b++) {
      const r = slice2({
        inputs: { x: real2D },
        backend: cpuBackend,
        attrs: { begin: [b, 0], size: [1, innerDim] }
      });
      const i = slice2({
        inputs: { x: imag2D },
        backend: cpuBackend,
        attrs: { begin: [b, 0], size: [1, innerDim] }
      });
      const input2 = complex2({ inputs: { real: r, imag: i }, backend: cpuBackend });
      const { real: real3, imag: imag3 } = fftImpl(input2, inverse, cpuBackend);
      const res = backend_util_exports.mergeRealAndImagArrays(real3, imag3);
      for (let d = 0; d < innerDim; d++) {
        const c = backend_util_exports.getComplexWithIndex(res, d);
        resultReal[b * innerDim + d] = c.real;
        resultImag[b * innerDim + d] = c.imag;
      }
      cpuBackend.disposeIntermediateTensorInfo(r);
      cpuBackend.disposeIntermediateTensorInfo(i);
      cpuBackend.disposeIntermediateTensorInfo(input2);
    }
    const $realInfo = cpuBackend.makeTensorInfo(resultShape, "float32", resultReal);
    const $imagInfo = cpuBackend.makeTensorInfo(resultShape, "float32", resultImag);
    const result = complex2({ inputs: { real: $realInfo, imag: $imagInfo }, backend: cpuBackend });
    cpuBackend.disposeIntermediateTensorInfo($realInfo);
    cpuBackend.disposeIntermediateTensorInfo($imagInfo);
    return result;
  }
  function fftImpl(input, inverse, cpuBackend) {
    const inputSize = util_exports.sizeFromShape(input.shape);
    const inputVals = cpuBackend.data.get(input.dataId);
    const realVals = cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values;
    const imagVals = cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values;
    if (isExponentOf2(inputSize)) {
      const result = fftRadix2(realVals, imagVals, inputSize, inverse, cpuBackend);
      const resultShape = [input.shape[0], input.shape[1]];
      if (inverse) {
        const realInfo = cpuBackend.makeTensorInfo(resultShape, "float32", result.real);
        const imagInfo = cpuBackend.makeTensorInfo(resultShape, "float32", result.imag);
        const sizeInfo = cpuBackend.makeTensorInfo([], "float32", util_exports.createScalarValue(inputSize, "float32"));
        const sizeInfoCopy = identity({ inputs: { x: sizeInfo }, backend: cpuBackend });
        const divRealInfo = realDivConfig.kernelFunc({ inputs: { a: realInfo, b: sizeInfo }, backend: cpuBackend });
        const divImagInfo = realDivConfig.kernelFunc({ inputs: { a: imagInfo, b: sizeInfoCopy }, backend: cpuBackend });
        const divRealVals = cpuBackend.data.get(divRealInfo.dataId).values;
        const divImagVals = cpuBackend.data.get(divImagInfo.dataId).values;
        cpuBackend.disposeIntermediateTensorInfo(realInfo);
        cpuBackend.disposeIntermediateTensorInfo(imagInfo);
        cpuBackend.disposeIntermediateTensorInfo(sizeInfo);
        cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy);
        cpuBackend.disposeIntermediateTensorInfo(divRealInfo);
        cpuBackend.disposeIntermediateTensorInfo(divImagInfo);
        return { real: divRealVals, imag: divImagVals };
      }
      return result;
    } else {
      const data = backend_util_exports.mergeRealAndImagArrays(realVals, imagVals);
      const rawOutput = fourierTransformByMatmul(data, inputSize, inverse);
      return backend_util_exports.splitRealAndImagArrays(rawOutput);
    }
  }
  function isExponentOf2(size) {
    return (size & size - 1) === 0;
  }
  function fftRadix2(realVals, imagVals, size, inverse, cpuBackend) {
    if (size === 1) {
      return { real: realVals, imag: imagVals };
    }
    const data = backend_util_exports.mergeRealAndImagArrays(realVals, imagVals);
    const half = size / 2;
    const evenComplex = backend_util_exports.complexWithEvenIndex(data);
    const evenRealVals = evenComplex.real;
    const evenImagVals = evenComplex.imag;
    const evenShape = [evenRealVals.length];
    const evenRealInfo = cpuBackend.makeTensorInfo(evenShape, "float32", evenRealVals);
    const evenImagInfo = cpuBackend.makeTensorInfo(evenShape, "float32", evenImagVals);
    const evenTensorInfo = complex2({ inputs: { real: evenRealInfo, imag: evenImagInfo }, backend: cpuBackend });
    const oddComplex = backend_util_exports.complexWithOddIndex(data);
    const oddRealVals = oddComplex.real;
    const oddImagVals = oddComplex.imag;
    const oddShape = [oddRealVals.length];
    const oddRealInfo = cpuBackend.makeTensorInfo(oddShape, "float32", oddRealVals);
    const oddImagInfo = cpuBackend.makeTensorInfo(oddShape, "float32", oddImagVals);
    const oddTensorInfo = complex2({ inputs: { real: oddRealInfo, imag: oddImagInfo }, backend: cpuBackend });
    const $evenComplex = fftRadix2(evenRealVals, evenImagVals, half, inverse, cpuBackend);
    const $evenRealVals = $evenComplex.real;
    const $evenImagVals = $evenComplex.imag;
    const $evenShape = [$evenRealVals.length];
    const $evenRealInfo = cpuBackend.makeTensorInfo($evenShape, "float32", $evenRealVals);
    const $evenImagInfo = cpuBackend.makeTensorInfo($evenShape, "float32", $evenImagVals);
    const $evenTensorInfo = complex2({
      inputs: { real: $evenRealInfo, imag: $evenImagInfo },
      backend: cpuBackend
    });
    const $oddComplex = fftRadix2(oddRealVals, oddImagVals, half, inverse, cpuBackend);
    const $oddRealVals = $oddComplex.real;
    const $oddImagVals = $oddComplex.imag;
    const $oddShape = [$oddRealVals.length];
    const $oddRealInfo = cpuBackend.makeTensorInfo($oddShape, "float32", $oddRealVals);
    const $oddImagInfo = cpuBackend.makeTensorInfo($oddShape, "float32", $oddImagVals);
    const $oddTensorInfo = complex2({ inputs: { real: $oddRealInfo, imag: $oddImagInfo }, backend: cpuBackend });
    const e = backend_util_exports.exponents(size, inverse);
    const eShape = [e.real.length];
    const eRealInfo = cpuBackend.makeTensorInfo(eShape, "float32", e.real);
    const eImagInfo = cpuBackend.makeTensorInfo(eShape, "float32", e.imag);
    const complexInfo = complex2({ inputs: { real: eRealInfo, imag: eImagInfo }, backend: cpuBackend });
    const exponentInfo = multiply({ inputs: { a: complexInfo, b: $oddTensorInfo }, backend: cpuBackend });
    const addPart = add3({
      inputs: { a: $evenTensorInfo, b: exponentInfo },
      backend: cpuBackend
    });
    const subPart = sub2({
      inputs: { a: $evenTensorInfo, b: exponentInfo },
      backend: cpuBackend
    });
    const addPartReal = real2({ inputs: { input: addPart }, backend: cpuBackend });
    const subPartReal = real2({ inputs: { input: subPart }, backend: cpuBackend });
    const addPartImag = imag2({ inputs: { input: addPart }, backend: cpuBackend });
    const subPartImag = imag2({ inputs: { input: subPart }, backend: cpuBackend });
    const $real = concat2({
      inputs: [addPartReal, subPartReal],
      backend: cpuBackend,
      attrs: { axis: 0 }
    });
    const $imag = concat2({
      inputs: [addPartImag, subPartImag],
      backend: cpuBackend,
      attrs: { axis: 0 }
    });
    const $realVals = cpuBackend.data.get($real.dataId).values;
    const $imagVals = cpuBackend.data.get($imag.dataId).values;
    cpuBackend.disposeIntermediateTensorInfo(evenRealInfo);
    cpuBackend.disposeIntermediateTensorInfo(evenImagInfo);
    cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo);
    cpuBackend.disposeIntermediateTensorInfo(oddRealInfo);
    cpuBackend.disposeIntermediateTensorInfo(oddImagInfo);
    cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo);
    cpuBackend.disposeIntermediateTensorInfo($evenRealInfo);
    cpuBackend.disposeIntermediateTensorInfo($evenImagInfo);
    cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo);
    cpuBackend.disposeIntermediateTensorInfo($oddRealInfo);
    cpuBackend.disposeIntermediateTensorInfo($oddImagInfo);
    cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo);
    cpuBackend.disposeIntermediateTensorInfo(eRealInfo);
    cpuBackend.disposeIntermediateTensorInfo(eImagInfo);
    cpuBackend.disposeIntermediateTensorInfo(complexInfo);
    cpuBackend.disposeIntermediateTensorInfo(exponentInfo);
    cpuBackend.disposeIntermediateTensorInfo(addPart);
    cpuBackend.disposeIntermediateTensorInfo(subPart);
    cpuBackend.disposeIntermediateTensorInfo(addPartReal);
    cpuBackend.disposeIntermediateTensorInfo(addPartImag);
    cpuBackend.disposeIntermediateTensorInfo(subPartReal);
    cpuBackend.disposeIntermediateTensorInfo(subPartImag);
    cpuBackend.disposeIntermediateTensorInfo($real);
    cpuBackend.disposeIntermediateTensorInfo($imag);
    return { real: $realVals, imag: $imagVals };
  }
  function fourierTransformByMatmul(data, size, inverse) {
    const ret = new Float32Array(size * 2);
    for (let r = 0; r < size; r++) {
      let real3 = 0;
      let imag3 = 0;
      for (let c = 0; c < size; c++) {
        const e = backend_util_exports.exponent(r * c, size, inverse);
        const term = backend_util_exports.getComplexWithIndex(data, c);
        real3 += term.real * e.real - term.imag * e.imag;
        imag3 += term.real * e.imag + term.imag * e.real;
      }
      if (inverse) {
        real3 /= size;
        imag3 /= size;
      }
      backend_util_exports.assignToTypedArray(ret, real3, imag3, r);
    }
    return ret;
  }
  var init_fft_utils = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/fft_utils.js"() {
      init_dist();
      init_Add();
      init_Complex();
      init_Concat();
      init_Identity();
      init_Imag();
      init_Multiply();
      init_Real();
      init_RealDiv();
      init_Slice();
      init_Sub();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FFT.js
  function fft2(args) {
    const { inputs, backend } = args;
    const { input } = inputs;
    const inputSize = util_exports.sizeFromShape(input.shape);
    const innerDimensionSize = input.shape[input.shape.length - 1];
    const batch = inputSize / innerDimensionSize;
    const input2D = reshape2({
      inputs: { x: input },
      backend,
      attrs: { shape: [batch, innerDimensionSize] }
    });
    const result = fftBatch(input2D, false, backend);
    const resultReshaped = reshape2({ inputs: { x: result }, backend, attrs: { shape: input.shape } });
    backend.disposeIntermediateTensorInfo(input2D);
    backend.disposeIntermediateTensorInfo(result);
    return resultReshaped;
  }
  var fftConfig;
  var init_FFT = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FFT.js"() {
      init_dist();
      init_fft_utils();
      init_Reshape();
      fftConfig = {
        kernelName: FFT,
        backendName: "cpu",
        kernelFunc: fft2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Fill.js
  function fill2(args) {
    const { backend, attrs } = args;
    const { shape, value, dtype } = attrs;
    const $dtype = dtype || util_exports.inferDtype(value);
    const values = util_exports.getArrayFromDType($dtype, util_exports.sizeFromShape(shape));
    fillValues(values, value, $dtype);
    return backend.makeTensorInfo(shape, $dtype, values);
  }
  function fillValues(values, value, dtype) {
    if (dtype === "string") {
      values.fill(value);
    } else {
      values.fill(value);
    }
  }
  var fillConfig;
  var init_Fill = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Fill.js"() {
      init_dist();
      fillConfig = {
        kernelName: Fill,
        backendName: "cpu",
        kernelFunc: fill2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FlipLeftRight.js
  var flipLeftRightConfig;
  var init_FlipLeftRight = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FlipLeftRight.js"() {
      init_dist();
      flipLeftRightConfig = {
        kernelName: FlipLeftRight,
        backendName: "cpu",
        kernelFunc: ({ inputs, attrs, backend }) => {
          const { image: image2 } = inputs;
          const cpuBackend = backend;
          const output = util_exports.getTypedArrayFromDType(image2.dtype, util_exports.sizeFromShape(image2.shape));
          const [batch, imageHeight, imageWidth, numChannels] = image2.shape;
          const imageVals = cpuBackend.data.get(image2.dataId).values;
          for (let batchIdx = 0; batchIdx < batch; batchIdx++) {
            const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;
            for (let row = 0; row < imageHeight; row++) {
              const rowOffset = row * (imageWidth * numChannels);
              for (let col = 0; col < imageWidth; col++) {
                const colOffset = col * numChannels;
                for (let channel = 0; channel < numChannels; channel++) {
                  const coordX = Math.round(imageWidth - col - 1);
                  const outIdx = batchOffset + rowOffset + colOffset + channel;
                  let outputValue = imageVals[outIdx];
                  if (coordX >= 0 && coordX < imageWidth) {
                    const rotatedColOffset = coordX * numChannels;
                    const imageIdx = batchOffset + rowOffset + rotatedColOffset + channel;
                    outputValue = imageVals[imageIdx];
                  }
                  output[outIdx] = outputValue;
                }
              }
            }
          }
          const dataId = cpuBackend.write(output, image2.shape, image2.dtype);
          return { dataId, shape: image2.shape, dtype: image2.dtype };
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FloorDiv.js
  var floorDivImpl, floorDiv2, floorDivConfig;
  var init_FloorDiv = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FloorDiv.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      floorDivImpl = createSimpleBinaryKernelImpl((a, b) => Math.floor(a / b));
      floorDiv2 = binaryKernelFunc(FloorDiv, floorDivImpl, null, "int32");
      floorDivConfig = {
        kernelName: FloorDiv,
        backendName: "cpu",
        kernelFunc: floorDiv2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FusedConv2D.js
  function fusedConv2D(args) {
    const { inputs, backend, attrs } = args;
    const { x, filter, bias, preluActivationWeights } = inputs;
    const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
    let result = conv2D({
      inputs: { x, filter },
      backend,
      attrs: { strides, pad: pad2, dataFormat, dilations, dimRoundingMode }
    });
    if (bias) {
      const resultOld = result;
      if (dataFormat === "NCHW" && bias.shape.length === 1 && bias.shape[0] !== 1) {
        const reshapedBias = reshape2({ inputs: { x: bias }, backend, attrs: { shape: [bias.shape[0], 1, 1] } });
        result = add3({ inputs: { a: result, b: reshapedBias }, backend });
        backend.disposeIntermediateTensorInfo(reshapedBias);
      } else {
        result = add3({ inputs: { a: result, b: bias }, backend });
      }
      backend.disposeIntermediateTensorInfo(resultOld);
    }
    if (activation) {
      const resultOld = result;
      if (dataFormat === "NCHW" && activation === "prelu" && preluActivationWeights.shape.length === 1 && preluActivationWeights.shape[0] !== 1) {
        const reshapedAlpha = reshape2({
          inputs: { x: preluActivationWeights },
          backend,
          attrs: { shape: [preluActivationWeights.shape[0], 1, 1] }
        });
        result = applyActivation2(backend, result, activation, reshapedAlpha, leakyreluAlpha);
        backend.disposeIntermediateTensorInfo(reshapedAlpha);
      } else {
        result = applyActivation2(backend, result, activation, preluActivationWeights, leakyreluAlpha);
      }
      backend.disposeIntermediateTensorInfo(resultOld);
    }
    return result;
  }
  var fusedConv2DConfig;
  var init_FusedConv2D = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FusedConv2D.js"() {
      init_dist();
      init_fused_utils();
      init_Add();
      init_Conv2D();
      init_Reshape();
      fusedConv2DConfig = {
        kernelName: FusedConv2D,
        backendName: "cpu",
        kernelFunc: fusedConv2D
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FusedDepthwiseConv2D.js
  function fusedDepthwiseConv2D(args) {
    const { inputs, backend, attrs } = args;
    const { x, filter, bias, preluActivationWeights } = inputs;
    const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
    let result = depthwiseConv2dNative({
      inputs: { x, filter },
      backend,
      attrs: { strides, pad: pad2, dataFormat, dilations, dimRoundingMode }
    });
    if (bias) {
      const oldResult = result;
      result = add3({ inputs: { a: result, b: bias }, backend });
      backend.disposeIntermediateTensorInfo(oldResult);
    }
    if (activation) {
      const oldResult = result;
      result = applyActivation2(backend, result, activation, preluActivationWeights, leakyreluAlpha);
      backend.disposeIntermediateTensorInfo(oldResult);
    }
    return result;
  }
  var fusedDepthwiseConv2DConfig;
  var init_FusedDepthwiseConv2D = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FusedDepthwiseConv2D.js"() {
      init_dist();
      init_fused_utils();
      init_Add();
      init_DepthwiseConv2dNative();
      fusedDepthwiseConv2DConfig = {
        kernelName: FusedDepthwiseConv2D,
        backendName: "cpu",
        kernelFunc: fusedDepthwiseConv2D
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd.js
  function gatherNd(args) {
    const { inputs, backend } = args;
    const { params, indices } = inputs;
    const paramsSize = util_exports.sizeFromShape(params.shape);
    const indicesShape = indices.shape;
    const sliceRank = indicesShape[indicesShape.length - 1];
    const [resultShape, numSlices, sliceSize, strides] = backend_util_exports.prepareAndValidate(params, indices);
    if (numSlices === 0) {
      return backend.makeTensorInfo(resultShape, params.dtype, []);
    }
    const indicesData = backend.data.get(indices.dataId).values;
    const paramsBuf = backend.bufferSync(params);
    const outBuf = gatherNdImpl(indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize, strides, params.shape, paramsSize);
    return backend.makeTensorInfo(resultShape, params.dtype, outBuf.values);
  }
  var gatherNdConfig;
  var init_GatherNd = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd.js"() {
      init_dist();
      init_GatherNd_Impl();
      gatherNdConfig = {
        kernelName: GatherNd,
        backendName: "cpu",
        kernelFunc: gatherNd
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2.js
  function gatherV2(args) {
    const { inputs, backend, attrs } = args;
    const { x, indices } = inputs;
    const { axis, batchDims } = attrs;
    assertNotComplex([x, indices], "gatherV2");
    const parsedAxis = util_exports.parseAxisParam(axis, x.shape)[0];
    const indicesVals = backend.data.get(indices.dataId).values;
    const axisDim = x.shape[parsedAxis];
    for (let i = 0; i < indicesVals.length; ++i) {
      const index = indicesVals[i];
      util_exports.assert(index <= axisDim - 1 && index >= 0, () => `GatherV2: the index value ${index} is not in [0, ${axisDim - 1}]`);
    }
    let $batchDims = batchDims;
    if (batchDims == null) {
      $batchDims = 0;
    }
    const indicesSize = util_exports.sizeFromShape(indices.shape);
    const shapeInfo = backend_util_exports.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, $batchDims);
    const flattenX = reshape2({
      inputs: { x },
      backend,
      attrs: {
        shape: [
          shapeInfo.batchSize,
          shapeInfo.outerSize,
          shapeInfo.dimSize,
          shapeInfo.sliceSize
        ]
      }
    });
    const flattenIndex = reshape2({
      inputs: { x: indices },
      backend,
      attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }
    });
    const flattenOutputShape = [
      shapeInfo.batchSize,
      shapeInfo.outerSize,
      indicesSize / shapeInfo.batchSize,
      shapeInfo.sliceSize
    ];
    const indicesBuf = backend.bufferSync(flattenIndex);
    const xBuf = backend.bufferSync(flattenX);
    const outBuf = gatherV2Impl(xBuf, indicesBuf, flattenOutputShape);
    backend.disposeIntermediateTensorInfo(flattenX);
    backend.disposeIntermediateTensorInfo(flattenIndex);
    return backend.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);
  }
  var gatherV2Config;
  var init_GatherV2 = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2.js"() {
      init_dist();
      init_cpu_util();
      init_GatherV2_impl();
      init_Reshape();
      gatherV2Config = {
        kernelName: GatherV2,
        backendName: "cpu",
        kernelFunc: gatherV2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IFFT.js
  function ifft2(args) {
    const { inputs, backend } = args;
    const { input } = inputs;
    const inputSize = util_exports.sizeFromShape(input.shape);
    const innerDimensionSize = input.shape[input.shape.length - 1];
    const batch = inputSize / innerDimensionSize;
    const input2D = reshape2({
      inputs: { x: input },
      backend,
      attrs: { shape: [batch, innerDimensionSize] }
    });
    const result = fftBatch(input2D, true, backend);
    const resultReshaped = reshape2({ inputs: { x: result }, backend, attrs: { shape: input.shape } });
    backend.disposeIntermediateTensorInfo(input2D);
    backend.disposeIntermediateTensorInfo(result);
    return resultReshaped;
  }
  var ifftConfig;
  var init_IFFT = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IFFT.js"() {
      init_dist();
      init_fft_utils();
      init_Reshape();
      ifftConfig = {
        kernelName: IFFT,
        backendName: "cpu",
        kernelFunc: ifft2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IsFinite.js
  var isFinite3, isFiniteConfig;
  var init_IsFinite = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IsFinite.js"() {
      init_dist();
      init_unary_utils();
      isFinite3 = unaryKernelFunc(IsFinite, (xi) => Number.isFinite(xi) ? 1 : 0, "bool");
      isFiniteConfig = {
        kernelName: IsFinite,
        backendName: "cpu",
        kernelFunc: isFinite3
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IsInf.js
  var isInf2, isInfConfig;
  var init_IsInf = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IsInf.js"() {
      init_dist();
      init_unary_utils();
      isInf2 = unaryKernelFunc(IsInf, (xi) => Math.abs(xi) === Infinity ? 1 : 0, "bool");
      isInfConfig = {
        kernelName: IsInf,
        backendName: "cpu",
        kernelFunc: isInf2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IsNaN.js
  var isNaN3, isNaNConfig;
  var init_IsNaN = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IsNaN.js"() {
      init_dist();
      init_unary_utils();
      isNaN3 = unaryKernelFunc(IsNan, (xi) => Number.isNaN(xi) ? 1 : 0, "bool");
      isNaNConfig = {
        kernelName: IsNan,
        backendName: "cpu",
        kernelFunc: isNaN3
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace.js
  function linSpace(args) {
    const { backend, attrs } = args;
    const { start, stop, num } = attrs;
    const outVals = linSpaceImpl(start, stop, num);
    return backend.makeTensorInfo([outVals.length], "float32", outVals);
  }
  var linSpaceConfig;
  var init_LinSpace = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace.js"() {
      init_dist();
      init_LinSpace_impl();
      linSpaceConfig = {
        kernelName: LinSpace,
        backendName: "cpu",
        kernelFunc: linSpace
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Log1p.js
  var log1p2, log1pConfig;
  var init_Log1p = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Log1p.js"() {
      init_dist();
      init_unary_utils();
      log1p2 = unaryKernelFunc(Log1p, (xi) => Math.log1p(xi));
      log1pConfig = {
        kernelName: Log1p,
        backendName: "cpu",
        kernelFunc: log1p2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalAnd.js
  var logicalAndImpl, logicalAnd2, logicalAndConfig;
  var init_LogicalAnd = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalAnd.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      logicalAndImpl = createSimpleBinaryKernelImpl((a, b) => a && b);
      logicalAnd2 = binaryKernelFunc(LogicalAnd, logicalAndImpl, null, "bool");
      logicalAndConfig = {
        kernelName: LogicalAnd,
        backendName: "cpu",
        kernelFunc: logicalAnd2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalNot.js
  var logicalNot2, logicalNotConfig;
  var init_LogicalNot = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalNot.js"() {
      init_dist();
      init_unary_utils();
      logicalNot2 = unaryKernelFunc(LogicalNot, (xi) => xi ? 0 : 1, "bool");
      logicalNotConfig = {
        kernelName: LogicalNot,
        backendName: "cpu",
        kernelFunc: logicalNot2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalOr.js
  var logicalOrImpl, logicalOr2, logicalOrConfig;
  var init_LogicalOr = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalOr.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      logicalOrImpl = createSimpleBinaryKernelImpl((a, b) => a || b);
      logicalOr2 = binaryKernelFunc(LogicalOr, logicalOrImpl, null, "bool");
      logicalOrConfig = {
        kernelName: LogicalOr,
        backendName: "cpu",
        kernelFunc: logicalOr2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LRN.js
  function lRN(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { depthRadius, bias, alpha, beta } = attrs;
    assertNotComplex(x, "LRN");
    const channels = x.shape[3];
    const maxD = channels - 1;
    const xValues = backend.data.get(x.dataId).values;
    const size = util_exports.sizeFromShape(x.shape);
    const result = new Float32Array(size);
    function sumAcrossChannels(offset) {
      const currentChannel = offset % channels;
      let beginSumOffset = offset - currentChannel + Math.max(0, currentChannel - depthRadius);
      const endSumOffset = offset - currentChannel + Math.min(currentChannel + depthRadius, maxD);
      let sum4 = 0;
      for (; beginSumOffset <= endSumOffset; beginSumOffset++) {
        const z2 = xValues[beginSumOffset];
        sum4 += z2 * z2;
      }
      return sum4;
    }
    for (let offset = 0; offset < size; offset++) {
      const sum4 = sumAcrossChannels(offset);
      const val = xValues[offset] * Math.pow(bias + alpha * sum4, -beta);
      result[offset] = val;
    }
    return backend.makeTensorInfo(x.shape, x.dtype, result);
  }
  var LRNConfig;
  var init_LRN = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LRN.js"() {
      init_dist();
      init_cpu_util();
      LRNConfig = {
        kernelName: LRN,
        backendName: "cpu",
        kernelFunc: lRN
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LRNGrad.js
  function lRNGrad(args) {
    const { inputs, backend, attrs } = args;
    const { x, y, dy } = inputs;
    const { depthRadius, bias, alpha, beta } = attrs;
    assertNotComplex(dy, "LRNGrad");
    const dySize = util_exports.sizeFromShape(dy.shape);
    const channels = dy.shape[3];
    const dyValues = backend.data.get(dy.dataId).values;
    const xValues = backend.data.get(x.dataId).values;
    const yValues = backend.data.get(y.dataId).values;
    const result = new Float32Array(dySize);
    const size = dySize;
    for (let offset = 0; offset < size; offset++) {
      const currentChannel = offset % channels;
      const depthBegin = offset - currentChannel + Math.max(0, currentChannel - depthRadius);
      const depthEnd = offset - currentChannel + Math.min(channels, currentChannel + depthRadius + 1);
      let norm2 = 0;
      for (let k3 = depthBegin; k3 < depthEnd; k3++) {
        norm2 += Math.pow(xValues[k3], 2);
      }
      norm2 = alpha * norm2 + bias;
      for (let k3 = depthBegin; k3 < depthEnd; k3++) {
        let dyi = -2 * alpha * beta * xValues[k3] * yValues[offset] / norm2;
        if (offset === k3) {
          dyi += Math.pow(norm2, -beta);
        }
        dyi *= dyValues[offset];
        result[k3] += dyi;
      }
    }
    return backend.makeTensorInfo(dy.shape, x.dtype, result);
  }
  var LRNGradConfig;
  var init_LRNGrad = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LRNGrad.js"() {
      init_dist();
      init_cpu_util();
      LRNGradConfig = {
        kernelName: LRNGrad,
        backendName: "cpu",
        kernelFunc: lRNGrad
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Max.js
  function max2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { reductionIndices, keepDims } = attrs;
    const cpuBackend = backend;
    let xShape = x.shape;
    const xRank = xShape.length;
    const origAxes = util_exports.parseAxisParam(reductionIndices, xShape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
    let xVals = cpuBackend.data.get(x.dataId).values;
    if (permutedAxes != null) {
      const newShape = new Array(xRank);
      for (let i = 0; i < newShape.length; i++) {
        newShape[i] = xShape[permutedAxes[i]];
      }
      xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);
      axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
      xShape = newShape;
    }
    assertNotComplex(x, "max");
    backend_util_exports.assertAxesAreInnerMostDims("max", axes, xRank);
    const [maxOutShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(xShape, axes);
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);
    const dataId = cpuBackend.write(result, maxOutShape, x.dtype);
    let outShape = maxOutShape;
    if (keepDims) {
      const newShape = backend_util_exports.expandShapeToKeepDim(maxOutShape, origAxes);
      outShape = newShape;
    }
    return { dataId, shape: outShape, dtype: x.dtype };
  }
  var maxConfig;
  var init_Max = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Max.js"() {
      init_dist();
      init_dist();
      init_dist();
      init_cpu_util();
      init_Max_impl();
      init_Transpose_impl();
      maxConfig = {
        kernelName: Max,
        backendName: "cpu",
        kernelFunc: max2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool.js
  function maxPool2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    assertNotComplex(x, "maxPool");
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    const dilations = 1;
    util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
    let res;
    if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports.arraysEqual(convInfo.inShape, convInfo.outShape)) {
      res = identity({ inputs: { x }, backend });
    } else {
      const xValues = backend.data.get(x.dataId).values;
      const strides2 = util_exports.computeStrides(x.shape);
      const buffer2 = pool2(xValues, x.shape, x.dtype, strides2, convInfo, "max");
      res = backend.makeTensorInfo(convInfo.outShape, x.dtype, buffer2.values);
    }
    return res;
  }
  var maxPoolConfig;
  var init_MaxPool = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool.js"() {
      init_dist();
      init_cpu_util();
      init_pool_utils();
      init_Identity();
      maxPoolConfig = {
        kernelName: MaxPool,
        backendName: "cpu",
        kernelFunc: maxPool2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3D.js
  function maxPool3D(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat } = attrs;
    assertNotComplex(x, "maxPool3d");
    const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode, dataFormat);
    const xValues = backend.data.get(x.dataId).values;
    const outBuf = pool3d(xValues, x.shape, x.dtype, util_exports.computeStrides(x.shape), convInfo, "max");
    return backend.makeTensorInfo(outBuf.shape, "float32", outBuf.values);
  }
  var maxPool3DConfig;
  var init_MaxPool3D = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3D.js"() {
      init_dist();
      init_cpu_util();
      init_pool_utils();
      maxPool3DConfig = {
        kernelName: MaxPool3D,
        backendName: "cpu",
        kernelFunc: maxPool3D
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3DGrad.js
  function maxPool3DGrad(args) {
    const { inputs, backend, attrs } = args;
    const { dy, input } = inputs;
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    assertNotComplex([dy, input], "maxPool3DGrad");
    const convInfo = backend_util_exports.computePool3DInfo(input.shape, filterSize, strides, 1, pad2, dimRoundingMode);
    const inputBuf = backend.bufferSync(input);
    const maxPosBuf = maxPool3dPositions(inputBuf, convInfo);
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationDepth = convInfo.dilationDepth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterDepth = convInfo.effectiveFilterDepth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
    const dx = buffer(input.shape, "float32");
    const dyBuf = backend.bufferSync(dy);
    for (let batch = 0; batch < convInfo.batchSize; ++batch) {
      for (let channel = 0; channel < convInfo.inChannels; ++channel) {
        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {
          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {
            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {
              const dyDepthCorner = dxDepth - padFront;
              const dyRowCorner = dxRow - padTop;
              const dyColCorner = dxCol - padLeft;
              let dotProd = 0;
              for (let wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {
                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;
                if (dyDepth < 0 || dyDepth >= convInfo.outDepth || Math.floor(dyDepth) !== dyDepth) {
                  continue;
                }
                for (let wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {
                  const dyRow = (dyRowCorner + wRow) / strideHeight;
                  if (dyRow < 0 || dyRow >= convInfo.outHeight || Math.floor(dyRow) !== dyRow) {
                    continue;
                  }
                  for (let wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {
                    const dyCol = (dyColCorner + wCol) / strideWidth;
                    if (dyCol < 0 || dyCol >= convInfo.outWidth || Math.floor(dyCol) !== dyCol) {
                      continue;
                    }
                    const maxPos = effectiveFilterDepth * effectiveFilterHeight * effectiveFilterWidth - 1 - maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                    const curPos = wDepth * effectiveFilterHeight * effectiveFilterWidth + wRow * effectiveFilterWidth + wCol;
                    const mask = maxPos === curPos ? 1 : 0;
                    if (mask === 0) {
                      continue;
                    }
                    const pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                    dotProd += pixel * mask;
                  }
                }
              }
              dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);
            }
          }
        }
      }
    }
    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var maxPool3DGradConfig;
  var init_MaxPool3DGrad = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3DGrad.js"() {
      init_dist();
      init_cpu_util();
      init_pool_utils();
      maxPool3DGradConfig = {
        kernelName: MaxPool3DGrad,
        backendName: "cpu",
        kernelFunc: maxPool3DGrad
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolGrad.js
  function maxPoolGrad(args) {
    const { inputs, backend, attrs } = args;
    const { dy, input, output } = inputs;
    const x = input;
    assertNotComplex([input, output], "maxPoolGrad");
    const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
    const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode);
    const xValues = backend.data.get(x.dataId).values;
    const maxPosBuf = buffer(convInfo.outShape, x.dtype, maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
    const dx = buffer(x.shape, "float32");
    const dyData = backend.data.get(dy.dataId).values;
    const dyBuf = buffer(dy.shape, "float32", dyData);
    for (let b = 0; b < convInfo.batchSize; ++b) {
      for (let d = 0; d < convInfo.inChannels; ++d) {
        for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {
          for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {
            const dyRCorner = dxR - padTop;
            const dyCCorner = dxC - padLeft;
            let dotProd = 0;
            for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {
              const dyR = (dyRCorner + wR) / strideHeight;
              if (dyR < 0 || dyR >= convInfo.outHeight || Math.floor(dyR) !== dyR) {
                continue;
              }
              for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {
                const dyC = (dyCCorner + wC) / strideWidth;
                if (dyC < 0 || dyC >= convInfo.outWidth || Math.floor(dyC) !== dyC) {
                  continue;
                }
                const maxPos = effectiveFilterHeight * effectiveFilterWidth - 1 - maxPosBuf.get(b, dyR, dyC, d);
                const curPos = wR * effectiveFilterWidth + wC;
                const mask = maxPos === curPos ? 1 : 0;
                if (mask === 0) {
                  continue;
                }
                const pixel = dyBuf.get(b, dyR, dyC, d);
                dotProd += pixel * mask;
              }
            }
            dx.set(dotProd, b, dxR, dxC, d);
          }
        }
      }
    }
    return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
  }
  var maxPoolGradConfig;
  var init_MaxPoolGrad = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolGrad.js"() {
      init_dist();
      init_cpu_util();
      init_pool_utils();
      maxPoolGradConfig = {
        kernelName: MaxPoolGrad,
        backendName: "cpu",
        kernelFunc: maxPoolGrad
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax_impl.js
  function maxPoolWithArgmaxImpl(xValues, xShape, dtype, includeBatchInIndex, convInfo) {
    const strides = util_exports.computeStrides(xShape);
    const maxPools = pool2(xValues, xShape, dtype, strides, convInfo, "max");
    const maxPositions = maxPoolPositions(xValues, xShape, dtype, convInfo, true, includeBatchInIndex);
    return [maxPools.values, maxPositions.values];
  }
  var init_MaxPoolWithArgmax_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax_impl.js"() {
      init_dist();
      init_pool_utils();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax.js
  var maxPoolWithArgmaxConfig;
  var init_MaxPoolWithArgmax = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax.js"() {
      init_dist();
      init_dist();
      init_cpu_util();
      init_MaxPoolWithArgmax_impl();
      maxPoolWithArgmaxConfig = {
        kernelName: MaxPoolWithArgmax,
        backendName: "cpu",
        kernelFunc: ({ inputs, attrs, backend }) => {
          const { x } = inputs;
          const { filterSize, strides, pad: pad2, includeBatchInIndex } = attrs;
          const cpuBackend = backend;
          assertNotComplex(x, "MaxPoolWithArgmax");
          const values = cpuBackend.data.get(x.dataId).values;
          const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, [1, 1], pad2);
          const [pooled, indexes] = maxPoolWithArgmaxImpl(values, x.shape, x.dtype, includeBatchInIndex, convInfo);
          const pooledDataId = cpuBackend.write(pooled, convInfo.outShape, x.dtype);
          const indexesDataId = cpuBackend.write(indexes, convInfo.outShape, x.dtype);
          return [
            { dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype },
            { dataId: indexesDataId, shape: convInfo.outShape, dtype: "int32" }
          ];
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Mean.js
  function mean2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    const axes = util_exports.parseAxisParam(axis, x.shape);
    const shapes = backend_util_exports.computeOutAndReduceShapes(x.shape, axes);
    const reduceShape = shapes[1];
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const toDispose = [];
    const reduceSizeScalar = backend.makeTensorInfo([], "float32", new Float32Array([reduceSize]));
    toDispose.push(reduceSizeScalar);
    const $x = cast2({ inputs: { x }, backend, attrs: { dtype: "float32" } });
    toDispose.push($x);
    const res = div2({ inputs: { a: $x, b: reduceSizeScalar }, backend });
    toDispose.push(res);
    const result = sum3({ inputs: { x: res }, backend, attrs: { axis, keepDims } });
    toDispose.forEach((t2) => backend.disposeIntermediateTensorInfo(t2));
    return result;
  }
  var meanConfig;
  var init_Mean = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Mean.js"() {
      init_dist();
      init_Cast();
      init_RealDiv();
      init_Sum();
      meanConfig = {
        kernelName: Mean,
        backendName: "cpu",
        kernelFunc: mean2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Min.js
  function min2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { axis, keepDims } = attrs;
    assertNotComplex(x, "min");
    const origAxes = util_exports.parseAxisParam(axis, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
    let $x = x;
    if (permutedAxes != null) {
      $x = transpose2({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
      axes = backend_util_exports.getInnerMostAxes(axes.length, x.shape.length);
    }
    backend_util_exports.assertAxesAreInnerMostDims("min", axes, $x.shape.length);
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
    const reduceSize = util_exports.sizeFromShape(reduceShape);
    const vals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), $x.dtype);
    const aVals = backend.data.get($x.dataId).values;
    for (let i = 0; i < vals.length; ++i) {
      const offset = i * reduceSize;
      let min3 = aVals[offset];
      for (let j2 = 0; j2 < reduceSize; ++j2) {
        const value = aVals[offset + j2];
        if (Number.isNaN(value) || value < min3) {
          min3 = value;
        }
      }
      vals[i] = min3;
    }
    if (permutedAxes != null) {
      backend.disposeIntermediateTensorInfo($x);
    }
    const result = backend.makeTensorInfo(outShape, $x.dtype, vals);
    if (keepDims) {
      const expandedShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
      const reshapedResult = reshape2({ inputs: { x: result }, backend, attrs: { shape: expandedShape } });
      backend.disposeIntermediateTensorInfo(result);
      return reshapedResult;
    }
    return result;
  }
  var minConfig;
  var init_Min = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Min.js"() {
      init_dist();
      init_cpu_util();
      init_Reshape();
      init_Transpose();
      minConfig = {
        kernelName: Min,
        backendName: "cpu",
        kernelFunc: min2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MirrorPad.js
  function mirrorPad2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { paddings, mode } = attrs;
    assertNotComplex(x, "mirrorPad");
    const outShape = paddings.map(
      (p2, i) => p2[0] + x.shape[i] + p2[1]
      /* afterPad */
    );
    const start = paddings.map((p2) => p2[0]);
    const end = paddings.map((p2, i) => p2[0] + x.shape[i]);
    const offset = mode === "reflect" ? 0 : 1;
    const xVals = backend.data.get(x.dataId).values;
    const xRank = x.shape.length;
    const xStrides = util_exports.computeStrides(x.shape);
    const resultSize = util_exports.sizeFromShape(outShape);
    const resultRank = outShape.length;
    const resultStrides = util_exports.computeStrides(outShape);
    const resVals = util_exports.getTypedArrayFromDType(x.dtype, resultSize);
    for (let i = 0; i < resultSize; i++) {
      let coords = util_exports.indexToLoc(i, resultRank, resultStrides);
      for (let i2 = 0; i2 < resultRank; i2++) {
        if (coords[i2] < start[i2]) {
          coords[i2] = start[i2] * 2 - coords[i2] - offset;
        } else if (coords[i2] >= end[i2]) {
          coords[i2] = (end[i2] - 1) * 2 - coords[i2] + offset;
        }
      }
      coords = coords.map((c, i2) => c - start[i2]);
      const inIndex = util_exports.locToIndex(coords, xRank, xStrides);
      resVals[i] = xVals[inIndex];
    }
    const outId = backend.write(resVals, outShape, x.dtype);
    return { dataId: outId, shape: outShape, dtype: x.dtype };
  }
  var mirrorPadConfig;
  var init_MirrorPad = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MirrorPad.js"() {
      init_dist();
      init_cpu_util();
      mirrorPadConfig = {
        kernelName: MirrorPad,
        backendName: "cpu",
        kernelFunc: mirrorPad2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Mod.js
  var modImpl, mod2, modConfig;
  var init_Mod = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Mod.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      modImpl = createSimpleBinaryKernelImpl((aValue, bValue) => {
        const rem = aValue % bValue;
        if (aValue < 0 && bValue < 0 || aValue >= 0 && bValue >= 0) {
          return rem;
        } else {
          return (rem + bValue) % bValue;
        }
      });
      mod2 = binaryKernelFunc(Mod, modImpl);
      modConfig = {
        kernelName: Mod,
        backendName: "cpu",
        kernelFunc: mod2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Softmax.js
  function softmax2(args) {
    const { inputs, backend, attrs } = args;
    const { logits } = inputs;
    const { dim } = attrs;
    const logitsRank = logits.shape.length;
    let $dim = dim;
    if ($dim === -1) {
      $dim = logitsRank - 1;
    }
    if ($dim !== logitsRank - 1) {
      throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${logitsRank} and dim was ${$dim}`);
    }
    const axes = util_exports.parseAxisParam([$dim], logits.shape);
    const maxLogit = max2({
      inputs: { x: logits },
      backend,
      attrs: { reductionIndices: axes, keepDims: false }
    });
    const expandedShape = backend_util_exports.expandShapeToKeepDim(maxLogit.shape, axes);
    const maxLogitReshaped = reshape2({ inputs: { x: maxLogit }, backend, attrs: { shape: expandedShape } });
    const a = sub2({ inputs: { a: logits, b: maxLogitReshaped }, backend });
    const b = exp2({ inputs: { x: a }, backend });
    const sumExp = sum3({ inputs: { x: b }, backend, attrs: { axis: axes, keepDims: false } });
    const sumReshaped = reshape2({ inputs: { x: sumExp }, backend, attrs: { shape: expandedShape } });
    const result = div2({ inputs: { a: b, b: sumReshaped }, backend });
    backend.disposeIntermediateTensorInfo(maxLogit);
    backend.disposeIntermediateTensorInfo(maxLogitReshaped);
    backend.disposeIntermediateTensorInfo(a);
    backend.disposeIntermediateTensorInfo(b);
    backend.disposeIntermediateTensorInfo(sumExp);
    backend.disposeIntermediateTensorInfo(sumReshaped);
    return result;
  }
  var softmaxConfig;
  var init_Softmax = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Softmax.js"() {
      init_dist();
      init_Exp();
      init_Max();
      init_RealDiv();
      init_Reshape();
      init_Sub();
      init_Sum();
      softmaxConfig = {
        kernelName: Softmax,
        backendName: "cpu",
        kernelFunc: softmax2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Multinomial.js
  function multinomial2(args) {
    const { inputs, backend, attrs } = args;
    const { logits } = inputs;
    const { numSamples, seed, normalized } = attrs;
    assertNotComplex(logits, "multinomial");
    const probabilities = normalized ? logits : softmax2({ inputs: { logits }, backend, attrs: { dim: -1 } });
    const batchSize = probabilities.shape[0];
    const numEvents = probabilities.shape[1];
    const probVals = backend.data.get(probabilities.dataId).values;
    const resShape = [batchSize, numSamples];
    const resVals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(resShape), "int32");
    for (let b = 0; b < batchSize; ++b) {
      const offset = b * numEvents;
      const cdf = new Float32Array(numEvents - 1);
      cdf[0] = probVals[offset];
      for (let event = 1; event < cdf.length; ++event) {
        cdf[event] = cdf[event - 1] + probVals[offset + event];
      }
      const random = seedrandom2.alea(seed.toString());
      const outOffset = b * numSamples;
      for (let sampleId = 0; sampleId < numSamples; ++sampleId) {
        const r = random();
        resVals[outOffset + sampleId] = cdf.length;
        for (let event = 0; event < cdf.length; event++) {
          if (r < cdf[event]) {
            resVals[outOffset + sampleId] = event;
            break;
          }
        }
      }
    }
    if (!normalized) {
      backend.disposeIntermediateTensorInfo(probabilities);
    }
    return backend.makeTensorInfo(resShape, "int32", resVals);
  }
  var seedrandom2, multinomialConfig;
  var init_Multinomial = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Multinomial.js"() {
      init_dist();
      seedrandom2 = __toESM(require_seedrandom2());
      init_cpu_util();
      init_Softmax();
      multinomialConfig = {
        kernelName: Multinomial,
        backendName: "cpu",
        kernelFunc: multinomial2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV3.js
  function nonMaxSuppressionV3(args) {
    const { inputs, backend, attrs } = args;
    const { boxes, scores } = inputs;
    const { maxOutputSize, iouThreshold, scoreThreshold } = attrs;
    assertNotComplex(boxes, "NonMaxSuppression");
    const boxesVals = backend.data.get(boxes.dataId).values;
    const scoresVals = backend.data.get(scores.dataId).values;
    const { selectedIndices } = nonMaxSuppressionV3Impl2(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
    return backend.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices));
  }
  var nonMaxSuppressionV3Impl2, nonMaxSuppressionV3Config;
  var init_NonMaxSuppressionV3 = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV3.js"() {
      init_dist();
      init_cpu_util();
      nonMaxSuppressionV3Impl2 = kernel_impls_exports.nonMaxSuppressionV3Impl;
      nonMaxSuppressionV3Config = {
        kernelName: NonMaxSuppressionV3,
        backendName: "cpu",
        kernelFunc: nonMaxSuppressionV3
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV4.js
  function nonMaxSuppressionV4(args) {
    const { inputs, backend, attrs } = args;
    const { boxes, scores } = inputs;
    const { maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize } = attrs;
    assertNotComplex(boxes, "NonMaxSuppressionPadded");
    const boxesVals = backend.data.get(boxes.dataId).values;
    const scoresVals = backend.data.get(scores.dataId).values;
    const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl2(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);
    return [
      backend.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
      backend.makeTensorInfo([], "int32", new Int32Array([validOutputs]))
    ];
  }
  var nonMaxSuppressionV4Impl2, nonMaxSuppressionV4Config;
  var init_NonMaxSuppressionV4 = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV4.js"() {
      init_dist();
      init_cpu_util();
      nonMaxSuppressionV4Impl2 = kernel_impls_exports.nonMaxSuppressionV4Impl;
      nonMaxSuppressionV4Config = {
        kernelName: NonMaxSuppressionV4,
        backendName: "cpu",
        kernelFunc: nonMaxSuppressionV4
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV5.js
  function nonMaxSuppressionV5(args) {
    const { inputs, backend, attrs } = args;
    const { boxes, scores } = inputs;
    const { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma } = attrs;
    assertNotComplex(boxes, "NonMaxSuppressionWithScore");
    const boxesVals = backend.data.get(boxes.dataId).values;
    const scoresVals = backend.data.get(scores.dataId).values;
    const maxOutputSizeVal = maxOutputSize;
    const iouThresholdVal = iouThreshold;
    const scoreThresholdVal = scoreThreshold;
    const softNmsSigmaVal = softNmsSigma;
    const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl2(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal);
    return [
      backend.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
      backend.makeTensorInfo([selectedScores.length], "float32", new Float32Array(selectedScores))
    ];
  }
  var nonMaxSuppressionV5Impl2, nonMaxSuppressionV5Config;
  var init_NonMaxSuppressionV5 = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV5.js"() {
      init_dist();
      init_cpu_util();
      nonMaxSuppressionV5Impl2 = kernel_impls_exports.nonMaxSuppressionV5Impl;
      nonMaxSuppressionV5Config = {
        kernelName: NonMaxSuppressionV5,
        backendName: "cpu",
        kernelFunc: nonMaxSuppressionV5
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/OneHot.js
  function oneHot2(args) {
    const { inputs, backend, attrs } = args;
    const { indices } = inputs;
    const { dtype, depth, onValue, offValue } = attrs;
    assertNotComplex(indices, "oneHot");
    const indicesSize = util_exports.sizeFromShape(indices.shape);
    const res = new Float32Array(indicesSize * depth);
    res.fill(offValue);
    const indicesVal = backend.data.get(indices.dataId).values;
    for (let event = 0; event < indicesSize; ++event) {
      if (indicesVal[event] >= 0 && indicesVal[event] < depth) {
        res[event * depth + indicesVal[event]] = onValue;
      }
    }
    return backend.makeTensorInfo([...indices.shape, depth], dtype, res);
  }
  var oneHotConfig;
  var init_OneHot = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/OneHot.js"() {
      init_dist();
      init_cpu_util();
      oneHotConfig = {
        kernelName: OneHot,
        backendName: "cpu",
        kernelFunc: oneHot2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ZerosLike.js
  function zerosLike2(args) {
    const { inputs, backend } = args;
    const { x } = inputs;
    if (x.dtype === "string") {
      throw new Error("zerosLike is not supported for string tensors");
    } else if (x.dtype === "complex64") {
      const realPart = real2({ inputs: { input: x }, backend });
      const r = zerosLike2({ inputs: { x: realPart }, backend });
      const imagPart = imag2({ inputs: { input: x }, backend });
      const i = zerosLike2({ inputs: { x: imagPart }, backend });
      const result = complex2({ inputs: { real: r, imag: i }, backend });
      backend.disposeIntermediateTensorInfo(realPart);
      backend.disposeIntermediateTensorInfo(r);
      backend.disposeIntermediateTensorInfo(imagPart);
      backend.disposeIntermediateTensorInfo(i);
      return result;
    } else {
      return fill2({ backend, attrs: { shape: x.shape, value: 0, dtype: x.dtype } });
    }
  }
  var zerosLikeConfig;
  var init_ZerosLike = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ZerosLike.js"() {
      init_dist();
      init_Complex();
      init_Fill();
      init_Imag();
      init_Real();
      zerosLikeConfig = {
        kernelName: ZerosLike,
        backendName: "cpu",
        kernelFunc: zerosLike2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/OnesLike.js
  function onesLike2(args) {
    const { inputs, backend } = args;
    const { x } = inputs;
    if (x.dtype === "string") {
      throw new Error("onesLike is not supported for string tensors");
    } else if (x.dtype === "complex64") {
      const realPart = real2({ inputs: { input: x }, backend });
      const r = onesLike2({ inputs: { x: realPart }, backend });
      const imagPart = imag2({ inputs: { input: x }, backend });
      const i = zerosLike2({ inputs: { x: imagPart }, backend });
      const result = complex2({ inputs: { real: r, imag: i }, backend });
      backend.disposeIntermediateTensorInfo(realPart);
      backend.disposeIntermediateTensorInfo(r);
      backend.disposeIntermediateTensorInfo(imagPart);
      backend.disposeIntermediateTensorInfo(i);
      return result;
    } else {
      return fill2({ backend, attrs: { shape: x.shape, value: 1, dtype: x.dtype } });
    }
  }
  var onesLikeConfig;
  var init_OnesLike = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/OnesLike.js"() {
      init_dist();
      init_Complex();
      init_Fill();
      init_Imag();
      init_Real();
      init_ZerosLike();
      onesLikeConfig = {
        kernelName: OnesLike,
        backendName: "cpu",
        kernelFunc: onesLike2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Pack.js
  function pack(args) {
    const { inputs, backend, attrs } = args;
    const { axis } = attrs;
    if (inputs.length === 1) {
      return expandDims2({ inputs: { input: inputs[0] }, backend, attrs: { dim: axis } });
    }
    const shape = inputs[0].shape;
    const dtype = inputs[0].dtype;
    inputs.forEach((t2) => {
      util_exports.assertShapesMatch(shape, t2.shape, "All tensors passed to stack must have matching shapes");
      util_exports.assert(dtype === t2.dtype, () => "All tensors passed to stack must have matching dtypes");
    });
    const intermediateTensorInfos = [];
    const expandedTensors = inputs.map((t2) => {
      const expandedT = expandDims2({ inputs: { input: t2 }, backend, attrs: { dim: axis } });
      intermediateTensorInfos.push(expandedT);
      return expandedT;
    });
    const result = concat2({ inputs: expandedTensors, backend, attrs: { axis } });
    intermediateTensorInfos.forEach((t2) => backend.disposeIntermediateTensorInfo(t2));
    return result;
  }
  var packConfig;
  var init_Pack = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Pack.js"() {
      init_dist();
      init_Concat();
      init_ExpandDims();
      packConfig = {
        kernelName: Pack,
        backendName: "cpu",
        kernelFunc: pack
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/PadV2.js
  function padV2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { paddings, constantValue } = attrs;
    assertNotComplex(x, "pad");
    const outShape = paddings.map(
      (p2, i) => p2[0] + x.shape[i] + p2[1]
      /* afterPad */
    );
    const start = paddings.map((p2) => p2[0]);
    const xVals = backend.data.get(x.dataId).values;
    const xSize = util_exports.sizeFromShape(x.shape);
    const xRank = x.shape.length;
    const xStrides = util_exports.computeStrides(x.shape);
    const resultSize = util_exports.sizeFromShape(outShape);
    const resultRank = outShape.length;
    const resultStrides = util_exports.computeStrides(outShape);
    const resVals = util_exports.getTypedArrayFromDType(x.dtype, resultSize);
    if (constantValue !== 0) {
      resVals.fill(constantValue);
    }
    for (let i = 0; i < xSize; i++) {
      const coords = util_exports.indexToLoc(i, xRank, xStrides);
      const outCoords = coords.map((c, i2) => c + start[i2]);
      const outIndex = util_exports.locToIndex(outCoords, resultRank, resultStrides);
      resVals[outIndex] = xVals[i];
    }
    const outId = backend.write(resVals, outShape, x.dtype);
    return { dataId: outId, shape: outShape, dtype: x.dtype };
  }
  var padV2Config;
  var init_PadV2 = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/PadV2.js"() {
      init_dist();
      init_cpu_util();
      padV2Config = {
        kernelName: PadV2,
        backendName: "cpu",
        kernelFunc: padV2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Pow.js
  var powImpl, pow2, powConfig;
  var init_Pow = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Pow.js"() {
      init_dist();
      init_binary_impl();
      init_binary_utils();
      powImpl = createSimpleBinaryKernelImpl((a, b) => Math.pow(a, b));
      pow2 = binaryKernelFunc(Pow, powImpl);
      powConfig = {
        kernelName: Pow,
        backendName: "cpu",
        kernelFunc: pow2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather.js
  function raggedGather2(args) {
    const { inputs, backend, attrs } = args;
    const { paramsNestedSplits, paramsDenseValues, indices } = inputs;
    const { outputRaggedRank } = attrs;
    const $paramsNestedSplits = paramsNestedSplits.map((t2) => backend.data.get(t2.dataId).values);
    const $paramsNestedSplitsShapes = paramsNestedSplits.map((t2) => t2.shape);
    const $paramsDenseValues = backend.data.get(paramsDenseValues.dataId).values;
    const $indices = backend.data.get(indices.dataId).values;
    const [outputNestedSplits, outputDenseValues, outputDenseValuesShape] = raggedGatherImpl($paramsNestedSplits, $paramsNestedSplitsShapes, $paramsDenseValues, paramsDenseValues.shape, paramsDenseValues.dtype, $indices, indices.shape, outputRaggedRank);
    const outputNestedSplitsTensors = outputNestedSplits.map((splits) => backend.makeTensorInfo([splits.length], "int32", splits));
    const outputDenseValuesTensor = backend.makeTensorInfo(outputDenseValuesShape, paramsDenseValues.dtype, outputDenseValues);
    return outputNestedSplitsTensors.concat([outputDenseValuesTensor]);
  }
  var raggedGatherConfig;
  var init_RaggedGather = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather.js"() {
      init_dist();
      init_RaggedGather_impl();
      raggedGatherConfig = {
        kernelName: RaggedGather,
        backendName: "cpu",
        kernelFunc: raggedGather2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange.js
  function raggedRange2(args) {
    const { inputs, backend } = args;
    const { starts, limits, deltas } = inputs;
    const $starts = backend.data.get(starts.dataId).values;
    const $limits = backend.data.get(limits.dataId).values;
    const $deltas = backend.data.get(deltas.dataId).values;
    const [rtNestedSplitsData, rtDenseValuesData] = raggedRangeImpl($starts, starts.shape, starts.dtype, $limits, limits.shape, $deltas, deltas.shape);
    const rtNestedSplits = backend.makeTensorInfo([rtNestedSplitsData.length], "int32", rtNestedSplitsData);
    const rtDenseValues = backend.makeTensorInfo([rtDenseValuesData.length], starts.dtype, rtDenseValuesData);
    return [rtNestedSplits, rtDenseValues];
  }
  var raggedRangeConfig;
  var init_RaggedRange = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange.js"() {
      init_dist();
      init_RaggedRange_impl();
      raggedRangeConfig = {
        kernelName: RaggedRange,
        backendName: "cpu",
        kernelFunc: raggedRange2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor.js
  function raggedTensorToTensor2(args) {
    const { inputs, backend, attrs } = args;
    const { shape, values, defaultValue, rowPartitionTensors } = inputs;
    const { rowPartitionTypes } = attrs;
    const $shape = backend.data.get(shape.dataId).values;
    const $values = backend.data.get(values.dataId).values;
    const $defaultValue = backend.data.get(defaultValue.dataId).values;
    const $rowPartitionValues = rowPartitionTensors.map((t2) => backend.data.get(t2.dataId).values);
    const rowPartitionValuesShapes = rowPartitionTensors.map((t2) => t2.shape);
    const [outputShape, output] = raggedTensorToTensorImpl($shape, shape.shape, $values, values.shape, values.dtype, $defaultValue, defaultValue.shape, $rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes);
    return backend.makeTensorInfo(outputShape, values.dtype, output);
  }
  var raggedTensorToTensorConfig;
  var init_RaggedTensorToTensor = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor.js"() {
      init_dist();
      init_RaggedTensorToTensor_impl();
      raggedTensorToTensorConfig = {
        kernelName: RaggedTensorToTensor,
        backendName: "cpu",
        kernelFunc: raggedTensorToTensor2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Range.js
  function range2(args) {
    const { backend, attrs } = args;
    const { start, stop, dtype, step: step3 } = attrs;
    const values = rangeImpl(start, stop, step3, dtype);
    return backend.makeTensorInfo([values.length], dtype, values);
  }
  var rangeConfig;
  var init_Range = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Range.js"() {
      init_dist();
      init_Range_impl();
      rangeConfig = {
        kernelName: Range,
        backendName: "cpu",
        kernelFunc: range2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Reciprocal.js
  var reciprocal2, reciprocalConfig;
  var init_Reciprocal = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Reciprocal.js"() {
      init_dist();
      init_unary_utils();
      reciprocal2 = unaryKernelFunc(Reciprocal, (xi) => 1 / xi);
      reciprocalConfig = {
        kernelName: Reciprocal,
        backendName: "cpu",
        kernelFunc: reciprocal2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinear.js
  function resizeBilinear2(args) {
    const { inputs, backend, attrs } = args;
    const { images } = inputs;
    const { alignCorners, halfPixelCenters, size } = attrs;
    assertNotComplex(images, "resizeBilinear");
    const imagesStrides = util_exports.computeStrides(images.shape);
    const [newHeight, newWidth] = size;
    const [batch, oldHeight, oldWidth, numChannels] = images.shape;
    const xValues = backend.data.get(images.dataId).values;
    const result = new Float32Array(util_exports.sizeFromShape([batch, newHeight, newWidth, numChannels]));
    const effectiveInputSize = [
      alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
      alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
    ];
    const effectiveOutputSize = [
      alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
      alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
    ];
    let outputIdx = 0;
    const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];
    const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];
    for (let b = 0; b < batch; b++) {
      for (let r = 0; r < newHeight; r++) {
        let sourceFracRow;
        if (halfPixelCenters) {
          sourceFracRow = effectiveRowSizeRatio * (r + 0.5) - 0.5;
        } else {
          sourceFracRow = effectiveRowSizeRatio * r;
        }
        const sourceRowFloor = Math.max(0, Math.floor(sourceFracRow));
        const rowFrac = sourceFracRow - sourceRowFloor;
        const sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));
        const topRowOffset = b * imagesStrides[0] + sourceRowFloor * imagesStrides[1];
        const botRowOffset = b * imagesStrides[0] + sourceRowCeil * imagesStrides[1];
        for (let c = 0; c < newWidth; c++) {
          let sourceFracCol;
          if (halfPixelCenters) {
            sourceFracCol = effectiveColSizeRatio * (c + 0.5) - 0.5;
          } else {
            sourceFracCol = effectiveColSizeRatio * c;
          }
          const sourceColFloor = Math.max(0, Math.floor(sourceFracCol));
          const colFrac = sourceFracCol - sourceColFloor;
          const sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));
          const topLeftOffest = topRowOffset + sourceColFloor * imagesStrides[2];
          const botLeftOffset = botRowOffset + sourceColFloor * imagesStrides[2];
          const topRightOffset = topRowOffset + sourceColCeil * imagesStrides[2];
          const botRightOffest = botRowOffset + sourceColCeil * imagesStrides[2];
          for (let d = 0; d < numChannels; d++) {
            const topLeft = xValues[topLeftOffest + d];
            const bottomLeft = xValues[botLeftOffset + d];
            const topRight = xValues[topRightOffset + d];
            const bottomRight = xValues[botRightOffest + d];
            const top = topLeft + (topRight - topLeft) * colFrac;
            const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;
            const newValue = top + (bottom - top) * rowFrac;
            result[outputIdx++] = newValue;
          }
        }
      }
    }
    return backend.makeTensorInfo([batch, newHeight, newWidth, numChannels], "float32", result);
  }
  var resizeBilinearConfig;
  var init_ResizeBilinear = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinear.js"() {
      init_dist();
      init_cpu_util();
      resizeBilinearConfig = {
        kernelName: ResizeBilinear,
        backendName: "cpu",
        kernelFunc: resizeBilinear2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinearGrad.js
  function resizeBilinearGrad(args) {
    const { inputs, backend, attrs } = args;
    const { images, dy } = inputs;
    const { alignCorners } = attrs;
    assertNotComplex([dy, images], "resizeBilinearGrad");
    const imagesStrides = util_exports.computeStrides(images.shape);
    const [batch, xHeight, xWidth, depth] = images.shape;
    const [, yHeight, yWidth] = dy.shape;
    const output = new Float32Array(batch * xHeight * xWidth * depth);
    const effectiveXSize = [
      alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
      alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
    ];
    const effectiveYSize = [
      alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
      alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
    ];
    const heightScale = effectiveXSize[0] / effectiveYSize[0];
    const widthScale = effectiveXSize[1] / effectiveYSize[1];
    const dyValues = backend.data.get(dy.dataId).values;
    let offset = 0;
    for (let b = 0; b < batch; b++) {
      const bOffset = b * imagesStrides[0];
      for (let r = 0; r < yHeight; r++) {
        const dxR = r * heightScale;
        const topDxRIndex = Math.floor(dxR);
        const bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);
        const topDxROffset = bOffset + topDxRIndex * imagesStrides[1];
        const bottomDxROffset = bOffset + bottomDxRIndex * imagesStrides[1];
        const dxRLerp = dxR - topDxRIndex;
        const inverseDxRLerp = 1 - dxRLerp;
        for (let c = 0; c < yWidth; c++) {
          const dxC = c * widthScale;
          const leftDxCIndex = Math.floor(dxC);
          const rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);
          const dxCLerp = dxC - leftDxCIndex;
          const inverseDxCLerp = 1 - dxCLerp;
          const topLeftRCOffset = topDxROffset + leftDxCIndex * imagesStrides[2];
          const topRightRCOffset = topDxROffset + rightDxCIndex * imagesStrides[2];
          const bottomLeftRCOffset = bottomDxROffset + leftDxCIndex * imagesStrides[2];
          const bottomRightRCOffset = bottomDxROffset + rightDxCIndex * imagesStrides[2];
          const inverseDxRLerpTimesInverseDxCLerp = inverseDxRLerp * inverseDxCLerp;
          const inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;
          const dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;
          const dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;
          for (let d = 0; d < depth; d++) {
            const dyVal = dyValues[offset++];
            output[topLeftRCOffset + d] += dyVal * inverseDxRLerpTimesInverseDxCLerp;
            output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;
            output[bottomLeftRCOffset + d] += dyVal * dxRLerpTimesInverseDxCLerp;
            output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;
          }
        }
      }
    }
    return backend.makeTensorInfo([batch, xWidth, xHeight, depth], "float32", output);
  }
  var resizeBilinearGradConfig;
  var init_ResizeBilinearGrad = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinearGrad.js"() {
      init_dist();
      init_cpu_util();
      resizeBilinearGradConfig = {
        kernelName: ResizeBilinearGrad,
        backendName: "cpu",
        kernelFunc: resizeBilinearGrad
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighbor.js
  function resizeNearestNeighbor2(args) {
    const { inputs, backend, attrs } = args;
    const { images } = inputs;
    const { alignCorners, halfPixelCenters, size } = attrs;
    assertNotComplex(images, "resizeNearestNeighbor");
    const imagesStrides = util_exports.computeStrides(images.shape);
    const [newHeight, newWidth] = size;
    const [batch, oldHeight, oldWidth, numChannels] = images.shape;
    const xValues = backend.data.get(images.dataId).values;
    const output = new Float32Array(batch * newHeight * newWidth * numChannels);
    const effectiveInputSize = [
      alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
      alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
    ];
    const effectiveOutputSize = [
      alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
      alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
    ];
    const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];
    const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];
    let outputOffset = 0;
    for (let b = 0; b < batch; b++) {
      const batchOffset = b * imagesStrides[0];
      for (let r = 0; r < newHeight; r++) {
        const sourceFracRow = halfPixelCenters ? effectiveRowSizeRatio * (r + 0.5) : effectiveRowSizeRatio * r;
        let sourceNearestRow = Math.min(oldHeight - 1, alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));
        if (halfPixelCenters) {
          sourceNearestRow = Math.max(0, sourceNearestRow);
        }
        const rowOffset = batchOffset + sourceNearestRow * imagesStrides[1];
        for (let c = 0; c < newWidth; c++) {
          const sourceFracCol = halfPixelCenters ? effectiveColSizeRatio * (c + 0.5) : effectiveColSizeRatio * c;
          let sourceNearestCol = Math.min(oldWidth - 1, alignCorners ? Math.round(sourceFracCol) : Math.floor(sourceFracCol));
          if (halfPixelCenters) {
            sourceNearestCol = Math.max(0, sourceNearestCol);
          }
          const colOffset = rowOffset + sourceNearestCol * imagesStrides[2];
          for (let d = 0; d < numChannels; d++) {
            const newVal = xValues[colOffset + d];
            output[outputOffset++] = newVal;
          }
        }
      }
    }
    return backend.makeTensorInfo([batch, newHeight, newWidth, numChannels], images.dtype, output);
  }
  var resizeNearestNeighborConfig;
  var init_ResizeNearestNeighbor = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighbor.js"() {
      init_dist();
      init_cpu_util();
      resizeNearestNeighborConfig = {
        kernelName: ResizeNearestNeighbor,
        backendName: "cpu",
        kernelFunc: resizeNearestNeighbor2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighborGrad.js
  function resizeNearestNeighborGrad(args) {
    const { inputs, backend, attrs } = args;
    const { images, dy } = inputs;
    const { alignCorners } = attrs;
    assertNotComplex([dy, images], "resizeNearestNeighborGrad");
    const imagesStrides = util_exports.computeStrides(images.shape);
    const dyStrides = util_exports.computeStrides(dy.shape);
    const [batch, xHeight, xWidth, depth] = images.shape;
    const [, yHeight, yWidth] = dy.shape;
    const output = new Float32Array(batch * xHeight * xWidth * depth);
    const dyValues = backend.data.get(dy.dataId).values;
    const effectiveXSize = [
      alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
      alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
    ];
    const effectiveYSize = [
      alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
      alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
    ];
    const heightScale = effectiveXSize[0] / effectiveYSize[0];
    const widthScale = effectiveXSize[1] / effectiveYSize[1];
    const invHeightScale = 1 / heightScale;
    const invWidthScale = 1 / widthScale;
    const winHeight = Math.ceil(invHeightScale) * 2 + 2;
    const winWidth = Math.ceil(invWidthScale) * 2 + 2;
    for (let b = 0; b < batch; b++) {
      const batchOffset = b * imagesStrides[0];
      for (let r = 0; r < xHeight; r++) {
        const rowOffset = batchOffset + r * imagesStrides[1];
        const startRLerp = Math.floor(r * invHeightScale);
        const startDyR = Math.floor(startRLerp - winHeight / 2);
        for (let c = 0; c < xWidth; c++) {
          const colOffset = rowOffset + c * imagesStrides[2];
          const startCLerp = Math.floor(c * invWidthScale);
          const startDyC = Math.floor(startCLerp - winWidth / 2);
          for (let d = 0; d < depth; d++) {
            let accum = 0;
            for (let dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {
              const dyR = dyRIndex + startDyR;
              if (dyR < 0 || dyR >= yHeight) {
                continue;
              }
              const dyROffset = batchOffset + dyR * dyStrides[1];
              const sourceFracRow = dyR * heightScale;
              const sourceNearestRow = Math.min(xHeight - 1, alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));
              if (r !== sourceNearestRow) {
                continue;
              }
              for (let dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {
                const dyC = dyCIndex + startDyC;
                if (dyC < 0 || dyC >= yWidth) {
                  continue;
                }
                const dyCOffset = dyROffset + dyC * dyStrides[2];
                const sourceFracCol = dyC * widthScale;
                const sourceNearestCol = Math.min(xWidth - 1, alignCorners ? Math.round(sourceFracCol) : Math.floor(sourceFracCol));
                if (c === sourceNearestCol) {
                  accum += dyValues[dyCOffset + d];
                }
              }
            }
            output[colOffset + d] = accum;
          }
        }
      }
    }
    return backend.makeTensorInfo(images.shape, images.dtype, output);
  }
  var resizeNearestNeighborGradConfig;
  var init_ResizeNearestNeighborGrad = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighborGrad.js"() {
      init_dist();
      init_cpu_util();
      resizeNearestNeighborGradConfig = {
        kernelName: ResizeNearestNeighborGrad,
        backendName: "cpu",
        kernelFunc: resizeNearestNeighborGrad
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Reverse.js
  function reverse2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { dims } = attrs;
    assertNotComplex(x, "reverse");
    const xRank = x.shape.length;
    const $dims = util_exports.parseAxisParam(dims, x.shape);
    if (xRank === 0) {
      return identity({ inputs: { x }, backend });
    }
    const outBuf = new TensorBuffer(x.shape, x.dtype);
    const xBuf = backend.bufferSync(x);
    for (let i = 0; i < outBuf.size; i++) {
      const outLoc = outBuf.indexToLoc(i);
      const inLoc = outLoc.slice();
      $dims.forEach((d) => inLoc[d] = x.shape[d] - 1 - inLoc[d]);
      outBuf.set(xBuf.get(...inLoc), ...outLoc);
    }
    return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
  }
  var reverseConfig;
  var init_Reverse = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Reverse.js"() {
      init_dist();
      init_cpu_util();
      init_Identity();
      reverseConfig = {
        kernelName: Reverse,
        backendName: "cpu",
        kernelFunc: reverse2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RotateWithOffset.js
  var rotateWithOffsetConfig;
  var init_RotateWithOffset = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RotateWithOffset.js"() {
      init_dist();
      rotateWithOffsetConfig = {
        kernelName: RotateWithOffset,
        backendName: "cpu",
        kernelFunc: ({ inputs, attrs, backend }) => {
          const { image: image2 } = inputs;
          const { radians, fillValue, center } = attrs;
          const cpuBackend = backend;
          const output = util_exports.getTypedArrayFromDType(image2.dtype, util_exports.sizeFromShape(image2.shape));
          const [batch, imageHeight, imageWidth, numChannels] = image2.shape;
          const [centerX, centerY] = backend_util_exports.getImageCenter(center, imageHeight, imageWidth);
          const fullOpacityValue = 255;
          const sinFactor = Math.sin(radians);
          const cosFactor = Math.cos(radians);
          const imageVals = cpuBackend.data.get(image2.dataId).values;
          for (let batchIdx = 0; batchIdx < batch; batchIdx++) {
            const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;
            for (let row = 0; row < imageHeight; row++) {
              const rowOffset = row * (imageWidth * numChannels);
              for (let col = 0; col < imageWidth; col++) {
                const colOffset = col * numChannels;
                for (let channel = 0; channel < numChannels; channel++) {
                  const coords = [batch, row, col, channel];
                  const x = coords[2];
                  const y = coords[1];
                  let coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;
                  let coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;
                  coordX = Math.round(coordX + centerX);
                  coordY = Math.round(coordY + centerY);
                  let outputValue = fillValue;
                  if (typeof fillValue !== "number") {
                    if (channel === 3) {
                      outputValue = fullOpacityValue;
                    } else {
                      outputValue = fillValue[channel];
                    }
                  }
                  if (coordX >= 0 && coordX < imageWidth && coordY >= 0 && coordY < imageHeight) {
                    const rotatedRowOffset = coordY * (imageWidth * numChannels);
                    const rotatedColOffset = coordX * numChannels;
                    const imageIdx = batchOffset + rotatedRowOffset + rotatedColOffset + channel;
                    outputValue = imageVals[imageIdx];
                  }
                  const outIdx = batchOffset + rowOffset + colOffset + channel;
                  output[outIdx] = outputValue;
                }
              }
            }
          }
          const dataId = cpuBackend.write(output, image2.shape, image2.dtype);
          return { dataId, shape: image2.shape, dtype: image2.dtype };
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Round.js
  var round3, roundConfig;
  var init_Round = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Round.js"() {
      init_dist();
      init_unary_utils();
      round3 = unaryKernelFunc(Round, (xi) => {
        const base = Math.floor(xi);
        if (xi - base < 0.5) {
          return Math.floor(xi);
        } else if (xi - base > 0.5) {
          return Math.ceil(xi);
        } else {
          if (base % 2 === 0) {
            return base;
          } else {
            return base + 1;
          }
        }
      });
      roundConfig = {
        kernelName: Round,
        backendName: "cpu",
        kernelFunc: round3
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ScatterNd.js
  function scatterNd(args) {
    const { inputs, backend, attrs } = args;
    const { indices, updates } = inputs;
    const { shape } = attrs;
    const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports.calculateShapes(updates, indices, shape);
    const sumDupeIndices = true;
    const indicesBuf = backend.bufferSync(indices);
    const updatesBuf = backend.bufferSync(updates);
    const outBuf = scatterImpl(indicesBuf, updatesBuf, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, 0, sumDupeIndices);
    return backend.makeTensorInfo(shape, outBuf.dtype, outBuf.values);
  }
  var scatterNdConfig;
  var init_ScatterNd = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ScatterNd.js"() {
      init_dist();
      init_Scatter_impl();
      scatterNdConfig = {
        kernelName: ScatterNd,
        backendName: "cpu",
        kernelFunc: scatterNd
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SearchSorted_impl.js
  function lowerBound2(array, value) {
    let left = 0;
    let right = array.length;
    let mid = 0;
    while (left < right) {
      mid = Math.floor((left + right) / 2);
      if (array[mid] < value) {
        left = mid + 1;
      } else {
        right = mid;
      }
    }
    return right;
  }
  function upperBound2(array, value) {
    let left = 0;
    let right = array.length;
    let mid = 0;
    while (left < right) {
      mid = Math.floor((left + right) / 2);
      if (array[mid] <= value) {
        left = mid + 1;
      } else {
        right = mid;
      }
    }
    return right;
  }
  function searchSortedImpl(sortedInputs, values, batchSize, numInputs, numValues, side) {
    const output = util_exports.getArrayFromDType("int32", batchSize * numValues);
    for (let b = 0; b < batchSize; ++b) {
      const sortedInputsSlice = sortedInputs.slice(b * numInputs, (b + 1) * numInputs);
      const outputOffset = b * numValues;
      for (let i = 0; i < numValues; ++i) {
        output[outputOffset + i] = side === "left" ? lowerBound2(sortedInputsSlice, values[i + outputOffset]) : upperBound2(sortedInputsSlice, values[i + outputOffset]);
      }
    }
    return output;
  }
  var init_SearchSorted_impl = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SearchSorted_impl.js"() {
      init_dist();
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SearchSorted.js
  function searchSorted2(args) {
    const { inputs, backend, attrs } = args;
    const { sortedSequence, values } = inputs;
    const { side } = attrs;
    const $sortedSequence = backend.data.get(sortedSequence.dataId).values;
    const $values = backend.data.get(values.dataId).values;
    const output = searchSortedImpl($sortedSequence, $values, sortedSequence.shape[0], sortedSequence.shape[1], values.shape[1], side);
    return backend.makeTensorInfo(values.shape, "int32", output);
  }
  var searchSortedConfig;
  var init_SearchSorted = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SearchSorted.js"() {
      init_dist();
      init_SearchSorted_impl();
      searchSortedConfig = {
        kernelName: SearchSorted,
        backendName: "cpu",
        kernelFunc: searchSorted2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Select.js
  function select2(args) {
    const { inputs, backend } = args;
    const { condition, t: t2, e } = inputs;
    assertNotComplex([condition, t2, e], "select");
    const conditionRank = condition.shape.length;
    const values = backend.data.get(condition.dataId).values;
    const tValues = backend.data.get(t2.dataId).values;
    const eValues = backend.data.get(e.dataId).values;
    const resultDtype = upcastType(t2.dtype, e.dtype);
    const newValues = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(t2.shape), resultDtype);
    let index = 0;
    const offset = conditionRank === 0 || conditionRank > 1 || t2.shape.length === 1 ? 1 : util_exports.sizeFromShape(t2.shape.slice(1));
    for (let i = 0; i < values.length; i++) {
      for (let j2 = 0; j2 < offset; j2++) {
        if (values[i] === 1) {
          newValues[index++] = tValues[i];
        } else {
          newValues[index++] = eValues[i];
        }
      }
    }
    return backend.makeTensorInfo(t2.shape, resultDtype, newValues);
  }
  var selectConfig;
  var init_Select = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Select.js"() {
      init_dist();
      init_cpu_util();
      selectConfig = {
        kernelName: Select,
        backendName: "cpu",
        kernelFunc: select2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Selu.js
  var scaleAlpha, scale, selu2, seluConfig;
  var init_Selu = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Selu.js"() {
      init_dist();
      init_unary_utils();
      scaleAlpha = backend_util_exports.SELU_SCALEALPHA;
      scale = backend_util_exports.SELU_SCALE;
      selu2 = unaryKernelFunc(Selu, (xi) => {
        if (xi >= 0) {
          return scale * xi;
        } else {
          return scaleAlpha * (Math.exp(xi) - 1);
        }
      });
      seluConfig = {
        kernelName: Selu,
        backendName: "cpu",
        kernelFunc: selu2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sign.js
  var sign2, signConfig;
  var init_Sign = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sign.js"() {
      init_dist();
      init_unary_utils();
      sign2 = unaryKernelFunc(Sign, (xi) => {
        if (xi < 0) {
          return -1;
        } else if (xi > 0) {
          return 1;
        } else {
          return 0;
        }
      });
      signConfig = {
        kernelName: Sign,
        backendName: "cpu",
        kernelFunc: sign2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sin.js
  var sin2, sinConfig;
  var init_Sin = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sin.js"() {
      init_dist();
      init_unary_utils();
      sin2 = unaryKernelFunc(Sin, (xi) => Math.sin(xi));
      sinConfig = {
        kernelName: Sin,
        backendName: "cpu",
        kernelFunc: sin2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sinh.js
  var sinh2, sinhConfig;
  var init_Sinh = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sinh.js"() {
      init_dist();
      init_unary_utils();
      sinh2 = unaryKernelFunc(Sinh, (xi) => Math.sinh(xi));
      sinhConfig = {
        kernelName: Sinh,
        backendName: "cpu",
        kernelFunc: sinh2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Softplus.js
  var epsilon, threshold2, softplus2, softplusConfig;
  var init_Softplus = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Softplus.js"() {
      init_dist();
      init_unary_utils();
      epsilon = 11920928955078125e-23;
      threshold2 = Math.log(epsilon) + 2;
      softplus2 = unaryKernelFunc(Softplus, (xi) => {
        const tooLarge = xi > -threshold2;
        const tooSmall = xi < threshold2;
        const expX = Math.exp(xi);
        let result;
        if (tooSmall) {
          result = expX;
        } else if (tooLarge) {
          result = xi;
        } else {
          result = Math.log(1 + expX);
        }
        return result;
      });
      softplusConfig = {
        kernelName: Softplus,
        backendName: "cpu",
        kernelFunc: softplus2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SpaceToBatchND.js
  function spaceToBatchND2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { blockShape, paddings } = attrs;
    assertNotComplex([x], "spaceToBatchND");
    const prod3 = util_exports.sizeFromShape(blockShape);
    const completePaddings = [[0, 0]];
    completePaddings.push(...paddings);
    for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {
      completePaddings.push([0, 0]);
    }
    const paddedX = padV2Config.kernelFunc({
      inputs: { x },
      backend,
      attrs: { paddings: completePaddings, constantValue: 0 }
    });
    const reshapedPaddedShape = backend_util_exports.getReshaped(paddedX.shape, blockShape, prod3, false);
    const permutedReshapedPaddedPermutation = backend_util_exports.getPermuted(reshapedPaddedShape.length, blockShape.length, false);
    const flattenShape = backend_util_exports.getReshapedPermuted(paddedX.shape, blockShape, prod3, false);
    const reshapeInputs = { x: paddedX };
    const reshapeAttrs = { shape: reshapedPaddedShape };
    const paddedXReshaped = reshape2({ inputs: reshapeInputs, backend, attrs: reshapeAttrs });
    const transposeInputs = { x: paddedXReshaped };
    const transposeAttrs = { perm: permutedReshapedPaddedPermutation };
    const paddedXT = transpose2({ inputs: transposeInputs, backend, attrs: transposeAttrs });
    const resultReshapeInputs = { x: paddedXT };
    const resultReshapeAttrs = { shape: flattenShape };
    const result = reshape2({ inputs: resultReshapeInputs, backend, attrs: resultReshapeAttrs });
    backend.disposeIntermediateTensorInfo(paddedX);
    backend.disposeIntermediateTensorInfo(paddedXReshaped);
    backend.disposeIntermediateTensorInfo(paddedXT);
    return result;
  }
  var spaceToBatchNDConfig;
  var init_SpaceToBatchND = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SpaceToBatchND.js"() {
      init_dist();
      init_cpu_util();
      init_PadV2();
      init_Reshape();
      init_Transpose();
      spaceToBatchNDConfig = {
        kernelName: SpaceToBatchND,
        backendName: "cpu",
        kernelFunc: spaceToBatchND2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows.js
  function sparseFillEmptyRows2(args) {
    const { inputs, backend } = args;
    const { indices, values, denseShape, defaultValue } = inputs;
    if (denseShape.shape.length !== 1) {
      throw new Error(`Dense shape must be a vector, saw:
        ${denseShape.shape}`);
    }
    if (indices.shape.length !== 2) {
      throw new Error(`Indices must be a matrix, saw:
        ${indices.shape}`);
    }
    if (values.shape.length !== 1) {
      throw new Error(`Values must be a vector, saw:
        ${values.shape}`);
    }
    if (defaultValue.shape.length !== 0) {
      throw new Error(`Default value must be a scalar, saw:
        ${defaultValue.shape}`);
    }
    const $indices = backend.data.get(indices.dataId).values;
    const $values = backend.data.get(values.dataId).values;
    const $denseShape = backend.data.get(denseShape.dataId).values;
    const $defaultValue = backend.data.get(defaultValue.dataId).values[0];
    const [outputIndices, outputIndicesShape, outputValues, emptyRowIndicator, reverseIndexMap] = sparseFillEmptyRowsImpl($indices, indices.shape, indices.dtype, $values, values.dtype, $denseShape, $defaultValue);
    return [
      backend.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),
      backend.makeTensorInfo([outputIndicesShape[0]], values.dtype, outputValues),
      backend.makeTensorInfo([emptyRowIndicator.length], "bool", new Uint8Array(emptyRowIndicator.map((value) => Number(value)))),
      backend.makeTensorInfo([reverseIndexMap.length], indices.dtype, new Int32Array(reverseIndexMap))
    ];
  }
  var sparseFillEmptyRowsConfig;
  var init_SparseFillEmptyRows = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows.js"() {
      init_dist();
      init_SparseFillEmptyRows_impl();
      sparseFillEmptyRowsConfig = {
        kernelName: SparseFillEmptyRows,
        backendName: "cpu",
        kernelFunc: sparseFillEmptyRows2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape.js
  function sparseReshape2(args) {
    const { inputs, backend } = args;
    const { inputIndices, inputShape, newShape } = inputs;
    if (inputIndices.shape.length !== 2) {
      throw new Error(`Input indices should be a matrix but received shape
        ${inputIndices.shape}`);
    }
    if (inputShape.shape.length !== 1) {
      throw new Error(`Input shape should be a vector but received shape
        ${inputShape.shape}`);
    }
    if (newShape.shape.length !== 1) {
      throw new Error(`Target shape should be a vector but received shape ${newShape.shape}`);
    }
    const $inputShape = Array.from(backend.data.get(inputShape.dataId).values);
    const $inputIndices = backend.data.get(inputIndices.dataId).values;
    const targetShape = Array.from(backend.data.get(newShape.dataId).values);
    const [newIndices, indicesShape, outputShape] = sparseReshapeImpl($inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape, targetShape);
    return [
      backend.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),
      backend.makeTensorInfo([outputShape.length], newShape.dtype, new Int32Array(outputShape))
    ];
  }
  var sparseReshapeConfig;
  var init_SparseReshape = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape.js"() {
      init_dist();
      init_SparseReshape_impl();
      sparseReshapeConfig = {
        kernelName: SparseReshape,
        backendName: "cpu",
        kernelFunc: sparseReshape2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentMean.js
  function sparseSegmentMean2(args) {
    const { inputs, backend } = args;
    const { data, indices, segmentIds } = inputs;
    if (data.shape.length < 1) {
      throw new Error(`Data should be at least 1 dimensional but received scalar`);
    }
    if (indices.shape.length !== 1) {
      throw new Error(`Indices should be a vector but received shape
          ${indices.shape}`);
    }
    if (segmentIds.shape.length !== 1) {
      throw new Error(`Segment ids should be a vector but received shape
          ${segmentIds.shape}`);
    }
    if (indices.shape[0] !== segmentIds.shape[0]) {
      throw new Error(`segmentIds and indices should have same size.`);
    }
    const $data = backend.data.get(data.dataId).values;
    const $indices = backend.data.get(indices.dataId).values;
    const $segmentIds = backend.data.get(segmentIds.dataId).values;
    const [outputData, outputDataShape] = sparseSegmentReductionImpl($data, data.shape, data.dtype, $indices, $segmentIds, true);
    return backend.makeTensorInfo(outputDataShape, data.dtype, outputData);
  }
  var sparseSegmentMeanConfig;
  var init_SparseSegmentMean = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentMean.js"() {
      init_dist();
      init_SparseSegmentReduction_impl();
      sparseSegmentMeanConfig = {
        kernelName: SparseSegmentMean,
        backendName: "cpu",
        kernelFunc: sparseSegmentMean2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentSum.js
  function sparseSegmentSum2(args) {
    const { inputs, backend } = args;
    const { data, indices, segmentIds } = inputs;
    if (data.shape.length < 1) {
      throw new Error(`Data should be at least 1 dimensional but received scalar`);
    }
    if (indices.shape.length !== 1) {
      throw new Error(`Indices should be a vector but received shape
         ${indices.shape}`);
    }
    if (segmentIds.shape.length !== 1) {
      throw new Error(`Segment ids should be a vector but received shape
         ${segmentIds.shape}`);
    }
    if (indices.shape[0] !== segmentIds.shape[0]) {
      throw new Error(`segmentIds and indices should have same size.`);
    }
    const $data = backend.data.get(data.dataId).values;
    const $indices = backend.data.get(indices.dataId).values;
    const $segmentIds = backend.data.get(segmentIds.dataId).values;
    const [outputData, outputDataShape] = sparseSegmentReductionImpl($data, data.shape, data.dtype, $indices, $segmentIds);
    return backend.makeTensorInfo(outputDataShape, data.dtype, outputData);
  }
  var sparseSegmentSumConfig;
  var init_SparseSegmentSum = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentSum.js"() {
      init_dist();
      init_SparseSegmentReduction_impl();
      sparseSegmentSumConfig = {
        kernelName: SparseSegmentSum,
        backendName: "cpu",
        kernelFunc: sparseSegmentSum2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseToDense.js
  function sparseToDense2(args) {
    const { inputs, backend, attrs } = args;
    const { sparseIndices, sparseValues, defaultValue } = inputs;
    const { outputShape } = attrs;
    const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports.calculateShapes(sparseValues, sparseIndices, outputShape);
    const sumDupeIndices = false;
    const indicesBuf = backend.bufferSync(sparseIndices);
    let outBuf;
    switch (sparseValues.dtype) {
      case "bool": {
        const updatesBuf = backend.bufferSync(sparseValues);
        const $defaultValue = Boolean(backend.data.get(defaultValue.dataId).values[0]);
        outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
        break;
      }
      case "float32": {
        const updatesBuf = backend.bufferSync(sparseValues);
        const $defaultValue = backend.data.get(defaultValue.dataId).values[0];
        outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
        break;
      }
      case "int32": {
        const updatesBuf = backend.bufferSync(sparseValues);
        const $defaultValue = backend.data.get(defaultValue.dataId).values[0];
        outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
        break;
      }
      case "string": {
        const updatesBuf = backend.bufferSync(sparseValues);
        const $defaultValue = util_exports.decodeString(backend.data.get(defaultValue.dataId).values[0]);
        outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
        break;
      }
      default:
        throw new Error(`Unsupported type ${sparseValues.dtype}`);
    }
    return backend.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);
  }
  var sparseToDenseConfig;
  var init_SparseToDense = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseToDense.js"() {
      init_dist();
      init_Scatter_impl();
      sparseToDenseConfig = {
        kernelName: SparseToDense,
        backendName: "cpu",
        kernelFunc: sparseToDense2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SplitV.js
  function splitV(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { numOrSizeSplits, axis } = attrs;
    const $axis = util_exports.parseAxisParam(axis, x.shape)[0];
    const splitSizes = backend_util_exports.prepareSplitSize(x, numOrSizeSplits, $axis);
    const begin = new Array(x.shape.length).fill(0);
    const size = x.shape.slice();
    return splitSizes.map((s) => {
      const sliceSize = [...size];
      sliceSize[$axis] = s;
      const sliceT = slice2({ inputs: { x }, backend, attrs: { begin, size: sliceSize } });
      begin[$axis] += s;
      return sliceT;
    });
  }
  var splitVConfig;
  var init_SplitV = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SplitV.js"() {
      init_dist();
      init_dist();
      init_Slice();
      splitVConfig = {
        kernelName: SplitV,
        backendName: "cpu",
        kernelFunc: splitV
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Square.js
  var squareConfig;
  var init_Square = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Square.js"() {
      init_dist();
      init_cpu_util();
      squareConfig = {
        kernelName: Square,
        backendName: "cpu",
        kernelFunc: ({ inputs, backend }) => {
          const { x } = inputs;
          const cpuBackend = backend;
          assertNotComplex(x, "square");
          const values = cpuBackend.data.get(x.dataId).values;
          const newValues = new Float32Array(values.length);
          for (let i = 0; i < values.length; ++i) {
            const value = values[i];
            newValues[i] = value * value;
          }
          const dataId = cpuBackend.write(newValues, x.shape, x.dtype);
          return { dataId, shape: x.shape, dtype: x.dtype };
        }
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Step.js
  var step2, stepConfig;
  var init_Step = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Step.js"() {
      init_dist();
      init_unary_utils();
      step2 = unaryKernelFunc(Step, (xi, attrs) => {
        const stepAttrs = attrs;
        if (isNaN(xi)) {
          return NaN;
        } else {
          return xi > 0 ? 1 : stepAttrs.alpha;
        }
      });
      stepConfig = {
        kernelName: Step,
        backendName: "cpu",
        kernelFunc: step2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice.js
  function stridedSlice2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask } = attrs;
    assertNotComplex(x, "stridedSlice");
    const { finalShapeSparse, finalShape, isIdentity, sliceDim0, isSimpleSlice, begin: $begin, end: $end, strides: $strides } = slice_util_exports.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);
    let result;
    if (isIdentity) {
      result = reshape2({ inputs: { x }, backend, attrs: { shape: finalShape } });
    } else if (sliceDim0 || isSimpleSlice) {
      util_exports.assert(x.shape.length >= 1, () => `Input must have rank at least 1, got: ${x.shape.length}`);
      const size = slice_util_exports.computeOutShape($begin, $end, $strides);
      const sliced = slice2({ inputs: { x }, backend, attrs: { begin: $begin, size } });
      result = reshape2({ inputs: { x: sliced }, backend, attrs: { shape: finalShape } });
      backend.disposeIntermediateTensorInfo(sliced);
    } else {
      const xBuf = backend.bufferSync(x);
      const outBuf = stridedSliceImpl(finalShapeSparse, xBuf, $strides, $begin);
      result = backend.makeTensorInfo(finalShape, outBuf.dtype, outBuf.values);
    }
    return result;
  }
  var stridedSliceConfig;
  var init_StridedSlice = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice.js"() {
      init_dist();
      init_cpu_util();
      init_Reshape();
      init_Slice();
      init_StridedSlice_impl();
      stridedSliceConfig = {
        kernelName: StridedSlice,
        backendName: "cpu",
        kernelFunc: stridedSlice2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams.js
  function stringNGrams2(args) {
    const { inputs, backend, attrs } = args;
    const { separator, nGramWidths, leftPad, rightPad: rightPad2, padWidth, preserveShortSequences } = attrs;
    const { data, dataSplits } = inputs;
    const $data = backend.data.get(data.dataId).values;
    const $dataSplits = backend.data.get(dataSplits.dataId).values;
    const [nGrams, nGramsSplits] = stringNGramsImpl($data, $dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences);
    return [
      backend.makeTensorInfo([nGrams.length], "string", nGrams),
      backend.makeTensorInfo(dataSplits.shape, "int32", nGramsSplits)
    ];
  }
  var stringNGramsConfig;
  var init_StringNGrams = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams.js"() {
      init_dist();
      init_StringNGrams_impl();
      stringNGramsConfig = {
        kernelName: StringNGrams,
        backendName: "cpu",
        kernelFunc: stringNGrams2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit.js
  function stringSplit2(args) {
    const { inputs, backend, attrs } = args;
    const { skipEmpty } = attrs;
    const { input, delimiter } = inputs;
    if (input.dtype !== "string") {
      throw new Error("Input must be of datatype string");
    }
    if (input.shape.length !== 1) {
      throw new Error(`Input must be a vector, got shape: ${input.shape}`);
    }
    if (delimiter.shape.length !== 0) {
      throw new Error(`Delimiter must be a scalar, got shape: ${delimiter.shape}`);
    }
    const $input = backend.data.get(input.dataId).values;
    const $delimiter = backend.data.get(delimiter.dataId).values[0];
    const [indices, values, shape] = stringSplitImpl($input, $delimiter, skipEmpty);
    const outputSize = values.length;
    return [
      backend.makeTensorInfo([outputSize, 2], "int32", indices),
      backend.makeTensorInfo([outputSize], "string", values),
      backend.makeTensorInfo([2], "int32", new Int32Array(shape))
    ];
  }
  var stringSplitConfig;
  var init_StringSplit = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit.js"() {
      init_dist();
      init_StringSplit_impl();
      stringSplitConfig = {
        kernelName: StringSplit,
        backendName: "cpu",
        kernelFunc: stringSplit2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast.js
  function stringToHashBucketFast2(args) {
    const { inputs, backend, attrs } = args;
    const { numBuckets } = attrs;
    const { input } = inputs;
    if (input.dtype !== "string") {
      throw new Error("Input must be of datatype string");
    }
    if (numBuckets <= 0) {
      throw new Error(`Number of buckets must be at least 1`);
    }
    const $input = backend.data.get(input.dataId).values;
    const output = stringToHashBucketFastImpl($input, numBuckets);
    return backend.makeTensorInfo(input.shape, "int32", output);
  }
  var stringToHashBucketFastConfig;
  var init_StringToHashBucketFast = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast.js"() {
      init_dist();
      init_StringToHashBucketFast_impl();
      stringToHashBucketFastConfig = {
        kernelName: StringToHashBucketFast,
        backendName: "cpu",
        kernelFunc: stringToHashBucketFast2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tan.js
  var tan2, tanConfig;
  var init_Tan = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tan.js"() {
      init_dist();
      init_unary_utils();
      tan2 = unaryKernelFunc(Tan, (xi) => Math.tan(xi));
      tanConfig = {
        kernelName: Tan,
        backendName: "cpu",
        kernelFunc: tan2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tanh.js
  var tanh3, tanhConfig;
  var init_Tanh = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tanh.js"() {
      init_dist();
      init_unary_utils();
      tanh3 = unaryKernelFunc(Tanh, (xi) => Math.tanh(xi));
      tanhConfig = {
        kernelName: Tanh,
        backendName: "cpu",
        kernelFunc: tanh3
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tile.js
  function tile2(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { reps } = attrs;
    assertNotComplex(x, "tile");
    const outBuf = tileImpl(backend.bufferSync(x), reps);
    return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
  }
  var tileConfig;
  var init_Tile = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tile.js"() {
      init_dist();
      init_cpu_util();
      init_Tile_impl();
      tileConfig = {
        kernelName: Tile,
        backendName: "cpu",
        kernelFunc: tile2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/TopK.js
  function topK(args) {
    const { inputs, backend, attrs } = args;
    const { x } = inputs;
    const { k: k3, sorted } = attrs;
    assertNotComplex(x, "topk");
    const xVals = backend.data.get(x.dataId).values;
    const [allTopKVals, allTopKIndices] = topKImpl(xVals, x.shape, x.dtype, k3, sorted);
    return [
      backend.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),
      backend.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)
    ];
  }
  var topKConfig;
  var init_TopK = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/TopK.js"() {
      init_dist();
      init_cpu_util();
      init_TopK_impl();
      topKConfig = {
        kernelName: TopK,
        backendName: "cpu",
        kernelFunc: topK
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transform.js
  function transform2(args) {
    const { inputs, attrs, backend } = args;
    const { image: image2, transforms } = inputs;
    const { interpolation, fillMode, fillValue, outputShape } = attrs;
    const [batch, imageHeight, imageWidth, numChannels] = image2.shape;
    const [outHeight, outWidth] = outputShape != null ? outputShape : [imageHeight, imageWidth];
    const outShape = [batch, outHeight, outWidth, numChannels];
    const inStrides = util_exports.computeStrides(image2.shape);
    const batchInStride = inStrides[0];
    const rowInStride = inStrides[1];
    const colInStride = inStrides[2];
    const outStrides = util_exports.computeStrides(outShape);
    const batchOutStride = outStrides[0];
    const rowOutStride = outStrides[1];
    const colOutStride = outStrides[2];
    const outVals = util_exports.getTypedArrayFromDType(image2.dtype, util_exports.sizeFromShape(outShape));
    outVals.fill(fillValue);
    const imageVals = backend.data.get(image2.dataId).values;
    const transformVals = backend.data.get(transforms.dataId).values;
    for (let b = 0; b < batch; ++b) {
      const transform3 = transforms.shape[0] === 1 ? transformVals : transformVals.subarray(b * 8, b * 8 + 8);
      for (let outY = 0; outY < outHeight; ++outY) {
        for (let outX = 0; outX < outWidth; ++outX) {
          for (let channel = 0; channel < numChannels; ++channel) {
            let val;
            const projection = transform3[6] * outX + transform3[7] * outY + 1;
            if (projection === 0) {
              continue;
            }
            const inX = (transform3[0] * outX + transform3[1] * outY + transform3[2]) / projection;
            const inY = (transform3[3] * outX + transform3[4] * outY + transform3[5]) / projection;
            const x = mapCoord(inX, imageWidth, fillMode);
            const y = mapCoord(inY, imageHeight, fillMode);
            switch (interpolation) {
              case "nearest":
                val = nearestInterpolation(imageVals, imageHeight, imageWidth, batchInStride, rowInStride, colInStride, b, y, x, channel, fillValue);
                break;
              case "bilinear":
                val = bilinearInterpolation(imageVals, imageHeight, imageWidth, batchInStride, rowInStride, colInStride, b, y, x, channel, fillValue);
                break;
              default:
                throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${interpolation}`);
            }
            const ind = b * batchOutStride + outY * rowOutStride + outX * colOutStride + channel;
            outVals[ind] = val;
          }
        }
      }
      return backend.makeTensorInfo(outShape, image2.dtype, outVals);
    }
    const dataId = backend.write(outVals, outShape, image2.dtype);
    return { dataId, shape: image2.shape, dtype: image2.dtype };
  }
  function mapCoord(outCoord, len, mode) {
    switch (mode) {
      case "reflect":
        return mapCoordReflect(outCoord, len);
      case "wrap":
        return mapCoordWrap(outCoord, len);
      case "nearest":
        return mapCoordNearest(outCoord, len);
      case "constant":
      default:
        return mapCoordConstant(outCoord, len);
    }
  }
  function mapCoordReflect(outCoord, len) {
    let inCoord = outCoord;
    if (inCoord < 0) {
      if (len <= 1) {
        inCoord = 0;
      } else {
        const sz2 = 2 * len;
        if (inCoord < sz2) {
          inCoord = sz2 * Math.trunc(-inCoord / sz2) + inCoord;
        }
        inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1;
      }
    } else if (inCoord > len - 1) {
      if (len <= 1) {
        inCoord = 0;
      } else {
        const sz2 = 2 * len;
        inCoord -= sz2 * Math.trunc(inCoord / sz2);
        if (inCoord >= len) {
          inCoord = sz2 - inCoord - 1;
        }
      }
    }
    return util_exports.clamp(0, inCoord, len - 1);
  }
  function mapCoordWrap(outCoord, len) {
    let inCoord = outCoord;
    if (inCoord < 0) {
      if (len <= 1) {
        inCoord = 0;
      } else {
        const sz = len - 1;
        inCoord += len * (Math.trunc(-inCoord / sz) + 1);
      }
    } else if (inCoord > len - 1) {
      if (len <= 1) {
        inCoord = 0;
      } else {
        const sz = len - 1;
        inCoord -= len * Math.trunc(inCoord / sz);
      }
    }
    return util_exports.clamp(0, inCoord, len - 1);
  }
  function mapCoordConstant(outCoord, len) {
    return outCoord;
  }
  function mapCoordNearest(outCoord, len) {
    return util_exports.clamp(0, outCoord, len - 1);
  }
  function readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
    const ind = batch * batchStride + y * rowStride + x * colStride + channel;
    if (0 <= y && y < imageHeight && 0 <= x && x < imageWidth) {
      return imageVals[ind];
    } else {
      return fillValue;
    }
  }
  function nearestInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
    const $y = Math.round(y);
    const $x = Math.round(x);
    return readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, $y, $x, channel, fillValue);
  }
  function bilinearInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
    const yFloor = Math.floor(y);
    const xFloor = Math.floor(x);
    const yCeil = yFloor + 1;
    const xCeil = xFloor + 1;
    const valueYFloor = (xCeil - x) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yFloor, xFloor, channel, fillValue) + (x - xFloor) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yFloor, xCeil, channel, fillValue);
    const valueYCeil = (xCeil - x) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yCeil, xFloor, channel, fillValue) + (x - xFloor) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yCeil, xCeil, channel, fillValue);
    return (yCeil - y) * valueYFloor + (y - yFloor) * valueYCeil;
  }
  var transformConfig;
  var init_Transform = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transform.js"() {
      init_dist();
      transformConfig = {
        kernelName: Transform,
        backendName: "cpu",
        kernelFunc: transform2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unique.js
  function unique2(args) {
    const { inputs, attrs, backend } = args;
    const { axis } = attrs;
    const { x } = inputs;
    assertNotComplex(x, "unique");
    const values = backend.data.get(x.dataId).values;
    const { outputValues, outputShape, indices } = uniqueImpl(values, axis, x.shape, x.dtype);
    return [
      backend.makeTensorInfo(outputShape, x.dtype, outputValues),
      backend.makeTensorInfo([indices.length], "int32", indices)
    ];
  }
  var uniqueConfig;
  var init_Unique = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unique.js"() {
      init_dist();
      init_cpu_util();
      init_Unique_impl();
      uniqueConfig = {
        kernelName: Unique,
        backendName: "cpu",
        kernelFunc: unique2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unpack.js
  function unpack(args) {
    const { inputs, backend, attrs } = args;
    const { value } = inputs;
    let { axis } = attrs;
    if (axis < 0) {
      axis += value.shape.length;
    }
    const valueRank = value.shape.length;
    const num = value.shape[axis];
    const outShape = new Array(valueRank - 1);
    let outIndex = 0;
    for (let i = 0; i < valueRank; i++) {
      if (i !== axis) {
        outShape[outIndex++] = value.shape[i];
      }
    }
    const begin = new Array(valueRank).fill(0);
    const size = value.shape.slice();
    size[axis] = 1;
    const res = new Array(num);
    for (let i = 0; i < res.length; i++) {
      begin[axis] = i;
      const tempRes = slice2({ inputs: { x: value }, backend, attrs: { begin, size } });
      res[i] = reshape2({ inputs: { x: tempRes }, backend, attrs: { shape: outShape } });
      backend.disposeIntermediateTensorInfo(tempRes);
    }
    return res;
  }
  var unpackConfig;
  var init_Unpack = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unpack.js"() {
      init_dist();
      init_Reshape();
      init_Slice();
      unpackConfig = {
        kernelName: Unpack,
        backendName: "cpu",
        kernelFunc: unpack
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/UnsortedSegmentSum.js
  function unsortedSegmentSum2(args) {
    const { inputs, backend, attrs } = args;
    const { x, segmentIds } = inputs;
    const { numSegments } = attrs;
    assertNotComplex(x, "unsortedSegmentSum");
    const xRank = x.shape.length;
    const segmentIdsRank = segmentIds.shape.length;
    const res = [];
    const intermediates = [];
    const numIters = xRank - segmentIdsRank;
    let $segmentIds = segmentIds;
    for (let i = 0; i < numIters; ++i) {
      const expanded = expandDims2({ inputs: { input: $segmentIds }, backend, attrs: { dim: i + 1 } });
      $segmentIds = expanded;
      intermediates.push(expanded);
    }
    for (let i = 0; i < numSegments; ++i) {
      const scalarValue = util_exports.createScalarValue(i, "int32");
      const segmentId = backend.makeTensorInfo([], "int32", scalarValue);
      const mask = equal2({ inputs: { a: segmentId, b: $segmentIds }, backend });
      const maskCasted = cast2({ inputs: { x: mask }, backend, attrs: { dtype: "float32" } });
      const mul2 = multiply({ inputs: { a: maskCasted, b: x }, backend });
      const sumTensorInfo = sum3({ inputs: { x: mul2 }, backend, attrs: { axis: 0, keepDims: false } });
      res.push(sumTensorInfo);
      intermediates.push(segmentId);
      intermediates.push(mask);
      intermediates.push(maskCasted);
      intermediates.push(mul2);
      intermediates.push(sumTensorInfo);
    }
    const result = pack({ inputs: res, backend, attrs: { axis: 0 } });
    intermediates.forEach((t2) => backend.disposeIntermediateTensorInfo(t2));
    return result;
  }
  var unsortedSegmentSumConfig;
  var init_UnsortedSegmentSum = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/UnsortedSegmentSum.js"() {
      init_dist();
      init_cpu_util();
      init_Cast();
      init_Equal();
      init_ExpandDims();
      init_Multiply();
      init_Pack();
      init_Sum();
      unsortedSegmentSumConfig = {
        kernelName: UnsortedSegmentSum,
        backendName: "cpu",
        kernelFunc: unsortedSegmentSum2
      };
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/register_all_kernels.js
  var kernelConfigs;
  var init_register_all_kernels = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/register_all_kernels.js"() {
      init_dist();
      init_FusedMatMul();
      init_Abs();
      init_Acos();
      init_Acosh();
      init_Add();
      init_AddN();
      init_All();
      init_Any();
      init_ArgMax();
      init_ArgMin();
      init_Asin();
      init_Asinh();
      init_Atan();
      init_Atan2();
      init_Atanh();
      init_AvgPool();
      init_AvgPool3D();
      init_AvgPool3DGrad();
      init_AvgPoolGrad();
      init_BatchMatMul();
      init_BatchNorm();
      init_BatchToSpaceND();
      init_Bincount();
      init_BroadcastArgs();
      init_Cast();
      init_Ceil();
      init_ClipByValue();
      init_Complex();
      init_ComplexAbs();
      init_Concat();
      init_Conv2D();
      init_Conv2DBackpropFilter();
      init_Conv2DBackpropInput();
      init_Conv3D();
      init_Conv3DBackpropFilterV2();
      init_Conv3DBackpropInputV2();
      init_Cos();
      init_Cosh();
      init_CropAndResize();
      init_Cumprod();
      init_Cumsum();
      init_DenseBincount();
      init_DepthToSpace();
      init_DepthwiseConv2dNative();
      init_DepthwiseConv2dNativeBackpropFilter();
      init_DepthwiseConv2dNativeBackpropInput();
      init_Diag();
      init_Dilation2D();
      init_Dilation2DBackpropFilter();
      init_Dilation2DBackpropInput();
      init_Einsum();
      init_Elu();
      init_EluGrad();
      init_Equal();
      init_Erf();
      init_Exp();
      init_ExpandDims();
      init_Expm1();
      init_FFT();
      init_Fill();
      init_FlipLeftRight();
      init_Floor();
      init_FloorDiv();
      init_FusedConv2D();
      init_FusedDepthwiseConv2D();
      init_GatherNd();
      init_GatherV2();
      init_Greater();
      init_GreaterEqual();
      init_Identity();
      init_IFFT();
      init_Imag();
      init_IsFinite();
      init_IsInf();
      init_IsNaN();
      init_LeakyRelu();
      init_Less();
      init_LessEqual();
      init_LinSpace();
      init_Log();
      init_Log1p();
      init_LogicalAnd();
      init_LogicalNot();
      init_LogicalOr();
      init_LRN();
      init_LRNGrad();
      init_Max();
      init_Maximum();
      init_MaxPool();
      init_MaxPool3D();
      init_MaxPool3DGrad();
      init_MaxPoolGrad();
      init_MaxPoolWithArgmax();
      init_Mean();
      init_Min();
      init_Minimum();
      init_MirrorPad();
      init_Mod();
      init_Multinomial();
      init_Multiply();
      init_Neg();
      init_NonMaxSuppressionV3();
      init_NonMaxSuppressionV4();
      init_NonMaxSuppressionV5();
      init_NotEqual();
      init_OneHot();
      init_OnesLike();
      init_Pack();
      init_PadV2();
      init_Pow();
      init_Prelu();
      init_Prod();
      init_RaggedGather();
      init_RaggedRange();
      init_RaggedTensorToTensor();
      init_Range();
      init_Real();
      init_RealDiv();
      init_Reciprocal();
      init_Relu();
      init_Relu6();
      init_Reshape();
      init_ResizeBilinear();
      init_ResizeBilinearGrad();
      init_ResizeNearestNeighbor();
      init_ResizeNearestNeighborGrad();
      init_Reverse();
      init_RotateWithOffset();
      init_Round();
      init_Rsqrt();
      init_ScatterNd();
      init_SearchSorted();
      init_Select();
      init_Selu();
      init_Sigmoid();
      init_Sign();
      init_Sin();
      init_Sinh();
      init_Slice();
      init_Softmax();
      init_Softplus();
      init_SpaceToBatchND();
      init_SparseFillEmptyRows();
      init_SparseReshape();
      init_SparseSegmentMean();
      init_SparseSegmentSum();
      init_SparseToDense();
      init_SplitV();
      init_Sqrt();
      init_Square();
      init_SquaredDifference();
      init_Step();
      init_StridedSlice();
      init_StringNGrams();
      init_StringSplit();
      init_StringToHashBucketFast();
      init_Sub();
      init_Sum();
      init_Tan();
      init_Tanh();
      init_Tile();
      init_TopK();
      init_Transform();
      init_Transpose();
      init_Unique();
      init_Unpack();
      init_UnsortedSegmentSum();
      init_ZerosLike();
      kernelConfigs = [
        _fusedMatMulConfig,
        absConfig,
        acosConfig,
        acoshConfig,
        addConfig,
        addNConfig,
        allConfig,
        anyConfig,
        argMaxConfig,
        argMinConfig,
        asinConfig,
        asinhConfig,
        atanConfig,
        atan2Config,
        atanhConfig,
        avgPoolConfig,
        avgPool3DConfig,
        avgPool3DGradConfig,
        avgPoolGradConfig,
        batchMatMulConfig,
        batchNormConfig,
        batchToSpaceNDConfig,
        bincountConfig,
        broadcastArgsConfig,
        castConfig,
        ceilConfig,
        clipByValueConfig,
        complexConfig,
        complexAbsConfig,
        concatConfig,
        conv2DConfig,
        conv2DBackpropFilterConfig,
        conv2DBackpropInputConfig,
        conv3DConfig,
        conv3DBackpropFilterV2Config,
        conv3DBackpropInputV2Config,
        cosConfig,
        coshConfig,
        cropAndResizeConfig,
        cumprodConfig,
        cumsumConfig,
        denseBincountConfig,
        depthToSpaceConfig,
        depthwiseConv2dNativeConfig,
        depthwiseConv2dNativeBackpropFilterConfig,
        depthwiseConv2dNativeBackpropInputConfig,
        diagConfig,
        dilation2DConfig,
        dilation2DBackpropFilterConfig,
        dilation2DBackpropInputConfig,
        einsumConfig,
        eluConfig,
        eluGradConfig,
        equalConfig,
        erfConfig,
        expConfig,
        expandDimsConfig,
        expm1Config,
        fftConfig,
        fillConfig,
        flipLeftRightConfig,
        floorConfig,
        floorDivConfig,
        fusedConv2DConfig,
        fusedDepthwiseConv2DConfig,
        gatherNdConfig,
        gatherV2Config,
        greaterConfig,
        greaterEqualConfig,
        identityConfig,
        ifftConfig,
        imagConfig,
        isFiniteConfig,
        isInfConfig,
        isNaNConfig,
        leakyReluConfig,
        lessConfig,
        lessEqualConfig,
        linSpaceConfig,
        logConfig,
        log1pConfig,
        logicalAndConfig,
        logicalNotConfig,
        logicalOrConfig,
        LRNConfig,
        LRNGradConfig,
        maxConfig,
        maximumConfig,
        maxPoolConfig,
        maxPool3DConfig,
        maxPool3DGradConfig,
        maxPoolGradConfig,
        maxPoolWithArgmaxConfig,
        meanConfig,
        minConfig,
        minimumConfig,
        mirrorPadConfig,
        modConfig,
        multinomialConfig,
        multiplyConfig,
        negConfig,
        nonMaxSuppressionV3Config,
        nonMaxSuppressionV4Config,
        nonMaxSuppressionV5Config,
        notEqualConfig,
        oneHotConfig,
        onesLikeConfig,
        packConfig,
        padV2Config,
        powConfig,
        preluConfig,
        prodConfig,
        raggedGatherConfig,
        raggedRangeConfig,
        raggedTensorToTensorConfig,
        rangeConfig,
        realConfig,
        realDivConfig,
        reciprocalConfig,
        reluConfig,
        relu6Config,
        reshapeConfig,
        resizeBilinearConfig,
        resizeBilinearGradConfig,
        resizeNearestNeighborConfig,
        resizeNearestNeighborGradConfig,
        reverseConfig,
        rotateWithOffsetConfig,
        roundConfig,
        rsqrtConfig,
        scatterNdConfig,
        searchSortedConfig,
        selectConfig,
        seluConfig,
        sigmoidConfig,
        signConfig,
        sinConfig,
        sinhConfig,
        sliceConfig,
        softmaxConfig,
        softplusConfig,
        spaceToBatchNDConfig,
        sparseFillEmptyRowsConfig,
        sparseReshapeConfig,
        sparseSegmentMeanConfig,
        sparseSegmentSumConfig,
        sparseToDenseConfig,
        splitVConfig,
        sqrtConfig,
        squareConfig,
        squaredDifferenceConfig,
        stepConfig,
        stridedSliceConfig,
        stringNGramsConfig,
        stringSplitConfig,
        stringToHashBucketFastConfig,
        subConfig,
        sumConfig,
        tanConfig,
        tanhConfig,
        tileConfig,
        topKConfig,
        transformConfig,
        transposeConfig,
        uniqueConfig,
        unpackConfig,
        unsortedSegmentSumConfig,
        zerosLikeConfig
      ];
      for (const kernelConfig of kernelConfigs) {
        registerKernel(kernelConfig);
      }
    }
  });

  // node_modules/@tensorflow/tfjs-backend-cpu/dist/index.js
  var init_dist3 = __esm({
    "node_modules/@tensorflow/tfjs-backend-cpu/dist/index.js"() {
      init_base2();
      init_register_all_kernels();
    }
  });

  // dist/index.js
  var require_dist = __commonJS({
    "dist/index.js"(exports) {
      init_dist();
      init_components();
      init_dist3();
      (() => __async(exports, null, function* () {
        yield ready();
        env().set("WEBGL_PACK", false);
        yield setBackend("cpu");
        let seconds = 0;
        let interval = null;
        window.createFaceDetector = function createFaceDetector(video, callbacks, canvas) {
          return __async(this, null, function* () {
            yield app(video, canvas, callbacks.onIndex);
            interval = setInterval(() => {
              seconds += 1;
              callbacks.onSecondIndex(handleSecond());
              if (seconds % 60 === 0) {
                handleMinute();
              }
            }, 1e3);
            return true;
          });
        };
        window.destroyFaceDetector = function destroyFaceDetector() {
          console.log("FaceDetector:destroyFaceDetector | Destroying");
          if (interval) {
            clearInterval(interval);
          }
        };
      }))();
    }
  });
  require_dist();
})();
/**
 * @license
 * Copyright 2022 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2020 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/*! Bundled license information:

@tensorflow/tfjs-core/dist/backends/backend.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/util_base.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/environment.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/global_util.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/log.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/kernel_registry.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/hash_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/profiler.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/tape.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/tensor_format.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/tensor.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/types.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/tensor_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/engine.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/device_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/flags.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/tensor_util_env.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/operation.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/complex.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/tensor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/io/types.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/io/io_utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/io/router_registry.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/io/indexed_db.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/io/local_storage.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/io/model_management.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/platforms/platform_browser.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/platforms/platform_node.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/buffer.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/cast.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/clone.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/print.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/base_side_effects.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/globals.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/add.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/floorDiv.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/div.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/mul.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/abs.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/acos.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/acosh.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/add_n.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/all.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/any.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/arg_max.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/arg_min.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/asin.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/asinh.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/atan.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/atan2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/atanh.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/conv_util.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/reshape.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/avg_pool.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/avg_pool_3d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/concat.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/mat_mul.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sigmoid.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/slice.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/tanh.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/basic_lstm_cell.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/batchnorm.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/bincount.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/broadcast_args.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/broadcast_to.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/ceil.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/fill.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/clip_by_value.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/conv2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/conv3d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/cos.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/cosh.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/cumprod.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the 'License');
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an 'AS IS' BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/cumsum.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/dense_bincount.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/depth_to_space.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/diag.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/dilation2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/broadcast_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/where.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/zeros_like.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/div_no_nan.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/dot.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/einsum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/elu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/erf.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/axis_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/max.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/min.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/pow.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/scalar.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sqrt.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/square.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sum.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/norm.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/euclidean_norm.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/exp.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/expand_dims.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/expm1.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/tile.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/eye.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/floor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/gather.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/greater.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/greater_equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/imag.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/is_finite.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/is_inf.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/is_nan.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/leaky_relu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/less.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/less_equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/linspace.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/local_response_normalization.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/log.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/log1p.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/gradients.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/neg.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/softplus.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/log_sigmoid.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sub.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/log_softmax.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/log_sum_exp.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/logical_and.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/logical_not.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/logical_or.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/logical_xor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/search_sorted.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/lower_bound.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/max_pool.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/max_pool_3d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/max_pool_with_argmax.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/maximum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/mean.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/zeros.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/ones.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/meshgrid.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/minimum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/mirror_pad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/mod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/moments.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/multinomial.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/not_equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/one_hot.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/ones_like.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/pad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/pool.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/prelu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/prod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/ragged_gather.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/ragged_range.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/ragged_tensor_to_tensor.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/rand.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/rand_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/random_gamma.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/random_normal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/random_standard_normal.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/random_uniform.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/range.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/real.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/reciprocal.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/relu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/relu6.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/reverse.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/reverse_1d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/reverse_2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/reverse_3d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/reverse_4d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/round.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/rsqrt.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/selu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/setdiff1d_async.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sign.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sin.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sinh.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/slice1d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/slice2d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/slice3d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/slice4d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/softmax.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/spectral/fft.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/spectral/ifft.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/spectral/irfft.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/split.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/spectral/rfft.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/squared_difference.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/squeeze.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/stack.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/step.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/strided_slice.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/tan.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/tensor1d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/tensor2d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/tensor3d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/tensor4d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/tensor5d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/tensor6d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/topk.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/truncated_normal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/unique.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/unstack.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/upper_bound.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/variable.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/backends/where_impl.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/where_async.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/boolean_mask.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/transpose.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/moving_average.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/scatter_nd.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/gather_nd.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/dropout_util.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/dropout.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/signal_ops_util.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/in_top_k.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/fused_util.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/fused/conv2d.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/fused/depthwise_conv2d.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/fused/mat_mul.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/fused_ops.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/signal/hamming_window.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/signal/hann_window.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/signal/frame.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/signal/stft.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/crop_and_resize.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/flip_left_right.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/grayscale_to_rgb.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/rotate_with_offset.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/nonmax_util.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/non_max_suppression.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_async.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score_async.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded_async.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/threshold.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/image/transform.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/linalg/band_part.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/linalg/gram_schmidt.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/linalg/qr.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/loss_ops_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/losses/absolute_difference.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/losses/huber_loss.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/losses/log_loss.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/losses/mean_squared_error.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/losses/sigmoid_cross_entropy.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/losses/softmax_cross_entropy.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_mean.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_sum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/string/string_n_grams.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/string/string_split.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/string/string_to_hash_bucket_fast.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/ops.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/serialization.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/optimizers/optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/optimizers/register_optimizers.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/io/browser_files.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/io/progress.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/io/weights_loader.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/io/http.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/io/passthrough.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/io/io.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/browser.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/slice_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/train.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/concat_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/fused_types.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/ragged_to_dense_util.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/reduce_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/rotate_util.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/array_ops_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/selu_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/erf_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/backends/complex_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/backends/einsum_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_reduction_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/segment_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/backends/backend_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/backends/kernel_impls.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/base.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/index.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/flags.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/data/compiled_api.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/custom_op/register.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/arithmetic.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/basic_math.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/control.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/convolution.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/creation.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/dynamic.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/evaluation.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/graph.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/hash_table.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/image.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/logical.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/matrices.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/normalization.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/reduction.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/slice_join.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/sparse.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/spectral.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/string.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/transformation.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/operation_mapper.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/custom_op/node_value_impl.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-core/dist/ops/ops_for_converter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/arithmetic_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/basic_math_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/tensor_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/tensor_array.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/tensor_list.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/control_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/convolution_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/creation_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/dynamic_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/evaluation_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/graph_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/hash_table.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/hash_table_executor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/image_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/logical_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/matrices_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/normalization_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/ragged_executor.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/reduction_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/slice_join_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/sparse_executor.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/spectral_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/string_executor.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/transformation_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/operation_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/model_analysis.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/graph_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/graph_model.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/version.js:
  (** @license See the LICENSE file. *)

@tensorflow/tfjs-converter/dist/index.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow-models/face-landmarks-detection/dist/face-landmarks-detection.esm.js:
  (**
      * @license
      * Copyright 2022 Google LLC. All Rights Reserved.
      * Licensed under the Apache License, Version 2.0 (the "License");
      * you may not use this file except in compliance with the License.
      * You may obtain a copy of the License at
      *
      * http://www.apache.org/licenses/LICENSE-2.0
      *
      * Unless required by applicable law or agreed to in writing, software
      * distributed under the License is distributed on an "AS IS" BASIS,
      * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      * See the License for the specific language governing permissions and
      * limitations under the License.
      * =============================================================================
      *)

@tensorflow/tfjs-backend-cpu/dist/cpu_util.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/backend_cpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Abs.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/utils/binary_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Complex.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/utils/zeros_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Identity.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Real.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Cast.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/utils/binary_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Add.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/utils/unary_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/utils/unary_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Ceil.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Concat_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Exp.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Expm1.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Floor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd_Impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Greater.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/GreaterEqual.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Less.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/LessEqual.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Log.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Max_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Maximum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Minimum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Multiply.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Neg.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/NotEqual.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Prod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Range_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Rsqrt.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Scatter_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Sigmoid.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Slice.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentReduction_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Sqrt.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SquaredDifference.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Sub.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Tile_impl.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/TopK_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Unique_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/base.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Elu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/LeakyRelu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Prelu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Relu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Relu6.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/utils/fused_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Reshape.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/BatchMatMul.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/_FusedMatMul.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Acos.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Acosh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/AddN.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/All.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Any.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/ArgMax.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/ArgMin.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Asin.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Asinh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Atan.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Atan2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Atanh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/utils/pool_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3DGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPoolGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/BatchNorm.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/BatchToSpaceND.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/BroadcastArgs.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/ClipByValue.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/ComplexAbs.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Imag.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Concat.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropFilter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropInput.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropFilterV2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropInputV2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Cos.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Cosh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/CropAndResize.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Cumprod.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Cumsum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/DenseBincount.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/DepthToSpace.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNative.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropInput.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Diag.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropFilter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropInput.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Sum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Einsum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/EluGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Erf.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/ExpandDims.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/RealDiv.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/utils/fft_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/FFT.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Fill.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/FlipLeftRight.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/FloorDiv.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/FusedConv2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/FusedDepthwiseConv2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/IFFT.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/IsFinite.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/IsInf.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/IsNaN.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Log1p.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalAnd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalNot.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalOr.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/LRN.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/LRNGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Max.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3DGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Mean.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Min.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/MirrorPad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Mod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Softmax.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Multinomial.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV3.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV4.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV5.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/OneHot.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/ZerosLike.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/OnesLike.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Pack.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/PadV2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Pow.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Range.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Reciprocal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinear.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinearGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighbor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighborGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Reverse.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/RotateWithOffset.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Round.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/ScatterNd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SearchSorted_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SearchSorted.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Select.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Selu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Sign.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Sin.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Sinh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Softplus.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SpaceToBatchND.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentMean.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentSum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseToDense.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/SplitV.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Square.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Step.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Tan.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Tanh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Tile.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/TopK.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Transform.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Unique.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/Unpack.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/kernels/UnsortedSegmentSum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/register_all_kernels.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-cpu/dist/index.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
